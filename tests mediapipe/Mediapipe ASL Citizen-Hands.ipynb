{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0db8f4",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Tests-LSTM+GRU\" data-toc-modified-id=\"Tests-LSTM+GRU-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Tests LSTM+GRU</a></span></li><li><span><a href=\"#Tests-1D-CNN\" data-toc-modified-id=\"Tests-1D-CNN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Tests 1D CNN</a></span></li><li><span><a href=\"#Hyperparameter-Tunning-3-1D-CNN-Layers\" data-toc-modified-id=\"Hyperparameter-Tunning-3-1D-CNN-Layers-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Hyperparameter Tunning 3 1D CNN Layers</a></span></li><li><span><a href=\"#Hyperparameter-Tunning-2-1D-CNN-Layers\" data-toc-modified-id=\"Hyperparameter-Tunning-2-1D-CNN-Layers-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Hyperparameter Tunning 2 1D CNN Layers</a></span></li><li><span><a href=\"#Realtime-Code-Prediction\" data-toc-modified-id=\"Realtime-Code-Prediction-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Realtime Code Prediction</a></span></li><li><span><a href=\"#Test-2-1D-CNN-Layers-+-3-GRU-Layers\" data-toc-modified-id=\"Test-2-1D-CNN-Layers-+-3-GRU-Layers-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Test 2 1D CNN Layers + 3 GRU Layers</a></span></li><li><span><a href=\"#Hyperparameter-Tunning-2-1D-CNN-Layers-+-3-GRU\" data-toc-modified-id=\"Hyperparameter-Tunning-2-1D-CNN-Layers-+-3-GRU-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Hyperparameter Tunning 2 1D CNN Layers + 3 GRU</a></span></li><li><span><a href=\"#Hyperparameter-Tuning-3-GRU-Layers\" data-toc-modified-id=\"Hyperparameter-Tuning-3-GRU-Layers-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Hyperparameter Tuning 3 GRU Layers</a></span></li><li><span><a href=\"#Hyperparameter-Tuning-3-LSTM-Layers\" data-toc-modified-id=\"Hyperparameter-Tuning-3-LSTM-Layers-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Hyperparameter Tuning 3 LSTM Layers</a></span></li><li><span><a href=\"#Hyperparameter-Tuning-4-1D-CNN-Layers\" data-toc-modified-id=\"Hyperparameter-Tuning-4-1D-CNN-Layers-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Hyperparameter Tuning 4 1D CNN Layers</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab7927e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:38:57.460006Z",
     "start_time": "2023-08-23T22:38:05.824060Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 23:38:18.600496: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-23 23:38:24.779704: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/home/kristian/miniconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fefa485b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:38:57.464637Z",
     "start_time": "2023-08-23T22:38:57.461944Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "05d07926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T19:19:39.953086Z",
     "start_time": "2023-08-22T19:19:33.295905Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture('file:///media/kristian/HDD/ASL_Citizen/ASL_Citizen/videos/876528433251724-SQUEEZE.mp4')\n",
    "\n",
    "with mp_holistic.Holistic(static_image_mode=False,\n",
    "                          model_complexity=1) as holistic:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "            \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(frame_rgb)\n",
    "        # Left hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "\n",
    "        # Right Hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3884fb03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:30.998554Z",
     "start_time": "2023-08-22T08:02:30.992693Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mediapipe.python.solution_base.SolutionOutputs"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f5879199",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:31.286656Z",
     "start_time": "2023-08-22T08:02:31.002623Z"
    }
   },
   "outputs": [],
   "source": [
    "pose = []\n",
    "for res in results.pose_landmarks.landmark:\n",
    "    test = np.array([res.x, res.y, res.z, res.visibility])\n",
    "    pose.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "85938609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:31.783097Z",
     "start_time": "2023-08-22T08:02:31.289683Z"
    }
   },
   "outputs": [],
   "source": [
    "#pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "#face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)\n",
    "lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d61e74ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:38:57.779204Z",
     "start_time": "2023-08-23T22:38:57.466054Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "#    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "#    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b7a805c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:32.295871Z",
     "start_time": "2023-08-22T08:02:32.065429Z"
    }
   },
   "outputs": [],
   "source": [
    "result_test = extract_keypoints(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "96d95912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:32.525468Z",
     "start_time": "2023-08-22T08:02:32.299735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8fb31b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:38:58.159544Z",
     "start_time": "2023-08-23T22:38:57.781366Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def signvideodataframe(filepath):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # Define the path to the videos directory\n",
    "    path = 'file:///media/kristian/HDD/ASL_Citizen/ASL_Citizen/videos/'\n",
    "\n",
    "    # Create a 'Path' column by concatenating the path with 'Video file' column\n",
    "    df['Path'] = path + df['Video file']\n",
    "    \n",
    "    # Calculate the frequency of each gloss and create a 'frequency' column\n",
    "    df['Frequency'] = df['Gloss'].map(df['Gloss'].value_counts())\n",
    "\n",
    "    # Sort the DataFrame by the 'Gloss' column\n",
    "    df = df.sort_values(by='Gloss')\n",
    "\n",
    "    # Reset the index of the DataFrame\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c90d3d92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:01.986948Z",
     "start_time": "2023-08-23T22:38:58.160938Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "traindf = signvideodataframe('file:///media/kristian/HDD/ASL_Citizen/ASL_Citizen/splits/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea9e1a27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:02.252374Z",
     "start_time": "2023-08-23T22:39:01.988230Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P31</td>\n",
       "      <td>3827306090663467-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P37</td>\n",
       "      <td>16792698524451422-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P11</td>\n",
       "      <td>6868778695018762-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P11</td>\n",
       "      <td>6870709051348651-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P50</td>\n",
       "      <td>0719792557216079-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                      Video file    Gloss ASL-LEX Code  \\\n",
       "0            P31   3827306090663467-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "1            P37  16792698524451422-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "2            P11   6868778695018762-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "3            P11   6870709051348651-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "4            P50   0719792557216079-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "\n",
       "                                                Path  Frequency  \n",
       "0  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "1  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "2  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "3  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "4  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bdd5fc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:02.501990Z",
     "start_time": "2023-08-23T22:39:02.253794Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40149</th>\n",
       "      <td>P37</td>\n",
       "      <td>9716493262876276-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40150</th>\n",
       "      <td>P31</td>\n",
       "      <td>7550572181460327-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40151</th>\n",
       "      <td>P46</td>\n",
       "      <td>47985881750082227-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40152</th>\n",
       "      <td>P50</td>\n",
       "      <td>04671245574824856-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40153</th>\n",
       "      <td>P51</td>\n",
       "      <td>19959052532136146-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant ID                      Video file    Gloss ASL-LEX Code  \\\n",
       "40149            P37   9716493262876276-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "40150            P31   7550572181460327-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "40151            P46  47985881750082227-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "40152            P50  04671245574824856-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "40153            P51  19959052532136146-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "\n",
       "                                                    Path  Frequency  \n",
       "40149  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "40150  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "40151  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "40152  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "40153  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "095e54bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:02.678463Z",
     "start_time": "2023-08-23T22:39:02.503356Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///media/kristian/HDD/ASL_Citizen/ASL_Citizen/videos/3827306090663467-1 DOLLAR.mp4'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf['Path'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d581c72d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:38.994712Z",
     "start_time": "2023-08-22T08:02:34.225604Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(traindf['Path'][0])\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(static_image_mode=False,\n",
    "                          model_complexity=1) as holistic:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(frame_rgb)\n",
    "        # Left hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "\n",
    "        # Right Hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7e7c3bde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:39.025718Z",
     "start_time": "2023-08-22T08:02:38.999520Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3028</th>\n",
       "      <td>P37</td>\n",
       "      <td>41775128552545326-BIRTHDAY.mp4</td>\n",
       "      <td>BIRTHDAY</td>\n",
       "      <td>D_01_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31945</th>\n",
       "      <td>P11</td>\n",
       "      <td>4196732067344118-SNAIL.mp4</td>\n",
       "      <td>SNAIL</td>\n",
       "      <td>G_01_067</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8896</th>\n",
       "      <td>P29</td>\n",
       "      <td>36433499886746423-DELEGATE.mp4</td>\n",
       "      <td>DELEGATE</td>\n",
       "      <td>H_03_001</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4777</th>\n",
       "      <td>P31</td>\n",
       "      <td>4634164353032284-CAKE.mp4</td>\n",
       "      <td>CAKE</td>\n",
       "      <td>D_01_033</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24376</th>\n",
       "      <td>P16</td>\n",
       "      <td>8628112408945923-OUTSIDE.mp4</td>\n",
       "      <td>OUTSIDE</td>\n",
       "      <td>E_03_071</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37902</th>\n",
       "      <td>P33</td>\n",
       "      <td>6353213788072032-VISITOR.mp4</td>\n",
       "      <td>VISITOR</td>\n",
       "      <td>J_01_097</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25118</th>\n",
       "      <td>P31</td>\n",
       "      <td>47043528831020653-PEEKABOO.mp4</td>\n",
       "      <td>PEEKABOO</td>\n",
       "      <td>E_02_026</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10473</th>\n",
       "      <td>P11</td>\n",
       "      <td>03909923207087029-DROP.mp4</td>\n",
       "      <td>DROP</td>\n",
       "      <td>C_03_052</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>P11</td>\n",
       "      <td>08568928378144558-BLINDS 2.mp4</td>\n",
       "      <td>BLINDS2</td>\n",
       "      <td>C_03_014</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35647</th>\n",
       "      <td>P33</td>\n",
       "      <td>6089188553523701-THINK CONNECT.mp4</td>\n",
       "      <td>THINKCONNECT</td>\n",
       "      <td>F_02_087</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18170</th>\n",
       "      <td>P31</td>\n",
       "      <td>8838800216414398-INSTAGRAM.mp4</td>\n",
       "      <td>INSTAGRAM</td>\n",
       "      <td>H_03_083</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9308</th>\n",
       "      <td>P50</td>\n",
       "      <td>42389735718505683-DIE.mp4</td>\n",
       "      <td>DIE</td>\n",
       "      <td>D_02_021</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22316</th>\n",
       "      <td>P50</td>\n",
       "      <td>7301914301807739-MOOSE.mp4</td>\n",
       "      <td>MOOSE</td>\n",
       "      <td>G_02_100</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14176</th>\n",
       "      <td>P29</td>\n",
       "      <td>3580101100770956-FROWN 1.mp4</td>\n",
       "      <td>FROWN2</td>\n",
       "      <td>F_02_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14626</th>\n",
       "      <td>P16</td>\n",
       "      <td>11282680563352021-GIFT.mp4</td>\n",
       "      <td>GIFT</td>\n",
       "      <td>E_01_055</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6935</th>\n",
       "      <td>P43</td>\n",
       "      <td>40787792317728133-CLUELESS.mp4</td>\n",
       "      <td>CLUELESS</td>\n",
       "      <td>F_03_082</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4654</th>\n",
       "      <td>P36</td>\n",
       "      <td>9465545544870055-BUT.mp4</td>\n",
       "      <td>BUT</td>\n",
       "      <td>D_03_030</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26416</th>\n",
       "      <td>P14</td>\n",
       "      <td>32457509805548823-POLE.mp4</td>\n",
       "      <td>POLE</td>\n",
       "      <td>H_02_014</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31923</th>\n",
       "      <td>P33</td>\n",
       "      <td>15145860097068975-SMOOTH.mp4</td>\n",
       "      <td>SMOOTH</td>\n",
       "      <td>H_02_101</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18997</th>\n",
       "      <td>P27</td>\n",
       "      <td>32706911002955863-KEEP.mp4</td>\n",
       "      <td>KEEP</td>\n",
       "      <td>H_03_005</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant ID                          Video file         Gloss  \\\n",
       "3028             P37      41775128552545326-BIRTHDAY.mp4      BIRTHDAY   \n",
       "31945            P11          4196732067344118-SNAIL.mp4         SNAIL   \n",
       "8896             P29      36433499886746423-DELEGATE.mp4      DELEGATE   \n",
       "4777             P31           4634164353032284-CAKE.mp4          CAKE   \n",
       "24376            P16        8628112408945923-OUTSIDE.mp4       OUTSIDE   \n",
       "37902            P33        6353213788072032-VISITOR.mp4       VISITOR   \n",
       "25118            P31      47043528831020653-PEEKABOO.mp4      PEEKABOO   \n",
       "10473            P11          03909923207087029-DROP.mp4          DROP   \n",
       "3262             P11      08568928378144558-BLINDS 2.mp4       BLINDS2   \n",
       "35647            P33  6089188553523701-THINK CONNECT.mp4  THINKCONNECT   \n",
       "18170            P31      8838800216414398-INSTAGRAM.mp4     INSTAGRAM   \n",
       "9308             P50           42389735718505683-DIE.mp4           DIE   \n",
       "22316            P50          7301914301807739-MOOSE.mp4         MOOSE   \n",
       "14176            P29        3580101100770956-FROWN 1.mp4        FROWN2   \n",
       "14626            P16          11282680563352021-GIFT.mp4          GIFT   \n",
       "6935             P43      40787792317728133-CLUELESS.mp4      CLUELESS   \n",
       "4654             P36            9465545544870055-BUT.mp4           BUT   \n",
       "26416            P14          32457509805548823-POLE.mp4          POLE   \n",
       "31923            P33        15145860097068975-SMOOTH.mp4        SMOOTH   \n",
       "18997            P27          32706911002955863-KEEP.mp4          KEEP   \n",
       "\n",
       "      ASL-LEX Code                                               Path  \\\n",
       "3028      D_01_054  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "31945     G_01_067  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "8896      H_03_001  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "4777      D_01_033  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "24376     E_03_071  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "37902     J_01_097  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "25118     E_02_026  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "10473     C_03_052  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "3262      C_03_014  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "35647     F_02_087  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "18170     H_03_083  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "9308      D_02_021  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "22316     G_02_100  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "14176     F_02_057  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "14626     E_01_055  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "6935      F_03_082  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "4654      D_03_030  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "26416     H_02_014  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "31923     H_02_101  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "18997     H_03_005  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "\n",
       "       Frequency  \n",
       "3028          15  \n",
       "31945         14  \n",
       "8896          15  \n",
       "4777          16  \n",
       "24376         15  \n",
       "37902         15  \n",
       "25118         17  \n",
       "10473         15  \n",
       "3262          16  \n",
       "35647         14  \n",
       "18170         14  \n",
       "9308          13  \n",
       "22316         14  \n",
       "14176         13  \n",
       "14626         16  \n",
       "6935          13  \n",
       "4654          15  \n",
       "26416         15  \n",
       "31923         16  \n",
       "18997         14  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cf42e5e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:39.386183Z",
     "start_time": "2023-08-22T08:02:39.029816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40154.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.819893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.317383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Frequency\n",
       "count  40154.000000\n",
       "mean      14.819893\n",
       "std        1.317383\n",
       "min        9.000000\n",
       "25%       14.000000\n",
       "50%       15.000000\n",
       "75%       16.000000\n",
       "max       24.000000"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4fb53ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:03.034407Z",
     "start_time": "2023-08-23T22:39:02.679775Z"
    },
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gloss</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOG1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HURDLE/TRIP1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BITE1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREAKFAST1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEMAND1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DARK1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MECHANIC1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARTY1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DECIDE1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ROCKINGCHAIR1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DEAF1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EDIT1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DEVELOP1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RIVER1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FINE1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ELEVATOR1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BELT1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AXE1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BACKPACK1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SHAVE1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CHRISTMAS1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BEE1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PATIENT2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BASKETBALL1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NOON1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HALLOWEEN1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LUNCH1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>EAT1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TWINS1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CANCER1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DINNER1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CONFUSED1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RAZOR2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>MEAT1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SQUEEZE</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>MICROSCOPE1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DRAG1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>THEY1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SINK</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MOVIE1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FLOAT1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>LOCK1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DOWNSIZE1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>GUESS1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>KNIGHT1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>JEWELRY</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>MAPLE</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FOREIGNER1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>HOSPITAL1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Gloss  Frequency\n",
       "0            DOG1         24\n",
       "1    HURDLE/TRIP1         22\n",
       "2           BITE1         21\n",
       "3      BREAKFAST1         21\n",
       "4         DEMAND1         21\n",
       "5           DARK1         21\n",
       "6       MECHANIC1         20\n",
       "7          PARTY1         20\n",
       "8         DECIDE1         20\n",
       "9        WHATFOR1         20\n",
       "10  ROCKINGCHAIR1         20\n",
       "11          DEAF1         20\n",
       "12          EDIT1         19\n",
       "13       DEVELOP1         19\n",
       "14         RIVER1         19\n",
       "15          FINE1         19\n",
       "16      ELEVATOR1         19\n",
       "17          BELT1         19\n",
       "18           AXE1         19\n",
       "19      BACKPACK1         19\n",
       "20         SHAVE1         19\n",
       "21     CHRISTMAS1         19\n",
       "22           BEE1         19\n",
       "23       PATIENT2         19\n",
       "24    BASKETBALL1         19\n",
       "25          NOON1         19\n",
       "26     HALLOWEEN1         19\n",
       "27         LUNCH1         19\n",
       "28           EAT1         18\n",
       "29         TWINS1         18\n",
       "30        CANCER1         18\n",
       "31        DINNER1         18\n",
       "32      CONFUSED1         18\n",
       "33         RAZOR2         18\n",
       "34          MEAT1         18\n",
       "35        SQUEEZE         18\n",
       "36    MICROSCOPE1         18\n",
       "37          DRAG1         18\n",
       "38          THEY1         18\n",
       "39           SINK         18\n",
       "40         MOVIE1         18\n",
       "41         FLOAT1         18\n",
       "42          LOCK1         18\n",
       "43      DOWNSIZE1         18\n",
       "44         GUESS1         18\n",
       "45        KNIGHT1         18\n",
       "46        JEWELRY         18\n",
       "47          MAPLE         18\n",
       "48     FOREIGNER1         18\n",
       "49      HOSPITAL1         18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = traindf.groupby(['Gloss'], sort=True)['Frequency'].count().sort_values(ascending=False).reset_index()\n",
    "words.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "52c86c92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:39.806739Z",
     "start_time": "2023-08-22T08:02:39.561071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "Frequency=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "rgb(127,39,4)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          24,
          22,
          21,
          21,
          21,
          21,
          20,
          20,
          20,
          20,
          20,
          20,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          9,
          9,
          9
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Frequency Data Distribution In Training Dataframe"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Frequency"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"53b29a31-4fda-4a54-bb9c-625468b0b53d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"53b29a31-4fda-4a54-bb9c-625468b0b53d\")) {                    Plotly.newPlot(                        \"53b29a31-4fda-4a54-bb9c-625468b0b53d\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"Frequency=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"rgb(127,39,4)\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[24,22,21,21,21,21,20,20,20,20,20,20,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,9,9,9],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Frequency\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Frequency Data Distribution In Training Dataframe\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('53b29a31-4fda-4a54-bb9c-625468b0b53d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(words,\n",
    "                    x='Frequency',\n",
    "                    color_discrete_sequence=px.colors.sequential.Oranges_r,\n",
    "                    title='Frequency Data Distribution In Training Dataframe')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "980e9aca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:03.208962Z",
     "start_time": "2023-08-23T22:39:03.037309Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "traindf = traindf[traindf['Gloss'].isin(words.Gloss.head(50))]\n",
    "traindf=traindf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e3da8550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:40.366359Z",
     "start_time": "2023-08-22T08:02:40.009127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P52</td>\n",
       "      <td>07157565148825373-seedAXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P28</td>\n",
       "      <td>7179300005186042-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P29</td>\n",
       "      <td>16216064841959765-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P37</td>\n",
       "      <td>6193814382865199-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P40</td>\n",
       "      <td>5947453960317015-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                     Video file Gloss ASL-LEX Code  \\\n",
       "0            P52  07157565148825373-seedAXE.mp4  AXE1     G_03_066   \n",
       "1            P28       7179300005186042-AXE.mp4  AXE1     G_03_066   \n",
       "2            P29      16216064841959765-AXE.mp4  AXE1     G_03_066   \n",
       "3            P37       6193814382865199-AXE.mp4  AXE1     G_03_066   \n",
       "4            P40       5947453960317015-AXE.mp4  AXE1     G_03_066   \n",
       "\n",
       "                                                Path  Frequency  \n",
       "0  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         19  \n",
       "1  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         19  \n",
       "2  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         19  \n",
       "3  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         19  \n",
       "4  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         19  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "98e78fd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:40.602173Z",
     "start_time": "2023-08-22T08:02:40.369818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>P50</td>\n",
       "      <td>9161417844146778-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>P14</td>\n",
       "      <td>00930662603221255-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>P27</td>\n",
       "      <td>82063651021682-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>P40</td>\n",
       "      <td>5268072837528903-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>P40</td>\n",
       "      <td>6363286086951516-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Participant ID                      Video file     Gloss ASL-LEX Code  \\\n",
       "945            P50   9161417844146778-WHAT FOR.mp4  WHATFOR1     C_02_054   \n",
       "946            P14  00930662603221255-WHAT FOR.mp4  WHATFOR1     C_02_054   \n",
       "947            P27     82063651021682-WHAT FOR.mp4  WHATFOR1     C_02_054   \n",
       "948            P40   5268072837528903-WHAT FOR.mp4  WHATFOR1     C_02_054   \n",
       "949            P40   6363286086951516-WHAT FOR.mp4  WHATFOR1     C_02_054   \n",
       "\n",
       "                                                  Path  Frequency  \n",
       "945  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         20  \n",
       "946  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         20  \n",
       "947  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         20  \n",
       "948  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         20  \n",
       "949  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         20  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "154ec9d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:40.844096Z",
     "start_time": "2023-08-22T08:02:40.604266Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gloss</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOG1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HURDLE/TRIP1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DARK1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BITE1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BREAKFAST1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DEMAND1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DEAF1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MECHANIC1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DECIDE1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PARTY1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ROCKINGCHAIR1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ELEVATOR1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NOON1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PATIENT2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RIVER1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LUNCH1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SHAVE1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HALLOWEEN1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BACKPACK1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FINE1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AXE1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>EDIT1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BASKETBALL1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BEE1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BELT1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CHRISTMAS1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DEVELOP1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MOVIE1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TWINS1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>THEY1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SQUEEZE</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SINK</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RAZOR2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CANCER1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>CONFUSED1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>MICROSCOPE1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>FLOAT1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>MEAT1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MAPLE</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DINNER1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>LOCK1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>KNIGHT1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>JEWELRY</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DOWNSIZE1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>HOSPITAL1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>DRAG1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>EAT1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FOREIGNER1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>GUESS1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Gloss  Frequency\n",
       "0            DOG1         24\n",
       "1    HURDLE/TRIP1         22\n",
       "2           DARK1         21\n",
       "3           BITE1         21\n",
       "4      BREAKFAST1         21\n",
       "5         DEMAND1         21\n",
       "6           DEAF1         20\n",
       "7       MECHANIC1         20\n",
       "8         DECIDE1         20\n",
       "9        WHATFOR1         20\n",
       "10         PARTY1         20\n",
       "11  ROCKINGCHAIR1         20\n",
       "12      ELEVATOR1         19\n",
       "13          NOON1         19\n",
       "14       PATIENT2         19\n",
       "15         RIVER1         19\n",
       "16         LUNCH1         19\n",
       "17         SHAVE1         19\n",
       "18     HALLOWEEN1         19\n",
       "19      BACKPACK1         19\n",
       "20          FINE1         19\n",
       "21           AXE1         19\n",
       "22          EDIT1         19\n",
       "23    BASKETBALL1         19\n",
       "24           BEE1         19\n",
       "25          BELT1         19\n",
       "26     CHRISTMAS1         19\n",
       "27       DEVELOP1         19\n",
       "28         MOVIE1         18\n",
       "29         TWINS1         18\n",
       "30          THEY1         18\n",
       "31        SQUEEZE         18\n",
       "32           SINK         18\n",
       "33         RAZOR2         18\n",
       "34        CANCER1         18\n",
       "35      CONFUSED1         18\n",
       "36    MICROSCOPE1         18\n",
       "37         FLOAT1         18\n",
       "38          MEAT1         18\n",
       "39          MAPLE         18\n",
       "40        DINNER1         18\n",
       "41          LOCK1         18\n",
       "42        KNIGHT1         18\n",
       "43        JEWELRY         18\n",
       "44      DOWNSIZE1         18\n",
       "45      HOSPITAL1         18\n",
       "46          DRAG1         18\n",
       "47           EAT1         18\n",
       "48     FOREIGNER1         18\n",
       "49         GUESS1         18"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = traindf.groupby(['Gloss'], sort=True)['Frequency'].count().sort_values(ascending=False).reset_index()\n",
    "words.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e156e7aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:41.147505Z",
     "start_time": "2023-08-22T08:02:40.846275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "Frequency=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "rgb(127,39,4)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          24,
          22,
          21,
          21,
          21,
          21,
          20,
          20,
          20,
          20,
          20,
          20,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Frequency Data Distribution In Training Dataframe Top 50 Words"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Frequency"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"922f4eca-975d-40c3-9c43-2148a2a29241\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"922f4eca-975d-40c3-9c43-2148a2a29241\")) {                    Plotly.newPlot(                        \"922f4eca-975d-40c3-9c43-2148a2a29241\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"Frequency=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"rgb(127,39,4)\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[24,22,21,21,21,21,20,20,20,20,20,20,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Frequency\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Frequency Data Distribution In Training Dataframe Top 50 Words\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('922f4eca-975d-40c3-9c43-2148a2a29241');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(words,\n",
    "                    x='Frequency',\n",
    "                    color_discrete_sequence=px.colors.sequential.Oranges_r,\n",
    "                    title='Frequency Data Distribution In Training Dataframe Top 50 Words')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c1d6fcb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:41.475339Z",
     "start_time": "2023-08-22T08:02:41.150591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.082105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.316026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Frequency\n",
       "count  950.000000\n",
       "mean    19.082105\n",
       "std      1.316026\n",
       "min     18.000000\n",
       "25%     18.000000\n",
       "50%     19.000000\n",
       "75%     20.000000\n",
       "max     24.000000"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "90a5583a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:41.704643Z",
     "start_time": "2023-08-22T08:02:41.477427Z"
    }
   },
   "outputs": [],
   "source": [
    "#traindf['Gloss'] = traindf['Gloss'].str.replace('\\d+', '',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "17318e0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:41.925211Z",
     "start_time": "2023-08-22T08:02:41.707099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf['Gloss'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2e7f4f27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:42.145469Z",
     "start_time": "2023-08-22T08:02:41.927789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AXE1', 'BACKPACK1', 'BASKETBALL1', 'BEE1', 'BELT1', 'BITE1',\n",
       "       'BREAKFAST1', 'CANCER1', 'CHRISTMAS1', 'CONFUSED1', 'DARK1',\n",
       "       'DEAF1', 'DECIDE1', 'DEMAND1', 'DEVELOP1', 'DINNER1', 'DOG1',\n",
       "       'DOWNSIZE1', 'DRAG1', 'EAT1', 'EDIT1', 'ELEVATOR1', 'FINE1',\n",
       "       'FLOAT1', 'FOREIGNER1', 'GUESS1', 'HALLOWEEN1', 'HOSPITAL1',\n",
       "       'HURDLE/TRIP1', 'JEWELRY', 'KNIGHT1', 'LOCK1', 'LUNCH1', 'MAPLE',\n",
       "       'MEAT1', 'MECHANIC1', 'MICROSCOPE1', 'MOVIE1', 'NOON1', 'PARTY1',\n",
       "       'PATIENT2', 'RAZOR2', 'RIVER1', 'ROCKINGCHAIR1', 'SHAVE1', 'SINK',\n",
       "       'SQUEEZE', 'THEY1', 'TWINS1', 'WHATFOR1'], dtype=object)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = traindf['Gloss'].unique()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c400650b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:42.409657Z",
     "start_time": "2023-08-22T08:02:42.155288Z"
    }
   },
   "outputs": [],
   "source": [
    "valdf = signvideodataframe('file:///media/kristian/HDD/ASL_Citizen/ASL_Citizen/splits/val.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8c148709",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:42.595152Z",
     "start_time": "2023-08-22T08:02:42.412175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P26</td>\n",
       "      <td>22595012150860327-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P39</td>\n",
       "      <td>7421622940519235-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P21</td>\n",
       "      <td>686738356933241-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P12</td>\n",
       "      <td>9219095671540121-5 DOLLARS.mp4</td>\n",
       "      <td>5DOLLARS</td>\n",
       "      <td>B_01_062</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P21</td>\n",
       "      <td>1448188216215387-5 DOLLARS.mp4</td>\n",
       "      <td>5DOLLARS</td>\n",
       "      <td>B_01_062</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                      Video file     Gloss ASL-LEX Code  \\\n",
       "0            P26  22595012150860327-1 DOLLAR.mp4   1DOLLAR     C_02_025   \n",
       "1            P39   7421622940519235-1 DOLLAR.mp4   1DOLLAR     C_02_025   \n",
       "2            P21    686738356933241-1 DOLLAR.mp4   1DOLLAR     C_02_025   \n",
       "3            P12  9219095671540121-5 DOLLARS.mp4  5DOLLARS     B_01_062   \n",
       "4            P21  1448188216215387-5 DOLLARS.mp4  5DOLLARS     B_01_062   \n",
       "\n",
       "                                                Path  Frequency  \n",
       "0  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          3  \n",
       "1  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          3  \n",
       "2  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          3  \n",
       "3  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4  \n",
       "4  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ec2b183e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:42.825410Z",
     "start_time": "2023-08-22T08:02:42.596789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10299</th>\n",
       "      <td>P21</td>\n",
       "      <td>6959326205750493-ZOOM IN.mp4</td>\n",
       "      <td>ZOOMIN</td>\n",
       "      <td>B_02_056</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10300</th>\n",
       "      <td>P12</td>\n",
       "      <td>7758716133684984-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10301</th>\n",
       "      <td>P39</td>\n",
       "      <td>844134294032034-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>P21</td>\n",
       "      <td>5548062993721732-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10303</th>\n",
       "      <td>P26</td>\n",
       "      <td>19366754134806952-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant ID                      Video file    Gloss ASL-LEX Code  \\\n",
       "10299            P21    6959326205750493-ZOOM IN.mp4   ZOOMIN     B_02_056   \n",
       "10300            P12   7758716133684984-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "10301            P39    844134294032034-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "10302            P21   5548062993721732-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "10303            P26  19366754134806952-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "\n",
       "                                                    Path  Frequency  \n",
       "10299  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          3  \n",
       "10300  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4  \n",
       "10301  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4  \n",
       "10302  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4  \n",
       "10303  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b1578a6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:43.168064Z",
     "start_time": "2023-08-22T08:02:42.827726Z"
    }
   },
   "outputs": [],
   "source": [
    "testdf = signvideodataframe('file:///media/kristian/HDD/ASL_Citizen/ASL_Citizen/splits/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2a22044f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:43.276478Z",
     "start_time": "2023-08-22T08:02:43.171172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P18</td>\n",
       "      <td>23521769221811684-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P42</td>\n",
       "      <td>023931338852502426-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P49</td>\n",
       "      <td>4893817008748198-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P17</td>\n",
       "      <td>13991818149960333-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P49</td>\n",
       "      <td>34625615110480457-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                       Video file    Gloss ASL-LEX Code  \\\n",
       "0            P18   23521769221811684-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "1            P42  023931338852502426-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "2            P49    4893817008748198-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "3            P17   13991818149960333-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "4            P49   34625615110480457-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "\n",
       "                                                Path  Frequency  \n",
       "0  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  \n",
       "1  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  \n",
       "2  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  \n",
       "3  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  \n",
       "4  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0a4cd28e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:43.865688Z",
     "start_time": "2023-08-22T08:02:43.279626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32936</th>\n",
       "      <td>P18</td>\n",
       "      <td>4320702510886756-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32937</th>\n",
       "      <td>P9</td>\n",
       "      <td>7676354653247301-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32938</th>\n",
       "      <td>P47</td>\n",
       "      <td>5386272465310649-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32939</th>\n",
       "      <td>P18</td>\n",
       "      <td>738440364224181-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32940</th>\n",
       "      <td>P17</td>\n",
       "      <td>9953298353288469-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant ID                     Video file    Gloss ASL-LEX Code  \\\n",
       "32936            P18  4320702510886756-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "32937             P9  7676354653247301-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "32938            P47  5386272465310649-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "32939            P18   738440364224181-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "32940            P17  9953298353288469-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "\n",
       "                                                    Path  Frequency  \n",
       "32936  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  \n",
       "32937  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  \n",
       "32938  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  \n",
       "32939  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  \n",
       "32940  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2e9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "309b17ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:44.385265Z",
     "start_time": "2023-08-22T08:02:43.867997Z"
    }
   },
   "outputs": [],
   "source": [
    "valdf = valdf[valdf['Gloss'].isin(words)]\n",
    "valdf = valdf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "17c21f12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:44.622174Z",
     "start_time": "2023-08-22T08:02:44.387812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P39</td>\n",
       "      <td>19778675091674147-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P26</td>\n",
       "      <td>8581142177964065-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P39</td>\n",
       "      <td>3877478645046861-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P21</td>\n",
       "      <td>8521417940364975-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P5</td>\n",
       "      <td>9990244640190733-BACKPACK.mp4</td>\n",
       "      <td>BACKPACK1</td>\n",
       "      <td>G_03_091</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                     Video file      Gloss ASL-LEX Code  \\\n",
       "0            P39      19778675091674147-AXE.mp4       AXE1     G_03_066   \n",
       "1            P26       8581142177964065-AXE.mp4       AXE1     G_03_066   \n",
       "2            P39       3877478645046861-AXE.mp4       AXE1     G_03_066   \n",
       "3            P21       8521417940364975-AXE.mp4       AXE1     G_03_066   \n",
       "4             P5  9990244640190733-BACKPACK.mp4  BACKPACK1     G_03_091   \n",
       "\n",
       "                                                Path  Frequency  \n",
       "0  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4  \n",
       "1  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4  \n",
       "2  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4  \n",
       "3  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4  \n",
       "4  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          3  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bc330590",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:44.859766Z",
     "start_time": "2023-08-22T08:02:44.625070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>P26</td>\n",
       "      <td>032677896012150764-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>P5</td>\n",
       "      <td>6523145816470133-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>P39</td>\n",
       "      <td>0283886564670357-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>P21</td>\n",
       "      <td>6142521746642153-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>P12</td>\n",
       "      <td>06408604416165864-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Participant ID                       Video file     Gloss ASL-LEX Code  \\\n",
       "186            P26  032677896012150764-WHAT FOR.mp4  WHATFOR1     C_02_054   \n",
       "187             P5    6523145816470133-WHAT FOR.mp4  WHATFOR1     C_02_054   \n",
       "188            P39    0283886564670357-WHAT FOR.mp4  WHATFOR1     C_02_054   \n",
       "189            P21    6142521746642153-WHAT FOR.mp4  WHATFOR1     C_02_054   \n",
       "190            P12   06408604416165864-WHAT FOR.mp4  WHATFOR1     C_02_054   \n",
       "\n",
       "                                                  Path  Frequency  \n",
       "186  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          5  \n",
       "187  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          5  \n",
       "188  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          5  \n",
       "189  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          5  \n",
       "190  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          5  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0182060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T13:08:33.954653Z",
     "start_time": "2023-08-04T13:08:33.951157Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d4dac473",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:45.036455Z",
     "start_time": "2023-08-22T08:02:44.862434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf['Gloss'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "252e3a11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:45.271690Z",
     "start_time": "2023-08-22T08:02:45.038816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.963351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.770316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Frequency\n",
       "count  191.000000\n",
       "mean     3.963351\n",
       "std      0.770316\n",
       "min      3.000000\n",
       "25%      3.000000\n",
       "50%      4.000000\n",
       "75%      4.000000\n",
       "max      6.000000"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a1bab0d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:45.498891Z",
     "start_time": "2023-08-22T08:02:45.273950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P39</td>\n",
       "      <td>19778675091674147-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P26</td>\n",
       "      <td>8581142177964065-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P39</td>\n",
       "      <td>3877478645046861-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P21</td>\n",
       "      <td>8521417940364975-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P5</td>\n",
       "      <td>9990244640190733-BACKPACK.mp4</td>\n",
       "      <td>BACKPACK1</td>\n",
       "      <td>G_03_091</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                     Video file      Gloss ASL-LEX Code  \\\n",
       "0            P39      19778675091674147-AXE.mp4       AXE1     G_03_066   \n",
       "1            P26       8581142177964065-AXE.mp4       AXE1     G_03_066   \n",
       "2            P39       3877478645046861-AXE.mp4       AXE1     G_03_066   \n",
       "3            P21       8521417940364975-AXE.mp4       AXE1     G_03_066   \n",
       "4             P5  9990244640190733-BACKPACK.mp4  BACKPACK1     G_03_091   \n",
       "\n",
       "                                                Path  Frequency  \n",
       "0  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4  \n",
       "1  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4  \n",
       "2  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4  \n",
       "3  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4  \n",
       "4  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          3  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b643e16a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:45.783285Z",
     "start_time": "2023-08-22T08:02:45.501476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "Frequency=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "rgb(127,39,4)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          6,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Frequency Data Distribution In Validation Dataframe Top 50 Words"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Frequency"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"b2506a29-04a4-46fb-9de4-64d81c9caae3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b2506a29-04a4-46fb-9de4-64d81c9caae3\")) {                    Plotly.newPlot(                        \"b2506a29-04a4-46fb-9de4-64d81c9caae3\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"Frequency=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"rgb(127,39,4)\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[6,5,5,5,5,5,5,5,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Frequency\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Frequency Data Distribution In Validation Dataframe Top 50 Words\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('b2506a29-04a4-46fb-9de4-64d81c9caae3');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.histogram(valdf.groupby(['Gloss'], sort=True)['Frequency'].count().sort_values(ascending=False).reset_index(),\n",
    "                    x='Frequency',\n",
    "                    color_discrete_sequence=px.colors.sequential.Oranges_r,\n",
    "                    title='Frequency Data Distribution In Validation Dataframe Top 50 Words')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "34fb9081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:46.033133Z",
     "start_time": "2023-08-22T08:02:45.785894Z"
    }
   },
   "outputs": [],
   "source": [
    "testdf = testdf[testdf['Gloss'].isin(words)]\n",
    "testdf = testdf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ca06885e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:46.283434Z",
     "start_time": "2023-08-22T08:02:46.035490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf['Gloss'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "da2567e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:46.518201Z",
     "start_time": "2023-08-22T08:02:46.285397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P15</td>\n",
       "      <td>33721516025652254-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P47</td>\n",
       "      <td>519067006979435-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P35</td>\n",
       "      <td>5104381603195376-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P42</td>\n",
       "      <td>44458614013793873-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P42</td>\n",
       "      <td>9604797909481075-AXE.mp4</td>\n",
       "      <td>AXE1</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                 Video file Gloss ASL-LEX Code  \\\n",
       "0            P15  33721516025652254-AXE.mp4  AXE1     G_03_066   \n",
       "1            P47    519067006979435-AXE.mp4  AXE1     G_03_066   \n",
       "2            P35   5104381603195376-AXE.mp4  AXE1     G_03_066   \n",
       "3            P42  44458614013793873-AXE.mp4  AXE1     G_03_066   \n",
       "4            P42   9604797909481075-AXE.mp4  AXE1     G_03_066   \n",
       "\n",
       "                                                Path  Frequency  \n",
       "0  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "1  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "2  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "3  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "4  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3282f968",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:46.838545Z",
     "start_time": "2023-08-22T08:02:46.520248Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>P42</td>\n",
       "      <td>3448123355846451-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>P47</td>\n",
       "      <td>034046510887022485-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>P22</td>\n",
       "      <td>9359050586202402-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>P42</td>\n",
       "      <td>2748457214117681-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>P15</td>\n",
       "      <td>540014801916062-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR1</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Participant ID                       Video file     Gloss ASL-LEX Code  \\\n",
       "724            P42    3448123355846451-WHAT FOR.mp4  WHATFOR1     C_02_054   \n",
       "725            P47  034046510887022485-WHAT FOR.mp4  WHATFOR1     C_02_054   \n",
       "726            P22    9359050586202402-WHAT FOR.mp4  WHATFOR1     C_02_054   \n",
       "727            P42    2748457214117681-WHAT FOR.mp4  WHATFOR1     C_02_054   \n",
       "728            P15     540014801916062-WHAT FOR.mp4  WHATFOR1     C_02_054   \n",
       "\n",
       "                                                  Path  Frequency  \n",
       "724  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         18  \n",
       "725  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         18  \n",
       "726  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         18  \n",
       "727  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         18  \n",
       "728  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         18  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "71973869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:47.067464Z",
     "start_time": "2023-08-22T08:02:46.840643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>729.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.978052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.229192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Frequency\n",
       "count  729.000000\n",
       "mean    14.978052\n",
       "std      2.229192\n",
       "min      9.000000\n",
       "25%     14.000000\n",
       "50%     15.000000\n",
       "75%     16.000000\n",
       "max     20.000000"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "98bd8020",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:47.626743Z",
     "start_time": "2023-08-22T08:02:47.070192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "Frequency=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "rgb(127,39,4)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "nbinsx": 20,
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          20,
          18,
          18,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          16,
          16,
          16,
          16,
          16,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          13,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          9
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Frequency Data Distribution In Test Dataframe Top 50 Words"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Frequency"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"e4505bf1-8b54-45af-a737-43be557c6006\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e4505bf1-8b54-45af-a737-43be557c6006\")) {                    Plotly.newPlot(                        \"e4505bf1-8b54-45af-a737-43be557c6006\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"Frequency=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"rgb(127,39,4)\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"nbinsx\":20,\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[20,18,18,17,17,17,17,17,17,17,16,16,16,16,16,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,14,14,14,14,14,14,14,14,13,10,10,10,10,10,10,10,9],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Frequency\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Frequency Data Distribution In Test Dataframe Top 50 Words\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e4505bf1-8b54-45af-a737-43be557c6006');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.histogram(testdf.groupby(['Gloss'], sort=True)['Frequency'].count().sort_values(ascending=False).reset_index(),\n",
    "                    x='Frequency',\n",
    "                    color_discrete_sequence=px.colors.sequential.Oranges_r,\n",
    "                    title='Frequency Data Distribution In Test Dataframe Top 50 Words', nbins=20)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6afdda5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:48.052464Z",
     "start_time": "2023-08-22T08:02:47.629699Z"
    }
   },
   "outputs": [],
   "source": [
    "valdf['Gloss'] = valdf['Gloss'].str.replace('\\d+', '',regex=True)\n",
    "testdf['Gloss'] = testdf['Gloss'].str.replace('\\d+', '',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fa31f47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:03.389063Z",
     "start_time": "2023-08-23T22:39:03.210196Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "traindf['Gloss'] = traindf['Gloss'].str.replace('\\d+', '',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "327c7f6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:48.573726Z",
     "start_time": "2023-08-22T08:02:48.054587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AXE', 'BACKPACK', 'BASKETBALL', 'BEE', 'BELT', 'BITE',\n",
       "       'BREAKFAST', 'CANCER', 'CHRISTMAS', 'CONFUSED', 'DARK', 'DEAF',\n",
       "       'DECIDE', 'DEMAND', 'DEVELOP', 'DINNER', 'DOG', 'DOWNSIZE', 'DRAG',\n",
       "       'EAT', 'EDIT', 'ELEVATOR', 'FINE', 'FLOAT', 'FOREIGNER', 'GUESS',\n",
       "       'HALLOWEEN', 'HOSPITAL', 'HURDLE/TRIP', 'JEWELRY', 'KNIGHT',\n",
       "       'LOCK', 'LUNCH', 'MAPLE', 'MEAT', 'MECHANIC', 'MICROSCOPE',\n",
       "       'MOVIE', 'NOON', 'PARTY', 'PATIENT', 'RAZOR', 'RIVER',\n",
       "       'ROCKINGCHAIR', 'SHAVE', 'SINK', 'SQUEEZE', 'THEY', 'TWINS',\n",
       "       'WHATFOR'], dtype=object)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = traindf['Gloss'].unique()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a6cfb4eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:48.821324Z",
     "start_time": "2023-08-22T08:02:48.576559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AXE', 'BACKPACK', 'BASKETBALL', 'BEE', 'BELT', 'BITE',\n",
       "       'BREAKFAST', 'CANCER', 'CHRISTMAS', 'CONFUSED', 'DARK', 'DEAF',\n",
       "       'DECIDE', 'DEMAND', 'DEVELOP', 'DINNER', 'DOG', 'DOWNSIZE', 'DRAG',\n",
       "       'EAT', 'EDIT', 'ELEVATOR', 'FINE', 'FLOAT', 'FOREIGNER', 'GUESS',\n",
       "       'HALLOWEEN', 'HOSPITAL', 'HURDLE/TRIP', 'JEWELRY', 'KNIGHT',\n",
       "       'LOCK', 'LUNCH', 'MAPLE', 'MEAT', 'MECHANIC', 'MICROSCOPE',\n",
       "       'MOVIE', 'NOON', 'PARTY', 'PATIENT', 'RAZOR', 'RIVER',\n",
       "       'ROCKINGCHAIR', 'SHAVE', 'SINK', 'SQUEEZE', 'THEY', 'TWINS',\n",
       "       'WHATFOR'], dtype=object)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = valdf['Gloss'].unique()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "dcfaf16e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:49.054864Z",
     "start_time": "2023-08-22T08:02:48.823584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AXE', 'BACKPACK', 'BASKETBALL', 'BEE', 'BELT', 'BITE',\n",
       "       'BREAKFAST', 'CANCER', 'CHRISTMAS', 'CONFUSED', 'DARK', 'DEAF',\n",
       "       'DECIDE', 'DEMAND', 'DEVELOP', 'DINNER', 'DOG', 'DOWNSIZE', 'DRAG',\n",
       "       'EAT', 'EDIT', 'ELEVATOR', 'FINE', 'FLOAT', 'FOREIGNER', 'GUESS',\n",
       "       'HALLOWEEN', 'HOSPITAL', 'HURDLE/TRIP', 'JEWELRY', 'KNIGHT',\n",
       "       'LOCK', 'LUNCH', 'MAPLE', 'MEAT', 'MECHANIC', 'MICROSCOPE',\n",
       "       'MOVIE', 'NOON', 'PARTY', 'PATIENT', 'RAZOR', 'RIVER',\n",
       "       'ROCKINGCHAIR', 'SHAVE', 'SINK', 'SQUEEZE', 'THEY', 'TWINS',\n",
       "       'WHATFOR'], dtype=object)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = testdf['Gloss'].unique()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fd22d14f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:49.285081Z",
     "start_time": "2023-08-22T08:02:49.057032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(traindf['Gloss'].nunique())\n",
    "print(valdf['Gloss'].nunique())\n",
    "print(testdf['Gloss'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "eac676d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:49.528876Z",
     "start_time": "2023-08-22T08:02:49.287849Z"
    }
   },
   "outputs": [],
   "source": [
    "traintest = pd.concat([traindf,testdf])\n",
    "traintest['Frequency'] = traintest['Gloss'].map(traintest['Gloss'].value_counts())\n",
    "traintest = traintest.sort_values(by='Gloss')\n",
    "\n",
    "traintest = traintest.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e66706f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:49.770368Z",
     "start_time": "2023-08-22T08:02:49.532506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>P37</td>\n",
       "      <td>8639087490010726-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>P40</td>\n",
       "      <td>6445331634562388-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>P37</td>\n",
       "      <td>6237575353180616-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>P11</td>\n",
       "      <td>9697621013006055-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>P15</td>\n",
       "      <td>540014801916062-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Participant ID                     Video file    Gloss ASL-LEX Code  \\\n",
       "1674            P37  8639087490010726-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "1675            P40  6445331634562388-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "1676            P37  6237575353180616-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "1677            P11  9697621013006055-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "1678            P15   540014801916062-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "\n",
       "                                                   Path  Frequency  \n",
       "1674  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         38  \n",
       "1675  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         38  \n",
       "1676  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         38  \n",
       "1677  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         38  \n",
       "1678  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         38  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9fbe611b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:50.018235Z",
     "start_time": "2023-08-22T08:02:49.773387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1679.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.840977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.876121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Frequency\n",
       "count  1679.000000\n",
       "mean     33.840977\n",
       "std       2.876121\n",
       "min      27.000000\n",
       "25%      33.000000\n",
       "50%      34.000000\n",
       "75%      35.000000\n",
       "max      41.000000"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8c1cca89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:02:50.262114Z",
     "start_time": "2023-08-22T08:02:50.021516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "Frequency=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "rgb(127,39,4)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "nbinsx": 20,
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          41,
          39,
          38,
          37,
          36,
          36,
          36,
          36,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          35,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          34,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          33,
          32,
          32,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          27
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Frequency Data Distribution In Training/Testing Dataframe Top 50 Words"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Frequency"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"85046bc9-9ea5-4c4d-8869-a99fa8977126\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"85046bc9-9ea5-4c4d-8869-a99fa8977126\")) {                    Plotly.newPlot(                        \"85046bc9-9ea5-4c4d-8869-a99fa8977126\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"Frequency=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"rgb(127,39,4)\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"nbinsx\":20,\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[41,39,38,37,36,36,36,36,35,35,35,35,35,35,35,35,35,35,35,35,35,35,34,34,34,34,34,34,34,34,34,33,33,33,33,33,33,33,33,33,32,32,28,28,28,28,28,28,28,27],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Frequency\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Frequency Data Distribution In Training/Testing Dataframe Top 50 Words\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('85046bc9-9ea5-4c4d-8869-a99fa8977126');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.histogram(traintest.groupby(['Gloss'], sort=True)['Frequency'].count().sort_values(ascending=False).reset_index(),\n",
    "                    x='Frequency',\n",
    "                    color_discrete_sequence=px.colors.sequential.Oranges_r,\n",
    "                    title='Frequency Data Distribution In Training/Testing Dataframe Top 50 Words', nbins=20)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ad70c4fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:03:00.194577Z",
     "start_time": "2023-08-22T08:02:50.266480Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(traindf.Path[4])\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(static_image_mode=False,\n",
    "                          model_complexity=1) as holistic:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(frame_rgb)\n",
    "\n",
    "        # Mano izquieda (azul)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "\n",
    "        # Mano derecha (verde)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b4860ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:03.557340Z",
     "start_time": "2023-08-23T22:39:03.390418Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Define a function to extract keypoints from a single video file\n",
    "def extract_keypoints_from_file(filepath):\n",
    "    # Initialize a MediaPipe Holistic model\n",
    "    holistic = mp.solutions.holistic.Holistic(static_image_mode=False,\n",
    "                                              model_complexity=1,\n",
    "                                              min_detection_confidence=0.5,\n",
    "                                              min_tracking_confidence=0.5)\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "\n",
    "    # Initialize an empty list to store the keypoints for each frame\n",
    "    keypoints = []\n",
    "\n",
    "    # Loop through the frames of the video\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB color space\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Use the Holistic model to detect landmarks for the face, pose, and hands\n",
    "        results = holistic.process(frame)\n",
    "\n",
    "        # Extract the keypoints from the results object and append them to the keypoints list\n",
    "        keypoints.append(extract_keypoints(results))\n",
    "\n",
    "    # Release the video capture object and the Holistic model\n",
    "    cap.release()\n",
    "    holistic.close()\n",
    "\n",
    "    return np.array(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "8cc9c343",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:03:00.762253Z",
     "start_time": "2023-08-22T08:03:00.210404Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to extract keypoints from a single video file\n",
    "def extract_keypoints_from_file_flip(filepath):\n",
    "    # Initialize a MediaPipe Holistic model\n",
    "    holistic = mp.solutions.holistic.Holistic(static_image_mode=False,\n",
    "                                              model_complexity=1,\n",
    "                                              min_detection_confidence=0.5,\n",
    "                                              min_tracking_confidence=0.5)\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "\n",
    "    # Initialize an empty list to store the keypoints for each frame\n",
    "    keypoints = []\n",
    "\n",
    "    # Loop through the frames of the video\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB color space\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        # Use the Holistic model to detect landmarks for the face, pose, and hands\n",
    "        results = holistic.process(frame)\n",
    "\n",
    "        # Extract the keypoints from the results object and append them to the keypoints list\n",
    "        keypoints.append(extract_keypoints(results))\n",
    "\n",
    "    # Release the video capture object and the Holistic model\n",
    "    cap.release()\n",
    "    holistic.close()\n",
    "\n",
    "    return np.array(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f6866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "49e95ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:03:11.504186Z",
     "start_time": "2023-08-22T08:03:00.764902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 126)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_keypoints_from_file(traindf.Path[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "dd37fc54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:03:21.416709Z",
     "start_time": "2023-08-22T08:03:11.506959Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.96414077e-01,  9.08715069e-01,  9.07866706e-08,  7.49651492e-01,\n",
       "        8.64592910e-01, -9.06617753e-03,  7.18871355e-01,  8.13641608e-01,\n",
       "       -1.42531497e-02,  7.00173020e-01,  7.75223196e-01, -2.11012661e-02,\n",
       "        6.85313523e-01,  7.38832355e-01, -2.72529013e-02,  7.53686905e-01,\n",
       "        7.23692119e-01,  1.10347848e-02,  7.51472771e-01,  6.68876708e-01,\n",
       "        1.31220720e-03,  7.49525487e-01,  6.38742685e-01, -1.18946834e-02,\n",
       "        7.46116936e-01,  6.16605282e-01, -2.20092256e-02,  7.77112484e-01,\n",
       "        7.26227760e-01,  5.35163376e-03,  7.76386797e-01,  6.63936794e-01,\n",
       "       -3.61846294e-03,  7.73537099e-01,  6.33621931e-01, -1.52370287e-02,\n",
       "        7.68957615e-01,  6.16506398e-01, -2.34815758e-02,  7.99829900e-01,\n",
       "        7.40132511e-01, -3.79953836e-03,  8.01362157e-01,  6.78541660e-01,\n",
       "       -1.29196774e-02,  7.97479153e-01,  6.52502894e-01, -1.86225455e-02,\n",
       "        7.91766882e-01,  6.40358806e-01, -2.22017895e-02,  8.21929336e-01,\n",
       "        7.65651405e-01, -1.46674123e-02,  8.24854314e-01,  7.17534840e-01,\n",
       "       -2.21609082e-02,  8.21130693e-01,  6.88872755e-01, -2.42062341e-02,\n",
       "        8.15555811e-01,  6.67642593e-01, -2.51563806e-02,  2.60131210e-01,\n",
       "        3.96844536e-01,  1.83333935e-08,  2.47957692e-01,  3.56893569e-01,\n",
       "        1.70896612e-02,  2.50141770e-01,  3.15991253e-01,  2.04622950e-02,\n",
       "        2.58258879e-01,  2.86541402e-01,  1.88637059e-02,  2.70099759e-01,\n",
       "        2.67284781e-01,  1.71739310e-02,  2.45038494e-01,  2.91480482e-01,\n",
       "        1.17030814e-02,  2.57864177e-01,  2.35139266e-01,  6.76223077e-03,\n",
       "        2.74434268e-01,  2.10311711e-01,  4.94650239e-03,  2.88115770e-01,\n",
       "        1.98338434e-01,  5.35590760e-03,  2.55617380e-01,  2.85091519e-01,\n",
       "       -6.56272750e-04,  2.69321561e-01,  2.17318401e-01, -4.64544585e-03,\n",
       "        2.87183046e-01,  1.88684076e-01, -4.33856668e-03,  3.02506834e-01,\n",
       "        1.75034598e-01, -3.07585881e-03,  2.70357072e-01,  2.85296112e-01,\n",
       "       -1.25349760e-02,  2.84903467e-01,  2.20406041e-01, -1.49186812e-02,\n",
       "        3.00180703e-01,  1.89506441e-01, -1.44295134e-02,  3.13080341e-01,\n",
       "        1.72104776e-01, -1.35856159e-02,  2.90387034e-01,  2.91853547e-01,\n",
       "       -2.32692044e-02,  3.04253280e-01,  2.43021309e-01, -2.06949115e-02,\n",
       "        3.14174086e-01,  2.16918111e-01, -1.67924110e-02,  3.21578920e-01,\n",
       "        1.98481828e-01, -1.41173527e-02])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=extract_keypoints_from_file_flip(traindf.Path[0])\n",
    "test[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c67746c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:03:31.687645Z",
     "start_time": "2023-08-22T08:03:21.419222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.41789162e-01,  4.14220452e-01, -8.04981610e-08,  7.52606869e-01,\n",
       "        3.70309889e-01,  2.84047537e-02,  7.49311566e-01,  3.29515249e-01,\n",
       "        4.10141498e-02,  7.39953101e-01,  3.03338051e-01,  4.79311235e-02,\n",
       "        7.29388475e-01,  2.87711948e-01,  5.33078238e-02,  7.54872143e-01,\n",
       "        2.95699596e-01,  2.53431760e-02,  7.42109537e-01,  2.41008013e-01,\n",
       "        2.82448940e-02,  7.27952123e-01,  2.12981150e-01,  3.09054554e-02,\n",
       "        7.15792120e-01,  1.95877552e-01,  3.31397988e-02,  7.44172215e-01,\n",
       "        2.90129274e-01,  1.05545465e-02,  7.29215205e-01,  2.24516720e-01,\n",
       "        1.45581122e-02,  7.13301122e-01,  1.93701595e-01,  1.77212693e-02,\n",
       "        7.00190902e-01,  1.74026877e-01,  1.94902867e-02,  7.28045106e-01,\n",
       "        2.91374683e-01, -2.65448634e-03,  7.14913905e-01,  2.26463526e-01,\n",
       "        8.32793710e-04,  7.00475335e-01,  1.94862932e-01,  1.59235217e-03,\n",
       "        6.88417256e-01,  1.72671020e-01,  9.31388815e-04,  7.07076907e-01,\n",
       "        2.96958238e-01, -1.33496495e-02,  6.94176733e-01,  2.47203171e-01,\n",
       "       -1.21597154e-02,  6.84255421e-01,  2.19075143e-01, -1.08818235e-02,\n",
       "        6.74976885e-01,  1.96626514e-01, -1.02415495e-02,  2.08620012e-01,\n",
       "        9.03532147e-01,  1.73204086e-07,  2.53460288e-01,  8.69549155e-01,\n",
       "       -9.52085294e-03,  2.81645447e-01,  8.15089762e-01, -1.18521424e-02,\n",
       "        2.99715340e-01,  7.75415838e-01, -1.52448947e-02,  3.13167214e-01,\n",
       "        7.42327690e-01, -1.87010467e-02,  2.45579019e-01,  7.23865867e-01,\n",
       "        6.31285785e-03,  2.47078061e-01,  6.67820454e-01, -2.47295387e-03,\n",
       "        2.48919547e-01,  6.37507379e-01, -1.30039155e-02,  2.51245409e-01,\n",
       "        6.17612481e-01, -2.00465247e-02,  2.21574709e-01,  7.27756679e-01,\n",
       "        3.20783630e-03,  2.22653583e-01,  6.68228149e-01, -2.80486699e-03,\n",
       "        2.26927370e-01,  6.37535632e-01, -1.20890103e-02,  2.32608691e-01,\n",
       "        6.19248986e-01, -1.89536177e-02,  1.98787794e-01,  7.43310750e-01,\n",
       "       -2.75677326e-03,  1.98783204e-01,  6.85976923e-01, -1.02470769e-02,\n",
       "        2.03182459e-01,  6.59094751e-01, -1.55144306e-02,  2.10077450e-01,\n",
       "        6.42322779e-01, -1.89075246e-02,  1.75356075e-01,  7.69238114e-01,\n",
       "       -1.02483621e-02,  1.74700290e-01,  7.24416196e-01, -1.70725137e-02,\n",
       "        1.79272637e-01,  6.97267652e-01, -1.85729433e-02,  1.86291158e-01,\n",
       "        6.74813032e-01, -1.89780090e-02])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=extract_keypoints_from_file(traindf.Path[0])\n",
    "test[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5d2a0a7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:03:31.702852Z",
     "start_time": "2023-08-22T08:03:31.690351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(traindf.Path[0])\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print( length )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b48bfa39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:03:41.597139Z",
     "start_time": "2023-08-22T08:03:31.705367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(extract_keypoints_from_file(traindf.Path[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f5533751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:03:41.609430Z",
     "start_time": "2023-08-22T08:03:41.599641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Participant ID    950\n",
       "Video file        950\n",
       "Gloss             950\n",
       "ASL-LEX Code      950\n",
       "Path              950\n",
       "Frequency         950\n",
       "dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a9a5517",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:03.773039Z",
     "start_time": "2023-08-23T22:39:03.558751Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def frames_from_file(filepath):\n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "    frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    length = round(frames / fps)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    return frames, fps, length, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2576a32d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:03:45.048298Z",
     "start_time": "2023-08-22T08:03:42.772309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 31, 3, 640, 480)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_from_file(traindf.Path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ce6941bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:03.437776Z",
     "start_time": "2023-08-22T08:03:45.052108Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1679/1679 [00:16<00:00, 99.74it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "traintest[['Frames', 'FPS', 'Length', 'Width', 'Height']] = traintest['Path'].progress_apply(lambda x: pd.Series(frames_from_file(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "96cc087f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:03.472910Z",
     "start_time": "2023-08-22T08:04:03.440602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1679.000000</td>\n",
       "      <td>1679.000000</td>\n",
       "      <td>1679.000000</td>\n",
       "      <td>1679.000000</td>\n",
       "      <td>1679.000000</td>\n",
       "      <td>1679.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.840977</td>\n",
       "      <td>82.300774</td>\n",
       "      <td>29.069089</td>\n",
       "      <td>2.846337</td>\n",
       "      <td>660.011912</td>\n",
       "      <td>483.752233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.876121</td>\n",
       "      <td>40.078670</td>\n",
       "      <td>2.653846</td>\n",
       "      <td>1.365843</td>\n",
       "      <td>77.504276</td>\n",
       "      <td>14.532052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>540.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Frequency       Frames          FPS       Length        Width  \\\n",
       "count  1679.000000  1679.000000  1679.000000  1679.000000  1679.000000   \n",
       "mean     33.840977    82.300774    29.069089     2.846337   660.011912   \n",
       "std       2.876121    40.078670     2.653846     1.365843    77.504276   \n",
       "min      27.000000    10.000000    11.000000     0.000000   640.000000   \n",
       "25%      33.000000    59.000000    29.000000     2.000000   640.000000   \n",
       "50%      34.000000    75.000000    30.000000     3.000000   640.000000   \n",
       "75%      35.000000    94.000000    30.000000     3.000000   640.000000   \n",
       "max      41.000000   540.000000    31.000000    18.000000   960.000000   \n",
       "\n",
       "            Height  \n",
       "count  1679.000000  \n",
       "mean    483.752233  \n",
       "std      14.532052  \n",
       "min     480.000000  \n",
       "25%     480.000000  \n",
       "50%     480.000000  \n",
       "75%     480.000000  \n",
       "max     540.000000  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8d6be473",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:04.366726Z",
     "start_time": "2023-08-22T08:04:03.474994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Frames=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "rgb(0,68,27)"
         },
         "name": "",
         "notched": false,
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "box",
         "x0": " ",
         "xaxis": "x",
         "y": [
          100,
          53,
          94,
          82,
          83,
          101,
          59,
          54,
          96,
          102,
          66,
          57,
          196,
          70,
          73,
          209,
          52,
          81,
          81,
          47,
          67,
          89,
          112,
          64,
          88,
          75,
          69,
          70,
          58,
          57,
          65,
          72,
          91,
          77,
          63,
          82,
          78,
          84,
          45,
          89,
          60,
          70,
          73,
          95,
          41,
          68,
          74,
          57,
          78,
          126,
          97,
          99,
          47,
          90,
          45,
          72,
          139,
          57,
          116,
          85,
          59,
          65,
          149,
          65,
          88,
          129,
          48,
          76,
          77,
          89,
          45,
          63,
          53,
          58,
          43,
          44,
          41,
          74,
          95,
          91,
          110,
          80,
          50,
          64,
          61,
          120,
          83,
          48,
          67,
          96,
          53,
          78,
          62,
          80,
          74,
          53,
          82,
          80,
          48,
          163,
          83,
          67,
          152,
          56,
          77,
          67,
          66,
          64,
          41,
          80,
          87,
          49,
          134,
          50,
          57,
          98,
          68,
          83,
          180,
          83,
          147,
          85,
          86,
          53,
          60,
          76,
          42,
          142,
          46,
          42,
          82,
          72,
          101,
          35,
          42,
          31,
          68,
          72,
          109,
          48,
          68,
          67,
          91,
          101,
          59,
          85,
          73,
          206,
          80,
          61,
          60,
          60,
          118,
          104,
          90,
          94,
          130,
          89,
          106,
          169,
          81,
          69,
          71,
          51,
          68,
          96,
          56,
          88,
          112,
          178,
          82,
          71,
          82,
          104,
          42,
          97,
          51,
          60,
          85,
          45,
          81,
          63,
          53,
          66,
          77,
          106,
          264,
          63,
          67,
          72,
          52,
          58,
          49,
          61,
          80,
          56,
          86,
          85,
          68,
          95,
          57,
          93,
          69,
          111,
          44,
          36,
          41,
          170,
          52,
          112,
          97,
          42,
          63,
          84,
          63,
          66,
          29,
          56,
          38,
          91,
          47,
          104,
          90,
          60,
          56,
          42,
          45,
          77,
          57,
          73,
          71,
          75,
          94,
          40,
          85,
          72,
          60,
          68,
          41,
          94,
          134,
          80,
          139,
          64,
          85,
          86,
          77,
          72,
          104,
          84,
          55,
          55,
          80,
          103,
          47,
          52,
          66,
          59,
          87,
          165,
          71,
          83,
          65,
          90,
          114,
          86,
          66,
          89,
          46,
          61,
          58,
          59,
          100,
          69,
          83,
          84,
          94,
          87,
          73,
          86,
          43,
          47,
          64,
          64,
          85,
          69,
          38,
          59,
          155,
          98,
          43,
          68,
          62,
          53,
          65,
          71,
          51,
          89,
          100,
          54,
          104,
          77,
          77,
          71,
          65,
          95,
          111,
          48,
          43,
          57,
          67,
          87,
          80,
          56,
          103,
          53,
          169,
          59,
          91,
          79,
          66,
          63,
          94,
          86,
          108,
          84,
          106,
          36,
          79,
          108,
          97,
          53,
          76,
          89,
          69,
          54,
          65,
          58,
          87,
          162,
          75,
          69,
          104,
          54,
          123,
          195,
          71,
          92,
          88,
          105,
          55,
          131,
          88,
          73,
          52,
          66,
          56,
          81,
          62,
          78,
          118,
          37,
          62,
          52,
          113,
          77,
          64,
          104,
          82,
          65,
          78,
          111,
          64,
          89,
          50,
          65,
          114,
          53,
          68,
          70,
          62,
          81,
          148,
          76,
          67,
          65,
          79,
          79,
          94,
          55,
          50,
          44,
          88,
          134,
          58,
          51,
          269,
          49,
          71,
          57,
          152,
          80,
          63,
          81,
          60,
          85,
          59,
          57,
          92,
          76,
          63,
          52,
          52,
          65,
          50,
          114,
          80,
          64,
          54,
          44,
          39,
          83,
          85,
          59,
          81,
          75,
          74,
          70,
          49,
          53,
          10,
          70,
          48,
          84,
          88,
          77,
          137,
          97,
          136,
          86,
          65,
          71,
          83,
          57,
          51,
          57,
          73,
          62,
          86,
          54,
          100,
          45,
          67,
          145,
          48,
          207,
          103,
          99,
          97,
          65,
          48,
          63,
          67,
          98,
          87,
          40,
          98,
          41,
          57,
          88,
          143,
          75,
          48,
          99,
          61,
          187,
          122,
          44,
          84,
          49,
          49,
          50,
          65,
          93,
          49,
          71,
          38,
          99,
          36,
          58,
          79,
          66,
          73,
          93,
          91,
          98,
          142,
          68,
          67,
          112,
          56,
          233,
          146,
          98,
          123,
          69,
          62,
          58,
          33,
          94,
          68,
          86,
          69,
          123,
          85,
          73,
          80,
          73,
          71,
          43,
          40,
          42,
          25,
          61,
          93,
          109,
          67,
          108,
          87,
          94,
          92,
          66,
          195,
          40,
          73,
          105,
          60,
          89,
          55,
          51,
          77,
          64,
          82,
          75,
          68,
          35,
          50,
          74,
          93,
          70,
          41,
          55,
          93,
          192,
          131,
          65,
          85,
          53,
          81,
          123,
          72,
          79,
          57,
          87,
          456,
          75,
          76,
          69,
          73,
          194,
          78,
          49,
          65,
          162,
          41,
          65,
          71,
          42,
          50,
          52,
          54,
          78,
          96,
          37,
          99,
          112,
          32,
          97,
          47,
          45,
          40,
          76,
          61,
          97,
          55,
          40,
          81,
          70,
          87,
          89,
          59,
          208,
          116,
          63,
          93,
          50,
          140,
          84,
          89,
          49,
          114,
          64,
          97,
          61,
          53,
          147,
          93,
          74,
          82,
          65,
          107,
          55,
          119,
          108,
          53,
          98,
          44,
          61,
          71,
          82,
          78,
          83,
          60,
          82,
          186,
          61,
          99,
          111,
          147,
          86,
          88,
          71,
          77,
          53,
          105,
          98,
          75,
          121,
          79,
          95,
          51,
          52,
          109,
          87,
          116,
          185,
          61,
          80,
          45,
          60,
          63,
          59,
          59,
          59,
          78,
          80,
          105,
          69,
          98,
          26,
          35,
          34,
          60,
          69,
          150,
          54,
          35,
          42,
          99,
          49,
          39,
          73,
          80,
          70,
          55,
          51,
          66,
          41,
          42,
          145,
          200,
          81,
          77,
          107,
          47,
          83,
          79,
          81,
          61,
          46,
          60,
          78,
          55,
          50,
          101,
          85,
          87,
          71,
          59,
          84,
          73,
          103,
          48,
          108,
          89,
          85,
          90,
          41,
          123,
          81,
          71,
          104,
          60,
          66,
          101,
          49,
          156,
          130,
          55,
          152,
          64,
          77,
          220,
          71,
          86,
          89,
          81,
          105,
          81,
          74,
          68,
          116,
          75,
          62,
          90,
          176,
          57,
          113,
          86,
          96,
          72,
          184,
          83,
          51,
          76,
          80,
          102,
          90,
          114,
          71,
          109,
          76,
          78,
          181,
          102,
          102,
          54,
          100,
          94,
          51,
          102,
          95,
          60,
          49,
          77,
          50,
          64,
          138,
          47,
          58,
          93,
          113,
          54,
          84,
          66,
          32,
          40,
          94,
          55,
          58,
          73,
          94,
          97,
          100,
          47,
          75,
          52,
          67,
          21,
          52,
          65,
          34,
          55,
          66,
          46,
          103,
          95,
          132,
          64,
          128,
          134,
          55,
          106,
          86,
          107,
          60,
          158,
          69,
          116,
          84,
          68,
          190,
          115,
          54,
          83,
          128,
          93,
          86,
          102,
          114,
          280,
          114,
          99,
          122,
          100,
          75,
          86,
          53,
          93,
          96,
          86,
          48,
          129,
          89,
          77,
          62,
          18,
          113,
          161,
          55,
          77,
          88,
          63,
          57,
          71,
          70,
          100,
          81,
          83,
          106,
          79,
          123,
          130,
          175,
          117,
          67,
          56,
          74,
          63,
          47,
          117,
          55,
          38,
          55,
          82,
          78,
          64,
          49,
          73,
          48,
          73,
          46,
          73,
          72,
          111,
          163,
          155,
          38,
          158,
          68,
          35,
          64,
          41,
          98,
          72,
          96,
          60,
          42,
          65,
          28,
          83,
          62,
          96,
          64,
          52,
          85,
          83,
          46,
          218,
          63,
          75,
          88,
          87,
          60,
          98,
          112,
          87,
          76,
          76,
          91,
          52,
          51,
          78,
          187,
          80,
          84,
          111,
          65,
          68,
          85,
          91,
          67,
          65,
          57,
          65,
          90,
          86,
          95,
          84,
          41,
          92,
          64,
          80,
          48,
          46,
          62,
          60,
          66,
          68,
          78,
          55,
          98,
          82,
          70,
          106,
          63,
          101,
          80,
          82,
          52,
          124,
          67,
          132,
          90,
          59,
          36,
          67,
          48,
          125,
          71,
          50,
          53,
          87,
          88,
          45,
          54,
          59,
          102,
          51,
          37,
          103,
          94,
          126,
          77,
          240,
          158,
          56,
          46,
          55,
          55,
          170,
          54,
          86,
          68,
          56,
          49,
          56,
          62,
          77,
          73,
          53,
          106,
          78,
          70,
          57,
          80,
          68,
          120,
          94,
          40,
          257,
          45,
          81,
          69,
          61,
          145,
          110,
          73,
          95,
          66,
          47,
          106,
          137,
          67,
          89,
          77,
          76,
          84,
          123,
          52,
          104,
          317,
          140,
          138,
          96,
          104,
          74,
          74,
          95,
          47,
          93,
          79,
          94,
          88,
          65,
          82,
          49,
          51,
          95,
          109,
          120,
          69,
          64,
          81,
          211,
          337,
          77,
          59,
          104,
          93,
          79,
          116,
          38,
          85,
          42,
          73,
          40,
          54,
          52,
          96,
          71,
          60,
          37,
          134,
          59,
          94,
          39,
          171,
          83,
          52,
          74,
          45,
          97,
          146,
          46,
          71,
          128,
          61,
          94,
          90,
          75,
          62,
          62,
          83,
          38,
          88,
          71,
          87,
          84,
          48,
          57,
          58,
          42,
          59,
          110,
          57,
          41,
          50,
          58,
          130,
          50,
          48,
          149,
          108,
          143,
          63,
          65,
          63,
          78,
          89,
          136,
          90,
          101,
          45,
          63,
          35,
          120,
          72,
          104,
          74,
          47,
          36,
          83,
          250,
          77,
          183,
          108,
          56,
          118,
          51,
          65,
          119,
          88,
          238,
          49,
          82,
          83,
          70,
          157,
          54,
          58,
          75,
          95,
          59,
          64,
          77,
          110,
          72,
          78,
          144,
          47,
          85,
          68,
          172,
          80,
          80,
          128,
          197,
          94,
          89,
          78,
          84,
          92,
          67,
          72,
          121,
          103,
          52,
          50,
          50,
          57,
          91,
          80,
          97,
          69,
          77,
          114,
          59,
          96,
          103,
          95,
          64,
          78,
          87,
          106,
          75,
          104,
          84,
          84,
          136,
          58,
          68,
          56,
          126,
          76,
          80,
          76,
          87,
          53,
          161,
          78,
          162,
          52,
          100,
          93,
          70,
          139,
          95,
          167,
          96,
          79,
          63,
          60,
          57,
          71,
          56,
          64,
          80,
          92,
          109,
          58,
          117,
          52,
          60,
          72,
          45,
          75,
          89,
          70,
          59,
          77,
          80,
          62,
          108,
          90,
          75,
          165,
          79,
          69,
          97,
          107,
          126,
          47,
          71,
          72,
          82,
          57,
          66,
          48,
          86,
          83,
          90,
          49,
          74,
          56,
          46,
          115,
          88,
          82,
          106,
          111,
          86,
          155,
          135,
          53,
          105,
          50,
          40,
          77,
          68,
          77,
          102,
          60,
          46,
          86,
          82,
          61,
          62,
          110,
          74,
          100,
          75,
          88,
          81,
          80,
          87,
          98,
          64,
          54,
          49,
          117,
          66,
          142,
          230,
          141,
          62,
          100,
          73,
          85,
          59,
          94,
          61,
          51,
          79,
          110,
          41,
          80,
          79,
          73,
          66,
          79,
          73,
          58,
          47,
          76,
          64,
          65,
          124,
          75,
          78,
          94,
          51,
          52,
          70,
          73,
          51,
          56,
          91,
          124,
          41,
          65,
          97,
          57,
          65,
          80,
          68,
          98,
          71,
          36,
          56,
          76,
          93,
          53,
          57,
          79,
          72,
          46,
          59,
          115,
          56,
          86,
          57,
          44,
          53,
          47,
          170,
          79,
          47,
          168,
          70,
          89,
          125,
          60,
          43,
          90,
          37,
          110,
          73,
          67,
          44,
          61,
          70,
          65,
          23,
          64,
          85,
          108,
          49,
          89,
          141,
          89,
          194,
          110,
          53,
          104,
          75,
          48,
          60,
          180,
          73,
          54,
          83,
          64,
          70,
          290,
          53,
          61,
          103,
          72,
          80,
          96,
          70,
          110,
          35,
          72,
          87,
          41,
          113,
          75,
          79,
          91,
          50,
          51,
          64,
          283,
          88,
          71,
          234,
          103,
          114,
          72,
          78,
          185,
          103,
          78,
          57,
          64,
          106,
          68,
          70,
          71,
          93,
          87,
          74,
          71,
          140,
          186,
          58,
          102,
          76,
          89,
          73,
          111,
          50,
          78,
          66,
          80,
          74,
          71,
          75,
          67,
          97,
          57,
          68,
          101,
          96,
          53,
          80,
          124,
          47,
          116,
          71,
          92,
          251,
          95,
          61,
          72,
          88,
          87,
          47,
          86,
          78,
          62,
          59,
          61,
          110,
          76,
          80,
          86,
          87,
          41,
          35,
          57,
          60,
          102,
          59,
          79,
          72,
          92,
          106,
          78,
          107,
          70,
          168,
          104,
          87,
          58,
          100,
          85,
          60,
          97,
          81,
          162,
          505,
          68,
          66,
          63,
          68,
          62,
          85,
          95,
          95,
          71,
          94,
          78,
          78,
          245,
          94,
          97,
          144,
          540,
          105,
          47,
          67,
          74,
          123,
          54,
          53,
          105,
          109,
          74,
          62,
          52,
          78,
          71,
          55,
          177,
          36,
          134,
          76,
          69,
          107,
          276,
          158,
          79,
          100,
          47,
          64,
          57,
          84,
          134,
          75,
          78,
          88,
          71,
          84,
          87,
          42,
          79,
          67,
          65,
          87,
          89,
          49,
          75,
          45,
          86,
          43,
          92,
          69,
          53,
          63,
          43,
          75,
          28,
          98,
          39,
          103,
          33,
          61,
          61,
          61,
          65,
          45,
          85,
          58,
          122,
          137,
          100,
          87,
          44,
          150,
          70,
          81,
          62,
          64,
          51,
          47,
          54,
          73,
          71,
          75,
          53,
          44,
          90,
          49,
          57,
          53,
          62,
          76,
          65,
          47,
          69,
          126,
          106,
          59,
          56,
          73,
          59,
          57,
          74,
          73,
          149,
          52,
          89,
          90,
          39,
          79,
          45,
          116,
          52,
          91,
          48,
          80,
          41,
          153,
          53,
          83,
          66,
          82,
          30,
          84,
          56,
          66,
          52,
          89,
          43,
          92,
          65,
          61,
          73,
          84,
          47,
          59,
          101,
          75,
          64,
          74,
          157,
          165,
          89,
          49,
          56,
          61,
          59,
          89,
          56,
          41,
          79
         ],
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "boxmode": "group",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Video Frames Boxplot In Training/Testing Dataframe Top 50 Words"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Frames"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"538ceae2-f2e3-4504-8a61-87fcd557fb8a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"538ceae2-f2e3-4504-8a61-87fcd557fb8a\")) {                    Plotly.newPlot(                        \"538ceae2-f2e3-4504-8a61-87fcd557fb8a\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Frames=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"rgb(0,68,27)\"},\"name\":\"\",\"notched\":false,\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[100,53,94,82,83,101,59,54,96,102,66,57,196,70,73,209,52,81,81,47,67,89,112,64,88,75,69,70,58,57,65,72,91,77,63,82,78,84,45,89,60,70,73,95,41,68,74,57,78,126,97,99,47,90,45,72,139,57,116,85,59,65,149,65,88,129,48,76,77,89,45,63,53,58,43,44,41,74,95,91,110,80,50,64,61,120,83,48,67,96,53,78,62,80,74,53,82,80,48,163,83,67,152,56,77,67,66,64,41,80,87,49,134,50,57,98,68,83,180,83,147,85,86,53,60,76,42,142,46,42,82,72,101,35,42,31,68,72,109,48,68,67,91,101,59,85,73,206,80,61,60,60,118,104,90,94,130,89,106,169,81,69,71,51,68,96,56,88,112,178,82,71,82,104,42,97,51,60,85,45,81,63,53,66,77,106,264,63,67,72,52,58,49,61,80,56,86,85,68,95,57,93,69,111,44,36,41,170,52,112,97,42,63,84,63,66,29,56,38,91,47,104,90,60,56,42,45,77,57,73,71,75,94,40,85,72,60,68,41,94,134,80,139,64,85,86,77,72,104,84,55,55,80,103,47,52,66,59,87,165,71,83,65,90,114,86,66,89,46,61,58,59,100,69,83,84,94,87,73,86,43,47,64,64,85,69,38,59,155,98,43,68,62,53,65,71,51,89,100,54,104,77,77,71,65,95,111,48,43,57,67,87,80,56,103,53,169,59,91,79,66,63,94,86,108,84,106,36,79,108,97,53,76,89,69,54,65,58,87,162,75,69,104,54,123,195,71,92,88,105,55,131,88,73,52,66,56,81,62,78,118,37,62,52,113,77,64,104,82,65,78,111,64,89,50,65,114,53,68,70,62,81,148,76,67,65,79,79,94,55,50,44,88,134,58,51,269,49,71,57,152,80,63,81,60,85,59,57,92,76,63,52,52,65,50,114,80,64,54,44,39,83,85,59,81,75,74,70,49,53,10,70,48,84,88,77,137,97,136,86,65,71,83,57,51,57,73,62,86,54,100,45,67,145,48,207,103,99,97,65,48,63,67,98,87,40,98,41,57,88,143,75,48,99,61,187,122,44,84,49,49,50,65,93,49,71,38,99,36,58,79,66,73,93,91,98,142,68,67,112,56,233,146,98,123,69,62,58,33,94,68,86,69,123,85,73,80,73,71,43,40,42,25,61,93,109,67,108,87,94,92,66,195,40,73,105,60,89,55,51,77,64,82,75,68,35,50,74,93,70,41,55,93,192,131,65,85,53,81,123,72,79,57,87,456,75,76,69,73,194,78,49,65,162,41,65,71,42,50,52,54,78,96,37,99,112,32,97,47,45,40,76,61,97,55,40,81,70,87,89,59,208,116,63,93,50,140,84,89,49,114,64,97,61,53,147,93,74,82,65,107,55,119,108,53,98,44,61,71,82,78,83,60,82,186,61,99,111,147,86,88,71,77,53,105,98,75,121,79,95,51,52,109,87,116,185,61,80,45,60,63,59,59,59,78,80,105,69,98,26,35,34,60,69,150,54,35,42,99,49,39,73,80,70,55,51,66,41,42,145,200,81,77,107,47,83,79,81,61,46,60,78,55,50,101,85,87,71,59,84,73,103,48,108,89,85,90,41,123,81,71,104,60,66,101,49,156,130,55,152,64,77,220,71,86,89,81,105,81,74,68,116,75,62,90,176,57,113,86,96,72,184,83,51,76,80,102,90,114,71,109,76,78,181,102,102,54,100,94,51,102,95,60,49,77,50,64,138,47,58,93,113,54,84,66,32,40,94,55,58,73,94,97,100,47,75,52,67,21,52,65,34,55,66,46,103,95,132,64,128,134,55,106,86,107,60,158,69,116,84,68,190,115,54,83,128,93,86,102,114,280,114,99,122,100,75,86,53,93,96,86,48,129,89,77,62,18,113,161,55,77,88,63,57,71,70,100,81,83,106,79,123,130,175,117,67,56,74,63,47,117,55,38,55,82,78,64,49,73,48,73,46,73,72,111,163,155,38,158,68,35,64,41,98,72,96,60,42,65,28,83,62,96,64,52,85,83,46,218,63,75,88,87,60,98,112,87,76,76,91,52,51,78,187,80,84,111,65,68,85,91,67,65,57,65,90,86,95,84,41,92,64,80,48,46,62,60,66,68,78,55,98,82,70,106,63,101,80,82,52,124,67,132,90,59,36,67,48,125,71,50,53,87,88,45,54,59,102,51,37,103,94,126,77,240,158,56,46,55,55,170,54,86,68,56,49,56,62,77,73,53,106,78,70,57,80,68,120,94,40,257,45,81,69,61,145,110,73,95,66,47,106,137,67,89,77,76,84,123,52,104,317,140,138,96,104,74,74,95,47,93,79,94,88,65,82,49,51,95,109,120,69,64,81,211,337,77,59,104,93,79,116,38,85,42,73,40,54,52,96,71,60,37,134,59,94,39,171,83,52,74,45,97,146,46,71,128,61,94,90,75,62,62,83,38,88,71,87,84,48,57,58,42,59,110,57,41,50,58,130,50,48,149,108,143,63,65,63,78,89,136,90,101,45,63,35,120,72,104,74,47,36,83,250,77,183,108,56,118,51,65,119,88,238,49,82,83,70,157,54,58,75,95,59,64,77,110,72,78,144,47,85,68,172,80,80,128,197,94,89,78,84,92,67,72,121,103,52,50,50,57,91,80,97,69,77,114,59,96,103,95,64,78,87,106,75,104,84,84,136,58,68,56,126,76,80,76,87,53,161,78,162,52,100,93,70,139,95,167,96,79,63,60,57,71,56,64,80,92,109,58,117,52,60,72,45,75,89,70,59,77,80,62,108,90,75,165,79,69,97,107,126,47,71,72,82,57,66,48,86,83,90,49,74,56,46,115,88,82,106,111,86,155,135,53,105,50,40,77,68,77,102,60,46,86,82,61,62,110,74,100,75,88,81,80,87,98,64,54,49,117,66,142,230,141,62,100,73,85,59,94,61,51,79,110,41,80,79,73,66,79,73,58,47,76,64,65,124,75,78,94,51,52,70,73,51,56,91,124,41,65,97,57,65,80,68,98,71,36,56,76,93,53,57,79,72,46,59,115,56,86,57,44,53,47,170,79,47,168,70,89,125,60,43,90,37,110,73,67,44,61,70,65,23,64,85,108,49,89,141,89,194,110,53,104,75,48,60,180,73,54,83,64,70,290,53,61,103,72,80,96,70,110,35,72,87,41,113,75,79,91,50,51,64,283,88,71,234,103,114,72,78,185,103,78,57,64,106,68,70,71,93,87,74,71,140,186,58,102,76,89,73,111,50,78,66,80,74,71,75,67,97,57,68,101,96,53,80,124,47,116,71,92,251,95,61,72,88,87,47,86,78,62,59,61,110,76,80,86,87,41,35,57,60,102,59,79,72,92,106,78,107,70,168,104,87,58,100,85,60,97,81,162,505,68,66,63,68,62,85,95,95,71,94,78,78,245,94,97,144,540,105,47,67,74,123,54,53,105,109,74,62,52,78,71,55,177,36,134,76,69,107,276,158,79,100,47,64,57,84,134,75,78,88,71,84,87,42,79,67,65,87,89,49,75,45,86,43,92,69,53,63,43,75,28,98,39,103,33,61,61,61,65,45,85,58,122,137,100,87,44,150,70,81,62,64,51,47,54,73,71,75,53,44,90,49,57,53,62,76,65,47,69,126,106,59,56,73,59,57,74,73,149,52,89,90,39,79,45,116,52,91,48,80,41,153,53,83,66,82,30,84,56,66,52,89,43,92,65,61,73,84,47,59,101,75,64,74,157,165,89,49,56,61,59,89,56,41,79],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Frames\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Video Frames Boxplot In Training/Testing Dataframe Top 50 Words\"},\"boxmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('538ceae2-f2e3-4504-8a61-87fcd557fb8a');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.box(traintest, y=\"Frames\", title=\"Video Frames Boxplot In Training/Testing Dataframe Top 50 Words\",\n",
    "                                color_discrete_sequence=px.colors.sequential.Greens_r)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "fad1ee21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:13.361081Z",
     "start_time": "2023-08-22T08:04:04.369482Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 950/950 [00:08<00:00, 111.54it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "traindf[['Frames', 'FPS', 'Length', 'Width', 'Height']] = traindf['Path'].progress_apply(lambda x: pd.Series(frames_from_file(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "87551a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:13.373129Z",
     "start_time": "2023-08-22T08:04:13.364967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf['Frames'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "491120f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:14.636910Z",
     "start_time": "2023-08-22T08:04:13.376011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P52</td>\n",
       "      <td>07157565148825373-seedAXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>19</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P28</td>\n",
       "      <td>7179300005186042-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>19</td>\n",
       "      <td>81</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P29</td>\n",
       "      <td>16216064841959765-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>19</td>\n",
       "      <td>47</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P37</td>\n",
       "      <td>6193814382865199-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>19</td>\n",
       "      <td>67</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P40</td>\n",
       "      <td>5947453960317015-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>19</td>\n",
       "      <td>89</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                     Video file Gloss ASL-LEX Code  \\\n",
       "0            P52  07157565148825373-seedAXE.mp4   AXE     G_03_066   \n",
       "1            P28       7179300005186042-AXE.mp4   AXE     G_03_066   \n",
       "2            P29      16216064841959765-AXE.mp4   AXE     G_03_066   \n",
       "3            P37       6193814382865199-AXE.mp4   AXE     G_03_066   \n",
       "4            P40       5947453960317015-AXE.mp4   AXE     G_03_066   \n",
       "\n",
       "                                                Path  Frequency  Frames  FPS  \\\n",
       "0  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         19     100   31   \n",
       "1  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         19      81   30   \n",
       "2  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         19      47   30   \n",
       "3  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         19      67   30   \n",
       "4  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         19      89   30   \n",
       "\n",
       "   Length  Width  Height  \n",
       "0       3    640     480  \n",
       "1       3    640     480  \n",
       "2       2    640     480  \n",
       "3       2    640     480  \n",
       "4       3    640     480  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "88f50ce9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:15.597998Z",
     "start_time": "2023-08-22T08:04:14.639372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>950.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.082105</td>\n",
       "      <td>87.755789</td>\n",
       "      <td>29.354737</td>\n",
       "      <td>3.016842</td>\n",
       "      <td>641.347368</td>\n",
       "      <td>480.252632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.316026</td>\n",
       "      <td>46.654745</td>\n",
       "      <td>2.197195</td>\n",
       "      <td>1.568167</td>\n",
       "      <td>20.731496</td>\n",
       "      <td>3.887155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>540.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Frequency      Frames         FPS      Length       Width      Height\n",
       "count  950.000000  950.000000  950.000000  950.000000  950.000000  950.000000\n",
       "mean    19.082105   87.755789   29.354737    3.016842  641.347368  480.252632\n",
       "std      1.316026   46.654745    2.197195    1.568167   20.731496    3.887155\n",
       "min     18.000000   25.000000   11.000000    1.000000  640.000000  480.000000\n",
       "25%     18.000000   60.000000   29.000000    2.000000  640.000000  480.000000\n",
       "50%     19.000000   77.000000   30.000000    3.000000  640.000000  480.000000\n",
       "75%     20.000000   97.000000   30.000000    3.000000  640.000000  480.000000\n",
       "max     24.000000  540.000000   31.000000   18.000000  960.000000  540.000000"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "860c8cbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:16.394668Z",
     "start_time": "2023-08-22T08:04:15.600225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>804.000000</td>\n",
       "      <td>804.000000</td>\n",
       "      <td>804.000000</td>\n",
       "      <td>804.000000</td>\n",
       "      <td>804.000000</td>\n",
       "      <td>804.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.261194</td>\n",
       "      <td>76.113184</td>\n",
       "      <td>29.680348</td>\n",
       "      <td>2.593284</td>\n",
       "      <td>641.592040</td>\n",
       "      <td>480.298507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.722009</td>\n",
       "      <td>20.091965</td>\n",
       "      <td>0.479790</td>\n",
       "      <td>0.671427</td>\n",
       "      <td>22.528858</td>\n",
       "      <td>4.224161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>540.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Frequency      Frames         FPS      Length       Width      Height\n",
       "count  804.000000  804.000000  804.000000  804.000000  804.000000  804.000000\n",
       "mean    16.261194   76.113184   29.680348    2.593284  641.592040  480.298507\n",
       "std      1.722009   20.091965    0.479790    0.671427   22.528858    4.224161\n",
       "min     13.000000   45.000000   29.000000    2.000000  640.000000  480.000000\n",
       "25%     15.000000   60.000000   29.000000    2.000000  640.000000  480.000000\n",
       "50%     16.000000   74.000000   30.000000    2.000000  640.000000  480.000000\n",
       "75%     17.000000   88.000000   30.000000    3.000000  640.000000  480.000000\n",
       "max     20.000000  130.000000   31.000000    4.000000  960.000000  540.000000"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf = traindf[(traindf['Length'] > 1) & (traindf['FPS'] > 28) &(traindf['Frames'] < 131) ]\n",
    "#filtered_df = traindf[(traindf['Frames'] > 0) & (traindf['Frames'] < 121)]\n",
    "#filtered_df = traindf[traindf['Frames'] > 0]\n",
    "traindf= traindf.reset_index(drop=True)\n",
    "traindf['Frequency'] = traindf['Gloss'].map(traindf['Gloss'].value_counts())\n",
    "traindf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "5eeb8014",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:17.471134Z",
     "start_time": "2023-08-22T08:04:16.397431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P52</td>\n",
       "      <td>07157565148825373-seedAXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P28</td>\n",
       "      <td>7179300005186042-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P29</td>\n",
       "      <td>16216064841959765-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P37</td>\n",
       "      <td>6193814382865199-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>18</td>\n",
       "      <td>67</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P40</td>\n",
       "      <td>5947453960317015-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P40</td>\n",
       "      <td>929570016067665-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>18</td>\n",
       "      <td>112</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P16</td>\n",
       "      <td>904767261814883-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>18</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P43</td>\n",
       "      <td>016134052760367945-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>18</td>\n",
       "      <td>75</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P40</td>\n",
       "      <td>23099527328070546-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>18</td>\n",
       "      <td>91</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P37</td>\n",
       "      <td>21310388087265242-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>18</td>\n",
       "      <td>69</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                     Video file Gloss ASL-LEX Code  \\\n",
       "0            P52  07157565148825373-seedAXE.mp4   AXE     G_03_066   \n",
       "1            P28       7179300005186042-AXE.mp4   AXE     G_03_066   \n",
       "2            P29      16216064841959765-AXE.mp4   AXE     G_03_066   \n",
       "3            P37       6193814382865199-AXE.mp4   AXE     G_03_066   \n",
       "4            P40       5947453960317015-AXE.mp4   AXE     G_03_066   \n",
       "5            P40        929570016067665-AXE.mp4   AXE     G_03_066   \n",
       "6            P16        904767261814883-AXE.mp4   AXE     G_03_066   \n",
       "7            P43     016134052760367945-AXE.mp4   AXE     G_03_066   \n",
       "8            P40      23099527328070546-AXE.mp4   AXE     G_03_066   \n",
       "9            P37      21310388087265242-AXE.mp4   AXE     G_03_066   \n",
       "\n",
       "                                                Path  Frequency  Frames  FPS  \\\n",
       "0  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         18     100   31   \n",
       "1  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         18      81   30   \n",
       "2  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         18      47   30   \n",
       "3  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         18      67   30   \n",
       "4  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         18      89   30   \n",
       "5  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         18     112   29   \n",
       "6  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         18      64   30   \n",
       "7  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         18      75   30   \n",
       "8  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         18      91   29   \n",
       "9  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         18      69   30   \n",
       "\n",
       "   Length  Width  Height  \n",
       "0       3    640     480  \n",
       "1       3    640     480  \n",
       "2       2    640     480  \n",
       "3       2    640     480  \n",
       "4       3    640     480  \n",
       "5       4    640     480  \n",
       "6       2    640     480  \n",
       "7       2    640     480  \n",
       "8       3    640     480  \n",
       "9       2    640     480  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e5173282",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:19.209007Z",
     "start_time": "2023-08-22T08:04:17.474145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(traindf['Gloss'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "cb3e9805",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:22.324452Z",
     "start_time": "2023-08-22T08:04:19.210611Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 191/191 [00:01<00:00, 97.27it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "valdf[['Frames', 'FPS', 'Length', 'Width', 'Height']] = valdf['Path'].progress_apply(lambda x: pd.Series(frames_from_file(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "51f9d882",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:22.344042Z",
     "start_time": "2023-08-22T08:04:22.328072Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P39</td>\n",
       "      <td>19778675091674147-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P26</td>\n",
       "      <td>8581142177964065-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P39</td>\n",
       "      <td>3877478645046861-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P21</td>\n",
       "      <td>8521417940364975-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P5</td>\n",
       "      <td>9990244640190733-BACKPACK.mp4</td>\n",
       "      <td>BACKPACK</td>\n",
       "      <td>G_03_091</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                     Video file     Gloss ASL-LEX Code  \\\n",
       "0            P39      19778675091674147-AXE.mp4       AXE     G_03_066   \n",
       "1            P26       8581142177964065-AXE.mp4       AXE     G_03_066   \n",
       "2            P39       3877478645046861-AXE.mp4       AXE     G_03_066   \n",
       "3            P21       8521417940364975-AXE.mp4       AXE     G_03_066   \n",
       "4             P5  9990244640190733-BACKPACK.mp4  BACKPACK     G_03_091   \n",
       "\n",
       "                                                Path  Frequency  Frames  FPS  \\\n",
       "0  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4     121   30   \n",
       "1  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4      81   29   \n",
       "2  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4     120   30   \n",
       "3  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4      71   29   \n",
       "4  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          3      93   29   \n",
       "\n",
       "   Length  Width  Height  \n",
       "0       4    640     480  \n",
       "1       3    640     480  \n",
       "2       4    640     480  \n",
       "3       2    640     480  \n",
       "4       3    640     480  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "366e7b55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:23.472286Z",
     "start_time": "2023-08-22T08:04:22.346646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>191.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>191.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.963351</td>\n",
       "      <td>88.905759</td>\n",
       "      <td>29.706806</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>640.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.770316</td>\n",
       "      <td>36.214006</td>\n",
       "      <td>0.456423</td>\n",
       "      <td>1.248157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>640.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>640.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>640.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>117.500000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>640.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>640.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Frequency      Frames         FPS      Length  Width  Height\n",
       "count  191.000000  191.000000  191.000000  191.000000  191.0   191.0\n",
       "mean     3.963351   88.905759   29.706806    3.000000  640.0   480.0\n",
       "std      0.770316   36.214006    0.456423    1.248157    0.0     0.0\n",
       "min      3.000000   37.000000   29.000000    1.000000  640.0   480.0\n",
       "25%      3.000000   61.500000   29.000000    2.000000  640.0   480.0\n",
       "50%      4.000000   76.000000   30.000000    3.000000  640.0   480.0\n",
       "75%      4.000000  117.500000   30.000000    4.000000  640.0   480.0\n",
       "max      6.000000  207.000000   30.000000    7.000000  640.0   480.0"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2c20676f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:24.744874Z",
     "start_time": "2023-08-22T08:04:23.475799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>162.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.506173</td>\n",
       "      <td>78.203704</td>\n",
       "      <td>29.691358</td>\n",
       "      <td>2.623457</td>\n",
       "      <td>640.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.907162</td>\n",
       "      <td>23.787397</td>\n",
       "      <td>0.463365</td>\n",
       "      <td>0.772311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>640.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>640.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>71.500000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>640.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>640.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>640.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Frequency      Frames         FPS      Length  Width  Height\n",
       "count  162.000000  162.000000  162.000000  162.000000  162.0   162.0\n",
       "mean     3.506173   78.203704   29.691358    2.623457  640.0   480.0\n",
       "std      0.907162   23.787397    0.463365    0.772311    0.0     0.0\n",
       "min      2.000000   45.000000   29.000000    2.000000  640.0   480.0\n",
       "25%      3.000000   59.250000   29.000000    2.000000  640.0   480.0\n",
       "50%      4.000000   71.500000   30.000000    2.000000  640.0   480.0\n",
       "75%      4.000000   92.000000   30.000000    3.000000  640.0   480.0\n",
       "max      5.000000  130.000000   30.000000    4.000000  640.0   480.0"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf = valdf[(valdf['Length'] > 1) & (valdf['FPS'] > 28) &(valdf['Frames'] < 131) ]\n",
    "#filtered_df = traindf[(traindf['Frames'] > 0) & (traindf['Frames'] < 121)]\n",
    "#filtered_df = traindf[traindf['Frames'] > 0]\n",
    "valdf = valdf.reset_index(drop=True)\n",
    "valdf['Frequency'] = valdf['Gloss'].map(valdf['Gloss'].value_counts())\n",
    "valdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "d63acde7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:26.071439Z",
     "start_time": "2023-08-22T08:04:24.747503Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(valdf['Gloss'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "6c7f817b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:27.460548Z",
     "start_time": "2023-08-22T08:04:26.090535Z"
    }
   },
   "outputs": [],
   "source": [
    "testdf['Path'] = testdf['Path'].str.replace('file:///media/kristian/HDD/ASL_Citizen/ASL_Citizen/', 'file:///home/kristian/ASL_Citizen/',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "db83287e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:36.407523Z",
     "start_time": "2023-08-22T08:04:27.462373Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 729/729 [00:07<00:00, 91.51it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "testdf[['Frames', 'FPS', 'Length', 'Width', 'Height']] = testdf['Path'].progress_apply(lambda x: pd.Series(frames_from_file(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7395e5bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:36.421457Z",
     "start_time": "2023-08-22T08:04:36.409656Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P15</td>\n",
       "      <td>33721516025652254-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/33721...</td>\n",
       "      <td>15</td>\n",
       "      <td>196</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P47</td>\n",
       "      <td>519067006979435-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/51906...</td>\n",
       "      <td>15</td>\n",
       "      <td>102</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P35</td>\n",
       "      <td>5104381603195376-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/51043...</td>\n",
       "      <td>15</td>\n",
       "      <td>70</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P42</td>\n",
       "      <td>44458614013793873-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/44458...</td>\n",
       "      <td>15</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>960</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P42</td>\n",
       "      <td>9604797909481075-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/96047...</td>\n",
       "      <td>15</td>\n",
       "      <td>66</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>960</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                 Video file Gloss ASL-LEX Code  \\\n",
       "0            P15  33721516025652254-AXE.mp4   AXE     G_03_066   \n",
       "1            P47    519067006979435-AXE.mp4   AXE     G_03_066   \n",
       "2            P35   5104381603195376-AXE.mp4   AXE     G_03_066   \n",
       "3            P42  44458614013793873-AXE.mp4   AXE     G_03_066   \n",
       "4            P42   9604797909481075-AXE.mp4   AXE     G_03_066   \n",
       "\n",
       "                                                Path  Frequency  Frames  FPS  \\\n",
       "0  file:///home/kristian/ASL_Citizen/videos/33721...         15     196   29   \n",
       "1  file:///home/kristian/ASL_Citizen/videos/51906...         15     102   26   \n",
       "2  file:///home/kristian/ASL_Citizen/videos/51043...         15      70   29   \n",
       "3  file:///home/kristian/ASL_Citizen/videos/44458...         15      57   30   \n",
       "4  file:///home/kristian/ASL_Citizen/videos/96047...         15      66   30   \n",
       "\n",
       "   Length  Width  Height  \n",
       "0       7    640     480  \n",
       "1       4    640     480  \n",
       "2       2    640     480  \n",
       "3       2    960     540  \n",
       "4       2    960     540  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "3aba3d90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:37.312514Z",
     "start_time": "2023-08-22T08:04:36.423283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>729.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>729.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.978052</td>\n",
       "      <td>75.192044</td>\n",
       "      <td>28.696845</td>\n",
       "      <td>2.624143</td>\n",
       "      <td>684.334705</td>\n",
       "      <td>488.312757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.229192</td>\n",
       "      <td>27.848864</td>\n",
       "      <td>3.113689</td>\n",
       "      <td>1.003439</td>\n",
       "      <td>110.626974</td>\n",
       "      <td>20.742558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>540.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Frequency      Frames         FPS      Length       Width      Height\n",
       "count  729.000000  729.000000  729.000000  729.000000  729.000000  729.000000\n",
       "mean    14.978052   75.192044   28.696845    2.624143  684.334705  488.312757\n",
       "std      2.229192   27.848864    3.113689    1.003439  110.626974   20.742558\n",
       "min      9.000000   10.000000   14.000000    0.000000  640.000000  480.000000\n",
       "25%     14.000000   56.000000   29.000000    2.000000  640.000000  480.000000\n",
       "50%     15.000000   73.000000   30.000000    3.000000  640.000000  480.000000\n",
       "75%     16.000000   90.000000   30.000000    3.000000  640.000000  480.000000\n",
       "max     20.000000  234.000000   31.000000    8.000000  960.000000  540.000000"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "1f35b8a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:37.896411Z",
     "start_time": "2023-08-22T08:04:37.315592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.254682</td>\n",
       "      <td>77.256554</td>\n",
       "      <td>29.702247</td>\n",
       "      <td>2.619850</td>\n",
       "      <td>688.539326</td>\n",
       "      <td>489.101124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.311308</td>\n",
       "      <td>19.420007</td>\n",
       "      <td>0.526337</td>\n",
       "      <td>0.670792</td>\n",
       "      <td>114.896647</td>\n",
       "      <td>21.543121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>540.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Frequency      Frames         FPS      Length       Width      Height\n",
       "count  534.000000  534.000000  534.000000  534.000000  534.000000  534.000000\n",
       "mean    11.254682   77.256554   29.702247    2.619850  688.539326  489.101124\n",
       "std      2.311308   19.420007    0.526337    0.670792  114.896647   21.543121\n",
       "min      5.000000   45.000000   29.000000    2.000000  640.000000  480.000000\n",
       "25%     10.000000   61.000000   29.000000    2.000000  640.000000  480.000000\n",
       "50%     12.000000   75.000000   30.000000    3.000000  640.000000  480.000000\n",
       "75%     13.000000   91.000000   30.000000    3.000000  640.000000  480.000000\n",
       "max     15.000000  130.000000   31.000000    4.000000  960.000000  540.000000"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf = testdf[(testdf['Length'] > 1) & (testdf['FPS'] > 28) &(testdf['Frames'] < 131) ]\n",
    "#filtered_df = traindf[(traindf['Frames'] > 0) & (traindf['Frames'] < 121)]\n",
    "#filtered_df = traindf[traindf['Frames'] > 0]\n",
    "testdf = testdf.reset_index(drop=True)\n",
    "testdf['Frequency'] = testdf['Gloss'].map(testdf['Gloss'].value_counts())\n",
    "testdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f92bddde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:38.861578Z",
     "start_time": "2023-08-22T08:04:37.900036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(testdf['Gloss'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "ec5b40db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:39.765186Z",
     "start_time": "2023-08-22T08:04:38.865498Z"
    }
   },
   "outputs": [],
   "source": [
    "traintest = pd.concat([traindf,testdf])\n",
    "traintest['Frequency'] = traintest['Gloss'].map(traintest['Gloss'].value_counts())\n",
    "traintest = traintest.sort_values(by='Gloss')\n",
    "\n",
    "traintest = traintest.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "3691cfa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:40.575756Z",
     "start_time": "2023-08-22T08:04:39.767163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>P37</td>\n",
       "      <td>8639087490010726-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>29</td>\n",
       "      <td>59</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>P40</td>\n",
       "      <td>6445331634562388-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>29</td>\n",
       "      <td>89</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>P37</td>\n",
       "      <td>6237575353180616-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>29</td>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>P37</td>\n",
       "      <td>16185522171162914-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>29</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>P15</td>\n",
       "      <td>540014801916062-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/54001...</td>\n",
       "      <td>29</td>\n",
       "      <td>79</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Participant ID                      Video file    Gloss ASL-LEX Code  \\\n",
       "1333            P37   8639087490010726-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "1334            P40   6445331634562388-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "1335            P37   6237575353180616-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "1336            P37  16185522171162914-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "1337            P15    540014801916062-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "\n",
       "                                                   Path  Frequency  Frames  \\\n",
       "1333  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         29      59   \n",
       "1334  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         29      89   \n",
       "1335  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         29      56   \n",
       "1336  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         29      64   \n",
       "1337  file:///home/kristian/ASL_Citizen/videos/54001...         29      79   \n",
       "\n",
       "      FPS  Length  Width  Height  \n",
       "1333   29       2    640     480  \n",
       "1334   30       3    640     480  \n",
       "1335   30       2    640     480  \n",
       "1336   30       2    640     480  \n",
       "1337   29       3    640     480  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "0016c9ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:41.110133Z",
     "start_time": "2023-08-22T08:04:40.579844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.203288</td>\n",
       "      <td>76.569507</td>\n",
       "      <td>29.689088</td>\n",
       "      <td>2.603886</td>\n",
       "      <td>660.328849</td>\n",
       "      <td>483.811659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.306202</td>\n",
       "      <td>19.827114</td>\n",
       "      <td>0.498810</td>\n",
       "      <td>0.671049</td>\n",
       "      <td>78.080254</td>\n",
       "      <td>14.640048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>540.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Frequency       Frames          FPS       Length        Width  \\\n",
       "count  1338.000000  1338.000000  1338.000000  1338.000000  1338.000000   \n",
       "mean     27.203288    76.569507    29.689088     2.603886   660.328849   \n",
       "std       3.306202    19.827114     0.498810     0.671049    78.080254   \n",
       "min      20.000000    45.000000    29.000000     2.000000   640.000000   \n",
       "25%      25.000000    60.000000    29.000000     2.000000   640.000000   \n",
       "50%      28.000000    75.000000    30.000000     2.000000   640.000000   \n",
       "75%      30.000000    89.000000    30.000000     3.000000   640.000000   \n",
       "max      32.000000   130.000000    31.000000     4.000000   960.000000   \n",
       "\n",
       "            Height  \n",
       "count  1338.000000  \n",
       "mean    483.811659  \n",
       "std      14.640048  \n",
       "min     480.000000  \n",
       "25%     480.000000  \n",
       "50%     480.000000  \n",
       "75%     480.000000  \n",
       "max     540.000000  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ff14c27e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:41.941245Z",
     "start_time": "2023-08-22T08:04:41.112422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "Frequency=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "rgb(127,39,4)",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "nbinsx": 20,
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          32,
          32,
          32,
          31,
          31,
          30,
          30,
          30,
          30,
          30,
          30,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          27,
          27,
          26,
          26,
          25,
          25,
          24,
          24,
          24,
          23,
          23,
          23,
          22,
          22,
          22,
          22,
          22,
          21,
          20,
          20,
          20
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Frequency Data Distribution In Final Training Dataframe"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Frequency"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"d46258df-8189-490c-89c2-fca0ce0e8fbc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d46258df-8189-490c-89c2-fca0ce0e8fbc\")) {                    Plotly.newPlot(                        \"d46258df-8189-490c-89c2-fca0ce0e8fbc\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"Frequency=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"rgb(127,39,4)\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"nbinsx\":20,\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[32,32,32,31,31,30,30,30,30,30,30,29,29,29,29,29,29,29,29,28,28,28,28,28,28,28,28,28,28,27,27,26,26,25,25,24,24,24,23,23,23,22,22,22,22,22,21,20,20,20],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Frequency\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Frequency Data Distribution In Final Training Dataframe\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d46258df-8189-490c-89c2-fca0ce0e8fbc');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.histogram(traintest.groupby(['Gloss'], sort=True)['Frequency'].count().sort_values(ascending=False).reset_index(),\n",
    "                    x='Frequency',\n",
    "                    color_discrete_sequence=px.colors.sequential.Oranges_r,\n",
    "                    title='Frequency Data Distribution In Final Training Dataframe',nbins=20)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "c8c45d91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:42.289865Z",
     "start_time": "2023-08-22T08:04:41.944020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gloss</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOG</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BASKETBALL</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DARK</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROCKINGCHAIR</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PARTY</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BELT</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MOVIE</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MECHANIC</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CHRISTMAS</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HALLOWEEN</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ELEVATOR</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AXE</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HURDLE/TRIP</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HOSPITAL</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FINE</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DOWNSIZE</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DECIDE</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CANCER</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BACKPACK</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DRAG</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BREAKFAST</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SHAVE</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NOON</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DEAF</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MICROSCOPE</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FOREIGNER</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TWINS</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>EDIT</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CONFUSED</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>BITE</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DEMAND</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DINNER</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RIVER</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PATIENT</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>THEY</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LUNCH</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DEVELOP</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>MEAT</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SINK</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>EAT</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>BEE</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>GUESS</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LOCK</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>JEWELRY</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>KNIGHT</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RAZOR</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SQUEEZE</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>MAPLE</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Gloss  Frequency\n",
       "0            DOG         32\n",
       "1     BASKETBALL         32\n",
       "2           DARK         32\n",
       "3   ROCKINGCHAIR         31\n",
       "4          PARTY         31\n",
       "5           BELT         30\n",
       "6          MOVIE         30\n",
       "7       MECHANIC         30\n",
       "8      CHRISTMAS         30\n",
       "9      HALLOWEEN         30\n",
       "10      ELEVATOR         30\n",
       "11           AXE         29\n",
       "12   HURDLE/TRIP         29\n",
       "13      HOSPITAL         29\n",
       "14          FINE         29\n",
       "15      DOWNSIZE         29\n",
       "16       WHATFOR         29\n",
       "17        DECIDE         29\n",
       "18        CANCER         29\n",
       "19      BACKPACK         28\n",
       "20          DRAG         28\n",
       "21     BREAKFAST         28\n",
       "22         SHAVE         28\n",
       "23          NOON         28\n",
       "24          DEAF         28\n",
       "25    MICROSCOPE         28\n",
       "26     FOREIGNER         28\n",
       "27         TWINS         28\n",
       "28          EDIT         28\n",
       "29      CONFUSED         27\n",
       "30          BITE         27\n",
       "31        DEMAND         26\n",
       "32        DINNER         26\n",
       "33         RIVER         25\n",
       "34       PATIENT         25\n",
       "35          THEY         24\n",
       "36         LUNCH         24\n",
       "37       DEVELOP         24\n",
       "38          MEAT         23\n",
       "39          SINK         23\n",
       "40           EAT         23\n",
       "41           BEE         22\n",
       "42         GUESS         22\n",
       "43          LOCK         22\n",
       "44       JEWELRY         22\n",
       "45         FLOAT         22\n",
       "46        KNIGHT         21\n",
       "47         RAZOR         20\n",
       "48       SQUEEZE         20\n",
       "49         MAPLE         20"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.groupby(['Gloss'], sort=True)['Frequency'].count().sort_values(ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "7692d95c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:42.958382Z",
     "start_time": "2023-08-22T08:04:42.293111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Frames=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "rgb(0,68,27)"
         },
         "name": "",
         "notched": false,
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "box",
         "x0": " ",
         "xaxis": "x",
         "y": [
          100,
          66,
          96,
          54,
          59,
          82,
          94,
          53,
          77,
          88,
          57,
          73,
          52,
          81,
          70,
          65,
          64,
          112,
          89,
          67,
          47,
          81,
          91,
          69,
          72,
          75,
          70,
          58,
          57,
          78,
          59,
          85,
          116,
          57,
          72,
          74,
          78,
          57,
          95,
          65,
          126,
          45,
          63,
          70,
          89,
          45,
          47,
          82,
          73,
          99,
          88,
          65,
          97,
          76,
          90,
          48,
          129,
          56,
          64,
          61,
          96,
          50,
          62,
          45,
          63,
          120,
          67,
          77,
          53,
          80,
          53,
          67,
          82,
          48,
          89,
          80,
          53,
          58,
          74,
          95,
          91,
          110,
          83,
          48,
          74,
          67,
          78,
          66,
          83,
          87,
          109,
          72,
          101,
          72,
          82,
          64,
          46,
          80,
          49,
          57,
          98,
          68,
          83,
          83,
          48,
          50,
          86,
          53,
          60,
          76,
          85,
          73,
          85,
          59,
          91,
          67,
          94,
          82,
          106,
          81,
          69,
          71,
          51,
          71,
          80,
          60,
          89,
          130,
          90,
          104,
          68,
          118,
          112,
          51,
          56,
          97,
          88,
          104,
          82,
          61,
          96,
          53,
          112,
          56,
          106,
          67,
          72,
          86,
          58,
          49,
          61,
          80,
          60,
          66,
          52,
          77,
          63,
          81,
          85,
          45,
          85,
          52,
          111,
          93,
          68,
          57,
          95,
          97,
          90,
          47,
          75,
          63,
          84,
          66,
          104,
          56,
          73,
          94,
          77,
          86,
          85,
          64,
          80,
          72,
          68,
          60,
          72,
          85,
          94,
          91,
          45,
          77,
          56,
          60,
          71,
          57,
          59,
          90,
          66,
          59,
          52,
          87,
          71,
          114,
          86,
          65,
          47,
          84,
          94,
          87,
          86,
          83,
          69,
          103,
          55,
          55,
          84,
          104,
          73,
          83,
          58,
          61,
          46,
          100,
          80,
          64,
          64,
          89,
          69,
          85,
          100,
          98,
          68,
          62,
          53,
          65,
          47,
          51,
          111,
          67,
          65,
          95,
          57,
          48,
          87,
          80,
          56,
          103,
          53,
          104,
          59,
          71,
          77,
          54,
          77,
          104,
          54,
          65,
          69,
          105,
          71,
          92,
          58,
          123,
          54,
          69,
          87,
          59,
          94,
          97,
          106,
          84,
          108,
          53,
          86,
          91,
          79,
          66,
          89,
          63,
          88,
          76,
          118,
          89,
          73,
          52,
          66,
          56,
          81,
          62,
          78,
          55,
          114,
          68,
          81,
          76,
          67,
          62,
          65,
          88,
          50,
          70,
          62,
          53,
          52,
          113,
          64,
          104,
          77,
          65,
          78,
          111,
          64,
          82,
          71,
          63,
          80,
          49,
          92,
          94,
          58,
          57,
          76,
          81,
          50,
          60,
          85,
          59,
          79,
          79,
          88,
          55,
          54,
          51,
          64,
          114,
          50,
          57,
          52,
          65,
          52,
          80,
          62,
          77,
          84,
          48,
          70,
          49,
          81,
          59,
          88,
          53,
          51,
          85,
          48,
          86,
          75,
          74,
          83,
          97,
          67,
          100,
          45,
          73,
          65,
          71,
          83,
          57,
          57,
          86,
          54,
          49,
          98,
          58,
          84,
          93,
          61,
          99,
          48,
          57,
          98,
          49,
          65,
          79,
          122,
          75,
          88,
          99,
          97,
          48,
          63,
          103,
          67,
          87,
          49,
          99,
          71,
          94,
          69,
          123,
          56,
          66,
          58,
          73,
          93,
          91,
          98,
          68,
          67,
          73,
          80,
          98,
          73,
          61,
          123,
          69,
          112,
          86,
          68,
          62,
          85,
          94,
          66,
          92,
          87,
          108,
          67,
          93,
          64,
          60,
          105,
          82,
          89,
          55,
          51,
          77,
          93,
          73,
          109,
          65,
          68,
          75,
          50,
          70,
          74,
          93,
          55,
          73,
          49,
          76,
          50,
          71,
          65,
          65,
          47,
          78,
          96,
          112,
          81,
          97,
          45,
          76,
          61,
          97,
          55,
          70,
          99,
          69,
          75,
          57,
          53,
          81,
          123,
          72,
          79,
          78,
          87,
          52,
          54,
          78,
          98,
          61,
          82,
          59,
          71,
          83,
          89,
          108,
          82,
          93,
          65,
          53,
          74,
          97,
          87,
          64,
          114,
          49,
          61,
          84,
          50,
          93,
          63,
          116,
          119,
          55,
          53,
          89,
          60,
          59,
          80,
          61,
          45,
          75,
          109,
          95,
          98,
          105,
          87,
          80,
          88,
          59,
          86,
          99,
          111,
          71,
          82,
          60,
          77,
          61,
          105,
          63,
          53,
          78,
          59,
          116,
          66,
          81,
          78,
          107,
          79,
          83,
          60,
          81,
          51,
          47,
          46,
          77,
          80,
          73,
          99,
          98,
          60,
          69,
          55,
          49,
          69,
          61,
          54,
          77,
          89,
          130,
          64,
          49,
          101,
          66,
          60,
          71,
          81,
          86,
          71,
          123,
          90,
          104,
          59,
          89,
          48,
          84,
          108,
          71,
          85,
          87,
          85,
          101,
          50,
          55,
          103,
          54,
          102,
          78,
          83,
          51,
          76,
          80,
          72,
          102,
          90,
          109,
          71,
          102,
          100,
          76,
          90,
          62,
          116,
          114,
          96,
          75,
          113,
          86,
          74,
          81,
          105,
          81,
          57,
          94,
          51,
          77,
          65,
          58,
          113,
          54,
          84,
          75,
          67,
          52,
          55,
          50,
          66,
          47,
          93,
          102,
          49,
          46,
          95,
          60,
          64,
          66,
          94,
          100,
          73,
          94,
          97,
          55,
          52,
          47,
          84,
          99,
          69,
          114,
          114,
          102,
          86,
          93,
          68,
          83,
          54,
          103,
          95,
          107,
          64,
          115,
          116,
          128,
          60,
          55,
          128,
          106,
          74,
          88,
          81,
          77,
          117,
          130,
          123,
          55,
          100,
          70,
          71,
          57,
          79,
          83,
          100,
          106,
          75,
          53,
          113,
          86,
          129,
          89,
          93,
          63,
          56,
          122,
          67,
          62,
          55,
          65,
          60,
          96,
          72,
          98,
          64,
          68,
          111,
          117,
          72,
          46,
          73,
          48,
          73,
          47,
          64,
          78,
          82,
          55,
          73,
          49,
          46,
          85,
          91,
          67,
          78,
          91,
          84,
          111,
          65,
          52,
          68,
          85,
          65,
          96,
          52,
          87,
          88,
          62,
          83,
          112,
          98,
          60,
          87,
          76,
          75,
          63,
          83,
          76,
          64,
          51,
          84,
          90,
          60,
          101,
          95,
          64,
          80,
          48,
          86,
          48,
          62,
          55,
          106,
          63,
          80,
          68,
          59,
          82,
          52,
          124,
          67,
          90,
          78,
          57,
          98,
          82,
          70,
          67,
          46,
          53,
          54,
          55,
          125,
          77,
          78,
          106,
          50,
          56,
          62,
          56,
          68,
          86,
          71,
          53,
          55,
          49,
          87,
          88,
          54,
          102,
          51,
          59,
          94,
          126,
          77,
          56,
          46,
          103,
          81,
          110,
          61,
          69,
          45,
          47,
          120,
          68,
          80,
          57,
          70,
          123,
          94,
          66,
          95,
          77,
          73,
          84,
          106,
          52,
          67,
          89,
          47,
          104,
          69,
          51,
          64,
          81,
          59,
          77,
          96,
          74,
          65,
          93,
          82,
          94,
          88,
          109,
          95,
          120,
          79,
          95,
          49,
          85,
          59,
          52,
          74,
          83,
          97,
          96,
          52,
          94,
          128,
          90,
          60,
          93,
          75,
          116,
          94,
          71,
          73,
          54,
          71,
          46,
          45,
          101,
          58,
          130,
          108,
          89,
          50,
          90,
          45,
          63,
          65,
          63,
          78,
          48,
          62,
          57,
          62,
          50,
          59,
          58,
          57,
          48,
          83,
          87,
          110,
          58,
          75,
          70,
          54,
          88,
          49,
          83,
          119,
          82,
          51,
          65,
          83,
          47,
          72,
          77,
          63,
          108,
          56,
          118,
          120,
          80,
          128,
          94,
          89,
          78,
          84,
          72,
          80,
          121,
          95,
          50,
          59,
          64,
          92,
          52,
          67,
          110,
          72,
          78,
          47,
          85,
          68,
          103,
          93,
          70,
          87,
          53,
          78,
          52,
          84,
          80,
          100,
          76,
          104,
          68,
          58,
          64,
          69,
          114,
          59,
          80,
          103,
          126,
          95,
          87,
          96,
          97,
          106,
          91,
          57,
          75,
          84,
          78,
          45,
          72,
          108,
          89,
          70,
          75,
          59,
          77,
          80,
          60,
          69,
          75,
          97,
          90,
          64,
          52,
          62,
          117,
          95,
          96,
          79,
          63,
          109,
          92,
          80,
          58,
          71,
          57,
          86,
          46,
          105,
          60,
          102,
          77,
          107,
          126,
          47,
          71,
          68,
          72,
          82,
          86,
          66,
          111,
          57,
          74,
          86,
          83,
          90,
          48,
          56,
          49,
          115,
          88,
          82,
          106,
          53,
          46,
          66,
          94,
          85,
          59,
          73,
          64,
          79,
          110,
          80,
          100,
          51,
          73,
          75,
          82,
          79,
          117,
          49,
          61,
          62,
          61,
          74,
          100,
          88,
          54,
          98,
          87,
          80,
          81,
          65,
          94,
          79,
          66,
          70,
          47,
          124,
          76,
          124,
          51,
          75,
          56,
          64,
          78,
          58,
          91,
          65,
          97,
          57,
          65,
          98,
          68,
          52,
          57,
          76,
          93,
          53,
          51,
          73,
          73,
          71,
          70,
          115,
          46,
          61,
          67,
          110,
          90,
          64,
          108,
          49,
          60,
          72,
          57,
          89,
          125,
          59,
          65,
          56,
          79,
          86,
          70,
          53,
          79,
          47,
          89,
          61,
          103,
          72,
          80,
          96,
          110,
          53,
          83,
          110,
          89,
          53,
          104,
          75,
          48,
          60,
          73,
          54,
          70,
          70,
          64,
          103,
          58,
          87,
          93,
          71,
          64,
          68,
          106,
          64,
          57,
          78,
          72,
          74,
          78,
          88,
          71,
          103,
          114,
          102,
          70,
          50,
          113,
          75,
          79,
          71,
          95,
          80,
          61,
          71,
          92,
          72,
          47,
          59,
          62,
          87,
          116,
          124,
          111,
          88,
          47,
          50,
          66,
          73,
          71,
          86,
          89,
          96,
          101,
          97,
          67,
          53,
          75,
          74,
          61,
          78,
          78,
          57,
          79,
          106,
          59,
          102,
          78,
          68,
          63,
          62,
          81,
          97,
          60,
          85,
          66,
          107,
          86,
          100,
          80,
          92,
          110,
          60,
          76,
          70,
          104,
          87,
          58,
          68,
          87,
          71,
          74,
          123,
          54,
          53,
          105,
          109,
          62,
          52,
          78,
          95,
          97,
          55,
          95,
          67,
          94,
          78,
          85,
          78,
          105,
          94,
          71,
          47,
          100,
          75,
          84,
          47,
          79,
          57,
          87,
          79,
          75,
          84,
          69,
          76,
          67,
          64,
          87,
          89,
          49,
          78,
          88,
          107,
          103,
          53,
          61,
          87,
          100,
          122,
          85,
          45,
          61,
          75,
          70,
          65,
          62,
          98,
          64,
          51,
          61,
          63,
          86,
          92,
          69,
          45,
          81,
          58,
          57,
          90,
          54,
          49,
          52,
          90,
          53,
          79,
          73,
          74,
          57,
          59,
          73,
          59,
          106,
          126,
          69,
          47,
          65,
          76,
          89,
          75,
          62,
          52,
          53,
          56,
          45,
          116,
          80,
          53,
          83,
          89,
          56,
          84,
          48,
          66,
          52,
          82,
          66,
          92,
          65,
          61,
          73,
          84,
          47,
          59,
          101,
          74,
          75,
          89,
          56,
          61,
          59,
          89,
          56,
          64,
          79
         ],
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "boxmode": "group",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Video Frames Boxplot In Final Training Dataframe"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Frames"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"badf729e-6cfb-425d-b48d-9df52ad83ee3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"badf729e-6cfb-425d-b48d-9df52ad83ee3\")) {                    Plotly.newPlot(                        \"badf729e-6cfb-425d-b48d-9df52ad83ee3\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Frames=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"rgb(0,68,27)\"},\"name\":\"\",\"notched\":false,\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[100,66,96,54,59,82,94,53,77,88,57,73,52,81,70,65,64,112,89,67,47,81,91,69,72,75,70,58,57,78,59,85,116,57,72,74,78,57,95,65,126,45,63,70,89,45,47,82,73,99,88,65,97,76,90,48,129,56,64,61,96,50,62,45,63,120,67,77,53,80,53,67,82,48,89,80,53,58,74,95,91,110,83,48,74,67,78,66,83,87,109,72,101,72,82,64,46,80,49,57,98,68,83,83,48,50,86,53,60,76,85,73,85,59,91,67,94,82,106,81,69,71,51,71,80,60,89,130,90,104,68,118,112,51,56,97,88,104,82,61,96,53,112,56,106,67,72,86,58,49,61,80,60,66,52,77,63,81,85,45,85,52,111,93,68,57,95,97,90,47,75,63,84,66,104,56,73,94,77,86,85,64,80,72,68,60,72,85,94,91,45,77,56,60,71,57,59,90,66,59,52,87,71,114,86,65,47,84,94,87,86,83,69,103,55,55,84,104,73,83,58,61,46,100,80,64,64,89,69,85,100,98,68,62,53,65,47,51,111,67,65,95,57,48,87,80,56,103,53,104,59,71,77,54,77,104,54,65,69,105,71,92,58,123,54,69,87,59,94,97,106,84,108,53,86,91,79,66,89,63,88,76,118,89,73,52,66,56,81,62,78,55,114,68,81,76,67,62,65,88,50,70,62,53,52,113,64,104,77,65,78,111,64,82,71,63,80,49,92,94,58,57,76,81,50,60,85,59,79,79,88,55,54,51,64,114,50,57,52,65,52,80,62,77,84,48,70,49,81,59,88,53,51,85,48,86,75,74,83,97,67,100,45,73,65,71,83,57,57,86,54,49,98,58,84,93,61,99,48,57,98,49,65,79,122,75,88,99,97,48,63,103,67,87,49,99,71,94,69,123,56,66,58,73,93,91,98,68,67,73,80,98,73,61,123,69,112,86,68,62,85,94,66,92,87,108,67,93,64,60,105,82,89,55,51,77,93,73,109,65,68,75,50,70,74,93,55,73,49,76,50,71,65,65,47,78,96,112,81,97,45,76,61,97,55,70,99,69,75,57,53,81,123,72,79,78,87,52,54,78,98,61,82,59,71,83,89,108,82,93,65,53,74,97,87,64,114,49,61,84,50,93,63,116,119,55,53,89,60,59,80,61,45,75,109,95,98,105,87,80,88,59,86,99,111,71,82,60,77,61,105,63,53,78,59,116,66,81,78,107,79,83,60,81,51,47,46,77,80,73,99,98,60,69,55,49,69,61,54,77,89,130,64,49,101,66,60,71,81,86,71,123,90,104,59,89,48,84,108,71,85,87,85,101,50,55,103,54,102,78,83,51,76,80,72,102,90,109,71,102,100,76,90,62,116,114,96,75,113,86,74,81,105,81,57,94,51,77,65,58,113,54,84,75,67,52,55,50,66,47,93,102,49,46,95,60,64,66,94,100,73,94,97,55,52,47,84,99,69,114,114,102,86,93,68,83,54,103,95,107,64,115,116,128,60,55,128,106,74,88,81,77,117,130,123,55,100,70,71,57,79,83,100,106,75,53,113,86,129,89,93,63,56,122,67,62,55,65,60,96,72,98,64,68,111,117,72,46,73,48,73,47,64,78,82,55,73,49,46,85,91,67,78,91,84,111,65,52,68,85,65,96,52,87,88,62,83,112,98,60,87,76,75,63,83,76,64,51,84,90,60,101,95,64,80,48,86,48,62,55,106,63,80,68,59,82,52,124,67,90,78,57,98,82,70,67,46,53,54,55,125,77,78,106,50,56,62,56,68,86,71,53,55,49,87,88,54,102,51,59,94,126,77,56,46,103,81,110,61,69,45,47,120,68,80,57,70,123,94,66,95,77,73,84,106,52,67,89,47,104,69,51,64,81,59,77,96,74,65,93,82,94,88,109,95,120,79,95,49,85,59,52,74,83,97,96,52,94,128,90,60,93,75,116,94,71,73,54,71,46,45,101,58,130,108,89,50,90,45,63,65,63,78,48,62,57,62,50,59,58,57,48,83,87,110,58,75,70,54,88,49,83,119,82,51,65,83,47,72,77,63,108,56,118,120,80,128,94,89,78,84,72,80,121,95,50,59,64,92,52,67,110,72,78,47,85,68,103,93,70,87,53,78,52,84,80,100,76,104,68,58,64,69,114,59,80,103,126,95,87,96,97,106,91,57,75,84,78,45,72,108,89,70,75,59,77,80,60,69,75,97,90,64,52,62,117,95,96,79,63,109,92,80,58,71,57,86,46,105,60,102,77,107,126,47,71,68,72,82,86,66,111,57,74,86,83,90,48,56,49,115,88,82,106,53,46,66,94,85,59,73,64,79,110,80,100,51,73,75,82,79,117,49,61,62,61,74,100,88,54,98,87,80,81,65,94,79,66,70,47,124,76,124,51,75,56,64,78,58,91,65,97,57,65,98,68,52,57,76,93,53,51,73,73,71,70,115,46,61,67,110,90,64,108,49,60,72,57,89,125,59,65,56,79,86,70,53,79,47,89,61,103,72,80,96,110,53,83,110,89,53,104,75,48,60,73,54,70,70,64,103,58,87,93,71,64,68,106,64,57,78,72,74,78,88,71,103,114,102,70,50,113,75,79,71,95,80,61,71,92,72,47,59,62,87,116,124,111,88,47,50,66,73,71,86,89,96,101,97,67,53,75,74,61,78,78,57,79,106,59,102,78,68,63,62,81,97,60,85,66,107,86,100,80,92,110,60,76,70,104,87,58,68,87,71,74,123,54,53,105,109,62,52,78,95,97,55,95,67,94,78,85,78,105,94,71,47,100,75,84,47,79,57,87,79,75,84,69,76,67,64,87,89,49,78,88,107,103,53,61,87,100,122,85,45,61,75,70,65,62,98,64,51,61,63,86,92,69,45,81,58,57,90,54,49,52,90,53,79,73,74,57,59,73,59,106,126,69,47,65,76,89,75,62,52,53,56,45,116,80,53,83,89,56,84,48,66,52,82,66,92,65,61,73,84,47,59,101,74,75,89,56,61,59,89,56,64,79],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Frames\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Video Frames Boxplot In Final Training Dataframe\"},\"boxmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('badf729e-6cfb-425d-b48d-9df52ad83ee3');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.box(traintest, y=\"Frames\", title=\"Video Frames Boxplot In Final Training Dataframe\",\n",
    "                                            color_discrete_sequence=px.colors.sequential.Greens_r)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "9ff961f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:43.545584Z",
     "start_time": "2023-08-22T08:04:42.961348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "9b98cfff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:05:16.060783Z",
     "start_time": "2023-08-22T08:05:16.053405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest['Participant ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "6ccde17f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:05:05.606291Z",
     "start_time": "2023-08-22T08:05:05.600924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf['Participant ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f4ff8ddd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T08:04:44.406239Z",
     "start_time": "2023-08-22T08:04:44.061181Z"
    }
   },
   "outputs": [],
   "source": [
    "traindf['Path'] = traindf['Path'].str.replace('file:///media/kristian/HDD/ASL_Citizen/ASL_Citizen/', 'file:///home/kristian/ASL_Citizen/',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "55f0bfc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:16:58.101926Z",
     "start_time": "2023-08-10T08:07:36.613958Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 804/804 [1:09:21<00:00,  5.18s/it]\n"
     ]
    }
   ],
   "source": [
    "keypoints_series = traindf['Path'].progress_apply(extract_keypoints_from_file)\n",
    "np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/train_keypoints.npy\", keypoints_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1885dfd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T22:57:26.182953Z",
     "start_time": "2023-08-10T21:46:53.518876Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 804/804 [1:10:32<00:00,  5.26s/it]\n"
     ]
    }
   ],
   "source": [
    "keypoints_series = traindf['Path'].progress_apply(extract_keypoints_from_file_flip)\n",
    "np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/train_keypoints_flip.npy\", keypoints_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e614bc50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T22:58:00.594520Z",
     "start_time": "2023-08-10T22:58:00.591001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(804,)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e13534ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:17:38.147362Z",
     "start_time": "2023-08-10T09:17:37.294495Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/train_keypoints.npy\", keypoints_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9f2a7ac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:17:40.075060Z",
     "start_time": "2023-08-10T09:17:40.053567Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "keypoints_series=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/train_keypoints.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e1248da2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:25:02.858695Z",
     "start_time": "2023-08-10T18:25:02.854548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(keypoints.shape[0] for keypoints in keypoints_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e0706526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:25:00.836672Z",
     "start_time": "2023-08-10T18:25:00.832422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(keypoints.shape[0] for keypoints in keypoints_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5777338f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:25:07.674223Z",
     "start_time": "2023-08-10T18:25:07.671779Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len = traindf['Frames'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c59e0367",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:25:08.283941Z",
     "start_time": "2023-08-10T18:25:08.280586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bd079722",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:17:54.005715Z",
     "start_time": "2023-08-10T09:17:54.003522Z"
    }
   },
   "outputs": [],
   "source": [
    "#keypoints_np = np.zeros((len(keypoints_series), max_len, 126))\n",
    "#for i, keypoints in enumerate(keypoints_series):\n",
    "#    keypoints_np[i, :keypoints.shape[0], :] = keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0fb0f5e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T17:17:56.244291Z",
     "start_time": "2023-08-07T17:17:55.941457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a padded array to store keypoints\n",
    "keypoints_np = np.zeros((len(keypoints_series), max_len, 126))\n",
    "\n",
    "# Iterate through keypoints_series and fill keypoints_np with pre-padding\n",
    "for i, keypoints in enumerate(keypoints_series):\n",
    "    keypoints_len = min(keypoints.shape[0], max_len)\n",
    "    padding_len = max_len - keypoints_len\n",
    "    keypoints_np[i, padding_len:, :] = keypoints[:keypoints_len, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "26eb2969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T17:17:57.157063Z",
     "start_time": "2023-08-07T17:17:57.153761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(804, 130, 1662)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "150f59b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T17:17:59.700799Z",
     "start_time": "2023-08-07T17:17:59.696698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.49487716  0.39238185 -1.29218626 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.49096876  0.39365393 -1.30090356 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.48817223  0.39431143 -1.3236835  ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(keypoints_np[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "237a962e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T17:18:20.250710Z",
     "start_time": "2023-08-07T17:18:20.246688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(804, 130, 1662)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1f2be3d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:32:01.147811Z",
     "start_time": "2023-08-10T09:18:14.762317Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 162/162 [13:46<00:00,  5.10s/it]\n"
     ]
    }
   ],
   "source": [
    "keypoints_series = valdf['Path'].progress_apply(extract_keypoints_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4ec22db7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:32:04.871584Z",
     "start_time": "2023-08-10T09:32:04.867806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "975a3ce7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:32:08.018591Z",
     "start_time": "2023-08-10T09:32:08.005700Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/val_keypoints.npy\", keypoints_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "44547126",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:32:10.588554Z",
     "start_time": "2023-08-10T09:32:10.545322Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "keypoints_series=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe/val_keypoints.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7f22c2fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T09:32:11.138392Z",
     "start_time": "2023-08-10T09:32:11.135278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8d955591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T17:49:08.142171Z",
     "start_time": "2023-08-07T17:49:08.139896Z"
    }
   },
   "outputs": [],
   "source": [
    "#keypoints_np = np.zeros((len(keypoints_series), max_len, 126))\n",
    "#for i, keypoints in enumerate(keypoints_series):\n",
    "#    keypoints_np[i, :keypoints.shape[0], :] = keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b376fa0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T17:49:12.787861Z",
     "start_time": "2023-08-07T17:49:12.741801Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a padded array to store keypoints\n",
    "keypoints_np = np.zeros((len(keypoints_series), max_len, 126))\n",
    "\n",
    "# Iterate through keypoints_series and fill keypoints_np with pre-padding\n",
    "for i, keypoints in enumerate(keypoints_series):\n",
    "    keypoints_len = min(keypoints.shape[0], max_len)\n",
    "    padding_len = max_len - keypoints_len\n",
    "    keypoints_np[i, padding_len:, :] = keypoints[:keypoints_len, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fc123465",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T17:49:16.366748Z",
     "start_time": "2023-08-07T17:49:16.363415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 130, 1662)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "48d73578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T17:49:17.423093Z",
     "start_time": "2023-08-07T17:49:17.419467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 130, 1662)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "34332d29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T17:49:26.623611Z",
     "start_time": "2023-08-07T17:49:26.617529Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.5595299 ,  0.3205725 , -1.27106977, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.55954963,  0.32069033, -1.25959992, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.55960971,  0.3209095 , -1.23169589, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.5183838 ,  0.33223236, -1.15552998, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.51840633,  0.33222494, -1.12819552, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.51843715,  0.33220932, -1.11825132, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.58451182,  0.30696356, -1.27353859, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.58379984,  0.30720744, -1.29565203, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.58312511,  0.30719438, -1.32043719, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.59118927,  0.39442283, -0.75201887, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.5912236 ,  0.39451751, -0.76342458, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.5915451 ,  0.39482784, -0.77948147, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.46675587,  0.3912048 , -0.82078028, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.46747947,  0.39122894, -0.8108533 , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.46801692,  0.39124438, -0.8093155 , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.4523553 ,  0.31633756, -1.122316  , ...,  0.31361642,\n",
       "          0.78425157, -0.03243052],\n",
       "        [ 0.45163697,  0.31579784, -1.15146101, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.45089644,  0.31528085, -1.16140938, ...,  0.        ,\n",
       "          0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "48c53a1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T10:35:55.104495Z",
     "start_time": "2023-08-10T09:50:37.082612Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 534/534 [45:17<00:00,  5.09s/it]\n"
     ]
    }
   ],
   "source": [
    "keypoints_series = testdf['Path'].progress_apply(extract_keypoints_from_file)\n",
    "np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/test_keypoints.npy\", keypoints_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f85a549a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T00:00:13.369959Z",
     "start_time": "2023-08-10T22:59:53.998932Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 534/534 [45:11<00:00,  5.08s/it]\n",
      "100%|| 162/162 [15:07<00:00,  5.60s/it]\n"
     ]
    }
   ],
   "source": [
    "keypoints_series = testdf['Path'].progress_apply(extract_keypoints_from_file_flip)\n",
    "np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/test_keypoints_flip.npy\", keypoints_series)\n",
    "keypoints_series = valdf['Path'].progress_apply(extract_keypoints_from_file_flip)\n",
    "np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/val_keypoints_flip.npy\", keypoints_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b97a37d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T21:04:42.540504Z",
     "start_time": "2023-08-05T21:04:42.537389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(705,)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/test_keypoints.npy\", keypoints_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8de71d83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T21:04:49.253829Z",
     "start_time": "2023-08-05T21:04:48.499114Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe/test_keypoints.npy\", keypoints_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c7518075",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:23:25.664545Z",
     "start_time": "2023-08-10T18:23:25.649846Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "keypoints_series=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/test_keypoints.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "02a925a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:23:26.305657Z",
     "start_time": "2023-08-10T18:23:26.302464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(534,)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0ba381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a padded array to store keypoints\n",
    "keypoints_np = np.zeros((len(keypoints_series), max_len, 126))\n",
    "\n",
    "# Iterate through keypoints_series and fill keypoints_np with pre-padding\n",
    "for i, keypoints in enumerate(keypoints_series):\n",
    "    keypoints_len = min(keypoints.shape[0], max_len)\n",
    "    padding_len = max_len - keypoints_len\n",
    "    keypoints_np[i, padding_len:, :] = keypoints[:keypoints_len, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a1eb043d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T21:04:45.493022Z",
     "start_time": "2023-08-05T21:04:45.220080Z"
    }
   },
   "outputs": [],
   "source": [
    "keypoints_np = np.zeros((len(keypoints_series), max_len, 126))\n",
    "for i, keypoints in enumerate(keypoints_series):\n",
    "    keypoints_np[i, :keypoints.shape[0], :] = keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "72bad504",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T21:04:46.330737Z",
     "start_time": "2023-08-05T21:04:46.327305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(705, 130, 1662)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ce62069f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T21:04:51.449533Z",
     "start_time": "2023-08-05T21:04:51.446147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(705, 130, 1662)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa54d2",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef55d8b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:08.803783Z",
     "start_time": "2023-08-23T22:39:03.774556Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Keypoints Shape: (804,)\n",
      "Validation Kepoints Shape: (162,)\n",
      "Test Keypoints Shape: (534,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_keypoints=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/train_keypoints.npy\",allow_pickle=True)\n",
    "val_keypoints =np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/val_keypoints.npy\",allow_pickle=True)\n",
    "test_keypoints=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/test_keypoints.npy\",allow_pickle=True)\n",
    "\n",
    "print('Training Keypoints Shape:', train_keypoints.shape)\n",
    "print('Validation Kepoints Shape:', val_keypoints.shape)\n",
    "print('Test Keypoints Shape:',test_keypoints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "411cafbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:13.059218Z",
     "start_time": "2023-08-23T22:39:08.805284Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Keypoints Shape: (804,)\n",
      "Validation Kepoints Shape: (162,)\n",
      "Test Keypoints Shape: (534,)\n"
     ]
    }
   ],
   "source": [
    "train_keypoints_flip=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/train_keypoints_flip.npy\",allow_pickle=True)\n",
    "val_keypoints_flip =np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/val_keypoints_flip.npy\",allow_pickle=True)\n",
    "test_keypoints_flip=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/test_keypoints_flip.npy\",allow_pickle=True)\n",
    "\n",
    "print('Training Keypoints Shape:', train_keypoints_flip.shape)\n",
    "print('Validation Kepoints Shape:', val_keypoints_flip.shape)\n",
    "print('Test Keypoints Shape:',test_keypoints_flip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f26ef7f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:13.063616Z",
     "start_time": "2023-08-23T22:39:13.060965Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "max_len=130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e3b03a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:13.491013Z",
     "start_time": "2023-08-23T22:39:13.065247Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Keypoints Shape: (804, 130, 126)\n"
     ]
    }
   ],
   "source": [
    "# Create a padded array to store keypoints\n",
    "keypoints_np = np.zeros((len(train_keypoints), max_len, 126))\n",
    "\n",
    "# Iterate through keypoints_series and fill keypoints_np with pre-padding\n",
    "for i, keypoints in enumerate(train_keypoints):\n",
    "    keypoints_len = min(keypoints.shape[0], max_len)\n",
    "    padding_len = max_len - keypoints_len\n",
    "    keypoints_np[i, padding_len:, :] = keypoints[:keypoints_len, :]\n",
    "    \n",
    "train_keypoints = keypoints_np\n",
    "print('Training Keypoints Shape:', train_keypoints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7153147b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:13.692645Z",
     "start_time": "2023-08-23T22:39:13.492792Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Keypoints Shape: (162, 130, 126)\n"
     ]
    }
   ],
   "source": [
    "# Create a padded array to store keypoints\n",
    "keypoints_np = np.zeros((len(val_keypoints), max_len, 126))\n",
    "\n",
    "# Iterate through keypoints_series and fill keypoints_np with pre-padding\n",
    "for i, keypoints in enumerate(val_keypoints):\n",
    "    keypoints_len = min(keypoints.shape[0], max_len)\n",
    "    padding_len = max_len - keypoints_len\n",
    "    keypoints_np[i, padding_len:, :] = keypoints[:keypoints_len, :]\n",
    "    \n",
    "val_keypoints = keypoints_np\n",
    "print('Validation Keypoints Shape:', val_keypoints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "627933c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:13.962415Z",
     "start_time": "2023-08-23T22:39:13.694135Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Keypoints Shape: (534, 130, 126)\n"
     ]
    }
   ],
   "source": [
    "# Create a padded array to store keypoints\n",
    "keypoints_np = np.zeros((len(test_keypoints), max_len, 126))\n",
    "\n",
    "# Iterate through keypoints_series and fill keypoints_np with pre-padding\n",
    "for i, keypoints in enumerate(test_keypoints):\n",
    "    keypoints_len = min(keypoints.shape[0], max_len)\n",
    "    padding_len = max_len - keypoints_len\n",
    "    keypoints_np[i, padding_len:, :] = keypoints[:keypoints_len, :]\n",
    "    \n",
    "test_keypoints = keypoints_np\n",
    "print('Test Keypoints Shape:', test_keypoints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc714977",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:14.129963Z",
     "start_time": "2023-08-23T22:39:13.963727Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Keypoints Shape: (804, 130, 126)\n"
     ]
    }
   ],
   "source": [
    "# Create a padded array to store keypoints\n",
    "keypoints_np = np.zeros((len(train_keypoints_flip), max_len, 126))\n",
    "\n",
    "# Iterate through keypoints_series and fill keypoints_np with pre-padding\n",
    "for i, keypoints in enumerate(train_keypoints_flip):\n",
    "    keypoints_len = min(keypoints.shape[0], max_len)\n",
    "    padding_len = max_len - keypoints_len\n",
    "    keypoints_np[i, padding_len:, :] = keypoints[:keypoints_len, :]\n",
    "    \n",
    "train_keypoints_flip = keypoints_np\n",
    "print('Training Keypoints Shape:', train_keypoints_flip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26f42d26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:14.322908Z",
     "start_time": "2023-08-23T22:39:14.131397Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Keypoints Shape: (162, 130, 126)\n"
     ]
    }
   ],
   "source": [
    "# Create a padded array to store keypoints\n",
    "keypoints_np = np.zeros((len(val_keypoints_flip), max_len, 126))\n",
    "\n",
    "# Iterate through keypoints_series and fill keypoints_np with pre-padding\n",
    "for i, keypoints in enumerate(val_keypoints_flip):\n",
    "    keypoints_len = min(keypoints.shape[0], max_len)\n",
    "    padding_len = max_len - keypoints_len\n",
    "    keypoints_np[i, padding_len:, :] = keypoints[:keypoints_len, :]\n",
    "    \n",
    "val_keypoints_flip = keypoints_np\n",
    "print('Validation Keypoints Shape:', val_keypoints_flip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67b2ac44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:14.516257Z",
     "start_time": "2023-08-23T22:39:14.324401Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Keypoints Shape: (534, 130, 126)\n"
     ]
    }
   ],
   "source": [
    "# Create a padded array to store keypoints\n",
    "keypoints_np = np.zeros((len(test_keypoints_flip), max_len, 126))\n",
    "\n",
    "# Iterate through keypoints_series and fill keypoints_np with pre-padding\n",
    "for i, keypoints in enumerate(test_keypoints_flip):\n",
    "    keypoints_len = min(keypoints.shape[0], max_len)\n",
    "    padding_len = max_len - keypoints_len\n",
    "    keypoints_np[i, padding_len:, :] = keypoints[:keypoints_len, :]\n",
    "    \n",
    "test_keypoints_flip = keypoints_np\n",
    "print('Test Keypoints Shape:', test_keypoints_flip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "223cc5ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:20.319491Z",
     "start_time": "2023-08-23T22:39:14.517550Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "#from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ddc114ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:32:32.667118Z",
     "start_time": "2023-08-10T18:32:32.656589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P52</td>\n",
       "      <td>07157565148825373-seedAXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/07157...</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P28</td>\n",
       "      <td>7179300005186042-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/71793...</td>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P29</td>\n",
       "      <td>16216064841959765-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/16216...</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P37</td>\n",
       "      <td>6193814382865199-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/61938...</td>\n",
       "      <td>18</td>\n",
       "      <td>67</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P40</td>\n",
       "      <td>5947453960317015-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/59474...</td>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                     Video file Gloss ASL-LEX Code  \\\n",
       "0            P52  07157565148825373-seedAXE.mp4   AXE     G_03_066   \n",
       "1            P28       7179300005186042-AXE.mp4   AXE     G_03_066   \n",
       "2            P29      16216064841959765-AXE.mp4   AXE     G_03_066   \n",
       "3            P37       6193814382865199-AXE.mp4   AXE     G_03_066   \n",
       "4            P40       5947453960317015-AXE.mp4   AXE     G_03_066   \n",
       "\n",
       "                                                Path  Frequency  Frames  FPS  \\\n",
       "0  file:///home/kristian/ASL_Citizen/videos/07157...         18     100   31   \n",
       "1  file:///home/kristian/ASL_Citizen/videos/71793...         18      81   30   \n",
       "2  file:///home/kristian/ASL_Citizen/videos/16216...         18      47   30   \n",
       "3  file:///home/kristian/ASL_Citizen/videos/61938...         18      67   30   \n",
       "4  file:///home/kristian/ASL_Citizen/videos/59474...         18      89   30   \n",
       "\n",
       "   Length  \n",
       "0       3  \n",
       "1       3  \n",
       "2       2  \n",
       "3       2  \n",
       "4       3  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "71e58811",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:32:33.728415Z",
     "start_time": "2023-08-10T18:32:33.726121Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0129a2ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:32:38.686143Z",
     "start_time": "2023-08-10T18:32:38.680626Z"
    }
   },
   "outputs": [],
   "source": [
    "traindf['Cat_label'] = encoder.fit_transform(traindf[['Gloss']]).astype(int)\n",
    "traindf = traindf.sort_values(by='Gloss',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "21e97f05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:32:40.360964Z",
     "start_time": "2023-08-10T18:32:40.352469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Cat_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P52</td>\n",
       "      <td>07157565148825373-seedAXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/07157...</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>P37</td>\n",
       "      <td>29360158406046777-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/29360...</td>\n",
       "      <td>18</td>\n",
       "      <td>73</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P27</td>\n",
       "      <td>053394218351220823-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/05339...</td>\n",
       "      <td>18</td>\n",
       "      <td>52</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P40</td>\n",
       "      <td>10598328043940142-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/10598...</td>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P50</td>\n",
       "      <td>3937261764308986-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/39372...</td>\n",
       "      <td>18</td>\n",
       "      <td>72</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant ID                     Video file Gloss ASL-LEX Code  \\\n",
       "0             P52  07157565148825373-seedAXE.mp4   AXE     G_03_066   \n",
       "17            P37      29360158406046777-AXE.mp4   AXE     G_03_066   \n",
       "16            P27     053394218351220823-AXE.mp4   AXE     G_03_066   \n",
       "15            P40      10598328043940142-AXE.mp4   AXE     G_03_066   \n",
       "14            P50       3937261764308986-AXE.mp4   AXE     G_03_066   \n",
       "\n",
       "                                                 Path  Frequency  Frames  FPS  \\\n",
       "0   file:///home/kristian/ASL_Citizen/videos/07157...         18     100   31   \n",
       "17  file:///home/kristian/ASL_Citizen/videos/29360...         18      73   30   \n",
       "16  file:///home/kristian/ASL_Citizen/videos/05339...         18      52   29   \n",
       "15  file:///home/kristian/ASL_Citizen/videos/10598...         18      81   29   \n",
       "14  file:///home/kristian/ASL_Citizen/videos/39372...         18      72   30   \n",
       "\n",
       "    Length  Cat_label  \n",
       "0        3          0  \n",
       "17       2          0  \n",
       "16       2          0  \n",
       "15       3          0  \n",
       "14       2          0  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5c7a48a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:32:41.344266Z",
     "start_time": "2023-08-10T18:32:41.333730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Cat_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>P40</td>\n",
       "      <td>6445331634562388-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/64453...</td>\n",
       "      <td>16</td>\n",
       "      <td>89</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>P37</td>\n",
       "      <td>6237575353180616-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/62375...</td>\n",
       "      <td>16</td>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>P40</td>\n",
       "      <td>5268072837528903-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/52680...</td>\n",
       "      <td>16</td>\n",
       "      <td>92</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>P37</td>\n",
       "      <td>16185522171162914-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/16185...</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>P40</td>\n",
       "      <td>6363286086951516-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/63632...</td>\n",
       "      <td>16</td>\n",
       "      <td>65</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Participant ID                      Video file    Gloss ASL-LEX Code  \\\n",
       "789            P40   6445331634562388-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "788            P37   6237575353180616-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "802            P40   5268072837528903-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "794            P37  16185522171162914-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "803            P40   6363286086951516-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "\n",
       "                                                  Path  Frequency  Frames  \\\n",
       "789  file:///home/kristian/ASL_Citizen/videos/64453...         16      89   \n",
       "788  file:///home/kristian/ASL_Citizen/videos/62375...         16      56   \n",
       "802  file:///home/kristian/ASL_Citizen/videos/52680...         16      92   \n",
       "794  file:///home/kristian/ASL_Citizen/videos/16185...         16      64   \n",
       "803  file:///home/kristian/ASL_Citizen/videos/63632...         16      65   \n",
       "\n",
       "     FPS  Length  Cat_label  \n",
       "789   30       3         49  \n",
       "788   30       2         49  \n",
       "802   29       3         49  \n",
       "794   30       2         49  \n",
       "803   29       2         49  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4319817b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:32:43.665809Z",
     "start_time": "2023-08-10T18:32:43.660657Z"
    }
   },
   "outputs": [],
   "source": [
    "valdf['Cat_label'] = encoder.fit_transform(valdf[['Gloss']]).astype(int)\n",
    "valdf = valdf.sort_values(by='Gloss',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "aef49cd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:32:44.319594Z",
     "start_time": "2023-08-10T18:32:44.312091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Cat_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P39</td>\n",
       "      <td>19778675091674147-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P26</td>\n",
       "      <td>8581142177964065-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P39</td>\n",
       "      <td>3877478645046861-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P21</td>\n",
       "      <td>8521417940364975-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P5</td>\n",
       "      <td>9990244640190733-BACKPACK.mp4</td>\n",
       "      <td>BACKPACK</td>\n",
       "      <td>G_03_091</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                     Video file     Gloss ASL-LEX Code  \\\n",
       "0            P39      19778675091674147-AXE.mp4       AXE     G_03_066   \n",
       "1            P26       8581142177964065-AXE.mp4       AXE     G_03_066   \n",
       "2            P39       3877478645046861-AXE.mp4       AXE     G_03_066   \n",
       "3            P21       8521417940364975-AXE.mp4       AXE     G_03_066   \n",
       "4             P5  9990244640190733-BACKPACK.mp4  BACKPACK     G_03_091   \n",
       "\n",
       "                                                Path  Frequency  Frames  FPS  \\\n",
       "0  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4     121   30   \n",
       "1  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4      81   29   \n",
       "2  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4     120   30   \n",
       "3  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4      71   29   \n",
       "4  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          3      93   29   \n",
       "\n",
       "   Length  Cat_label  \n",
       "0       4          0  \n",
       "1       3          0  \n",
       "2       4          0  \n",
       "3       2          0  \n",
       "4       3          1  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "46a71f83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:32:44.902531Z",
     "start_time": "2023-08-10T18:32:44.894792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Cat_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>P39</td>\n",
       "      <td>0283886564670357-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>P21</td>\n",
       "      <td>6142521746642153-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>P26</td>\n",
       "      <td>032677896012150764-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>P5</td>\n",
       "      <td>6523145816470133-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>P12</td>\n",
       "      <td>06408604416165864-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Participant ID                       Video file    Gloss ASL-LEX Code  \\\n",
       "159            P39    0283886564670357-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "160            P21    6142521746642153-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "157            P26  032677896012150764-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "158             P5    6523145816470133-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "161            P12   06408604416165864-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "\n",
       "                                                  Path  Frequency  Frames  \\\n",
       "159  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          5     121   \n",
       "160  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          5      57   \n",
       "157  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          5      81   \n",
       "158  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          5     116   \n",
       "161  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          5      71   \n",
       "\n",
       "     FPS  Length  Cat_label  \n",
       "159   30       4         49  \n",
       "160   30       2         49  \n",
       "157   29       3         49  \n",
       "158   30       4         49  \n",
       "161   30       2         49  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1b4c8529",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:32:45.951127Z",
     "start_time": "2023-08-10T18:32:45.945618Z"
    }
   },
   "outputs": [],
   "source": [
    "testdf['Cat_label'] = encoder.fit_transform(testdf[['Gloss']]).astype(int)\n",
    "testdf = testdf.sort_values(by='Gloss',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b22157d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:32:47.475815Z",
     "start_time": "2023-08-10T18:32:47.468273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Cat_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P35</td>\n",
       "      <td>5104381603195376-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/51043...</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P42</td>\n",
       "      <td>44458614013793873-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/44458...</td>\n",
       "      <td>11</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P42</td>\n",
       "      <td>9604797909481075-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/96047...</td>\n",
       "      <td>11</td>\n",
       "      <td>66</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P9</td>\n",
       "      <td>30728048195204827-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/30728...</td>\n",
       "      <td>11</td>\n",
       "      <td>96</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P6</td>\n",
       "      <td>28522130623160047-AXE.mp4</td>\n",
       "      <td>AXE</td>\n",
       "      <td>G_03_066</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/28522...</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                 Video file Gloss ASL-LEX Code  \\\n",
       "0            P35   5104381603195376-AXE.mp4   AXE     G_03_066   \n",
       "1            P42  44458614013793873-AXE.mp4   AXE     G_03_066   \n",
       "2            P42   9604797909481075-AXE.mp4   AXE     G_03_066   \n",
       "3             P9  30728048195204827-AXE.mp4   AXE     G_03_066   \n",
       "4             P6  28522130623160047-AXE.mp4   AXE     G_03_066   \n",
       "\n",
       "                                                Path  Frequency  Frames  FPS  \\\n",
       "0  file:///home/kristian/ASL_Citizen/videos/51043...         11      70   29   \n",
       "1  file:///home/kristian/ASL_Citizen/videos/44458...         11      57   30   \n",
       "2  file:///home/kristian/ASL_Citizen/videos/96047...         11      66   30   \n",
       "3  file:///home/kristian/ASL_Citizen/videos/30728...         11      96   30   \n",
       "4  file:///home/kristian/ASL_Citizen/videos/28522...         11      54   29   \n",
       "\n",
       "   Length  Cat_label  \n",
       "0       2          0  \n",
       "1       2          0  \n",
       "2       2          0  \n",
       "3       3          0  \n",
       "4       2          0  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3da4ef9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:33:05.341090Z",
     "start_time": "2023-08-10T18:33:05.333662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Cat_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>P6</td>\n",
       "      <td>6734748834983595-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/67347...</td>\n",
       "      <td>13</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>P17</td>\n",
       "      <td>33051835760678294-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/33051...</td>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>P42</td>\n",
       "      <td>2748457214117681-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/27484...</td>\n",
       "      <td>13</td>\n",
       "      <td>74</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>P42</td>\n",
       "      <td>9684934734400592-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/96849...</td>\n",
       "      <td>13</td>\n",
       "      <td>89</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>P15</td>\n",
       "      <td>540014801916062-WHAT FOR.mp4</td>\n",
       "      <td>WHATFOR</td>\n",
       "      <td>C_02_054</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/54001...</td>\n",
       "      <td>13</td>\n",
       "      <td>79</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Participant ID                      Video file    Gloss ASL-LEX Code  \\\n",
       "522             P6   6734748834983595-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "521            P17  33051835760678294-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "532            P42   2748457214117681-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "526            P42   9684934734400592-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "533            P15    540014801916062-WHAT FOR.mp4  WHATFOR     C_02_054   \n",
       "\n",
       "                                                  Path  Frequency  Frames  \\\n",
       "522  file:///home/kristian/ASL_Citizen/videos/67347...         13      66   \n",
       "521  file:///home/kristian/ASL_Citizen/videos/33051...         13      52   \n",
       "532  file:///home/kristian/ASL_Citizen/videos/27484...         13      74   \n",
       "526  file:///home/kristian/ASL_Citizen/videos/96849...         13      89   \n",
       "533  file:///home/kristian/ASL_Citizen/videos/54001...         13      79   \n",
       "\n",
       "     FPS  Length  Cat_label  \n",
       "522   29       2         49  \n",
       "521   31       2         49  \n",
       "532   30       2         49  \n",
       "526   30       3         49  \n",
       "533   29       3         49  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9d509a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:20.324292Z",
     "start_time": "2023-08-23T22:39:20.320890Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(traindf['Gloss'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2139a4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:20.617440Z",
     "start_time": "2023-08-23T22:39:20.326141Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AXE': 0,\n",
       " 'BACKPACK': 1,\n",
       " 'BASKETBALL': 2,\n",
       " 'BEE': 3,\n",
       " 'BELT': 4,\n",
       " 'BITE': 5,\n",
       " 'BREAKFAST': 6,\n",
       " 'CANCER': 7,\n",
       " 'CHRISTMAS': 8,\n",
       " 'CONFUSED': 9,\n",
       " 'DARK': 10,\n",
       " 'DEAF': 11,\n",
       " 'DECIDE': 12,\n",
       " 'DEMAND': 13,\n",
       " 'DEVELOP': 14,\n",
       " 'DINNER': 15,\n",
       " 'DOG': 16,\n",
       " 'DOWNSIZE': 17,\n",
       " 'DRAG': 18,\n",
       " 'EAT': 19,\n",
       " 'EDIT': 20,\n",
       " 'ELEVATOR': 21,\n",
       " 'FINE': 22,\n",
       " 'FLOAT': 23,\n",
       " 'FOREIGNER': 24,\n",
       " 'GUESS': 25,\n",
       " 'HALLOWEEN': 26,\n",
       " 'HOSPITAL': 27,\n",
       " 'HURDLE/TRIP': 28,\n",
       " 'JEWELRY': 29,\n",
       " 'KNIGHT': 30,\n",
       " 'LOCK': 31,\n",
       " 'LUNCH': 32,\n",
       " 'MAPLE': 33,\n",
       " 'MEAT': 34,\n",
       " 'MECHANIC': 35,\n",
       " 'MICROSCOPE': 36,\n",
       " 'MOVIE': 37,\n",
       " 'NOON': 38,\n",
       " 'PARTY': 39,\n",
       " 'PATIENT': 40,\n",
       " 'RAZOR': 41,\n",
       " 'RIVER': 42,\n",
       " 'ROCKINGCHAIR': 43,\n",
       " 'SHAVE': 44,\n",
       " 'SINK': 45,\n",
       " 'SQUEEZE': 46,\n",
       " 'THEY': 47,\n",
       " 'TWINS': 48,\n",
       " 'WHATFOR': 49}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0300bdfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:20.940587Z",
     "start_time": "2023-08-23T22:39:20.619034Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "inv_label_map = {v: k for k, v in label_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "f78c717f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T21:01:27.566476Z",
     "start_time": "2023-08-23T21:01:27.562399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'AXE',\n",
       " 1: 'BACKPACK',\n",
       " 2: 'BASKETBALL',\n",
       " 3: 'BEE',\n",
       " 4: 'BELT',\n",
       " 5: 'BITE',\n",
       " 6: 'BREAKFAST',\n",
       " 7: 'CANCER',\n",
       " 8: 'CHRISTMAS',\n",
       " 9: 'CONFUSED',\n",
       " 10: 'DARK',\n",
       " 11: 'DEAF',\n",
       " 12: 'DECIDE',\n",
       " 13: 'DEMAND',\n",
       " 14: 'DEVELOP',\n",
       " 15: 'DINNER',\n",
       " 16: 'DOG',\n",
       " 17: 'DOWNSIZE',\n",
       " 18: 'DRAG',\n",
       " 19: 'EAT',\n",
       " 20: 'EDIT',\n",
       " 21: 'ELEVATOR',\n",
       " 22: 'FINE',\n",
       " 23: 'FLOAT',\n",
       " 24: 'FOREIGNER',\n",
       " 25: 'GUESS',\n",
       " 26: 'HALLOWEEN',\n",
       " 27: 'HOSPITAL',\n",
       " 28: 'HURDLE/TRIP',\n",
       " 29: 'JEWELRY',\n",
       " 30: 'KNIGHT',\n",
       " 31: 'LOCK',\n",
       " 32: 'LUNCH',\n",
       " 33: 'MAPLE',\n",
       " 34: 'MEAT',\n",
       " 35: 'MECHANIC',\n",
       " 36: 'MICROSCOPE',\n",
       " 37: 'MOVIE',\n",
       " 38: 'NOON',\n",
       " 39: 'PARTY',\n",
       " 40: 'PATIENT',\n",
       " 41: 'RAZOR',\n",
       " 42: 'RIVER',\n",
       " 43: 'ROCKINGCHAIR',\n",
       " 44: 'SHAVE',\n",
       " 45: 'SINK',\n",
       " 46: 'SQUEEZE',\n",
       " 47: 'THEY',\n",
       " 48: 'TWINS',\n",
       " 49: 'WHATFOR'}"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "8fc7849a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T21:01:50.727422Z",
     "start_time": "2023-08-23T21:01:50.723649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AXE'"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_label_map[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "962046fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:33:15.462254Z",
     "start_time": "2023-08-10T18:33:15.451567Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Cat_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>P11</td>\n",
       "      <td>93340344109002-DEAF.mp4</td>\n",
       "      <td>DEAF</td>\n",
       "      <td>F_03_038</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/93340...</td>\n",
       "      <td>18</td>\n",
       "      <td>52</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>P50</td>\n",
       "      <td>6965626273607881-DEAF.mp4</td>\n",
       "      <td>DEAF</td>\n",
       "      <td>F_03_038</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/69656...</td>\n",
       "      <td>18</td>\n",
       "      <td>63</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>P50</td>\n",
       "      <td>37298532610460033-RAZOR 2.mp4</td>\n",
       "      <td>RAZOR</td>\n",
       "      <td>K_03_103</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/37298...</td>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>P27</td>\n",
       "      <td>635034042192421-DOG.mp4</td>\n",
       "      <td>DOG</td>\n",
       "      <td>A_01_056</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/63503...</td>\n",
       "      <td>20</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>P29</td>\n",
       "      <td>2296487888208607-BITE.mp4</td>\n",
       "      <td>BITE</td>\n",
       "      <td>K_02_045</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/22964...</td>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>P37</td>\n",
       "      <td>9047865551380374-PARTY.mp4</td>\n",
       "      <td>PARTY</td>\n",
       "      <td>G_02_059</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/90478...</td>\n",
       "      <td>20</td>\n",
       "      <td>75</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>P29</td>\n",
       "      <td>3817632832150144-MEAT.mp4</td>\n",
       "      <td>MEAT</td>\n",
       "      <td>D_02_022</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/38176...</td>\n",
       "      <td>16</td>\n",
       "      <td>52</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>P27</td>\n",
       "      <td>4163876725261626-THEY.mp4</td>\n",
       "      <td>THEY</td>\n",
       "      <td>F_02_103</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/41638...</td>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>P43</td>\n",
       "      <td>9855459225573504-TWINS.mp4</td>\n",
       "      <td>TWINS</td>\n",
       "      <td>F_01_032</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/98554...</td>\n",
       "      <td>17</td>\n",
       "      <td>69</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>P40</td>\n",
       "      <td>14052296225070893-BACKPACK.mp4</td>\n",
       "      <td>BACKPACK</td>\n",
       "      <td>G_03_091</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/14052...</td>\n",
       "      <td>17</td>\n",
       "      <td>88</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Participant ID                      Video file     Gloss ASL-LEX Code  \\\n",
       "197            P11         93340344109002-DEAF.mp4      DEAF     F_03_038   \n",
       "190            P50       6965626273607881-DEAF.mp4      DEAF     F_03_038   \n",
       "671            P50   37298532610460033-RAZOR 2.mp4     RAZOR     K_03_103   \n",
       "278            P27         635034042192421-DOG.mp4       DOG     A_01_056   \n",
       "99             P29       2296487888208607-BITE.mp4      BITE     K_02_045   \n",
       "639            P37      9047865551380374-PARTY.mp4     PARTY     G_02_059   \n",
       "554            P29       3817632832150144-MEAT.mp4      MEAT     D_02_022   \n",
       "762            P27       4163876725261626-THEY.mp4      THEY     F_02_103   \n",
       "779            P43      9855459225573504-TWINS.mp4     TWINS     F_01_032   \n",
       "30             P40  14052296225070893-BACKPACK.mp4  BACKPACK     G_03_091   \n",
       "\n",
       "                                                  Path  Frequency  Frames  \\\n",
       "197  file:///home/kristian/ASL_Citizen/videos/93340...         18      52   \n",
       "190  file:///home/kristian/ASL_Citizen/videos/69656...         18      63   \n",
       "671  file:///home/kristian/ASL_Citizen/videos/37298...         13      60   \n",
       "278  file:///home/kristian/ASL_Citizen/videos/63503...         20      49   \n",
       "99   file:///home/kristian/ASL_Citizen/videos/22964...         19      45   \n",
       "639  file:///home/kristian/ASL_Citizen/videos/90478...         20      75   \n",
       "554  file:///home/kristian/ASL_Citizen/videos/38176...         16      52   \n",
       "762  file:///home/kristian/ASL_Citizen/videos/41638...         14      45   \n",
       "779  file:///home/kristian/ASL_Citizen/videos/98554...         17      69   \n",
       "30   file:///home/kristian/ASL_Citizen/videos/14052...         17      88   \n",
       "\n",
       "     FPS  Length  Cat_label  \n",
       "197   29       2         11  \n",
       "190   30       2         11  \n",
       "671   30       2         41  \n",
       "278   30       2         16  \n",
       "99    30       2          5  \n",
       "639   30       2         39  \n",
       "554   30       2         34  \n",
       "762   30       2         47  \n",
       "779   29       2         48  \n",
       "30    30       3          1  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6bf774ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:33:16.375416Z",
     "start_time": "2023-08-10T18:33:16.367455Z"
    }
   },
   "outputs": [],
   "source": [
    "Ytrain = encoder.fit_transform(traindf[['Gloss']])\n",
    "Ytest = encoder.fit_transform(testdf[['Gloss']])\n",
    "Yval = encoder.fit_transform(valdf[['Gloss']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7cd74294",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:33:37.818388Z",
     "start_time": "2023-08-10T18:33:37.814994Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/train_labels_array_1D.npy\", Ytrain)\n",
    "np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/test_labels_array_1D.npy\", Ytest)\n",
    "np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/val_labels_array_1D.npy\", Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26877e3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:21.365155Z",
     "start_time": "2023-08-23T22:39:20.942029Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "Ytrain=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/train_labels_array_1D.npy\")\n",
    "Ytest=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/test_labels_array_1D.npy\")\n",
    "Yval=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/val_labels_array_1D.npy\")\n",
    "Ytrain_flip=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/train_labels_array_1D.npy\")\n",
    "Ytest_flip=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/test_labels_array_1D.npy\")\n",
    "Yval_flip=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe_hands/val_labels_array_1D.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28e63d67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:21.578707Z",
     "start_time": "2023-08-23T22:39:21.372262Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "Xtrain = train_keypoints\n",
    "Xtest = test_keypoints\n",
    "Xval = val_keypoints\n",
    "Xtrain_flip = train_keypoints_flip\n",
    "Xtest_flip = test_keypoints_flip\n",
    "Xval_flip = val_keypoints_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f8c38c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:21.758967Z",
     "start_time": "2023-08-23T22:39:21.579972Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "Xval = val_keypoints\n",
    "Xval_flip = val_keypoints_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d52a77ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:21.929132Z",
     "start_time": "2023-08-23T22:39:21.760329Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (804, 1)\n",
      "Shape after one-hot encoding:  (804, 50)\n",
      "Shape before one-hot encoding:  (534, 1)\n",
      "Shape after one-hot encoding:  (534, 50)\n",
      "Shape before one-hot encoding:  (162, 1)\n",
      "Shape after one-hot encoding:  (162, 50)\n",
      "Shape before one-hot encoding:  (804, 1)\n",
      "Shape after one-hot encoding:  (804, 50)\n",
      "Shape before one-hot encoding:  (534, 1)\n",
      "Shape after one-hot encoding:  (534, 50)\n",
      "Shape before one-hot encoding:  (162, 1)\n",
      "Shape after one-hot encoding:  (162, 50)\n"
     ]
    }
   ],
   "source": [
    "n_classes = 50\n",
    "print(\"Shape before one-hot encoding: \", Ytrain.shape)\n",
    "Ytrain = to_categorical(Ytrain, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Ytrain.shape)\n",
    "print(\"Shape before one-hot encoding: \", Ytest.shape)\n",
    "Ytest = to_categorical(Ytest, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Ytest.shape)\n",
    "print(\"Shape before one-hot encoding: \", Yval.shape)\n",
    "Yval = to_categorical(Yval, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Yval.shape)\n",
    "print(\"Shape before one-hot encoding: \", Ytrain_flip.shape)\n",
    "Ytrain_flip = to_categorical(Ytrain_flip, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Ytrain_flip.shape)\n",
    "print(\"Shape before one-hot encoding: \", Ytest_flip.shape)\n",
    "Ytest_flip = to_categorical(Ytest_flip, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Ytest_flip.shape)\n",
    "print(\"Shape before one-hot encoding: \", Yval_flip.shape)\n",
    "Yval_flip = to_categorical(Yval_flip, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Yval_flip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb749626",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:22.145107Z",
     "start_time": "2023-08-23T22:39:21.930976Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3258ad3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:22.311711Z",
     "start_time": "2023-08-23T22:39:22.146855Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(804, 50)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a2e3c0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T18:54:09.792399Z",
     "start_time": "2023-08-03T18:54:08.816481Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4298ab7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:22.573612Z",
     "start_time": "2023-08-23T22:39:22.313723Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2676, 130, 126)\n",
      "(2676, 50)\n"
     ]
    }
   ],
   "source": [
    "Xtrain = np.concatenate((Xtrain, Xtest,Xtrain_flip,Xtest_flip), axis=0)\n",
    "print(Xtrain.shape)\n",
    "Ytrain = np.concatenate((Ytrain, Ytest, Ytrain_flip, Ytest_flip), axis=0)\n",
    "print(Ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8609169",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:22.660917Z",
     "start_time": "2023-08-23T22:39:22.575402Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 130, 126)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "265f503d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:22.885517Z",
     "start_time": "2023-08-23T22:39:22.662493Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 130, 126)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval_flip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbac8ea5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:23.072233Z",
     "start_time": "2023-08-23T22:39:22.886984Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(324, 130, 126)\n",
      "(324, 50)\n"
     ]
    }
   ],
   "source": [
    "Xval = np.concatenate((Xval, Xval_flip), axis=0)\n",
    "print(Xval.shape)\n",
    "Yval = np.concatenate((Yval, Yval_flip), axis=0)\n",
    "print(Yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0f523460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T22:37:12.298215Z",
     "start_time": "2023-08-18T22:37:12.294391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2676, 130, 126)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(324, 130, 126)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "Xval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4848089",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:23.278848Z",
     "start_time": "2023-08-23T22:39:23.073695Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 79.97%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the sparsity\n",
    "num_zero_values = np.count_nonzero(Xtrain == 0)\n",
    "total_values = Xtrain.size\n",
    "\n",
    "sparsity = num_zero_values / total_values\n",
    "\n",
    "print(f\"Sparsity: {sparsity:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a8fde5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:23.683989Z",
     "start_time": "2023-08-23T22:39:23.280152Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler, Normalizer\n",
    "\n",
    "#scaletrain = np.concatenate((Xtrain, Xval), axis=0)\n",
    "#num_samples, num_frames, num_keypoints = scaletrain.shape\n",
    "#scaletrain = scaletrain.reshape(num_samples, -1)\n",
    "\n",
    "num_samples, num_frames, num_keypoints = Xtrain.shape\n",
    "Xtrain = Xtrain.reshape(num_samples, -1)\n",
    "\n",
    "# Create a MinMaxScaler\n",
    "#scaler = StandardScaler()\n",
    "#scaler = Normalizer(norm='l2')\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "#scaler.fit(scaletrain)\n",
    "scaler.fit(Xtrain)\n",
    "# Fit and transform the data\n",
    "Xtrain = scaler.transform(Xtrain)\n",
    "\n",
    "# Reshape the scaled data back to the original shape\n",
    "Xtrain = Xtrain.reshape(num_samples, num_frames, num_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0de98a96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:23.707258Z",
     "start_time": "2023-08-23T22:39:23.685363Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "num_samples, num_frames, num_keypoints = Xval.shape\n",
    "Xval = Xval.reshape(num_samples, -1)\n",
    "\n",
    "# Fit and transform the data\n",
    "Xval = scaler.transform(Xval)\n",
    "\n",
    "# Reshape the scaled data back to the original shape\n",
    "Xval = Xval.reshape(num_samples, num_frames, num_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8eb66ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:23.915112Z",
     "start_time": "2023-08-23T22:39:23.709401Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "num_samples, num_frames, num_keypoints = Xval_flip.shape\n",
    "Xval_flip = Xval_flip.reshape(num_samples, -1)\n",
    "\n",
    "# Fit and transform the data\n",
    "Xval_flip = scaler.transform(Xval_flip)\n",
    "\n",
    "# Reshape the scaled data back to the original shape\n",
    "Xval_flip = Xval_flip.reshape(num_samples, num_frames, num_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "f1adaee8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T13:53:47.194415Z",
     "start_time": "2023-08-14T13:53:47.190349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324, 16380)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum = Xval.reshape(num_samples,-1)\n",
    "dum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8042926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:24.089158Z",
     "start_time": "2023-08-23T22:39:23.916687Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2676, 130, 126)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49da28e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T15:51:46.223692Z",
     "start_time": "2023-08-03T15:51:46.190010Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_data_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, X_test, Y_train, Y_test, mask_train, mask_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43minput_data_scaled\u001b[49m,\n\u001b[1;32m      2\u001b[0m                                                     Y, mask,\n\u001b[1;32m      3\u001b[0m                                                     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                                     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_data_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(input_data_scaled,\n",
    "                                                    Y,\n",
    "                                                    test_size=0.,\n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c00d3fb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:24.258915Z",
     "start_time": "2023-08-23T22:39:24.090621Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2676, 130, 126)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(534, 130, 126)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89609a73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:24.439458Z",
     "start_time": "2023-08-23T22:39:24.260701Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2676, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(534, 50)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Ytrain.shape)\n",
    "Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afebe752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:24.620283Z",
     "start_time": "2023-08-23T22:39:24.441123Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.91113161,  0.7384477 , -0.3212467 , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.90280331,  0.73794292, -0.23713726, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.85894328,  0.74385538, -0.30313562, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c73fc3f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T16:00:08.136362Z",
     "start_time": "2023-08-14T16:00:08.132643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "a30e25a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T13:44:27.763634Z",
     "start_time": "2023-08-14T13:44:27.760029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324, 50)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "7986d4b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T13:44:35.372225Z",
     "start_time": "2023-08-14T13:44:35.368187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324, 130, 126)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a4a24",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80a6472e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:24.833058Z",
     "start_time": "2023-08-23T22:39:24.621958Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, GRU\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam ,Adagrad, Adadelta, SGD, Nadam\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "84471a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:25.012319Z",
     "start_time": "2023-08-23T22:39:24.834471Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "tf.random.set_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ae984cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:25.408865Z",
     "start_time": "2023-08-23T22:39:25.013670Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913fba46",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tests LSTM+GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "882eff58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:39:25.636789Z",
     "start_time": "2023-08-23T22:39:25.410070Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "max_len = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "83de7026",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T09:05:24.050419Z",
     "start_time": "2023-08-11T09:04:59.522103Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 130, 180)          221040    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 130, 90)           97560     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 90)                65160     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 90)                8190      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 50)                4550      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 396500 (1.51 MB)\n",
      "Trainable params: 396500 (1.51 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "34/34 [==============================] - 8s 111ms/step - loss: 8.6338 - categorical_accuracy: 0.0182 - val_loss: 8.0591 - val_categorical_accuracy: 0.0224\n",
      "Epoch 2/1000\n",
      "34/34 [==============================] - 3s 78ms/step - loss: 8.1264 - categorical_accuracy: 0.0178 - val_loss: 9.2347 - val_categorical_accuracy: 0.0224\n",
      "Epoch 3/1000\n",
      "34/34 [==============================] - 3s 78ms/step - loss: 8.0434 - categorical_accuracy: 0.0206 - val_loss: 9.2347 - val_categorical_accuracy: 0.0224\n",
      "Epoch 4/1000\n",
      "34/34 [==============================] - 3s 79ms/step - loss: 8.0615 - categorical_accuracy: 0.0192 - val_loss: 9.0610 - val_categorical_accuracy: 0.0168\n",
      "Epoch 5/1000\n",
      "34/34 [==============================] - 3s 79ms/step - loss: 8.0402 - categorical_accuracy: 0.0187 - val_loss: 8.9668 - val_categorical_accuracy: 0.0168\n",
      "Epoch 6/1000\n",
      "34/34 [==============================] - 3s 79ms/step - loss: 8.0312 - categorical_accuracy: 0.0206 - val_loss: 8.9679 - val_categorical_accuracy: 0.0168\n",
      "Epoch 7/1000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 7.8898 - categorical_accuracy: 0.0156"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m SGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.00001\u001b[39m,nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential(name='Sequential')\n",
    "act_function = 'tanh'\n",
    "model.add(LSTM(180, return_sequences=True, activation=act_function, input_shape=(130,126)))\n",
    "model.add(LSTM(90, return_sequences=True, activation=act_function))\n",
    "#model.add(LSTM(180, return_sequences=True, activation=act_function))\n",
    "model.add(LSTM(90, return_sequences=False,activation=act_function))\n",
    "#model.add(Dense(90, activation=act_function))\n",
    "#model.add(Dense(90, activation=act_function))\n",
    "#model.add(Dense(90, activation=act_function))\n",
    "#model.add(Dense(90, activation=act_function))\n",
    "#model.add(Dense(45, activation=act_function))\n",
    "model.add(Dense(90, activation=act_function))\n",
    "model.add(Dense(50, activation=act_function))\n",
    "model.summary()\n",
    "\n",
    "optimizer = SGD(learning_rate=.00001,nesterov=True)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, epochs=1000, validation_split=.2, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b4546c78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:38:30.577940Z",
     "start_time": "2023-08-10T18:37:25.626381Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 19:37:31.086458: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 7s 64ms/step - loss: 8.5475 - categorical_accuracy: 0.0234 - val_loss: 8.1678 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.7508 - categorical_accuracy: 0.0271 - val_loss: 7.6328 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.9888 - categorical_accuracy: 0.0243 - val_loss: 8.2151 - val_categorical_accuracy: 0.0522\n",
      "Epoch 4/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 9.8813 - categorical_accuracy: 0.0243 - val_loss: 7.1391 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.5391 - categorical_accuracy: 0.0280 - val_loss: 10.0403 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 6.3260 - categorical_accuracy: 0.0290 - val_loss: 7.3463 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 9.2137 - categorical_accuracy: 0.0252 - val_loss: 10.7248 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.9247 - categorical_accuracy: 0.0262 - val_loss: 8.9891 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.9443 - categorical_accuracy: 0.0336 - val_loss: 8.2190 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.9135 - categorical_accuracy: 0.0271 - val_loss: 8.3828 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.7235 - categorical_accuracy: 0.0271 - val_loss: 9.5185 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.0521 - categorical_accuracy: 0.0252 - val_loss: 8.7501 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 8.4629 - categorical_accuracy: 0.0271 - val_loss: 8.6888 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.3681 - categorical_accuracy: 0.0280 - val_loss: 9.1107 - val_categorical_accuracy: 0.0075\n",
      "Epoch 15/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.3455 - categorical_accuracy: 0.0262 - val_loss: 7.2673 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.0092 - categorical_accuracy: 0.0262 - val_loss: 9.1117 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.3035 - categorical_accuracy: 0.0252 - val_loss: 9.9380 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 8.0913 - categorical_accuracy: 0.0206 - val_loss: 9.8400 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.8041 - categorical_accuracy: 0.0262 - val_loss: 9.5655 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.6098 - categorical_accuracy: 0.0271 - val_loss: 8.7795 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.4684 - categorical_accuracy: 0.0262 - val_loss: 9.4187 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.8328 - categorical_accuracy: 0.0252 - val_loss: 8.9967 - val_categorical_accuracy: 0.0373\n",
      "Epoch 23/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.4073 - categorical_accuracy: 0.0252 - val_loss: 8.7216 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.3384 - categorical_accuracy: 0.0271 - val_loss: 8.5452 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.4510 - categorical_accuracy: 0.0299 - val_loss: 8.3844 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.6940 - categorical_accuracy: 0.0252 - val_loss: 9.7711 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.8751 - categorical_accuracy: 0.0252 - val_loss: 8.6919 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.9407 - categorical_accuracy: 0.0206 - val_loss: 8.4993 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.9400 - categorical_accuracy: 0.0262 - val_loss: 7.4909 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.4977 - categorical_accuracy: 0.0224 - val_loss: 8.4486 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.8725 - categorical_accuracy: 0.0280 - val_loss: 8.4549 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.6532 - categorical_accuracy: 0.0271 - val_loss: 7.5395 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.4118 - categorical_accuracy: 0.0252 - val_loss: 7.6586 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.4151 - categorical_accuracy: 0.0243 - val_loss: 8.6234 - val_categorical_accuracy: 0.0336\n",
      "Epoch 35/1000\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 7.9226 - categorical_accuracy: 0.0243 - val_loss: 8.2403 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.0497 - categorical_accuracy: 0.0299 - val_loss: 7.0547 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.9398 - categorical_accuracy: 0.0290 - val_loss: 7.6019 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.8045 - categorical_accuracy: 0.0243 - val_loss: 6.9583 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.7035 - categorical_accuracy: 0.0234 - val_loss: 7.8507 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.8464 - categorical_accuracy: 0.0262 - val_loss: 7.7873 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.1804 - categorical_accuracy: 0.0262 - val_loss: 7.3699 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.6623 - categorical_accuracy: 0.0243 - val_loss: 8.3538 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.9952 - categorical_accuracy: 0.0252 - val_loss: 7.8220 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.6206 - categorical_accuracy: 0.0280 - val_loss: 8.9510 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.5288 - categorical_accuracy: 0.0308 - val_loss: 7.8669 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.8664 - categorical_accuracy: 0.0262 - val_loss: 7.9083 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.8809 - categorical_accuracy: 0.0318 - val_loss: 7.7720 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.8940 - categorical_accuracy: 0.0243 - val_loss: 6.3898 - val_categorical_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.4271 - categorical_accuracy: 0.0262 - val_loss: 6.2155 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.7637 - categorical_accuracy: 0.0252 - val_loss: 8.3997 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.7397 - categorical_accuracy: 0.0224 - val_loss: 7.5216 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.5803 - categorical_accuracy: 0.0187 - val_loss: 8.2021 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.8845 - categorical_accuracy: 0.0299 - val_loss: 8.2387 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.7295 - categorical_accuracy: 0.0271 - val_loss: 6.6656 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.6980 - categorical_accuracy: 0.0280 - val_loss: 8.2064 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.0188 - categorical_accuracy: 0.0178 - val_loss: 7.6154 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.6170 - categorical_accuracy: 0.0252 - val_loss: 8.5378 - val_categorical_accuracy: 0.0112\n",
      "Epoch 58/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.9098 - categorical_accuracy: 0.0206 - val_loss: 8.4949 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.9889 - categorical_accuracy: 0.0252 - val_loss: 7.7316 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.5774 - categorical_accuracy: 0.0262 - val_loss: 7.6796 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.0982 - categorical_accuracy: 0.0308 - val_loss: 8.5539 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.6391 - categorical_accuracy: 0.0234 - val_loss: 7.9853 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.0528 - categorical_accuracy: 0.0271 - val_loss: 8.4180 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.5589 - categorical_accuracy: 0.0280 - val_loss: 8.2339 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.7460 - categorical_accuracy: 0.0262 - val_loss: 8.4146 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.6673 - categorical_accuracy: 0.0290 - val_loss: 8.4887 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.3115 - categorical_accuracy: 0.0187 - val_loss: 7.9367 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.9955 - categorical_accuracy: 0.0252 - val_loss: 8.1514 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.0019 - categorical_accuracy: 0.0243 - val_loss: 8.2227 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.6123 - categorical_accuracy: 0.0280 - val_loss: 6.9994 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 7.8784 - categorical_accuracy: 0.0318 - val_loss: 8.1701 - val_categorical_accuracy: 0.0187\n",
      "Epoch 72/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.7123 - categorical_accuracy: 0.0262 - val_loss: 8.9220 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.6087 - categorical_accuracy: 0.0262 - val_loss: 8.1979 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.7714 - categorical_accuracy: 0.0271 - val_loss: 6.7595 - val_categorical_accuracy: 0.0336\n",
      "Epoch 75/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.5881 - categorical_accuracy: 0.0215 - val_loss: 10.0762 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.0276 - categorical_accuracy: 0.0215 - val_loss: 10.0668 - val_categorical_accuracy: 0.0224\n",
      "Epoch 77/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.5032 - categorical_accuracy: 0.0252 - val_loss: 8.1453 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.9426 - categorical_accuracy: 0.0271 - val_loss: 9.4594 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.4756 - categorical_accuracy: 0.0252 - val_loss: 7.7517 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 7.9163 - categorical_accuracy: 0.0206 - val_loss: 9.4151 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.8680 - categorical_accuracy: 0.0234 - val_loss: 9.0900 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.5664 - categorical_accuracy: 0.0224 - val_loss: 8.7886 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.8523 - categorical_accuracy: 0.0234 - val_loss: 7.5125 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 8.4162 - categorical_accuracy: 0.0168 - val_loss: 6.6617 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.6798 - categorical_accuracy: 0.0252 - val_loss: 7.9503 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.8436 - categorical_accuracy: 0.0262 - val_loss: 7.0473 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.0603 - categorical_accuracy: 0.0215 - val_loss: 8.0182 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.2415 - categorical_accuracy: 0.0262 - val_loss: 8.3867 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.3777 - categorical_accuracy: 0.0290 - val_loss: 6.6297 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.1213 - categorical_accuracy: 0.0271 - val_loss: 7.9115 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.5810 - categorical_accuracy: 0.0252 - val_loss: 6.0238 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.7173 - categorical_accuracy: 0.0271 - val_loss: 7.4153 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.5869 - categorical_accuracy: 0.0271 - val_loss: 6.6462 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.5079 - categorical_accuracy: 0.0271 - val_loss: 5.3906 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.8577 - categorical_accuracy: 0.0252 - val_loss: 5.8476 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.7644 - categorical_accuracy: 0.0224 - val_loss: 8.0942 - val_categorical_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.7295 - categorical_accuracy: 0.0280 - val_loss: 6.0611 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.6836 - categorical_accuracy: 0.0252 - val_loss: 5.3140 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.6254 - categorical_accuracy: 0.0271 - val_loss: 7.3098 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 100/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.7652 - categorical_accuracy: 0.0290 - val_loss: 5.8322 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.6242 - categorical_accuracy: 0.0336 - val_loss: 7.9454 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.5506 - categorical_accuracy: 0.0243 - val_loss: 7.8198 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 103/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.6540 - categorical_accuracy: 0.0290 - val_loss: 7.1545 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.6650 - categorical_accuracy: 0.0243 - val_loss: 8.4503 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.3348 - categorical_accuracy: 0.0280 - val_loss: 7.5106 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.1844 - categorical_accuracy: 0.0215 - val_loss: 8.4397 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.7129 - categorical_accuracy: 0.0196 - val_loss: 8.4647 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.5879 - categorical_accuracy: 0.0290 - val_loss: 7.7851 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.6103 - categorical_accuracy: 0.0271 - val_loss: 7.7386 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 110/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.6674 - categorical_accuracy: 0.0262 - val_loss: 8.4146 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 111/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.5094 - categorical_accuracy: 0.0308 - val_loss: 9.4931 - val_categorical_accuracy: 0.0261\n",
      "Epoch 112/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.6832 - categorical_accuracy: 0.0234 - val_loss: 8.4757 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 113/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.7000 - categorical_accuracy: 0.0243 - val_loss: 8.4142 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 114/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.3002 - categorical_accuracy: 0.0252 - val_loss: 5.8094 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 115/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.5368 - categorical_accuracy: 0.0290 - val_loss: 9.0826 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 116/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.6222 - categorical_accuracy: 0.0262 - val_loss: 8.3829 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 117/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.3766 - categorical_accuracy: 0.0262 - val_loss: 7.3047 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 118/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.0302 - categorical_accuracy: 0.0290 - val_loss: 8.8762 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 119/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.3603 - categorical_accuracy: 0.0290 - val_loss: 9.1087 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 120/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.4026 - categorical_accuracy: 0.0262 - val_loss: 7.9267 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 121/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.6202 - categorical_accuracy: 0.0290 - val_loss: 9.2697 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 122/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 8.5260 - categorical_accuracy: 0.0252 - val_loss: 8.1992 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 123/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.5901 - categorical_accuracy: 0.0262 - val_loss: 9.0482 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 124/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.0130 - categorical_accuracy: 0.0308 - val_loss: 9.1983 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 125/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.5665 - categorical_accuracy: 0.0252 - val_loss: 7.6262 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.6045 - categorical_accuracy: 0.0271 - val_loss: 8.5689 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 127/1000\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 7.4565 - categorical_accuracy: 0.0224 - val_loss: 8.0201 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 128/1000\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 7.4677 - categorical_accuracy: 0.0168 - val_loss: 7.9143 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 129/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.7088 - categorical_accuracy: 0.0262 - val_loss: 8.6854 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 130/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 7.5318 - categorical_accuracy: 0.0271 - val_loss: 7.9234 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 131/1000\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 7.8346 - categorical_accuracy: 0.0290 - val_loss: 8.5074 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 8.7599 - categorical_accuracy: 0.0224 - val_loss: 9.2849 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "13/17 [=====================>........] - ETA: 0s - loss: 8.5317 - categorical_accuracy: 0.0228"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[170], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adagrad(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.01\u001b[39m)\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential(name='Sequential')\n",
    "act_function = 'tanh'\n",
    "model.add(GRU(64, return_sequences=True, activation=act_function, input_shape=(130,126)))\n",
    "model.add(GRU(64, return_sequences=False, activation=act_function))\n",
    "model.add(Dense(64, activation=act_function))\n",
    "model.add(Dense(50, activation=act_function))\n",
    "optimizer = Adagrad(learning_rate=.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, epochs=1000, validation_split=.2, batch_size = 64)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b335502b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T18:40:11.656593Z",
     "start_time": "2023-08-10T18:38:45.727314Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/1000\n",
      "34/34 [==============================] - 24s 563ms/step - loss: 3.9129 - categorical_accuracy: 0.0280 - val_loss: 3.9095 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "34/34 [==============================] - 18s 534ms/step - loss: 3.9129 - categorical_accuracy: 0.0280 - val_loss: 3.9095 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "34/34 [==============================] - 18s 528ms/step - loss: 3.9129 - categorical_accuracy: 0.0280 - val_loss: 3.9095 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "34/34 [==============================] - 17s 512ms/step - loss: 3.9129 - categorical_accuracy: 0.0280 - val_loss: 3.9095 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "14/34 [===========>..................] - ETA: 10s - loss: 3.9135 - categorical_accuracy: 0.0290"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[171], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m SGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.0000005\u001b[39m)\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "act_function = 'LeakyReLU'\n",
    "model.add(LSTM(64, return_sequences=True, activation=act_function, input_shape=(130,126)))\n",
    "model.add(GRU(128, return_sequences=True, activation=act_function))\n",
    "model.add(LSTM(64, return_sequences=False, activation=act_function))\n",
    "model.add(Dense(64, activation=act_function))\n",
    "model.add(Dense(32, activation=act_function))\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "optimizer = SGD(learning_rate=.0000005)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, epochs=1000, validation_split=.2, batch_size = 32, callbacks=[tb_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1c679311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T19:18:22.906546Z",
     "start_time": "2023-08-10T18:40:22.741843Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 9s 442ms/step - loss: 3.9150 - categorical_accuracy: 0.0249 - val_loss: 3.9111 - val_categorical_accuracy: 0.0205\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 5s 412ms/step - loss: 3.9105 - categorical_accuracy: 0.0237 - val_loss: 3.9111 - val_categorical_accuracy: 0.0131\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 5s 410ms/step - loss: 3.9039 - categorical_accuracy: 0.0224 - val_loss: 3.9114 - val_categorical_accuracy: 0.0205\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 5s 418ms/step - loss: 3.8937 - categorical_accuracy: 0.0262 - val_loss: 3.9152 - val_categorical_accuracy: 0.0205\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 5s 416ms/step - loss: 3.8874 - categorical_accuracy: 0.0274 - val_loss: 3.9219 - val_categorical_accuracy: 0.0112\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 5s 416ms/step - loss: 3.8808 - categorical_accuracy: 0.0187 - val_loss: 3.9215 - val_categorical_accuracy: 0.0112\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 5s 413ms/step - loss: 3.8748 - categorical_accuracy: 0.0262 - val_loss: 3.9268 - val_categorical_accuracy: 0.0112\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 5s 417ms/step - loss: 3.8687 - categorical_accuracy: 0.0274 - val_loss: 3.9332 - val_categorical_accuracy: 0.0112\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 6s 428ms/step - loss: 3.8616 - categorical_accuracy: 0.0274 - val_loss: 3.9462 - val_categorical_accuracy: 0.0131\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 5s 426ms/step - loss: 3.8548 - categorical_accuracy: 0.0299 - val_loss: 3.9643 - val_categorical_accuracy: 0.0131\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 6s 428ms/step - loss: 3.8482 - categorical_accuracy: 0.0312 - val_loss: 3.9829 - val_categorical_accuracy: 0.0224\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 5s 425ms/step - loss: 3.8399 - categorical_accuracy: 0.0274 - val_loss: 4.0030 - val_categorical_accuracy: 0.0261\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 5s 424ms/step - loss: 3.8321 - categorical_accuracy: 0.0362 - val_loss: 4.0234 - val_categorical_accuracy: 0.0224\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 6s 428ms/step - loss: 3.8217 - categorical_accuracy: 0.0424 - val_loss: 4.0465 - val_categorical_accuracy: 0.0205\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 6s 429ms/step - loss: 3.8144 - categorical_accuracy: 0.0399 - val_loss: 4.0773 - val_categorical_accuracy: 0.0224\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 5s 419ms/step - loss: 3.7981 - categorical_accuracy: 0.0374 - val_loss: 4.1073 - val_categorical_accuracy: 0.0261\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 6s 438ms/step - loss: 3.7787 - categorical_accuracy: 0.0474 - val_loss: 4.1444 - val_categorical_accuracy: 0.0299\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 5s 421ms/step - loss: 3.7543 - categorical_accuracy: 0.0499 - val_loss: 4.1458 - val_categorical_accuracy: 0.0299\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 6s 434ms/step - loss: 3.7331 - categorical_accuracy: 0.0524 - val_loss: 4.1205 - val_categorical_accuracy: 0.0392\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 6s 435ms/step - loss: 3.7012 - categorical_accuracy: 0.0561 - val_loss: 4.1289 - val_categorical_accuracy: 0.0336\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 6s 434ms/step - loss: 3.6532 - categorical_accuracy: 0.0711 - val_loss: 4.1299 - val_categorical_accuracy: 0.0354\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 6s 435ms/step - loss: 3.5889 - categorical_accuracy: 0.0786 - val_loss: 4.0921 - val_categorical_accuracy: 0.0429\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 6s 427ms/step - loss: 3.5028 - categorical_accuracy: 0.0786 - val_loss: 4.0427 - val_categorical_accuracy: 0.0690\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 6s 435ms/step - loss: 3.3985 - categorical_accuracy: 0.0910 - val_loss: 4.0219 - val_categorical_accuracy: 0.0690\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 6s 432ms/step - loss: 3.3224 - categorical_accuracy: 0.1047 - val_loss: 3.9177 - val_categorical_accuracy: 0.0802\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 6s 439ms/step - loss: 3.2152 - categorical_accuracy: 0.1147 - val_loss: 3.8322 - val_categorical_accuracy: 0.0970\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 6s 435ms/step - loss: 3.1223 - categorical_accuracy: 0.1209 - val_loss: 3.7491 - val_categorical_accuracy: 0.1157\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 6s 437ms/step - loss: 2.9965 - categorical_accuracy: 0.1471 - val_loss: 3.6944 - val_categorical_accuracy: 0.1213\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 6s 434ms/step - loss: 2.9094 - categorical_accuracy: 0.1796 - val_loss: 3.6422 - val_categorical_accuracy: 0.1231\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 6s 434ms/step - loss: 2.7621 - categorical_accuracy: 0.2007 - val_loss: 3.6601 - val_categorical_accuracy: 0.1362\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 6s 437ms/step - loss: 2.6832 - categorical_accuracy: 0.2107 - val_loss: 3.5152 - val_categorical_accuracy: 0.1922\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 6s 437ms/step - loss: 2.5570 - categorical_accuracy: 0.2506 - val_loss: 3.4606 - val_categorical_accuracy: 0.2108\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 6s 440ms/step - loss: 2.4388 - categorical_accuracy: 0.2494 - val_loss: 3.5171 - val_categorical_accuracy: 0.1940\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 6s 433ms/step - loss: 2.3824 - categorical_accuracy: 0.2993 - val_loss: 3.6827 - val_categorical_accuracy: 0.2164\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 6s 449ms/step - loss: 2.2566 - categorical_accuracy: 0.3217 - val_loss: 3.5422 - val_categorical_accuracy: 0.2183\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 6s 431ms/step - loss: 2.1955 - categorical_accuracy: 0.3404 - val_loss: 3.5927 - val_categorical_accuracy: 0.1978\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 6s 448ms/step - loss: 2.0872 - categorical_accuracy: 0.3728 - val_loss: 3.3703 - val_categorical_accuracy: 0.2444\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 6s 438ms/step - loss: 1.9886 - categorical_accuracy: 0.3865 - val_loss: 3.4527 - val_categorical_accuracy: 0.2537\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 6s 444ms/step - loss: 1.8881 - categorical_accuracy: 0.4140 - val_loss: 3.6167 - val_categorical_accuracy: 0.2593\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 6s 431ms/step - loss: 1.7964 - categorical_accuracy: 0.4489 - val_loss: 3.6394 - val_categorical_accuracy: 0.2836\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 6s 445ms/step - loss: 1.7143 - categorical_accuracy: 0.4713 - val_loss: 3.6712 - val_categorical_accuracy: 0.2854\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 6s 449ms/step - loss: 1.6120 - categorical_accuracy: 0.4913 - val_loss: 3.8493 - val_categorical_accuracy: 0.2649\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 6s 444ms/step - loss: 1.5418 - categorical_accuracy: 0.4988 - val_loss: 4.0762 - val_categorical_accuracy: 0.2799\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 6s 449ms/step - loss: 1.4459 - categorical_accuracy: 0.5337 - val_loss: 4.4490 - val_categorical_accuracy: 0.2500\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 6s 450ms/step - loss: 1.3662 - categorical_accuracy: 0.5748 - val_loss: 4.4910 - val_categorical_accuracy: 0.2910\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 6s 447ms/step - loss: 1.2692 - categorical_accuracy: 0.5948 - val_loss: 4.5429 - val_categorical_accuracy: 0.2817\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 6s 452ms/step - loss: 1.2597 - categorical_accuracy: 0.6072 - val_loss: 4.4801 - val_categorical_accuracy: 0.2929\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 6s 440ms/step - loss: 1.1841 - categorical_accuracy: 0.6147 - val_loss: 4.6412 - val_categorical_accuracy: 0.3041\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 6s 439ms/step - loss: 1.1384 - categorical_accuracy: 0.6372 - val_loss: 4.6283 - val_categorical_accuracy: 0.3228\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 6s 449ms/step - loss: 1.0968 - categorical_accuracy: 0.6559 - val_loss: 4.7393 - val_categorical_accuracy: 0.3153\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 6s 443ms/step - loss: 1.0123 - categorical_accuracy: 0.6696 - val_loss: 5.0987 - val_categorical_accuracy: 0.3153\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 6s 451ms/step - loss: 0.9520 - categorical_accuracy: 0.6895 - val_loss: 4.9586 - val_categorical_accuracy: 0.3134\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 6s 451ms/step - loss: 0.9242 - categorical_accuracy: 0.7020 - val_loss: 5.1635 - val_categorical_accuracy: 0.3246\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 6s 449ms/step - loss: 0.8573 - categorical_accuracy: 0.7332 - val_loss: 5.0632 - val_categorical_accuracy: 0.3134\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 6s 453ms/step - loss: 0.8201 - categorical_accuracy: 0.7332 - val_loss: 5.2245 - val_categorical_accuracy: 0.3433\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 6s 445ms/step - loss: 0.8105 - categorical_accuracy: 0.7444 - val_loss: 5.0496 - val_categorical_accuracy: 0.3396\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 6s 446ms/step - loss: 0.7341 - categorical_accuracy: 0.7631 - val_loss: 5.5026 - val_categorical_accuracy: 0.3545\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 6s 445ms/step - loss: 0.6950 - categorical_accuracy: 0.7731 - val_loss: 5.6492 - val_categorical_accuracy: 0.3414\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 6s 453ms/step - loss: 0.6441 - categorical_accuracy: 0.7943 - val_loss: 5.9890 - val_categorical_accuracy: 0.3246\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 6s 457ms/step - loss: 0.6112 - categorical_accuracy: 0.8080 - val_loss: 5.6471 - val_categorical_accuracy: 0.3470\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 6s 451ms/step - loss: 0.5964 - categorical_accuracy: 0.8155 - val_loss: 5.8881 - val_categorical_accuracy: 0.3545\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 6s 453ms/step - loss: 0.5745 - categorical_accuracy: 0.8192 - val_loss: 5.7558 - val_categorical_accuracy: 0.3396\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 6s 455ms/step - loss: 0.5401 - categorical_accuracy: 0.8167 - val_loss: 6.0968 - val_categorical_accuracy: 0.3787\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 6s 451ms/step - loss: 0.4938 - categorical_accuracy: 0.8392 - val_loss: 6.4691 - val_categorical_accuracy: 0.3451\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 6s 445ms/step - loss: 0.4593 - categorical_accuracy: 0.8579 - val_loss: 6.5807 - val_categorical_accuracy: 0.3563\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 6s 447ms/step - loss: 0.4148 - categorical_accuracy: 0.8728 - val_loss: 6.5637 - val_categorical_accuracy: 0.3489\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 6s 448ms/step - loss: 0.4229 - categorical_accuracy: 0.8691 - val_loss: 6.9028 - val_categorical_accuracy: 0.3507\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 6s 452ms/step - loss: 0.3824 - categorical_accuracy: 0.8728 - val_loss: 7.1524 - val_categorical_accuracy: 0.3619\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 6s 450ms/step - loss: 0.3970 - categorical_accuracy: 0.8778 - val_loss: 7.0301 - val_categorical_accuracy: 0.3526\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 6s 450ms/step - loss: 0.3838 - categorical_accuracy: 0.8766 - val_loss: 7.0470 - val_categorical_accuracy: 0.3601\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 6s 449ms/step - loss: 0.3449 - categorical_accuracy: 0.8815 - val_loss: 6.7299 - val_categorical_accuracy: 0.3619\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 6s 450ms/step - loss: 0.3690 - categorical_accuracy: 0.8716 - val_loss: 6.8778 - val_categorical_accuracy: 0.3657\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 6s 463ms/step - loss: 0.3179 - categorical_accuracy: 0.8978 - val_loss: 6.8867 - val_categorical_accuracy: 0.3657\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 6s 457ms/step - loss: 0.2766 - categorical_accuracy: 0.9077 - val_loss: 6.9785 - val_categorical_accuracy: 0.3545\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 6s 450ms/step - loss: 0.2880 - categorical_accuracy: 0.9077 - val_loss: 7.6152 - val_categorical_accuracy: 0.3507\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 6s 462ms/step - loss: 0.2644 - categorical_accuracy: 0.9115 - val_loss: 7.3013 - val_categorical_accuracy: 0.3675\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 6s 457ms/step - loss: 0.2889 - categorical_accuracy: 0.9115 - val_loss: 7.3502 - val_categorical_accuracy: 0.3470\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 6s 454ms/step - loss: 0.2905 - categorical_accuracy: 0.9102 - val_loss: 7.0544 - val_categorical_accuracy: 0.3601\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 6s 452ms/step - loss: 0.2834 - categorical_accuracy: 0.9077 - val_loss: 7.4207 - val_categorical_accuracy: 0.3433\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 6s 458ms/step - loss: 0.2392 - categorical_accuracy: 0.9252 - val_loss: 7.2935 - val_categorical_accuracy: 0.3414\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 6s 461ms/step - loss: 0.2538 - categorical_accuracy: 0.9202 - val_loss: 7.1851 - val_categorical_accuracy: 0.3507\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 6s 448ms/step - loss: 0.2136 - categorical_accuracy: 0.9289 - val_loss: 7.3653 - val_categorical_accuracy: 0.3507\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 6s 460ms/step - loss: 0.2398 - categorical_accuracy: 0.9214 - val_loss: 7.1803 - val_categorical_accuracy: 0.3582\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 0.1957 - categorical_accuracy: 0.9339 - val_loss: 7.0987 - val_categorical_accuracy: 0.3638\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 6s 456ms/step - loss: 0.2100 - categorical_accuracy: 0.9314 - val_loss: 7.2649 - val_categorical_accuracy: 0.3657\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 6s 468ms/step - loss: 0.2601 - categorical_accuracy: 0.9214 - val_loss: 7.1470 - val_categorical_accuracy: 0.3451\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 6s 453ms/step - loss: 0.2758 - categorical_accuracy: 0.9115 - val_loss: 7.1371 - val_categorical_accuracy: 0.3601\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 6s 468ms/step - loss: 0.2020 - categorical_accuracy: 0.9302 - val_loss: 7.3227 - val_categorical_accuracy: 0.3321\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 6s 455ms/step - loss: 0.2200 - categorical_accuracy: 0.9426 - val_loss: 7.2477 - val_categorical_accuracy: 0.3787\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 6s 458ms/step - loss: 0.2283 - categorical_accuracy: 0.9314 - val_loss: 7.1441 - val_categorical_accuracy: 0.3563\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 6s 457ms/step - loss: 0.1869 - categorical_accuracy: 0.9426 - val_loss: 7.6072 - val_categorical_accuracy: 0.3228\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 6s 458ms/step - loss: 0.1920 - categorical_accuracy: 0.9414 - val_loss: 7.6394 - val_categorical_accuracy: 0.3246\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 6s 458ms/step - loss: 0.1961 - categorical_accuracy: 0.9414 - val_loss: 7.2566 - val_categorical_accuracy: 0.3638\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 6s 461ms/step - loss: 0.1576 - categorical_accuracy: 0.9501 - val_loss: 7.7150 - val_categorical_accuracy: 0.3470\n",
      "Epoch 95/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 6s 453ms/step - loss: 0.1663 - categorical_accuracy: 0.9476 - val_loss: 7.7187 - val_categorical_accuracy: 0.3582\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 6s 462ms/step - loss: 0.1604 - categorical_accuracy: 0.9589 - val_loss: 7.9065 - val_categorical_accuracy: 0.3675\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 6s 462ms/step - loss: 0.2348 - categorical_accuracy: 0.9377 - val_loss: 7.6548 - val_categorical_accuracy: 0.3731\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 6s 461ms/step - loss: 0.2026 - categorical_accuracy: 0.9377 - val_loss: 7.6788 - val_categorical_accuracy: 0.3619\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 6s 451ms/step - loss: 0.1327 - categorical_accuracy: 0.9539 - val_loss: 7.5109 - val_categorical_accuracy: 0.3638\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 6s 461ms/step - loss: 0.1414 - categorical_accuracy: 0.9514 - val_loss: 7.2929 - val_categorical_accuracy: 0.3489\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 6s 460ms/step - loss: 0.1349 - categorical_accuracy: 0.9576 - val_loss: 7.1571 - val_categorical_accuracy: 0.3451\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 6s 462ms/step - loss: 0.1361 - categorical_accuracy: 0.9589 - val_loss: 7.3590 - val_categorical_accuracy: 0.3638\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 6s 453ms/step - loss: 0.1431 - categorical_accuracy: 0.9651 - val_loss: 7.5606 - val_categorical_accuracy: 0.3563\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.1018 - categorical_accuracy: 0.9688 - val_loss: 7.6148 - val_categorical_accuracy: 0.3619\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 6s 459ms/step - loss: 0.1302 - categorical_accuracy: 0.9651 - val_loss: 7.9971 - val_categorical_accuracy: 0.3451\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 6s 463ms/step - loss: 0.1279 - categorical_accuracy: 0.9526 - val_loss: 8.0096 - val_categorical_accuracy: 0.3619\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 6s 457ms/step - loss: 0.1205 - categorical_accuracy: 0.9514 - val_loss: 8.2958 - val_categorical_accuracy: 0.3414\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 6s 457ms/step - loss: 0.1649 - categorical_accuracy: 0.9526 - val_loss: 8.0528 - val_categorical_accuracy: 0.3825\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 6s 460ms/step - loss: 0.1395 - categorical_accuracy: 0.9539 - val_loss: 8.4111 - val_categorical_accuracy: 0.3713\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.1261 - categorical_accuracy: 0.9613 - val_loss: 8.2244 - val_categorical_accuracy: 0.3619\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 6s 460ms/step - loss: 0.1497 - categorical_accuracy: 0.9489 - val_loss: 8.3358 - val_categorical_accuracy: 0.3619\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.1395 - categorical_accuracy: 0.9551 - val_loss: 8.3807 - val_categorical_accuracy: 0.3694\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 0.2052 - categorical_accuracy: 0.9414 - val_loss: 8.0694 - val_categorical_accuracy: 0.3769\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 0.0754 - categorical_accuracy: 0.9776 - val_loss: 8.3268 - val_categorical_accuracy: 0.3601\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 0.1182 - categorical_accuracy: 0.9626 - val_loss: 8.3696 - val_categorical_accuracy: 0.3489\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 6s 476ms/step - loss: 0.1255 - categorical_accuracy: 0.9589 - val_loss: 8.5399 - val_categorical_accuracy: 0.3694\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.1145 - categorical_accuracy: 0.9551 - val_loss: 8.1756 - val_categorical_accuracy: 0.3731\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 6s 466ms/step - loss: 0.0963 - categorical_accuracy: 0.9701 - val_loss: 8.2506 - val_categorical_accuracy: 0.3881\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 6s 463ms/step - loss: 0.1148 - categorical_accuracy: 0.9626 - val_loss: 8.3162 - val_categorical_accuracy: 0.3731\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.0784 - categorical_accuracy: 0.9726 - val_loss: 8.6120 - val_categorical_accuracy: 0.3731\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 6s 466ms/step - loss: 0.1126 - categorical_accuracy: 0.9663 - val_loss: 8.4268 - val_categorical_accuracy: 0.3750\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 6s 476ms/step - loss: 0.1232 - categorical_accuracy: 0.9564 - val_loss: 8.2797 - val_categorical_accuracy: 0.3974\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 6s 476ms/step - loss: 0.1298 - categorical_accuracy: 0.9626 - val_loss: 7.8934 - val_categorical_accuracy: 0.3918\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 0.1096 - categorical_accuracy: 0.9663 - val_loss: 8.0114 - val_categorical_accuracy: 0.3787\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 0.1270 - categorical_accuracy: 0.9638 - val_loss: 8.1745 - val_categorical_accuracy: 0.3769\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 6s 469ms/step - loss: 0.1332 - categorical_accuracy: 0.9564 - val_loss: 7.8302 - val_categorical_accuracy: 0.3899\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 0.1055 - categorical_accuracy: 0.9638 - val_loss: 7.6512 - val_categorical_accuracy: 0.3862\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 6s 464ms/step - loss: 0.0974 - categorical_accuracy: 0.9688 - val_loss: 7.7470 - val_categorical_accuracy: 0.3769\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 6s 469ms/step - loss: 0.1035 - categorical_accuracy: 0.9638 - val_loss: 7.6380 - val_categorical_accuracy: 0.3825\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 6s 481ms/step - loss: 0.0816 - categorical_accuracy: 0.9751 - val_loss: 7.8332 - val_categorical_accuracy: 0.3806\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 0.1104 - categorical_accuracy: 0.9601 - val_loss: 7.8070 - val_categorical_accuracy: 0.4030\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 6s 468ms/step - loss: 0.0813 - categorical_accuracy: 0.9701 - val_loss: 7.8705 - val_categorical_accuracy: 0.4086\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0825 - categorical_accuracy: 0.9726 - val_loss: 8.0821 - val_categorical_accuracy: 0.3862\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 6s 468ms/step - loss: 0.1006 - categorical_accuracy: 0.9713 - val_loss: 8.0976 - val_categorical_accuracy: 0.4086\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 6s 468ms/step - loss: 0.0953 - categorical_accuracy: 0.9688 - val_loss: 8.0541 - val_categorical_accuracy: 0.4123\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 6s 468ms/step - loss: 0.0944 - categorical_accuracy: 0.9751 - val_loss: 8.2985 - val_categorical_accuracy: 0.3974\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 6s 480ms/step - loss: 0.1124 - categorical_accuracy: 0.9626 - val_loss: 8.1883 - val_categorical_accuracy: 0.4179\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 0.0967 - categorical_accuracy: 0.9688 - val_loss: 8.6515 - val_categorical_accuracy: 0.3843\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.1066 - categorical_accuracy: 0.9651 - val_loss: 8.5649 - val_categorical_accuracy: 0.4030\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.0658 - categorical_accuracy: 0.9788 - val_loss: 8.9479 - val_categorical_accuracy: 0.3713\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.1198 - categorical_accuracy: 0.9626 - val_loss: 8.7732 - val_categorical_accuracy: 0.3862\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.1048 - categorical_accuracy: 0.9676 - val_loss: 8.6990 - val_categorical_accuracy: 0.3937\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 6s 487ms/step - loss: 0.0744 - categorical_accuracy: 0.9763 - val_loss: 9.1035 - val_categorical_accuracy: 0.3862\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0956 - categorical_accuracy: 0.9688 - val_loss: 8.6928 - val_categorical_accuracy: 0.3825\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.1122 - categorical_accuracy: 0.9688 - val_loss: 8.5852 - val_categorical_accuracy: 0.3843\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 6s 470ms/step - loss: 0.0999 - categorical_accuracy: 0.9713 - val_loss: 8.2588 - val_categorical_accuracy: 0.4104\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 6s 464ms/step - loss: 0.0800 - categorical_accuracy: 0.9738 - val_loss: 8.2599 - val_categorical_accuracy: 0.3974\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 6s 469ms/step - loss: 0.0717 - categorical_accuracy: 0.9776 - val_loss: 8.1588 - val_categorical_accuracy: 0.4011\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.0517 - categorical_accuracy: 0.9825 - val_loss: 8.3182 - val_categorical_accuracy: 0.4235\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0827 - categorical_accuracy: 0.9763 - val_loss: 8.4833 - val_categorical_accuracy: 0.4216\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.1285 - categorical_accuracy: 0.9626 - val_loss: 8.3654 - val_categorical_accuracy: 0.4422\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 6s 469ms/step - loss: 0.1265 - categorical_accuracy: 0.9638 - val_loss: 8.7569 - val_categorical_accuracy: 0.4160\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.1406 - categorical_accuracy: 0.9688 - val_loss: 8.7692 - val_categorical_accuracy: 0.4198\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 6s 480ms/step - loss: 0.1057 - categorical_accuracy: 0.9651 - val_loss: 8.4935 - val_categorical_accuracy: 0.4030\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0792 - categorical_accuracy: 0.9800 - val_loss: 8.3753 - val_categorical_accuracy: 0.4235\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 0.1055 - categorical_accuracy: 0.9638 - val_loss: 8.2301 - val_categorical_accuracy: 0.4272\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0919 - categorical_accuracy: 0.9676 - val_loss: 7.9175 - val_categorical_accuracy: 0.4347\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 6s 468ms/step - loss: 0.0697 - categorical_accuracy: 0.9800 - val_loss: 7.7524 - val_categorical_accuracy: 0.4254\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0693 - categorical_accuracy: 0.9751 - val_loss: 8.2986 - val_categorical_accuracy: 0.4030\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 6s 464ms/step - loss: 0.0791 - categorical_accuracy: 0.9738 - val_loss: 8.2601 - val_categorical_accuracy: 0.4011\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.1149 - categorical_accuracy: 0.9638 - val_loss: 8.1590 - val_categorical_accuracy: 0.4067\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 6s 464ms/step - loss: 0.1268 - categorical_accuracy: 0.9688 - val_loss: 7.8785 - val_categorical_accuracy: 0.4272\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 0.0621 - categorical_accuracy: 0.9788 - val_loss: 7.8272 - val_categorical_accuracy: 0.4254\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 0.0944 - categorical_accuracy: 0.9688 - val_loss: 7.8728 - val_categorical_accuracy: 0.4310\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 6s 464ms/step - loss: 0.0814 - categorical_accuracy: 0.9763 - val_loss: 7.8622 - val_categorical_accuracy: 0.4142\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 0.0831 - categorical_accuracy: 0.9763 - val_loss: 7.8824 - val_categorical_accuracy: 0.4123\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 6s 468ms/step - loss: 0.1013 - categorical_accuracy: 0.9663 - val_loss: 8.0846 - val_categorical_accuracy: 0.3993\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 0.0742 - categorical_accuracy: 0.9788 - val_loss: 8.0626 - val_categorical_accuracy: 0.4254\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.1044 - categorical_accuracy: 0.9788 - val_loss: 7.6867 - val_categorical_accuracy: 0.4272\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 0.0727 - categorical_accuracy: 0.9813 - val_loss: 7.9528 - val_categorical_accuracy: 0.4086\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 6s 470ms/step - loss: 0.1091 - categorical_accuracy: 0.9701 - val_loss: 7.6627 - val_categorical_accuracy: 0.4160\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 0.0745 - categorical_accuracy: 0.9776 - val_loss: 7.8209 - val_categorical_accuracy: 0.4235\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 6s 464ms/step - loss: 0.0495 - categorical_accuracy: 0.9825 - val_loss: 7.5941 - val_categorical_accuracy: 0.4515\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 6s 466ms/step - loss: 0.0898 - categorical_accuracy: 0.9713 - val_loss: 7.7669 - val_categorical_accuracy: 0.4552\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 6s 470ms/step - loss: 0.0613 - categorical_accuracy: 0.9813 - val_loss: 8.0090 - val_categorical_accuracy: 0.4366\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 6s 461ms/step - loss: 0.0807 - categorical_accuracy: 0.9776 - val_loss: 8.1080 - val_categorical_accuracy: 0.4254\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.0567 - categorical_accuracy: 0.9863 - val_loss: 8.4867 - val_categorical_accuracy: 0.4142\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 0.0451 - categorical_accuracy: 0.9850 - val_loss: 8.3070 - val_categorical_accuracy: 0.4160\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 6s 464ms/step - loss: 0.0858 - categorical_accuracy: 0.9800 - val_loss: 8.2153 - val_categorical_accuracy: 0.4272\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.0646 - categorical_accuracy: 0.9763 - val_loss: 8.1856 - val_categorical_accuracy: 0.4310\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 0.0778 - categorical_accuracy: 0.9788 - val_loss: 8.3025 - val_categorical_accuracy: 0.4179\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 6s 478ms/step - loss: 0.0527 - categorical_accuracy: 0.9763 - val_loss: 7.8507 - val_categorical_accuracy: 0.4011\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 6s 478ms/step - loss: 0.0713 - categorical_accuracy: 0.9800 - val_loss: 8.2246 - val_categorical_accuracy: 0.4216\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 6s 469ms/step - loss: 0.0924 - categorical_accuracy: 0.9626 - val_loss: 8.3418 - val_categorical_accuracy: 0.3937\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 6s 461ms/step - loss: 0.0589 - categorical_accuracy: 0.9776 - val_loss: 8.5594 - val_categorical_accuracy: 0.4067\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 0.1140 - categorical_accuracy: 0.9688 - val_loss: 8.1412 - val_categorical_accuracy: 0.4235\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 0.0793 - categorical_accuracy: 0.9788 - val_loss: 8.1387 - val_categorical_accuracy: 0.4235\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 6s 460ms/step - loss: 0.1216 - categorical_accuracy: 0.9701 - val_loss: 7.8605 - val_categorical_accuracy: 0.4422\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 6s 466ms/step - loss: 0.0782 - categorical_accuracy: 0.9726 - val_loss: 7.5448 - val_categorical_accuracy: 0.4515\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 6s 462ms/step - loss: 0.0422 - categorical_accuracy: 0.9838 - val_loss: 7.7711 - val_categorical_accuracy: 0.4179\n",
      "Epoch 191/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 6s 462ms/step - loss: 0.0572 - categorical_accuracy: 0.9825 - val_loss: 7.4264 - val_categorical_accuracy: 0.4347\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 0.0595 - categorical_accuracy: 0.9813 - val_loss: 8.1414 - val_categorical_accuracy: 0.4347\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 6s 464ms/step - loss: 0.0871 - categorical_accuracy: 0.9713 - val_loss: 7.8970 - val_categorical_accuracy: 0.4347\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0746 - categorical_accuracy: 0.9751 - val_loss: 8.1593 - val_categorical_accuracy: 0.4328\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 6s 466ms/step - loss: 0.0704 - categorical_accuracy: 0.9738 - val_loss: 8.0066 - val_categorical_accuracy: 0.4515\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 0.0665 - categorical_accuracy: 0.9825 - val_loss: 8.0449 - val_categorical_accuracy: 0.4552\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 6s 470ms/step - loss: 0.0832 - categorical_accuracy: 0.9738 - val_loss: 7.9584 - val_categorical_accuracy: 0.4403\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 6s 456ms/step - loss: 0.0935 - categorical_accuracy: 0.9751 - val_loss: 8.0219 - val_categorical_accuracy: 0.4534\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.0813 - categorical_accuracy: 0.9838 - val_loss: 7.8509 - val_categorical_accuracy: 0.4366\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 6s 462ms/step - loss: 0.0835 - categorical_accuracy: 0.9763 - val_loss: 7.7384 - val_categorical_accuracy: 0.4384\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 6s 468ms/step - loss: 0.0942 - categorical_accuracy: 0.9763 - val_loss: 7.9144 - val_categorical_accuracy: 0.4347\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 6s 461ms/step - loss: 0.0335 - categorical_accuracy: 0.9888 - val_loss: 8.0314 - val_categorical_accuracy: 0.4496\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 6s 451ms/step - loss: 0.0620 - categorical_accuracy: 0.9776 - val_loss: 7.5722 - val_categorical_accuracy: 0.4515\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 6s 459ms/step - loss: 0.0684 - categorical_accuracy: 0.9763 - val_loss: 7.8453 - val_categorical_accuracy: 0.4235\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 6s 499ms/step - loss: 0.0706 - categorical_accuracy: 0.9751 - val_loss: 7.6257 - val_categorical_accuracy: 0.4310\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.0599 - categorical_accuracy: 0.9875 - val_loss: 7.8753 - val_categorical_accuracy: 0.4235\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 6s 459ms/step - loss: 0.0472 - categorical_accuracy: 0.9900 - val_loss: 7.6553 - val_categorical_accuracy: 0.4272\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 6s 482ms/step - loss: 0.0613 - categorical_accuracy: 0.9788 - val_loss: 7.6929 - val_categorical_accuracy: 0.4310\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 6s 480ms/step - loss: 0.0565 - categorical_accuracy: 0.9825 - val_loss: 7.9834 - val_categorical_accuracy: 0.4366\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 6s 464ms/step - loss: 0.0590 - categorical_accuracy: 0.9788 - val_loss: 7.8488 - val_categorical_accuracy: 0.4422\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0343 - categorical_accuracy: 0.9913 - val_loss: 8.2900 - val_categorical_accuracy: 0.4179\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0678 - categorical_accuracy: 0.9825 - val_loss: 8.6632 - val_categorical_accuracy: 0.4160\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0704 - categorical_accuracy: 0.9776 - val_loss: 9.1730 - val_categorical_accuracy: 0.4198\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 6s 468ms/step - loss: 0.0555 - categorical_accuracy: 0.9800 - val_loss: 9.2775 - val_categorical_accuracy: 0.4086\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.0742 - categorical_accuracy: 0.9776 - val_loss: 9.3480 - val_categorical_accuracy: 0.4272\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 6s 468ms/step - loss: 0.0674 - categorical_accuracy: 0.9813 - val_loss: 8.7689 - val_categorical_accuracy: 0.4328\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.0641 - categorical_accuracy: 0.9838 - val_loss: 8.5261 - val_categorical_accuracy: 0.4328\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0664 - categorical_accuracy: 0.9800 - val_loss: 8.4537 - val_categorical_accuracy: 0.4422\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 6s 482ms/step - loss: 0.0687 - categorical_accuracy: 0.9776 - val_loss: 8.5436 - val_categorical_accuracy: 0.4328\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 6s 458ms/step - loss: 0.0668 - categorical_accuracy: 0.9813 - val_loss: 8.5814 - val_categorical_accuracy: 0.4254\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 6s 469ms/step - loss: 0.0826 - categorical_accuracy: 0.9738 - val_loss: 8.4747 - val_categorical_accuracy: 0.4552\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0539 - categorical_accuracy: 0.9838 - val_loss: 8.6935 - val_categorical_accuracy: 0.4310\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 0.0551 - categorical_accuracy: 0.9825 - val_loss: 8.6689 - val_categorical_accuracy: 0.4440\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 6s 478ms/step - loss: 0.0437 - categorical_accuracy: 0.9888 - val_loss: 8.8494 - val_categorical_accuracy: 0.4496\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0759 - categorical_accuracy: 0.9825 - val_loss: 8.5786 - val_categorical_accuracy: 0.4608\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 6s 476ms/step - loss: 0.0743 - categorical_accuracy: 0.9763 - val_loss: 8.2844 - val_categorical_accuracy: 0.4757\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 6s 478ms/step - loss: 0.0453 - categorical_accuracy: 0.9863 - val_loss: 8.4939 - val_categorical_accuracy: 0.4496\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 6s 476ms/step - loss: 0.0695 - categorical_accuracy: 0.9813 - val_loss: 8.0573 - val_categorical_accuracy: 0.4552\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 6s 470ms/step - loss: 0.0484 - categorical_accuracy: 0.9850 - val_loss: 8.0058 - val_categorical_accuracy: 0.4459\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 6s 466ms/step - loss: 0.0664 - categorical_accuracy: 0.9813 - val_loss: 8.6175 - val_categorical_accuracy: 0.4440\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 6s 479ms/step - loss: 0.0652 - categorical_accuracy: 0.9875 - val_loss: 8.7236 - val_categorical_accuracy: 0.4552\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 6s 466ms/step - loss: 0.0934 - categorical_accuracy: 0.9701 - val_loss: 8.8596 - val_categorical_accuracy: 0.4683\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 0.0548 - categorical_accuracy: 0.9825 - val_loss: 8.9241 - val_categorical_accuracy: 0.4552\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 6s 480ms/step - loss: 0.0615 - categorical_accuracy: 0.9838 - val_loss: 9.0249 - val_categorical_accuracy: 0.4552\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.0737 - categorical_accuracy: 0.9763 - val_loss: 9.2637 - val_categorical_accuracy: 0.4515\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 6s 470ms/step - loss: 0.0734 - categorical_accuracy: 0.9825 - val_loss: 8.8203 - val_categorical_accuracy: 0.4478\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 6s 466ms/step - loss: 0.0836 - categorical_accuracy: 0.9751 - val_loss: 8.5967 - val_categorical_accuracy: 0.4310\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 6s 463ms/step - loss: 0.0885 - categorical_accuracy: 0.9776 - val_loss: 8.6657 - val_categorical_accuracy: 0.4515\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0596 - categorical_accuracy: 0.9788 - val_loss: 8.8090 - val_categorical_accuracy: 0.4552\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 0.0743 - categorical_accuracy: 0.9825 - val_loss: 8.7819 - val_categorical_accuracy: 0.4608\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0879 - categorical_accuracy: 0.9788 - val_loss: 8.1050 - val_categorical_accuracy: 0.4739\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 0.0652 - categorical_accuracy: 0.9825 - val_loss: 8.4533 - val_categorical_accuracy: 0.4627\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.0874 - categorical_accuracy: 0.9726 - val_loss: 8.4717 - val_categorical_accuracy: 0.4664\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0523 - categorical_accuracy: 0.9825 - val_loss: 8.6567 - val_categorical_accuracy: 0.4646\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0919 - categorical_accuracy: 0.9788 - val_loss: 8.3967 - val_categorical_accuracy: 0.4552\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 6s 480ms/step - loss: 0.0736 - categorical_accuracy: 0.9813 - val_loss: 8.5167 - val_categorical_accuracy: 0.4757\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.0359 - categorical_accuracy: 0.9838 - val_loss: 8.4738 - val_categorical_accuracy: 0.4683\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.0704 - categorical_accuracy: 0.9776 - val_loss: 8.7533 - val_categorical_accuracy: 0.4664\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0514 - categorical_accuracy: 0.9825 - val_loss: 9.1290 - val_categorical_accuracy: 0.4422\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0572 - categorical_accuracy: 0.9850 - val_loss: 8.6459 - val_categorical_accuracy: 0.4440\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0688 - categorical_accuracy: 0.9788 - val_loss: 8.6460 - val_categorical_accuracy: 0.4552\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.0610 - categorical_accuracy: 0.9825 - val_loss: 8.6242 - val_categorical_accuracy: 0.4496\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0443 - categorical_accuracy: 0.9875 - val_loss: 8.9043 - val_categorical_accuracy: 0.4552\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0398 - categorical_accuracy: 0.9863 - val_loss: 8.6925 - val_categorical_accuracy: 0.4515\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 6s 480ms/step - loss: 0.0489 - categorical_accuracy: 0.9813 - val_loss: 8.4842 - val_categorical_accuracy: 0.4571\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.0678 - categorical_accuracy: 0.9813 - val_loss: 8.7822 - val_categorical_accuracy: 0.4590\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.0534 - categorical_accuracy: 0.9838 - val_loss: 9.3803 - val_categorical_accuracy: 0.4478\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 6s 469ms/step - loss: 0.0661 - categorical_accuracy: 0.9776 - val_loss: 9.1610 - val_categorical_accuracy: 0.4534\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0551 - categorical_accuracy: 0.9763 - val_loss: 9.3107 - val_categorical_accuracy: 0.4440\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0391 - categorical_accuracy: 0.9813 - val_loss: 9.4394 - val_categorical_accuracy: 0.4627\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 6s 470ms/step - loss: 0.0715 - categorical_accuracy: 0.9788 - val_loss: 9.4300 - val_categorical_accuracy: 0.4720\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 6s 468ms/step - loss: 0.0695 - categorical_accuracy: 0.9825 - val_loss: 9.7867 - val_categorical_accuracy: 0.4608\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 6s 470ms/step - loss: 0.0828 - categorical_accuracy: 0.9776 - val_loss: 9.6102 - val_categorical_accuracy: 0.4646\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 6s 481ms/step - loss: 0.0488 - categorical_accuracy: 0.9900 - val_loss: 9.9787 - val_categorical_accuracy: 0.4608\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 6s 476ms/step - loss: 0.0796 - categorical_accuracy: 0.9751 - val_loss: 9.7180 - val_categorical_accuracy: 0.4552\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 0.0700 - categorical_accuracy: 0.9813 - val_loss: 9.3115 - val_categorical_accuracy: 0.4813\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 6s 466ms/step - loss: 0.0648 - categorical_accuracy: 0.9776 - val_loss: 9.1135 - val_categorical_accuracy: 0.4701\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.0354 - categorical_accuracy: 0.9888 - val_loss: 9.0121 - val_categorical_accuracy: 0.4683\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 6s 481ms/step - loss: 0.0464 - categorical_accuracy: 0.9850 - val_loss: 9.4108 - val_categorical_accuracy: 0.4496\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.0487 - categorical_accuracy: 0.9800 - val_loss: 9.2589 - val_categorical_accuracy: 0.4496\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 0.0437 - categorical_accuracy: 0.9825 - val_loss: 9.4309 - val_categorical_accuracy: 0.4608\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0480 - categorical_accuracy: 0.9850 - val_loss: 9.5710 - val_categorical_accuracy: 0.4646\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.0550 - categorical_accuracy: 0.9825 - val_loss: 9.8155 - val_categorical_accuracy: 0.4552\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0687 - categorical_accuracy: 0.9838 - val_loss: 9.6194 - val_categorical_accuracy: 0.4459\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 6s 470ms/step - loss: 0.0613 - categorical_accuracy: 0.9800 - val_loss: 9.6479 - val_categorical_accuracy: 0.4515\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.0602 - categorical_accuracy: 0.9800 - val_loss: 9.3347 - val_categorical_accuracy: 0.4627\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 6s 479ms/step - loss: 0.0574 - categorical_accuracy: 0.9825 - val_loss: 9.3189 - val_categorical_accuracy: 0.4496\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.0400 - categorical_accuracy: 0.9900 - val_loss: 9.3867 - val_categorical_accuracy: 0.4534\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0605 - categorical_accuracy: 0.9825 - val_loss: 9.2808 - val_categorical_accuracy: 0.4459\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 6s 478ms/step - loss: 0.0738 - categorical_accuracy: 0.9813 - val_loss: 9.2802 - val_categorical_accuracy: 0.4403\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 6s 470ms/step - loss: 0.1004 - categorical_accuracy: 0.9763 - val_loss: 9.2380 - val_categorical_accuracy: 0.4496\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 0.0360 - categorical_accuracy: 0.9875 - val_loss: 9.3030 - val_categorical_accuracy: 0.4496\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0547 - categorical_accuracy: 0.9825 - val_loss: 9.4583 - val_categorical_accuracy: 0.4683\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.0912 - categorical_accuracy: 0.9825 - val_loss: 9.5471 - val_categorical_accuracy: 0.4571\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 6s 478ms/step - loss: 0.0760 - categorical_accuracy: 0.9751 - val_loss: 9.2979 - val_categorical_accuracy: 0.4776\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 6s 470ms/step - loss: 0.0462 - categorical_accuracy: 0.9888 - val_loss: 9.3472 - val_categorical_accuracy: 0.4590\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 6s 479ms/step - loss: 0.0561 - categorical_accuracy: 0.9863 - val_loss: 9.1304 - val_categorical_accuracy: 0.4627\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0606 - categorical_accuracy: 0.9825 - val_loss: 9.1830 - val_categorical_accuracy: 0.4478\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 6s 483ms/step - loss: 0.0690 - categorical_accuracy: 0.9838 - val_loss: 9.6757 - val_categorical_accuracy: 0.4664\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 6s 482ms/step - loss: 0.0844 - categorical_accuracy: 0.9751 - val_loss: 9.7388 - val_categorical_accuracy: 0.4701\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.0720 - categorical_accuracy: 0.9763 - val_loss: 9.2409 - val_categorical_accuracy: 0.4720\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0556 - categorical_accuracy: 0.9850 - val_loss: 8.9168 - val_categorical_accuracy: 0.4739\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 6s 461ms/step - loss: 0.0750 - categorical_accuracy: 0.9825 - val_loss: 8.8000 - val_categorical_accuracy: 0.4795\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 6s 469ms/step - loss: 0.0487 - categorical_accuracy: 0.9825 - val_loss: 8.9301 - val_categorical_accuracy: 0.5019\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 6s 480ms/step - loss: 0.0673 - categorical_accuracy: 0.9863 - val_loss: 8.9634 - val_categorical_accuracy: 0.4664\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0402 - categorical_accuracy: 0.9863 - val_loss: 9.3446 - val_categorical_accuracy: 0.4646\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0465 - categorical_accuracy: 0.9850 - val_loss: 9.4597 - val_categorical_accuracy: 0.4739\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 6s 479ms/step - loss: 0.0472 - categorical_accuracy: 0.9850 - val_loss: 9.6551 - val_categorical_accuracy: 0.4384\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 6s 470ms/step - loss: 0.0599 - categorical_accuracy: 0.9800 - val_loss: 9.6334 - val_categorical_accuracy: 0.4963\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 6s 483ms/step - loss: 0.0688 - categorical_accuracy: 0.9800 - val_loss: 9.6193 - val_categorical_accuracy: 0.4851\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0505 - categorical_accuracy: 0.9850 - val_loss: 9.5440 - val_categorical_accuracy: 0.4683\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0706 - categorical_accuracy: 0.9838 - val_loss: 9.4735 - val_categorical_accuracy: 0.4851\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 0.0428 - categorical_accuracy: 0.9850 - val_loss: 9.7800 - val_categorical_accuracy: 0.4683\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 0.0322 - categorical_accuracy: 0.9888 - val_loss: 9.2661 - val_categorical_accuracy: 0.4757\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 0.0589 - categorical_accuracy: 0.9813 - val_loss: 8.9706 - val_categorical_accuracy: 0.4832\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 0.0616 - categorical_accuracy: 0.9776 - val_loss: 9.1477 - val_categorical_accuracy: 0.4664\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 6s 476ms/step - loss: 0.0629 - categorical_accuracy: 0.9751 - val_loss: 9.1156 - val_categorical_accuracy: 0.4608\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0523 - categorical_accuracy: 0.9825 - val_loss: 9.6730 - val_categorical_accuracy: 0.4701\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 6s 485ms/step - loss: 0.0747 - categorical_accuracy: 0.9726 - val_loss: 10.1874 - val_categorical_accuracy: 0.4534\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 6s 480ms/step - loss: 0.0475 - categorical_accuracy: 0.9825 - val_loss: 9.9951 - val_categorical_accuracy: 0.4851\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 6s 478ms/step - loss: 0.0458 - categorical_accuracy: 0.9813 - val_loss: 9.6434 - val_categorical_accuracy: 0.4646\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 6s 478ms/step - loss: 0.0726 - categorical_accuracy: 0.9838 - val_loss: 9.7754 - val_categorical_accuracy: 0.4757\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.0385 - categorical_accuracy: 0.9850 - val_loss: 9.7131 - val_categorical_accuracy: 0.4925\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 6s 467ms/step - loss: 0.0560 - categorical_accuracy: 0.9788 - val_loss: 9.5564 - val_categorical_accuracy: 0.4851\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 6s 482ms/step - loss: 0.0289 - categorical_accuracy: 0.9925 - val_loss: 9.4655 - val_categorical_accuracy: 0.4944\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0664 - categorical_accuracy: 0.9863 - val_loss: 9.7366 - val_categorical_accuracy: 0.4664\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.0395 - categorical_accuracy: 0.9900 - val_loss: 9.8101 - val_categorical_accuracy: 0.4888\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 6s 476ms/step - loss: 0.0708 - categorical_accuracy: 0.9800 - val_loss: 9.7445 - val_categorical_accuracy: 0.4869\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 6s 490ms/step - loss: 0.0346 - categorical_accuracy: 0.9913 - val_loss: 9.6674 - val_categorical_accuracy: 0.4664\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 6s 485ms/step - loss: 0.0528 - categorical_accuracy: 0.9825 - val_loss: 9.7418 - val_categorical_accuracy: 0.4720\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 0.0581 - categorical_accuracy: 0.9838 - val_loss: 9.5767 - val_categorical_accuracy: 0.4813\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 0.0366 - categorical_accuracy: 0.9875 - val_loss: 9.7046 - val_categorical_accuracy: 0.4832\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 6s 479ms/step - loss: 0.0745 - categorical_accuracy: 0.9788 - val_loss: 10.2649 - val_categorical_accuracy: 0.4851\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0792 - categorical_accuracy: 0.9726 - val_loss: 10.1372 - val_categorical_accuracy: 0.4739\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0550 - categorical_accuracy: 0.9813 - val_loss: 10.4584 - val_categorical_accuracy: 0.4701\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 6s 483ms/step - loss: 0.0630 - categorical_accuracy: 0.9875 - val_loss: 9.6438 - val_categorical_accuracy: 0.5019\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0529 - categorical_accuracy: 0.9813 - val_loss: 10.1807 - val_categorical_accuracy: 0.4459\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0383 - categorical_accuracy: 0.9850 - val_loss: 9.6872 - val_categorical_accuracy: 0.4832\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0509 - categorical_accuracy: 0.9875 - val_loss: 10.0579 - val_categorical_accuracy: 0.4496\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0808 - categorical_accuracy: 0.9838 - val_loss: 9.9632 - val_categorical_accuracy: 0.4701\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 6s 482ms/step - loss: 0.0364 - categorical_accuracy: 0.9825 - val_loss: 10.1367 - val_categorical_accuracy: 0.4776\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0923 - categorical_accuracy: 0.9763 - val_loss: 9.7736 - val_categorical_accuracy: 0.4925\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0757 - categorical_accuracy: 0.9776 - val_loss: 9.5788 - val_categorical_accuracy: 0.5019\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 6s 483ms/step - loss: 0.0473 - categorical_accuracy: 0.9825 - val_loss: 9.8088 - val_categorical_accuracy: 0.4832\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.0837 - categorical_accuracy: 0.9800 - val_loss: 9.9215 - val_categorical_accuracy: 0.4776\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 6s 468ms/step - loss: 0.0983 - categorical_accuracy: 0.9776 - val_loss: 9.3307 - val_categorical_accuracy: 0.4683\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 0.0537 - categorical_accuracy: 0.9850 - val_loss: 9.2517 - val_categorical_accuracy: 0.4608\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0374 - categorical_accuracy: 0.9863 - val_loss: 9.1280 - val_categorical_accuracy: 0.4739\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 6s 487ms/step - loss: 0.0270 - categorical_accuracy: 0.9913 - val_loss: 9.6719 - val_categorical_accuracy: 0.4683\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 6s 481ms/step - loss: 0.0459 - categorical_accuracy: 0.9813 - val_loss: 9.4040 - val_categorical_accuracy: 0.4646\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 6s 480ms/step - loss: 0.0467 - categorical_accuracy: 0.9813 - val_loss: 9.3948 - val_categorical_accuracy: 0.4739\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 6s 481ms/step - loss: 0.0657 - categorical_accuracy: 0.9800 - val_loss: 10.1201 - val_categorical_accuracy: 0.4813\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0778 - categorical_accuracy: 0.9813 - val_loss: 9.7915 - val_categorical_accuracy: 0.4646\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 6s 479ms/step - loss: 0.0593 - categorical_accuracy: 0.9838 - val_loss: 9.7406 - val_categorical_accuracy: 0.4851\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.0520 - categorical_accuracy: 0.9863 - val_loss: 9.7891 - val_categorical_accuracy: 0.4776\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 6s 468ms/step - loss: 0.0432 - categorical_accuracy: 0.9900 - val_loss: 10.1297 - val_categorical_accuracy: 0.4776\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 0.0704 - categorical_accuracy: 0.9800 - val_loss: 9.7932 - val_categorical_accuracy: 0.5000\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 6s 478ms/step - loss: 0.0625 - categorical_accuracy: 0.9726 - val_loss: 9.5016 - val_categorical_accuracy: 0.4907\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 6s 480ms/step - loss: 0.0783 - categorical_accuracy: 0.9813 - val_loss: 9.4056 - val_categorical_accuracy: 0.5056\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 6s 478ms/step - loss: 0.0563 - categorical_accuracy: 0.9875 - val_loss: 9.3129 - val_categorical_accuracy: 0.5019\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 6s 487ms/step - loss: 0.0562 - categorical_accuracy: 0.9825 - val_loss: 9.5886 - val_categorical_accuracy: 0.5093\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 6s 485ms/step - loss: 0.0926 - categorical_accuracy: 0.9838 - val_loss: 9.4431 - val_categorical_accuracy: 0.4944\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 6s 480ms/step - loss: 0.0394 - categorical_accuracy: 0.9850 - val_loss: 9.8590 - val_categorical_accuracy: 0.4776\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 6s 478ms/step - loss: 0.0505 - categorical_accuracy: 0.9850 - val_loss: 9.8307 - val_categorical_accuracy: 0.4664\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.0451 - categorical_accuracy: 0.9875 - val_loss: 9.5972 - val_categorical_accuracy: 0.4776\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0310 - categorical_accuracy: 0.9900 - val_loss: 9.5850 - val_categorical_accuracy: 0.4776\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0667 - categorical_accuracy: 0.9838 - val_loss: 10.3285 - val_categorical_accuracy: 0.4664\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0590 - categorical_accuracy: 0.9888 - val_loss: 10.6154 - val_categorical_accuracy: 0.4683\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0570 - categorical_accuracy: 0.9875 - val_loss: 10.6094 - val_categorical_accuracy: 0.4795\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 6s 482ms/step - loss: 0.0646 - categorical_accuracy: 0.9900 - val_loss: 9.9260 - val_categorical_accuracy: 0.4832\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 6s 476ms/step - loss: 0.0715 - categorical_accuracy: 0.9788 - val_loss: 10.2365 - val_categorical_accuracy: 0.4851\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 6s 478ms/step - loss: 0.0959 - categorical_accuracy: 0.9763 - val_loss: 10.1559 - val_categorical_accuracy: 0.4757\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.0366 - categorical_accuracy: 0.9863 - val_loss: 9.2796 - val_categorical_accuracy: 0.4739\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 6s 481ms/step - loss: 0.0525 - categorical_accuracy: 0.9838 - val_loss: 9.7787 - val_categorical_accuracy: 0.4515\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 0.0734 - categorical_accuracy: 0.9788 - val_loss: 8.9902 - val_categorical_accuracy: 0.4851\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 0.0654 - categorical_accuracy: 0.9863 - val_loss: 9.2970 - val_categorical_accuracy: 0.4869\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 6s 469ms/step - loss: 0.0538 - categorical_accuracy: 0.9863 - val_loss: 10.1091 - val_categorical_accuracy: 0.4888\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0848 - categorical_accuracy: 0.9800 - val_loss: 10.1970 - val_categorical_accuracy: 0.4832\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 6s 487ms/step - loss: 0.0531 - categorical_accuracy: 0.9850 - val_loss: 10.3964 - val_categorical_accuracy: 0.4683\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 6s 475ms/step - loss: 0.0460 - categorical_accuracy: 0.9850 - val_loss: 10.1388 - val_categorical_accuracy: 0.4925\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0735 - categorical_accuracy: 0.9838 - val_loss: 10.2059 - val_categorical_accuracy: 0.4795\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 6s 471ms/step - loss: 0.0441 - categorical_accuracy: 0.9900 - val_loss: 10.4030 - val_categorical_accuracy: 0.4552\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0740 - categorical_accuracy: 0.9788 - val_loss: 10.1572 - val_categorical_accuracy: 0.5037\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0373 - categorical_accuracy: 0.9863 - val_loss: 10.2904 - val_categorical_accuracy: 0.4869\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 6s 487ms/step - loss: 0.0388 - categorical_accuracy: 0.9888 - val_loss: 10.4323 - val_categorical_accuracy: 0.4795\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 6s 473ms/step - loss: 0.0467 - categorical_accuracy: 0.9813 - val_loss: 10.5948 - val_categorical_accuracy: 0.4646\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 6s 474ms/step - loss: 0.0827 - categorical_accuracy: 0.9776 - val_loss: 10.8826 - val_categorical_accuracy: 0.4776\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.0808 - categorical_accuracy: 0.9776 - val_loss: 10.7332 - val_categorical_accuracy: 0.4776\n",
      "Epoch 379/1000\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.0363 - categorical_accuracy: 0.9896"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[172], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Lion(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.00025\u001b[39m)\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 14\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential(name='Sequential') #good, overfitting\n",
    "\n",
    "act_function = 'LeakyReLU'\n",
    "model.add(GRU(128, return_sequences=True, activation=act_function, input_shape=(130,126)))\n",
    "model.add(GRU(128, return_sequences=False, activation=act_function))\n",
    "#model.add(LSTM(64, return_sequences=False, activation=act_function))\n",
    "model.add(Dense(128, activation=act_function, input_shape=(130,126)))\n",
    "model.add(Dense(128, activation=act_function))\n",
    "model.add(Dense(64, activation=act_function))\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "optimizer = Lion(learning_rate=.00025)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, epochs=1000, validation_split=.4, batch_size = 64, callbacks=[tb_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "08d05ac6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T19:22:40.335972Z",
     "start_time": "2023-08-10T19:22:39.644721Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 66ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c6b4e57c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T19:22:42.274312Z",
     "start_time": "2023-08-10T19:22:42.271067Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(res[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "29089018",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T19:22:45.350274Z",
     "start_time": "2023-08-10T19:22:45.347022Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Yval[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2582eb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:54:42.087213Z",
     "start_time": "2023-08-11T08:53:21.844914Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/1000\n",
      "30/30 [==============================] - 8s 215ms/step - loss: 3.9204 - categorical_accuracy: 0.0144 - val_loss: 3.9345 - val_categorical_accuracy: 0.0249\n",
      "Epoch 2/1000\n",
      "30/30 [==============================] - 6s 191ms/step - loss: 3.9167 - categorical_accuracy: 0.0160 - val_loss: 3.9284 - val_categorical_accuracy: 0.0386\n",
      "Epoch 3/1000\n",
      "30/30 [==============================] - 6s 192ms/step - loss: 3.9122 - categorical_accuracy: 0.0208 - val_loss: 3.9255 - val_categorical_accuracy: 0.0174\n",
      "Epoch 4/1000\n",
      "30/30 [==============================] - 6s 190ms/step - loss: 3.9099 - categorical_accuracy: 0.0203 - val_loss: 3.9239 - val_categorical_accuracy: 0.0174\n",
      "Epoch 5/1000\n",
      "30/30 [==============================] - 6s 193ms/step - loss: 3.9066 - categorical_accuracy: 0.0230 - val_loss: 3.9242 - val_categorical_accuracy: 0.0174\n",
      "Epoch 6/1000\n",
      "30/30 [==============================] - 6s 191ms/step - loss: 3.9071 - categorical_accuracy: 0.0182 - val_loss: 3.9249 - val_categorical_accuracy: 0.0174\n",
      "Epoch 7/1000\n",
      "30/30 [==============================] - 6s 195ms/step - loss: 3.9054 - categorical_accuracy: 0.0219 - val_loss: 3.9253 - val_categorical_accuracy: 0.0174\n",
      "Epoch 8/1000\n",
      "30/30 [==============================] - 6s 195ms/step - loss: 3.9086 - categorical_accuracy: 0.0208 - val_loss: 3.9259 - val_categorical_accuracy: 0.0174\n",
      "Epoch 9/1000\n",
      "30/30 [==============================] - 6s 191ms/step - loss: 3.9028 - categorical_accuracy: 0.0267 - val_loss: 3.9277 - val_categorical_accuracy: 0.0174\n",
      "Epoch 10/1000\n",
      "30/30 [==============================] - 6s 194ms/step - loss: 3.9028 - categorical_accuracy: 0.0283 - val_loss: 3.9295 - val_categorical_accuracy: 0.0174\n",
      "Epoch 11/1000\n",
      "30/30 [==============================] - 6s 193ms/step - loss: 3.9028 - categorical_accuracy: 0.0256 - val_loss: 3.9304 - val_categorical_accuracy: 0.0174\n",
      "Epoch 12/1000\n",
      "30/30 [==============================] - 6s 195ms/step - loss: 3.9007 - categorical_accuracy: 0.0251 - val_loss: 3.9308 - val_categorical_accuracy: 0.0174\n",
      "Epoch 13/1000\n",
      "30/30 [==============================] - 6s 200ms/step - loss: 3.9030 - categorical_accuracy: 0.0267 - val_loss: 3.9312 - val_categorical_accuracy: 0.0174\n",
      "Epoch 14/1000\n",
      " 6/30 [=====>........................] - ETA: 4s - loss: 3.9028 - categorical_accuracy: 0.0365"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Lion(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.00005\u001b[39m,global_clipnorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.25\u001b[39m)\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential(name='Sequential') ##best\n",
    "\n",
    "act_function = 'LeakyReLU'\n",
    "model.add(GRU(32, return_sequences=False, activation=act_function, dropout=.5,input_shape=(130,126)))\n",
    "#model.add(GRU(128, return_sequences=True, activation=act_function))\n",
    "#model.add(LSTM(64, return_sequences=False, activation=act_function))\n",
    "model.add(Dense(32, activation=act_function))\n",
    "#model.add(Dense(64, activation=act_function))\n",
    "model.add(Dense(16, activation=act_function))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "optimizer = Lion(learning_rate=.00005,global_clipnorm=.25)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, epochs=1000, validation_split=.3, batch_size = 64, callbacks=[tb_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9db2dd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:53:13.701389Z",
     "start_time": "2023-08-11T08:51:02.350790Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 09:51:02.420040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1739 MB memory:  -> device: 0, name: NVIDIA GeForce MX250, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 09:51:05.936031: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff908411900 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-11 09:51:05.936057: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce MX250, Compute Capability 6.1\n",
      "2023-08-11 09:51:05.940241: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-11 09:51:05.953295: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-08-11 09:51:06.015538: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 9s 241ms/step - loss: 4.0962 - categorical_accuracy: 0.0168 - val_loss: 4.0085 - val_categorical_accuracy: 0.0065\n",
      "Epoch 2/5000\n",
      "26/26 [==============================] - 4s 158ms/step - loss: 3.9604 - categorical_accuracy: 0.0249 - val_loss: 3.9157 - val_categorical_accuracy: 0.0336\n",
      "Epoch 3/5000\n",
      "26/26 [==============================] - 4s 164ms/step - loss: 3.8279 - categorical_accuracy: 0.0336 - val_loss: 3.7152 - val_categorical_accuracy: 0.0327\n",
      "Epoch 4/5000\n",
      "26/26 [==============================] - 4s 166ms/step - loss: 3.6075 - categorical_accuracy: 0.0561 - val_loss: 3.5930 - val_categorical_accuracy: 0.0401\n",
      "Epoch 5/5000\n",
      "26/26 [==============================] - 4s 171ms/step - loss: 3.4629 - categorical_accuracy: 0.0766 - val_loss: 3.6859 - val_categorical_accuracy: 0.0523\n",
      "Epoch 6/5000\n",
      "26/26 [==============================] - 5s 173ms/step - loss: 3.3429 - categorical_accuracy: 0.0854 - val_loss: 3.3516 - val_categorical_accuracy: 0.0682\n",
      "Epoch 7/5000\n",
      "26/26 [==============================] - 5s 175ms/step - loss: 3.2592 - categorical_accuracy: 0.1128 - val_loss: 3.3955 - val_categorical_accuracy: 0.0486\n",
      "Epoch 8/5000\n",
      "26/26 [==============================] - 5s 175ms/step - loss: 3.2122 - categorical_accuracy: 0.1059 - val_loss: 3.6712 - val_categorical_accuracy: 0.0355\n",
      "Epoch 9/5000\n",
      "26/26 [==============================] - 5s 180ms/step - loss: 3.1930 - categorical_accuracy: 0.1009 - val_loss: 3.1375 - val_categorical_accuracy: 0.0971\n",
      "Epoch 10/5000\n",
      "26/26 [==============================] - 5s 182ms/step - loss: 3.1429 - categorical_accuracy: 0.1134 - val_loss: 3.1831 - val_categorical_accuracy: 0.0906\n",
      "Epoch 11/5000\n",
      "26/26 [==============================] - 5s 183ms/step - loss: 3.1328 - categorical_accuracy: 0.1265 - val_loss: 3.1846 - val_categorical_accuracy: 0.1018\n",
      "Epoch 12/5000\n",
      "26/26 [==============================] - 5s 191ms/step - loss: 3.0504 - categorical_accuracy: 0.1396 - val_loss: 152498260479837351182336.0000 - val_categorical_accuracy: 0.0934\n",
      "Epoch 13/5000\n",
      "26/26 [==============================] - 5s 187ms/step - loss: 3.0989 - categorical_accuracy: 0.1234 - val_loss: 3.3562 - val_categorical_accuracy: 0.0822\n",
      "Epoch 14/5000\n",
      "26/26 [==============================] - 5s 190ms/step - loss: 3.0125 - categorical_accuracy: 0.1383 - val_loss: 3.1703 - val_categorical_accuracy: 0.0934\n",
      "Epoch 15/5000\n",
      "26/26 [==============================] - 5s 192ms/step - loss: 3.0476 - categorical_accuracy: 0.1371 - val_loss: 3.4506 - val_categorical_accuracy: 0.0971\n",
      "Epoch 16/5000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 3.0903 - categorical_accuracy: 0.1240 - val_loss: 3.3045 - val_categorical_accuracy: 0.1036\n",
      "Epoch 17/5000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 3.1229 - categorical_accuracy: 0.1184 - val_loss: 3.1757 - val_categorical_accuracy: 0.0840\n",
      "Epoch 18/5000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 203514.6562 - categorical_accuracy: 0.1340 - val_loss: 3.6162 - val_categorical_accuracy: 0.0579\n",
      "Epoch 19/5000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 3.1031 - categorical_accuracy: 0.1227 - val_loss: 3.2510 - val_categorical_accuracy: 0.0747\n",
      "Epoch 20/5000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 3.1018 - categorical_accuracy: 0.1296 - val_loss: 3.3674 - val_categorical_accuracy: 0.0934\n",
      "Epoch 21/5000\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 3.1066 - categorical_accuracy: 0.1327 - val_loss: 3.0794 - val_categorical_accuracy: 0.1298\n",
      "Epoch 22/5000\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 3.0817 - categorical_accuracy: 0.1427 - val_loss: 3.2479 - val_categorical_accuracy: 0.0980\n",
      "Epoch 23/5000\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 3.1377 - categorical_accuracy: 0.1277 - val_loss: 3.3744 - val_categorical_accuracy: 0.0616\n",
      "Epoch 24/5000\n",
      "26/26 [==============================] - 5s 199ms/step - loss: nan - categorical_accuracy: 0.1340 - val_loss: nan - val_categorical_accuracy: 0.0103\n",
      "Epoch 25/5000\n",
      "26/26 [==============================] - 5s 203ms/step - loss: nan - categorical_accuracy: 0.0293 - val_loss: nan - val_categorical_accuracy: 0.0103\n",
      "Epoch 26/5000\n",
      "19/26 [====================>.........] - ETA: 1s - loss: nan - categorical_accuracy: 0.0312"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Lion(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.005\u001b[39m,global_clipnorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential(name='Sequential') #chingon\n",
    "\n",
    "act_function = 'selu'\n",
    "model.add(GRU(64, return_sequences=False, activation=act_function, dropout=.5,kernel_initializer='he_uniform',input_shape=(130,126)))\n",
    "#model.add(GRU(128, return_sequences=True, activation=act_function))\n",
    "#model.add(LSTM(64, return_sequences=False, activation=act_function))\n",
    "model.add(Dense(32, activation=act_function))\n",
    "#model.add(Dense(64, activation=act_function))\n",
    "model.add(Dense(16, activation=act_function))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "optimizer = Lion(learning_rate=.005,global_clipnorm=10)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, epochs=5000, validation_split=.4, batch_size = 64, callbacks=[tb_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f9f29569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T19:29:17.787450Z",
     "start_time": "2023-08-10T19:26:40.255171Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/1000\n",
      "15/15 [==============================] - 12s 587ms/step - loss: 3.9141 - categorical_accuracy: 0.0192 - val_loss: 3.9452 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "15/15 [==============================] - 6s 426ms/step - loss: 3.8960 - categorical_accuracy: 0.0321 - val_loss: 4.0005 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "15/15 [==============================] - 6s 415ms/step - loss: 3.8835 - categorical_accuracy: 0.0278 - val_loss: 4.0428 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "15/15 [==============================] - 6s 427ms/step - loss: 3.8513 - categorical_accuracy: 0.0417 - val_loss: 3.9643 - val_categorical_accuracy: 0.0274\n",
      "Epoch 5/1000\n",
      "15/15 [==============================] - 6s 421ms/step - loss: 3.7220 - categorical_accuracy: 0.0524 - val_loss: 3.7845 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "15/15 [==============================] - 6s 432ms/step - loss: 3.5726 - categorical_accuracy: 0.0598 - val_loss: 3.6370 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "15/15 [==============================] - 6s 424ms/step - loss: 3.4980 - categorical_accuracy: 0.0470 - val_loss: 3.6191 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "15/15 [==============================] - 6s 429ms/step - loss: 3.4270 - categorical_accuracy: 0.0609 - val_loss: 3.4974 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "15/15 [==============================] - 6s 423ms/step - loss: 3.3606 - categorical_accuracy: 0.0748 - val_loss: 3.5254 - val_categorical_accuracy: 0.0249\n",
      "Epoch 10/1000\n",
      "15/15 [==============================] - 6s 428ms/step - loss: 3.3344 - categorical_accuracy: 0.0748 - val_loss: 3.5691 - val_categorical_accuracy: 0.0025\n",
      "Epoch 11/1000\n",
      "15/15 [==============================] - 6s 426ms/step - loss: 3.2974 - categorical_accuracy: 0.0897 - val_loss: 3.4361 - val_categorical_accuracy: 0.0050\n",
      "Epoch 12/1000\n",
      "15/15 [==============================] - 6s 437ms/step - loss: 3.1901 - categorical_accuracy: 0.1165 - val_loss: 3.4127 - val_categorical_accuracy: 0.0348\n",
      "Epoch 13/1000\n",
      "15/15 [==============================] - 6s 420ms/step - loss: 3.1214 - categorical_accuracy: 0.1058 - val_loss: 3.3689 - val_categorical_accuracy: 0.0274\n",
      "Epoch 14/1000\n",
      "15/15 [==============================] - 6s 429ms/step - loss: 3.0269 - categorical_accuracy: 0.1261 - val_loss: 3.4719 - val_categorical_accuracy: 0.0224\n",
      "Epoch 15/1000\n",
      "15/15 [==============================] - 6s 432ms/step - loss: 2.9066 - categorical_accuracy: 0.1400 - val_loss: 3.4609 - val_categorical_accuracy: 0.0498\n",
      "Epoch 16/1000\n",
      "15/15 [==============================] - 6s 425ms/step - loss: 2.8615 - categorical_accuracy: 0.1656 - val_loss: 3.5256 - val_categorical_accuracy: 0.0398\n",
      "Epoch 17/1000\n",
      "15/15 [==============================] - 6s 423ms/step - loss: 2.7589 - categorical_accuracy: 0.1763 - val_loss: 3.4013 - val_categorical_accuracy: 0.0771\n",
      "Epoch 18/1000\n",
      "15/15 [==============================] - 6s 423ms/step - loss: 2.7148 - categorical_accuracy: 0.1870 - val_loss: 3.3827 - val_categorical_accuracy: 0.0945\n",
      "Epoch 19/1000\n",
      "15/15 [==============================] - 6s 429ms/step - loss: 2.6441 - categorical_accuracy: 0.2126 - val_loss: 3.4162 - val_categorical_accuracy: 0.0647\n",
      "Epoch 20/1000\n",
      "15/15 [==============================] - 6s 432ms/step - loss: 2.5786 - categorical_accuracy: 0.2115 - val_loss: 3.2158 - val_categorical_accuracy: 0.1020\n",
      "Epoch 21/1000\n",
      "15/15 [==============================] - 6s 430ms/step - loss: 554387.3125 - categorical_accuracy: 0.1923 - val_loss: 3475085.7500 - val_categorical_accuracy: 0.0075\n",
      "Epoch 22/1000\n",
      "15/15 [==============================] - 6s 424ms/step - loss: 7116011.0000 - categorical_accuracy: 0.0449 - val_loss: 8619709.0000 - val_categorical_accuracy: 0.0199\n",
      "Epoch 23/1000\n",
      "15/15 [==============================] - 6s 436ms/step - loss: 194139472.0000 - categorical_accuracy: 0.0192 - val_loss: 2249584384.0000 - val_categorical_accuracy: 0.0025\n",
      "Epoch 24/1000\n",
      " 8/15 [===============>..............] - ETA: 2s - loss: 123111407616.0000 - categorical_accuracy: 0.0293"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[178], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Lion(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.005\u001b[39m)\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential(name='Sequential') \n",
    "\n",
    "act_function = 'LeakyReLU'\n",
    "initializer = 'lecun_uniform'\n",
    "model.add(GRU(32, return_sequences=True, kernel_initializer=initializer, activation=act_function, dropout=0,input_shape=(130,126)))\n",
    "model.add(GRU(8, return_sequences=False, activation=act_function))\n",
    "#model.add(LSTM(64, return_sequences=False, activation=act_function))\n",
    "model.add(Dense(32, activation=act_function, kernel_initializer=initializer))\n",
    "model.add(Dense(32, activation=act_function, kernel_initializer=initializer))\n",
    "model.add(Dense(16, activation=act_function, kernel_initializer=initializer))\n",
    "#model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "optimizer = Lion(learning_rate=.005)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, epochs=1000, validation_split=.3, batch_size = 64, callbacks=[tb_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8df18665",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T17:06:41.794473Z",
     "start_time": "2023-08-08T17:06:41.777177Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initializer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minitializer\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'initializer' is not defined"
     ]
    }
   ],
   "source": [
    "initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30e0c4e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T16:43:40.044523Z",
     "start_time": "2023-08-08T16:36:17.221137Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 10:10:09.127784: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 924736800 exceeds 10% of free system memory.\n",
      "2023-08-08 10:10:09.961623: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 924736800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "34/34 [==============================] - 9s 207ms/step - loss: 3.9179 - categorical_accuracy: 0.0224 - val_loss: 4.3422 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 3.8832 - categorical_accuracy: 0.0234 - val_loss: 5.0312 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "34/34 [==============================] - 7s 192ms/step - loss: 3.8310 - categorical_accuracy: 0.0215 - val_loss: 5.5114 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 3.8174 - categorical_accuracy: 0.0271 - val_loss: 5.8857 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "34/34 [==============================] - 7s 210ms/step - loss: 3.7950 - categorical_accuracy: 0.0336 - val_loss: 5.7742 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "34/34 [==============================] - 7s 212ms/step - loss: 3.7763 - categorical_accuracy: 0.0262 - val_loss: 6.2825 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "34/34 [==============================] - 7s 208ms/step - loss: 3.7677 - categorical_accuracy: 0.0393 - val_loss: 6.2689 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "34/34 [==============================] - 7s 214ms/step - loss: 3.7600 - categorical_accuracy: 0.0318 - val_loss: 6.8157 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "34/34 [==============================] - 7s 213ms/step - loss: 3.7398 - categorical_accuracy: 0.0336 - val_loss: 6.5783 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      " 2/34 [>.............................] - ETA: 6s - loss: 3.6622 - categorical_accuracy: 0.0156    "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Lion(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.00025\u001b[39m)\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential(name='Sequential')\n",
    "\n",
    "act_function = 'LeakyReLU'\n",
    "model.add(GRU(128, return_sequences=False, activation=act_function, input_shape=(130,126)))\n",
    "#model.add(GRU(128, return_sequences=True, activation=act_function))\n",
    "#model.add(LSTM(64, return_sequences=False, activation=act_function))\n",
    "model.add(Dense(128, activation=act_function, input_shape=(130,126)))\n",
    "model.add(Dense(128, activation=act_function))\n",
    "model.add(Dense(64, activation=act_function))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "optimizer = Lion(learning_rate=.00025)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, epochs=1000, validation_split=.2, batch_size = 32, callbacks=[tb_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daa289c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tests 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbab687d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:06:51.639702Z",
     "start_time": "2023-08-11T08:02:34.162928Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_10 (Conv1D)          (None, 129, 50)           12650     \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPooli  (None, 64, 50)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 63, 100)           10100     \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPooli  (None, 31, 100)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 30, 50)            10050     \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPooli  (None, 15, 50)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 14, 100)           10100     \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPooli  (None, 7, 100)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " spatial_dropout1d_2 (Spati  (None, 7, 100)            0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 5, 64)             19264     \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPooli  (None, 2, 64)             0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " spatial_dropout1d_3 (Spati  (None, 2, 64)             0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 40)                5160      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                656       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 50)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 68830 (268.87 KB)\n",
      "Trainable params: 68830 (268.87 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5000\n",
      "15/15 [==============================] - 3s 124ms/step - loss: 4.2989 - categorical_accuracy: 0.0187 - val_loss: 4.1024 - val_categorical_accuracy: 0.0137\n",
      "Epoch 2/5000\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 4.2208 - categorical_accuracy: 0.0294 - val_loss: 4.1879 - val_categorical_accuracy: 0.0137\n",
      "Epoch 3/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 4.1138 - categorical_accuracy: 0.0208 - val_loss: 4.0927 - val_categorical_accuracy: 0.0199\n",
      "Epoch 4/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 4.0164 - categorical_accuracy: 0.0427 - val_loss: 4.0405 - val_categorical_accuracy: 0.0324\n",
      "Epoch 5/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 3.9314 - categorical_accuracy: 0.0459 - val_loss: 3.9825 - val_categorical_accuracy: 0.0386\n",
      "Epoch 6/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 3.8411 - categorical_accuracy: 0.0545 - val_loss: 3.9288 - val_categorical_accuracy: 0.0461\n",
      "Epoch 7/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 3.7757 - categorical_accuracy: 0.0742 - val_loss: 3.7867 - val_categorical_accuracy: 0.0548\n",
      "Epoch 8/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 3.6571 - categorical_accuracy: 0.0785 - val_loss: 3.8080 - val_categorical_accuracy: 0.0710\n",
      "Epoch 9/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 3.5443 - categorical_accuracy: 0.0854 - val_loss: 3.6775 - val_categorical_accuracy: 0.0884\n",
      "Epoch 10/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 3.4683 - categorical_accuracy: 0.0956 - val_loss: 3.5375 - val_categorical_accuracy: 0.0934\n",
      "Epoch 11/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 3.3743 - categorical_accuracy: 0.1121 - val_loss: 3.4822 - val_categorical_accuracy: 0.0847\n",
      "Epoch 12/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 3.2678 - categorical_accuracy: 0.1313 - val_loss: 3.5013 - val_categorical_accuracy: 0.0984\n",
      "Epoch 13/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 3.1739 - categorical_accuracy: 0.1388 - val_loss: 3.2872 - val_categorical_accuracy: 0.1096\n",
      "Epoch 14/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 3.0902 - categorical_accuracy: 0.1511 - val_loss: 3.1555 - val_categorical_accuracy: 0.1220\n",
      "Epoch 15/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 3.0228 - categorical_accuracy: 0.1607 - val_loss: 3.1255 - val_categorical_accuracy: 0.1407\n",
      "Epoch 16/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.9458 - categorical_accuracy: 0.1703 - val_loss: 2.9914 - val_categorical_accuracy: 0.1469\n",
      "Epoch 17/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 2.8955 - categorical_accuracy: 0.1810 - val_loss: 2.9325 - val_categorical_accuracy: 0.1606\n",
      "Epoch 18/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.8390 - categorical_accuracy: 0.1847 - val_loss: 2.8722 - val_categorical_accuracy: 0.1706\n",
      "Epoch 19/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.7501 - categorical_accuracy: 0.2114 - val_loss: 2.6790 - val_categorical_accuracy: 0.2329\n",
      "Epoch 20/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.6680 - categorical_accuracy: 0.2264 - val_loss: 2.5865 - val_categorical_accuracy: 0.2341\n",
      "Epoch 21/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.5981 - categorical_accuracy: 0.2547 - val_loss: 2.5380 - val_categorical_accuracy: 0.2453\n",
      "Epoch 22/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.5284 - categorical_accuracy: 0.2659 - val_loss: 2.6077 - val_categorical_accuracy: 0.2217\n",
      "Epoch 23/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.4781 - categorical_accuracy: 0.2643 - val_loss: 2.5359 - val_categorical_accuracy: 0.2453\n",
      "Epoch 24/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.4708 - categorical_accuracy: 0.2760 - val_loss: 2.5422 - val_categorical_accuracy: 0.2565\n",
      "Epoch 25/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.4307 - categorical_accuracy: 0.2915 - val_loss: 2.4642 - val_categorical_accuracy: 0.2441\n",
      "Epoch 26/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.3850 - categorical_accuracy: 0.3033 - val_loss: 2.4531 - val_categorical_accuracy: 0.2516\n",
      "Epoch 27/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.3409 - categorical_accuracy: 0.3086 - val_loss: 2.3646 - val_categorical_accuracy: 0.2814\n",
      "Epoch 28/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.3126 - categorical_accuracy: 0.3038 - val_loss: 2.4166 - val_categorical_accuracy: 0.2790\n",
      "Epoch 29/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.2552 - categorical_accuracy: 0.3369 - val_loss: 2.3479 - val_categorical_accuracy: 0.2839\n",
      "Epoch 30/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.2278 - categorical_accuracy: 0.3364 - val_loss: 2.3067 - val_categorical_accuracy: 0.2914\n",
      "Epoch 31/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.1664 - categorical_accuracy: 0.3518 - val_loss: 2.3609 - val_categorical_accuracy: 0.2889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.1337 - categorical_accuracy: 0.3513 - val_loss: 2.1980 - val_categorical_accuracy: 0.3412\n",
      "Epoch 33/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.1407 - categorical_accuracy: 0.3679 - val_loss: 2.1737 - val_categorical_accuracy: 0.3425\n",
      "Epoch 34/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.0837 - categorical_accuracy: 0.3962 - val_loss: 2.1697 - val_categorical_accuracy: 0.3499\n",
      "Epoch 35/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.0354 - categorical_accuracy: 0.3807 - val_loss: 2.1663 - val_categorical_accuracy: 0.3412\n",
      "Epoch 36/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.0273 - categorical_accuracy: 0.3951 - val_loss: 2.2525 - val_categorical_accuracy: 0.3300\n",
      "Epoch 37/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.0277 - categorical_accuracy: 0.4026 - val_loss: 2.1512 - val_categorical_accuracy: 0.3587\n",
      "Epoch 38/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.9955 - categorical_accuracy: 0.3892 - val_loss: 2.0436 - val_categorical_accuracy: 0.3761\n",
      "Epoch 39/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.9353 - categorical_accuracy: 0.3983 - val_loss: 2.1306 - val_categorical_accuracy: 0.3512\n",
      "Epoch 40/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.8827 - categorical_accuracy: 0.4175 - val_loss: 2.0719 - val_categorical_accuracy: 0.3811\n",
      "Epoch 41/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.9197 - categorical_accuracy: 0.4202 - val_loss: 2.0431 - val_categorical_accuracy: 0.3773\n",
      "Epoch 42/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.8789 - categorical_accuracy: 0.4330 - val_loss: 2.0700 - val_categorical_accuracy: 0.3960\n",
      "Epoch 43/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.8511 - categorical_accuracy: 0.4389 - val_loss: 2.0010 - val_categorical_accuracy: 0.3910\n",
      "Epoch 44/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.8336 - categorical_accuracy: 0.4447 - val_loss: 2.1003 - val_categorical_accuracy: 0.3599\n",
      "Epoch 45/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.8010 - categorical_accuracy: 0.4570 - val_loss: 2.0422 - val_categorical_accuracy: 0.3748\n",
      "Epoch 46/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.7912 - categorical_accuracy: 0.4522 - val_loss: 2.0536 - val_categorical_accuracy: 0.3836\n",
      "Epoch 47/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.7512 - categorical_accuracy: 0.4570 - val_loss: 2.0452 - val_categorical_accuracy: 0.3674\n",
      "Epoch 48/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.7232 - categorical_accuracy: 0.4853 - val_loss: 1.9289 - val_categorical_accuracy: 0.3898\n",
      "Epoch 49/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.7258 - categorical_accuracy: 0.4853 - val_loss: 2.0243 - val_categorical_accuracy: 0.3811\n",
      "Epoch 50/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.6948 - categorical_accuracy: 0.4837 - val_loss: 1.9243 - val_categorical_accuracy: 0.4184\n",
      "Epoch 51/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.7261 - categorical_accuracy: 0.4709 - val_loss: 1.8711 - val_categorical_accuracy: 0.4284\n",
      "Epoch 52/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.6727 - categorical_accuracy: 0.4901 - val_loss: 1.9853 - val_categorical_accuracy: 0.4047\n",
      "Epoch 53/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.6256 - categorical_accuracy: 0.4955 - val_loss: 1.9650 - val_categorical_accuracy: 0.4134\n",
      "Epoch 54/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.6722 - categorical_accuracy: 0.4891 - val_loss: 1.9228 - val_categorical_accuracy: 0.4209\n",
      "Epoch 55/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.6285 - categorical_accuracy: 0.5099 - val_loss: 2.0855 - val_categorical_accuracy: 0.3873\n",
      "Epoch 56/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.6422 - categorical_accuracy: 0.4987 - val_loss: 1.9728 - val_categorical_accuracy: 0.4222\n",
      "Epoch 57/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.5899 - categorical_accuracy: 0.5168 - val_loss: 2.1437 - val_categorical_accuracy: 0.3786\n",
      "Epoch 58/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.5530 - categorical_accuracy: 0.5190 - val_loss: 1.9765 - val_categorical_accuracy: 0.4271\n",
      "Epoch 59/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.5963 - categorical_accuracy: 0.5158 - val_loss: 1.8922 - val_categorical_accuracy: 0.4359\n",
      "Epoch 60/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.5841 - categorical_accuracy: 0.5328 - val_loss: 2.0133 - val_categorical_accuracy: 0.4097\n",
      "Epoch 61/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.5389 - categorical_accuracy: 0.5286 - val_loss: 2.0054 - val_categorical_accuracy: 0.4184\n",
      "Epoch 62/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.5853 - categorical_accuracy: 0.5238 - val_loss: 1.9966 - val_categorical_accuracy: 0.4060\n",
      "Epoch 63/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.5121 - categorical_accuracy: 0.5414 - val_loss: 1.8570 - val_categorical_accuracy: 0.4620\n",
      "Epoch 64/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.4922 - categorical_accuracy: 0.5451 - val_loss: 1.9610 - val_categorical_accuracy: 0.4222\n",
      "Epoch 65/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.4386 - categorical_accuracy: 0.5638 - val_loss: 1.8951 - val_categorical_accuracy: 0.4533\n",
      "Epoch 66/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.4936 - categorical_accuracy: 0.5505 - val_loss: 1.9114 - val_categorical_accuracy: 0.4533\n",
      "Epoch 67/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.4556 - categorical_accuracy: 0.5649 - val_loss: 1.9889 - val_categorical_accuracy: 0.4085\n",
      "Epoch 68/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.4765 - categorical_accuracy: 0.5697 - val_loss: 1.9580 - val_categorical_accuracy: 0.4446\n",
      "Epoch 69/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.4139 - categorical_accuracy: 0.5590 - val_loss: 1.8721 - val_categorical_accuracy: 0.4682\n",
      "Epoch 70/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.4347 - categorical_accuracy: 0.5489 - val_loss: 1.9247 - val_categorical_accuracy: 0.4483\n",
      "Epoch 71/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.3994 - categorical_accuracy: 0.5771 - val_loss: 1.7905 - val_categorical_accuracy: 0.4857\n",
      "Epoch 72/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.3875 - categorical_accuracy: 0.5921 - val_loss: 1.9078 - val_categorical_accuracy: 0.4595\n",
      "Epoch 73/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.3805 - categorical_accuracy: 0.5825 - val_loss: 1.7731 - val_categorical_accuracy: 0.4944\n",
      "Epoch 74/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.3874 - categorical_accuracy: 0.5889 - val_loss: 1.8958 - val_categorical_accuracy: 0.4670\n",
      "Epoch 75/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.3778 - categorical_accuracy: 0.5969 - val_loss: 1.8264 - val_categorical_accuracy: 0.4732\n",
      "Epoch 76/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.3718 - categorical_accuracy: 0.5745 - val_loss: 1.9919 - val_categorical_accuracy: 0.4732\n",
      "Epoch 77/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.3503 - categorical_accuracy: 0.5980 - val_loss: 1.8364 - val_categorical_accuracy: 0.4832\n",
      "Epoch 78/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.3273 - categorical_accuracy: 0.5980 - val_loss: 1.8554 - val_categorical_accuracy: 0.4795\n",
      "Epoch 79/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.3396 - categorical_accuracy: 0.5910 - val_loss: 1.8082 - val_categorical_accuracy: 0.4919\n",
      "Epoch 80/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.2982 - categorical_accuracy: 0.6172 - val_loss: 1.8081 - val_categorical_accuracy: 0.4956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.3167 - categorical_accuracy: 0.6044 - val_loss: 1.9463 - val_categorical_accuracy: 0.4633\n",
      "Epoch 82/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.3047 - categorical_accuracy: 0.6012 - val_loss: 1.7397 - val_categorical_accuracy: 0.4819\n",
      "Epoch 83/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.2917 - categorical_accuracy: 0.6097 - val_loss: 1.8784 - val_categorical_accuracy: 0.4732\n",
      "Epoch 84/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.2986 - categorical_accuracy: 0.6070 - val_loss: 1.7948 - val_categorical_accuracy: 0.4807\n",
      "Epoch 85/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.2531 - categorical_accuracy: 0.6295 - val_loss: 1.8634 - val_categorical_accuracy: 0.4869\n",
      "Epoch 86/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.2604 - categorical_accuracy: 0.6204 - val_loss: 1.7198 - val_categorical_accuracy: 0.5044\n",
      "Epoch 87/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.2718 - categorical_accuracy: 0.6177 - val_loss: 1.6912 - val_categorical_accuracy: 0.5205\n",
      "Epoch 88/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.2202 - categorical_accuracy: 0.6257 - val_loss: 1.7618 - val_categorical_accuracy: 0.5181\n",
      "Epoch 89/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.2625 - categorical_accuracy: 0.6129 - val_loss: 1.8079 - val_categorical_accuracy: 0.4882\n",
      "Epoch 90/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.2269 - categorical_accuracy: 0.6209 - val_loss: 1.8101 - val_categorical_accuracy: 0.5019\n",
      "Epoch 91/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.1857 - categorical_accuracy: 0.6439 - val_loss: 1.8801 - val_categorical_accuracy: 0.4782\n",
      "Epoch 92/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.1774 - categorical_accuracy: 0.6562 - val_loss: 1.8516 - val_categorical_accuracy: 0.5093\n",
      "Epoch 93/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.1848 - categorical_accuracy: 0.6418 - val_loss: 1.9384 - val_categorical_accuracy: 0.4869\n",
      "Epoch 94/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.1511 - categorical_accuracy: 0.6514 - val_loss: 1.7552 - val_categorical_accuracy: 0.5218\n",
      "Epoch 95/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.1694 - categorical_accuracy: 0.6551 - val_loss: 1.8069 - val_categorical_accuracy: 0.5044\n",
      "Epoch 96/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.1866 - categorical_accuracy: 0.6524 - val_loss: 1.8013 - val_categorical_accuracy: 0.5193\n",
      "Epoch 97/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.1638 - categorical_accuracy: 0.6594 - val_loss: 1.8952 - val_categorical_accuracy: 0.5006\n",
      "Epoch 98/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.1321 - categorical_accuracy: 0.6668 - val_loss: 1.8730 - val_categorical_accuracy: 0.5318\n",
      "Epoch 99/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.1357 - categorical_accuracy: 0.6572 - val_loss: 1.9011 - val_categorical_accuracy: 0.5218\n",
      "Epoch 100/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.1899 - categorical_accuracy: 0.6460 - val_loss: 1.8699 - val_categorical_accuracy: 0.4882\n",
      "Epoch 101/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.1109 - categorical_accuracy: 0.6754 - val_loss: 1.9289 - val_categorical_accuracy: 0.5006\n",
      "Epoch 102/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.1605 - categorical_accuracy: 0.6524 - val_loss: 1.8581 - val_categorical_accuracy: 0.5118\n",
      "Epoch 103/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0918 - categorical_accuracy: 0.6690 - val_loss: 1.7913 - val_categorical_accuracy: 0.5380\n",
      "Epoch 104/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.1158 - categorical_accuracy: 0.6679 - val_loss: 1.7725 - val_categorical_accuracy: 0.5455\n",
      "Epoch 105/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.1227 - categorical_accuracy: 0.6668 - val_loss: 1.8488 - val_categorical_accuracy: 0.5305\n",
      "Epoch 106/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.0856 - categorical_accuracy: 0.6765 - val_loss: 1.9832 - val_categorical_accuracy: 0.4932\n",
      "Epoch 107/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.1050 - categorical_accuracy: 0.6882 - val_loss: 1.8793 - val_categorical_accuracy: 0.5205\n",
      "Epoch 108/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.0949 - categorical_accuracy: 0.6941 - val_loss: 1.8537 - val_categorical_accuracy: 0.5118\n",
      "Epoch 109/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.0581 - categorical_accuracy: 0.6962 - val_loss: 1.9974 - val_categorical_accuracy: 0.4969\n",
      "Epoch 110/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0609 - categorical_accuracy: 0.6962 - val_loss: 1.8646 - val_categorical_accuracy: 0.5355\n",
      "Epoch 111/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0593 - categorical_accuracy: 0.6770 - val_loss: 1.9535 - val_categorical_accuracy: 0.5181\n",
      "Epoch 112/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0734 - categorical_accuracy: 0.6957 - val_loss: 1.9846 - val_categorical_accuracy: 0.4807\n",
      "Epoch 113/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.1048 - categorical_accuracy: 0.6909 - val_loss: 1.8282 - val_categorical_accuracy: 0.5243\n",
      "Epoch 114/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.1044 - categorical_accuracy: 0.6733 - val_loss: 2.1062 - val_categorical_accuracy: 0.5019\n",
      "Epoch 115/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0581 - categorical_accuracy: 0.6877 - val_loss: 2.0215 - val_categorical_accuracy: 0.4844\n",
      "Epoch 116/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.0780 - categorical_accuracy: 0.6978 - val_loss: 1.7895 - val_categorical_accuracy: 0.5243\n",
      "Epoch 117/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0625 - categorical_accuracy: 0.6781 - val_loss: 1.9537 - val_categorical_accuracy: 0.4981\n",
      "Epoch 118/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0043 - categorical_accuracy: 0.7096 - val_loss: 1.7887 - val_categorical_accuracy: 0.5517\n",
      "Epoch 119/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.0357 - categorical_accuracy: 0.7015 - val_loss: 1.8891 - val_categorical_accuracy: 0.5131\n",
      "Epoch 120/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0295 - categorical_accuracy: 0.7042 - val_loss: 1.7413 - val_categorical_accuracy: 0.5442\n",
      "Epoch 121/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0039 - categorical_accuracy: 0.7015 - val_loss: 1.9080 - val_categorical_accuracy: 0.5156\n",
      "Epoch 122/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0370 - categorical_accuracy: 0.7048 - val_loss: 1.8869 - val_categorical_accuracy: 0.5268\n",
      "Epoch 123/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0241 - categorical_accuracy: 0.7058 - val_loss: 1.8828 - val_categorical_accuracy: 0.5330\n",
      "Epoch 124/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.9652 - categorical_accuracy: 0.7272 - val_loss: 1.9154 - val_categorical_accuracy: 0.5305\n",
      "Epoch 125/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.0214 - categorical_accuracy: 0.7208 - val_loss: 1.8664 - val_categorical_accuracy: 0.5243\n",
      "Epoch 126/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0319 - categorical_accuracy: 0.7085 - val_loss: 1.9538 - val_categorical_accuracy: 0.5044\n",
      "Epoch 127/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9786 - categorical_accuracy: 0.7165 - val_loss: 1.8812 - val_categorical_accuracy: 0.5243\n",
      "Epoch 128/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.9652 - categorical_accuracy: 0.7272 - val_loss: 1.8908 - val_categorical_accuracy: 0.5467\n",
      "Epoch 129/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.9517 - categorical_accuracy: 0.7496 - val_loss: 1.8606 - val_categorical_accuracy: 0.5467\n",
      "Epoch 130/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.0017 - categorical_accuracy: 0.7197 - val_loss: 1.7908 - val_categorical_accuracy: 0.5467\n",
      "Epoch 131/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.9707 - categorical_accuracy: 0.7208 - val_loss: 1.9731 - val_categorical_accuracy: 0.5006\n",
      "Epoch 132/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.9937 - categorical_accuracy: 0.7176 - val_loss: 1.9043 - val_categorical_accuracy: 0.5342\n",
      "Epoch 133/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9239 - categorical_accuracy: 0.7400 - val_loss: 1.9664 - val_categorical_accuracy: 0.4969\n",
      "Epoch 134/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.9445 - categorical_accuracy: 0.7309 - val_loss: 1.8663 - val_categorical_accuracy: 0.5517\n",
      "Epoch 135/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9210 - categorical_accuracy: 0.7336 - val_loss: 1.9706 - val_categorical_accuracy: 0.5492\n",
      "Epoch 136/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9942 - categorical_accuracy: 0.7208 - val_loss: 1.8615 - val_categorical_accuracy: 0.5280\n",
      "Epoch 137/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.9233 - categorical_accuracy: 0.7475 - val_loss: 1.8756 - val_categorical_accuracy: 0.5442\n",
      "Epoch 138/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9248 - categorical_accuracy: 0.7395 - val_loss: 1.8873 - val_categorical_accuracy: 0.5280\n",
      "Epoch 139/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9162 - categorical_accuracy: 0.7512 - val_loss: 1.8785 - val_categorical_accuracy: 0.5430\n",
      "Epoch 140/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8927 - categorical_accuracy: 0.7517 - val_loss: 2.0039 - val_categorical_accuracy: 0.5504\n",
      "Epoch 141/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9102 - categorical_accuracy: 0.7597 - val_loss: 1.8169 - val_categorical_accuracy: 0.5616\n",
      "Epoch 142/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9305 - categorical_accuracy: 0.7464 - val_loss: 1.9599 - val_categorical_accuracy: 0.5342\n",
      "Epoch 143/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8872 - categorical_accuracy: 0.7571 - val_loss: 1.9408 - val_categorical_accuracy: 0.5380\n",
      "Epoch 144/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8930 - categorical_accuracy: 0.7533 - val_loss: 1.8661 - val_categorical_accuracy: 0.5616\n",
      "Epoch 145/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8904 - categorical_accuracy: 0.7539 - val_loss: 1.7934 - val_categorical_accuracy: 0.5592\n",
      "Epoch 146/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9083 - categorical_accuracy: 0.7619 - val_loss: 1.9853 - val_categorical_accuracy: 0.5455\n",
      "Epoch 147/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.9133 - categorical_accuracy: 0.7448 - val_loss: 1.9420 - val_categorical_accuracy: 0.5542\n",
      "Epoch 148/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8949 - categorical_accuracy: 0.7656 - val_loss: 1.9762 - val_categorical_accuracy: 0.5517\n",
      "Epoch 149/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9129 - categorical_accuracy: 0.7464 - val_loss: 1.9189 - val_categorical_accuracy: 0.5504\n",
      "Epoch 150/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.9025 - categorical_accuracy: 0.7533 - val_loss: 1.9439 - val_categorical_accuracy: 0.5704\n",
      "Epoch 151/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8852 - categorical_accuracy: 0.7581 - val_loss: 1.9071 - val_categorical_accuracy: 0.5567\n",
      "Epoch 152/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8881 - categorical_accuracy: 0.7576 - val_loss: 2.1034 - val_categorical_accuracy: 0.5342\n",
      "Epoch 153/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8465 - categorical_accuracy: 0.7576 - val_loss: 1.8403 - val_categorical_accuracy: 0.5791\n",
      "Epoch 154/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8693 - categorical_accuracy: 0.7624 - val_loss: 1.8450 - val_categorical_accuracy: 0.5778\n",
      "Epoch 155/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8979 - categorical_accuracy: 0.7549 - val_loss: 1.8682 - val_categorical_accuracy: 0.5704\n",
      "Epoch 156/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8744 - categorical_accuracy: 0.7683 - val_loss: 1.8909 - val_categorical_accuracy: 0.5529\n",
      "Epoch 157/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8937 - categorical_accuracy: 0.7597 - val_loss: 2.0202 - val_categorical_accuracy: 0.5318\n",
      "Epoch 158/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8966 - categorical_accuracy: 0.7597 - val_loss: 1.9468 - val_categorical_accuracy: 0.5529\n",
      "Epoch 159/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8845 - categorical_accuracy: 0.7597 - val_loss: 1.9974 - val_categorical_accuracy: 0.5430\n",
      "Epoch 160/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8479 - categorical_accuracy: 0.7544 - val_loss: 2.0013 - val_categorical_accuracy: 0.5629\n",
      "Epoch 161/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8463 - categorical_accuracy: 0.7688 - val_loss: 1.9419 - val_categorical_accuracy: 0.5641\n",
      "Epoch 162/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8458 - categorical_accuracy: 0.7710 - val_loss: 1.8778 - val_categorical_accuracy: 0.5741\n",
      "Epoch 163/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8612 - categorical_accuracy: 0.7726 - val_loss: 1.9852 - val_categorical_accuracy: 0.5741\n",
      "Epoch 164/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8973 - categorical_accuracy: 0.7560 - val_loss: 1.8871 - val_categorical_accuracy: 0.5778\n",
      "Epoch 165/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8539 - categorical_accuracy: 0.7603 - val_loss: 1.8950 - val_categorical_accuracy: 0.5641\n",
      "Epoch 166/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8404 - categorical_accuracy: 0.7806 - val_loss: 1.9045 - val_categorical_accuracy: 0.5753\n",
      "Epoch 167/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8065 - categorical_accuracy: 0.7816 - val_loss: 1.8193 - val_categorical_accuracy: 0.5791\n",
      "Epoch 168/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8218 - categorical_accuracy: 0.7795 - val_loss: 1.9001 - val_categorical_accuracy: 0.5455\n",
      "Epoch 169/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8279 - categorical_accuracy: 0.7822 - val_loss: 1.9322 - val_categorical_accuracy: 0.5704\n",
      "Epoch 170/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7642 - categorical_accuracy: 0.8019 - val_loss: 1.8736 - val_categorical_accuracy: 0.5716\n",
      "Epoch 171/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7998 - categorical_accuracy: 0.7800 - val_loss: 1.7291 - val_categorical_accuracy: 0.6090\n",
      "Epoch 172/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8266 - categorical_accuracy: 0.7736 - val_loss: 1.8709 - val_categorical_accuracy: 0.5928\n",
      "Epoch 173/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8377 - categorical_accuracy: 0.7694 - val_loss: 2.0128 - val_categorical_accuracy: 0.5729\n",
      "Epoch 174/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7930 - categorical_accuracy: 0.7918 - val_loss: 1.8226 - val_categorical_accuracy: 0.5903\n",
      "Epoch 175/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8425 - categorical_accuracy: 0.7752 - val_loss: 2.0064 - val_categorical_accuracy: 0.5579\n",
      "Epoch 176/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8183 - categorical_accuracy: 0.7774 - val_loss: 1.7648 - val_categorical_accuracy: 0.6102\n",
      "Epoch 177/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8539 - categorical_accuracy: 0.7806 - val_loss: 1.7826 - val_categorical_accuracy: 0.6090\n",
      "Epoch 178/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8016 - categorical_accuracy: 0.7854 - val_loss: 1.9159 - val_categorical_accuracy: 0.5766\n",
      "Epoch 179/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8124 - categorical_accuracy: 0.7886 - val_loss: 1.9770 - val_categorical_accuracy: 0.5517\n",
      "Epoch 180/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.7867 - categorical_accuracy: 0.7912 - val_loss: 1.8922 - val_categorical_accuracy: 0.5791\n",
      "Epoch 181/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7878 - categorical_accuracy: 0.7859 - val_loss: 1.8395 - val_categorical_accuracy: 0.5965\n",
      "Epoch 182/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.7808 - categorical_accuracy: 0.7859 - val_loss: 2.0498 - val_categorical_accuracy: 0.5629\n",
      "Epoch 183/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8127 - categorical_accuracy: 0.7870 - val_loss: 2.0220 - val_categorical_accuracy: 0.5716\n",
      "Epoch 184/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8269 - categorical_accuracy: 0.7731 - val_loss: 1.9872 - val_categorical_accuracy: 0.5741\n",
      "Epoch 185/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8298 - categorical_accuracy: 0.7864 - val_loss: 1.8852 - val_categorical_accuracy: 0.6040\n",
      "Epoch 186/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8308 - categorical_accuracy: 0.7736 - val_loss: 2.0547 - val_categorical_accuracy: 0.5729\n",
      "Epoch 187/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7689 - categorical_accuracy: 0.8062 - val_loss: 2.0406 - val_categorical_accuracy: 0.5554\n",
      "Epoch 188/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8256 - categorical_accuracy: 0.7859 - val_loss: 2.0854 - val_categorical_accuracy: 0.5691\n",
      "Epoch 189/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7520 - categorical_accuracy: 0.8030 - val_loss: 2.0652 - val_categorical_accuracy: 0.5791\n",
      "Epoch 190/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8510 - categorical_accuracy: 0.7731 - val_loss: 2.1557 - val_categorical_accuracy: 0.5455\n",
      "Epoch 191/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8064 - categorical_accuracy: 0.8009 - val_loss: 2.0569 - val_categorical_accuracy: 0.5641\n",
      "Epoch 192/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.7948 - categorical_accuracy: 0.7918 - val_loss: 2.0264 - val_categorical_accuracy: 0.5691\n",
      "Epoch 193/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7676 - categorical_accuracy: 0.8041 - val_loss: 1.9824 - val_categorical_accuracy: 0.5853\n",
      "Epoch 194/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8147 - categorical_accuracy: 0.7928 - val_loss: 2.0222 - val_categorical_accuracy: 0.5666\n",
      "Epoch 195/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7628 - categorical_accuracy: 0.8078 - val_loss: 2.0271 - val_categorical_accuracy: 0.5841\n",
      "Epoch 196/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7988 - categorical_accuracy: 0.7886 - val_loss: 1.9955 - val_categorical_accuracy: 0.5828\n",
      "Epoch 197/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7434 - categorical_accuracy: 0.8003 - val_loss: 1.8822 - val_categorical_accuracy: 0.5940\n",
      "Epoch 198/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7905 - categorical_accuracy: 0.8035 - val_loss: 2.0313 - val_categorical_accuracy: 0.5567\n",
      "Epoch 199/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.7843 - categorical_accuracy: 0.7971 - val_loss: 1.9819 - val_categorical_accuracy: 0.5517\n",
      "Epoch 200/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8177 - categorical_accuracy: 0.7854 - val_loss: 2.1575 - val_categorical_accuracy: 0.5342\n",
      "Epoch 201/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7564 - categorical_accuracy: 0.8009 - val_loss: 2.0214 - val_categorical_accuracy: 0.5654\n",
      "Epoch 202/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7814 - categorical_accuracy: 0.8014 - val_loss: 1.9081 - val_categorical_accuracy: 0.5866\n",
      "Epoch 203/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7649 - categorical_accuracy: 0.8115 - val_loss: 1.8788 - val_categorical_accuracy: 0.6027\n",
      "Epoch 204/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7790 - categorical_accuracy: 0.8041 - val_loss: 1.9678 - val_categorical_accuracy: 0.5729\n",
      "Epoch 205/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8118 - categorical_accuracy: 0.7998 - val_loss: 1.9843 - val_categorical_accuracy: 0.5716\n",
      "Epoch 206/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7773 - categorical_accuracy: 0.7987 - val_loss: 2.0215 - val_categorical_accuracy: 0.5654\n",
      "Epoch 207/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.7573 - categorical_accuracy: 0.8115 - val_loss: 1.8519 - val_categorical_accuracy: 0.5878\n",
      "Epoch 208/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7676 - categorical_accuracy: 0.8003 - val_loss: 1.9056 - val_categorical_accuracy: 0.5890\n",
      "Epoch 209/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7547 - categorical_accuracy: 0.8174 - val_loss: 1.9195 - val_categorical_accuracy: 0.6040\n",
      "Epoch 210/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7579 - categorical_accuracy: 0.8147 - val_loss: 1.8802 - val_categorical_accuracy: 0.5928\n",
      "Epoch 211/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7735 - categorical_accuracy: 0.7886 - val_loss: 1.8929 - val_categorical_accuracy: 0.5791\n",
      "Epoch 212/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7351 - categorical_accuracy: 0.8238 - val_loss: 2.0092 - val_categorical_accuracy: 0.5704\n",
      "Epoch 213/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7183 - categorical_accuracy: 0.8169 - val_loss: 2.0473 - val_categorical_accuracy: 0.5679\n",
      "Epoch 214/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7570 - categorical_accuracy: 0.8078 - val_loss: 1.9010 - val_categorical_accuracy: 0.6102\n",
      "Epoch 215/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7814 - categorical_accuracy: 0.7998 - val_loss: 2.0649 - val_categorical_accuracy: 0.5641\n",
      "Epoch 216/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7934 - categorical_accuracy: 0.7971 - val_loss: 1.9904 - val_categorical_accuracy: 0.5778\n",
      "Epoch 217/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7784 - categorical_accuracy: 0.8014 - val_loss: 1.9896 - val_categorical_accuracy: 0.5629\n",
      "Epoch 218/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7435 - categorical_accuracy: 0.8089 - val_loss: 2.0177 - val_categorical_accuracy: 0.5716\n",
      "Epoch 219/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7337 - categorical_accuracy: 0.8233 - val_loss: 1.9291 - val_categorical_accuracy: 0.5666\n",
      "Epoch 220/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8510 - categorical_accuracy: 0.7923 - val_loss: 2.0689 - val_categorical_accuracy: 0.5679\n",
      "Epoch 221/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8240 - categorical_accuracy: 0.7993 - val_loss: 2.0902 - val_categorical_accuracy: 0.5691\n",
      "Epoch 222/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8319 - categorical_accuracy: 0.7891 - val_loss: 1.9820 - val_categorical_accuracy: 0.5716\n",
      "Epoch 223/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7905 - categorical_accuracy: 0.7982 - val_loss: 1.8953 - val_categorical_accuracy: 0.5928\n",
      "Epoch 224/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7994 - categorical_accuracy: 0.7944 - val_loss: 1.9434 - val_categorical_accuracy: 0.5953\n",
      "Epoch 225/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7728 - categorical_accuracy: 0.8153 - val_loss: 1.9337 - val_categorical_accuracy: 0.5828\n",
      "Epoch 226/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8363 - categorical_accuracy: 0.7838 - val_loss: 1.9264 - val_categorical_accuracy: 0.5978\n",
      "Epoch 227/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8104 - categorical_accuracy: 0.7977 - val_loss: 1.8722 - val_categorical_accuracy: 0.5828\n",
      "Epoch 228/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8126 - categorical_accuracy: 0.8067 - val_loss: 2.0479 - val_categorical_accuracy: 0.5479\n",
      "Epoch 229/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8421 - categorical_accuracy: 0.7859 - val_loss: 1.9075 - val_categorical_accuracy: 0.5766\n",
      "Epoch 230/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.8074 - categorical_accuracy: 0.7934 - val_loss: 1.9104 - val_categorical_accuracy: 0.5716\n",
      "Epoch 231/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8567 - categorical_accuracy: 0.7918 - val_loss: 2.0336 - val_categorical_accuracy: 0.5666\n",
      "Epoch 232/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8655 - categorical_accuracy: 0.7838 - val_loss: 2.0681 - val_categorical_accuracy: 0.5629\n",
      "Epoch 233/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7989 - categorical_accuracy: 0.7993 - val_loss: 2.0192 - val_categorical_accuracy: 0.5679\n",
      "Epoch 234/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7736 - categorical_accuracy: 0.8035 - val_loss: 1.9581 - val_categorical_accuracy: 0.6177\n",
      "Epoch 235/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8106 - categorical_accuracy: 0.8147 - val_loss: 1.9405 - val_categorical_accuracy: 0.5853\n",
      "Epoch 236/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8216 - categorical_accuracy: 0.7880 - val_loss: 1.9902 - val_categorical_accuracy: 0.5928\n",
      "Epoch 237/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8163 - categorical_accuracy: 0.8030 - val_loss: 2.0882 - val_categorical_accuracy: 0.5517\n",
      "Epoch 238/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7969 - categorical_accuracy: 0.8083 - val_loss: 2.0084 - val_categorical_accuracy: 0.5704\n",
      "Epoch 239/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7272 - categorical_accuracy: 0.8169 - val_loss: 2.1498 - val_categorical_accuracy: 0.5567\n",
      "Epoch 240/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7626 - categorical_accuracy: 0.8089 - val_loss: 2.0599 - val_categorical_accuracy: 0.5791\n",
      "Epoch 241/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.7424 - categorical_accuracy: 0.8142 - val_loss: 2.1194 - val_categorical_accuracy: 0.5641\n",
      "Epoch 242/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7878 - categorical_accuracy: 0.8142 - val_loss: 2.1732 - val_categorical_accuracy: 0.5604\n",
      "Epoch 243/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8048 - categorical_accuracy: 0.8121 - val_loss: 2.0155 - val_categorical_accuracy: 0.5878\n",
      "Epoch 244/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7822 - categorical_accuracy: 0.8089 - val_loss: 1.9814 - val_categorical_accuracy: 0.5953\n",
      "Epoch 245/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8246 - categorical_accuracy: 0.8035 - val_loss: 1.9913 - val_categorical_accuracy: 0.5965\n",
      "Epoch 246/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7787 - categorical_accuracy: 0.8121 - val_loss: 1.9224 - val_categorical_accuracy: 0.6015\n",
      "Epoch 247/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7676 - categorical_accuracy: 0.8158 - val_loss: 2.0110 - val_categorical_accuracy: 0.5666\n",
      "Epoch 248/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8084 - categorical_accuracy: 0.8142 - val_loss: 2.0308 - val_categorical_accuracy: 0.5554\n",
      "Epoch 249/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.7474 - categorical_accuracy: 0.8147 - val_loss: 1.9744 - val_categorical_accuracy: 0.5778\n",
      "Epoch 250/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.8116 - categorical_accuracy: 0.8126 - val_loss: 1.9560 - val_categorical_accuracy: 0.5716\n",
      "Epoch 251/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7646 - categorical_accuracy: 0.8153 - val_loss: 1.9363 - val_categorical_accuracy: 0.5828\n",
      "Epoch 252/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7667 - categorical_accuracy: 0.8051 - val_loss: 1.9232 - val_categorical_accuracy: 0.5903\n",
      "Epoch 253/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7138 - categorical_accuracy: 0.8270 - val_loss: 2.0590 - val_categorical_accuracy: 0.5579\n",
      "Epoch 254/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7317 - categorical_accuracy: 0.8201 - val_loss: 1.9678 - val_categorical_accuracy: 0.5915\n",
      "Epoch 255/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7302 - categorical_accuracy: 0.8222 - val_loss: 2.1760 - val_categorical_accuracy: 0.5529\n",
      "Epoch 256/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7505 - categorical_accuracy: 0.8163 - val_loss: 1.9777 - val_categorical_accuracy: 0.5953\n",
      "Epoch 257/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7761 - categorical_accuracy: 0.8089 - val_loss: 1.9862 - val_categorical_accuracy: 0.5816\n",
      "Epoch 258/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7206 - categorical_accuracy: 0.8233 - val_loss: 2.0068 - val_categorical_accuracy: 0.5853\n",
      "Epoch 259/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6846 - categorical_accuracy: 0.8366 - val_loss: 2.0746 - val_categorical_accuracy: 0.5492\n",
      "Epoch 260/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7209 - categorical_accuracy: 0.8313 - val_loss: 2.0210 - val_categorical_accuracy: 0.6002\n",
      "Epoch 261/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7509 - categorical_accuracy: 0.8195 - val_loss: 2.1185 - val_categorical_accuracy: 0.5729\n",
      "Epoch 262/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7384 - categorical_accuracy: 0.8222 - val_loss: 1.9814 - val_categorical_accuracy: 0.6152\n",
      "Epoch 263/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7376 - categorical_accuracy: 0.8147 - val_loss: 1.9558 - val_categorical_accuracy: 0.5940\n",
      "Epoch 264/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7576 - categorical_accuracy: 0.8227 - val_loss: 1.8583 - val_categorical_accuracy: 0.6015\n",
      "Epoch 265/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7029 - categorical_accuracy: 0.8238 - val_loss: 1.9408 - val_categorical_accuracy: 0.5841\n",
      "Epoch 266/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7423 - categorical_accuracy: 0.8281 - val_loss: 1.9711 - val_categorical_accuracy: 0.5791\n",
      "Epoch 267/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6672 - categorical_accuracy: 0.8308 - val_loss: 1.8832 - val_categorical_accuracy: 0.6177\n",
      "Epoch 268/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7331 - categorical_accuracy: 0.8361 - val_loss: 1.9943 - val_categorical_accuracy: 0.5828\n",
      "Epoch 269/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7260 - categorical_accuracy: 0.8185 - val_loss: 2.0030 - val_categorical_accuracy: 0.5828\n",
      "Epoch 270/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6955 - categorical_accuracy: 0.8329 - val_loss: 2.0203 - val_categorical_accuracy: 0.5828\n",
      "Epoch 271/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6583 - categorical_accuracy: 0.8510 - val_loss: 2.0643 - val_categorical_accuracy: 0.5803\n",
      "Epoch 272/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7300 - categorical_accuracy: 0.8227 - val_loss: 1.8842 - val_categorical_accuracy: 0.6090\n",
      "Epoch 273/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7219 - categorical_accuracy: 0.8350 - val_loss: 2.0357 - val_categorical_accuracy: 0.5791\n",
      "Epoch 274/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7027 - categorical_accuracy: 0.8350 - val_loss: 2.0901 - val_categorical_accuracy: 0.5766\n",
      "Epoch 275/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7359 - categorical_accuracy: 0.8334 - val_loss: 2.1743 - val_categorical_accuracy: 0.5641\n",
      "Epoch 276/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6781 - categorical_accuracy: 0.8324 - val_loss: 2.2822 - val_categorical_accuracy: 0.5803\n",
      "Epoch 277/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7110 - categorical_accuracy: 0.8356 - val_loss: 2.0423 - val_categorical_accuracy: 0.6139\n",
      "Epoch 278/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6634 - categorical_accuracy: 0.8414 - val_loss: 2.2474 - val_categorical_accuracy: 0.5666\n",
      "Epoch 279/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7084 - categorical_accuracy: 0.8302 - val_loss: 2.1542 - val_categorical_accuracy: 0.5890\n",
      "Epoch 280/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6949 - categorical_accuracy: 0.8457 - val_loss: 2.1373 - val_categorical_accuracy: 0.5915\n",
      "Epoch 281/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6974 - categorical_accuracy: 0.8361 - val_loss: 2.2620 - val_categorical_accuracy: 0.5405\n",
      "Epoch 282/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7181 - categorical_accuracy: 0.8308 - val_loss: 2.1992 - val_categorical_accuracy: 0.5704\n",
      "Epoch 283/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6989 - categorical_accuracy: 0.8409 - val_loss: 2.2589 - val_categorical_accuracy: 0.5641\n",
      "Epoch 284/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6868 - categorical_accuracy: 0.8324 - val_loss: 2.0671 - val_categorical_accuracy: 0.5853\n",
      "Epoch 285/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6774 - categorical_accuracy: 0.8404 - val_loss: 2.1610 - val_categorical_accuracy: 0.5778\n",
      "Epoch 286/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6536 - categorical_accuracy: 0.8468 - val_loss: 2.1800 - val_categorical_accuracy: 0.5828\n",
      "Epoch 287/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6489 - categorical_accuracy: 0.8532 - val_loss: 2.3146 - val_categorical_accuracy: 0.5654\n",
      "Epoch 288/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6757 - categorical_accuracy: 0.8404 - val_loss: 2.3304 - val_categorical_accuracy: 0.5666\n",
      "Epoch 289/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7096 - categorical_accuracy: 0.8308 - val_loss: 2.0919 - val_categorical_accuracy: 0.5866\n",
      "Epoch 290/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7023 - categorical_accuracy: 0.8297 - val_loss: 2.0340 - val_categorical_accuracy: 0.6040\n",
      "Epoch 291/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6868 - categorical_accuracy: 0.8393 - val_loss: 2.0850 - val_categorical_accuracy: 0.5890\n",
      "Epoch 292/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7587 - categorical_accuracy: 0.8195 - val_loss: 1.9856 - val_categorical_accuracy: 0.5890\n",
      "Epoch 293/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6966 - categorical_accuracy: 0.8361 - val_loss: 2.0074 - val_categorical_accuracy: 0.5791\n",
      "Epoch 294/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6976 - categorical_accuracy: 0.8286 - val_loss: 2.0286 - val_categorical_accuracy: 0.5915\n",
      "Epoch 295/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6540 - categorical_accuracy: 0.8505 - val_loss: 2.2937 - val_categorical_accuracy: 0.5704\n",
      "Epoch 296/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7222 - categorical_accuracy: 0.8259 - val_loss: 2.0636 - val_categorical_accuracy: 0.5828\n",
      "Epoch 297/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7219 - categorical_accuracy: 0.8201 - val_loss: 2.1651 - val_categorical_accuracy: 0.5654\n",
      "Epoch 298/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7273 - categorical_accuracy: 0.8265 - val_loss: 2.0937 - val_categorical_accuracy: 0.6077\n",
      "Epoch 299/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6572 - categorical_accuracy: 0.8409 - val_loss: 2.1158 - val_categorical_accuracy: 0.6015\n",
      "Epoch 300/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6741 - categorical_accuracy: 0.8420 - val_loss: 2.1456 - val_categorical_accuracy: 0.6040\n",
      "Epoch 301/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7097 - categorical_accuracy: 0.8329 - val_loss: 2.0761 - val_categorical_accuracy: 0.5928\n",
      "Epoch 302/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7149 - categorical_accuracy: 0.8227 - val_loss: 2.2416 - val_categorical_accuracy: 0.5841\n",
      "Epoch 303/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7036 - categorical_accuracy: 0.8350 - val_loss: 2.1737 - val_categorical_accuracy: 0.5666\n",
      "Epoch 304/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6959 - categorical_accuracy: 0.8372 - val_loss: 2.1167 - val_categorical_accuracy: 0.5654\n",
      "Epoch 305/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7071 - categorical_accuracy: 0.8286 - val_loss: 2.2167 - val_categorical_accuracy: 0.5729\n",
      "Epoch 306/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7076 - categorical_accuracy: 0.8382 - val_loss: 2.0598 - val_categorical_accuracy: 0.5965\n",
      "Epoch 307/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6859 - categorical_accuracy: 0.8377 - val_loss: 2.3235 - val_categorical_accuracy: 0.5293\n",
      "Epoch 308/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7381 - categorical_accuracy: 0.8233 - val_loss: 2.0867 - val_categorical_accuracy: 0.5940\n",
      "Epoch 309/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7204 - categorical_accuracy: 0.8356 - val_loss: 2.1037 - val_categorical_accuracy: 0.5704\n",
      "Epoch 310/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7283 - categorical_accuracy: 0.8249 - val_loss: 2.0364 - val_categorical_accuracy: 0.5953\n",
      "Epoch 311/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6777 - categorical_accuracy: 0.8425 - val_loss: 1.9768 - val_categorical_accuracy: 0.6164\n",
      "Epoch 312/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6969 - categorical_accuracy: 0.8292 - val_loss: 2.2742 - val_categorical_accuracy: 0.5554\n",
      "Epoch 313/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6702 - categorical_accuracy: 0.8494 - val_loss: 2.1131 - val_categorical_accuracy: 0.6202\n",
      "Epoch 314/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7279 - categorical_accuracy: 0.8302 - val_loss: 2.1067 - val_categorical_accuracy: 0.6227\n",
      "Epoch 315/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7354 - categorical_accuracy: 0.8254 - val_loss: 2.1789 - val_categorical_accuracy: 0.5828\n",
      "Epoch 316/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7074 - categorical_accuracy: 0.8281 - val_loss: 2.2272 - val_categorical_accuracy: 0.5791\n",
      "Epoch 317/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6875 - categorical_accuracy: 0.8356 - val_loss: 2.2498 - val_categorical_accuracy: 0.5965\n",
      "Epoch 318/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7056 - categorical_accuracy: 0.8270 - val_loss: 2.2787 - val_categorical_accuracy: 0.5841\n",
      "Epoch 319/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6830 - categorical_accuracy: 0.8409 - val_loss: 2.3062 - val_categorical_accuracy: 0.5729\n",
      "Epoch 320/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6902 - categorical_accuracy: 0.8350 - val_loss: 2.2786 - val_categorical_accuracy: 0.5616\n",
      "Epoch 321/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6547 - categorical_accuracy: 0.8484 - val_loss: 2.2036 - val_categorical_accuracy: 0.5567\n",
      "Epoch 322/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7386 - categorical_accuracy: 0.8259 - val_loss: 2.1607 - val_categorical_accuracy: 0.5816\n",
      "Epoch 323/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6970 - categorical_accuracy: 0.8350 - val_loss: 2.1296 - val_categorical_accuracy: 0.5965\n",
      "Epoch 324/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6912 - categorical_accuracy: 0.8430 - val_loss: 2.0464 - val_categorical_accuracy: 0.5953\n",
      "Epoch 325/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6947 - categorical_accuracy: 0.8436 - val_loss: 2.0954 - val_categorical_accuracy: 0.5953\n",
      "Epoch 326/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6858 - categorical_accuracy: 0.8372 - val_loss: 2.3110 - val_categorical_accuracy: 0.5641\n",
      "Epoch 327/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7063 - categorical_accuracy: 0.8361 - val_loss: 2.2964 - val_categorical_accuracy: 0.5604\n",
      "Epoch 328/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7065 - categorical_accuracy: 0.8388 - val_loss: 2.2901 - val_categorical_accuracy: 0.5604\n",
      "Epoch 329/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6963 - categorical_accuracy: 0.8457 - val_loss: 2.1121 - val_categorical_accuracy: 0.5978\n",
      "Epoch 330/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6619 - categorical_accuracy: 0.8516 - val_loss: 2.2154 - val_categorical_accuracy: 0.6189\n",
      "Epoch 331/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7356 - categorical_accuracy: 0.8382 - val_loss: 2.0570 - val_categorical_accuracy: 0.5953\n",
      "Epoch 332/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6827 - categorical_accuracy: 0.8484 - val_loss: 2.1157 - val_categorical_accuracy: 0.5953\n",
      "Epoch 333/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6483 - categorical_accuracy: 0.8623 - val_loss: 2.1064 - val_categorical_accuracy: 0.5816\n",
      "Epoch 334/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6561 - categorical_accuracy: 0.8500 - val_loss: 2.1723 - val_categorical_accuracy: 0.5978\n",
      "Epoch 335/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7049 - categorical_accuracy: 0.8478 - val_loss: 2.3248 - val_categorical_accuracy: 0.5903\n",
      "Epoch 336/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7349 - categorical_accuracy: 0.8350 - val_loss: 2.4005 - val_categorical_accuracy: 0.5641\n",
      "Epoch 337/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7228 - categorical_accuracy: 0.8372 - val_loss: 2.1437 - val_categorical_accuracy: 0.6052\n",
      "Epoch 338/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7426 - categorical_accuracy: 0.8398 - val_loss: 2.2259 - val_categorical_accuracy: 0.5915\n",
      "Epoch 339/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6907 - categorical_accuracy: 0.8393 - val_loss: 2.1215 - val_categorical_accuracy: 0.5878\n",
      "Epoch 340/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6949 - categorical_accuracy: 0.8452 - val_loss: 2.1854 - val_categorical_accuracy: 0.5704\n",
      "Epoch 341/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7719 - categorical_accuracy: 0.8238 - val_loss: 2.3377 - val_categorical_accuracy: 0.5430\n",
      "Epoch 342/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7522 - categorical_accuracy: 0.8292 - val_loss: 2.3834 - val_categorical_accuracy: 0.5529\n",
      "Epoch 343/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7034 - categorical_accuracy: 0.8388 - val_loss: 2.1960 - val_categorical_accuracy: 0.5953\n",
      "Epoch 344/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7389 - categorical_accuracy: 0.8393 - val_loss: 2.4824 - val_categorical_accuracy: 0.5592\n",
      "Epoch 345/5000\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.8824 - categorical_accuracy: 0.7987 - val_loss: 2.2555 - val_categorical_accuracy: 0.5641\n",
      "Epoch 346/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9837 - categorical_accuracy: 0.7576 - val_loss: 2.0732 - val_categorical_accuracy: 0.5803\n",
      "Epoch 347/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9304 - categorical_accuracy: 0.7795 - val_loss: 2.0921 - val_categorical_accuracy: 0.5741\n",
      "Epoch 348/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9125 - categorical_accuracy: 0.7816 - val_loss: 1.9183 - val_categorical_accuracy: 0.6052\n",
      "Epoch 349/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8962 - categorical_accuracy: 0.7683 - val_loss: 1.9799 - val_categorical_accuracy: 0.5878\n",
      "Epoch 350/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9392 - categorical_accuracy: 0.7699 - val_loss: 2.0918 - val_categorical_accuracy: 0.5753\n",
      "Epoch 351/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.9100 - categorical_accuracy: 0.7806 - val_loss: 1.9606 - val_categorical_accuracy: 0.6015\n",
      "Epoch 352/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.8672 - categorical_accuracy: 0.7896 - val_loss: 2.0392 - val_categorical_accuracy: 0.6040\n",
      "Epoch 353/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.9147 - categorical_accuracy: 0.7683 - val_loss: 2.0674 - val_categorical_accuracy: 0.5778\n",
      "Epoch 354/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8898 - categorical_accuracy: 0.7955 - val_loss: 2.0451 - val_categorical_accuracy: 0.5729\n",
      "Epoch 355/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8156 - categorical_accuracy: 0.8073 - val_loss: 1.9798 - val_categorical_accuracy: 0.5866\n",
      "Epoch 356/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8801 - categorical_accuracy: 0.8041 - val_loss: 1.9989 - val_categorical_accuracy: 0.6139\n",
      "Epoch 357/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.9472 - categorical_accuracy: 0.7699 - val_loss: 2.1562 - val_categorical_accuracy: 0.5741\n",
      "Epoch 358/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0753 - categorical_accuracy: 0.7544 - val_loss: 2.1260 - val_categorical_accuracy: 0.5592\n",
      "Epoch 359/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0855 - categorical_accuracy: 0.7379 - val_loss: 2.0318 - val_categorical_accuracy: 0.5853\n",
      "Epoch 360/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9689 - categorical_accuracy: 0.7597 - val_loss: 2.0000 - val_categorical_accuracy: 0.5729\n",
      "Epoch 361/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0025 - categorical_accuracy: 0.7491 - val_loss: 1.8735 - val_categorical_accuracy: 0.6152\n",
      "Epoch 362/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9627 - categorical_accuracy: 0.7694 - val_loss: 2.0213 - val_categorical_accuracy: 0.5791\n",
      "Epoch 363/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9566 - categorical_accuracy: 0.7624 - val_loss: 1.9328 - val_categorical_accuracy: 0.5990\n",
      "Epoch 364/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9471 - categorical_accuracy: 0.7710 - val_loss: 1.9202 - val_categorical_accuracy: 0.5965\n",
      "Epoch 365/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.9829 - categorical_accuracy: 0.7651 - val_loss: 1.8849 - val_categorical_accuracy: 0.5853\n",
      "Epoch 366/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9421 - categorical_accuracy: 0.7710 - val_loss: 1.9375 - val_categorical_accuracy: 0.5915\n",
      "Epoch 367/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9260 - categorical_accuracy: 0.7752 - val_loss: 1.9390 - val_categorical_accuracy: 0.6052\n",
      "Epoch 368/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8839 - categorical_accuracy: 0.7848 - val_loss: 1.8590 - val_categorical_accuracy: 0.6065\n",
      "Epoch 369/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9295 - categorical_accuracy: 0.7806 - val_loss: 1.8402 - val_categorical_accuracy: 0.6152\n",
      "Epoch 370/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9163 - categorical_accuracy: 0.7811 - val_loss: 1.9252 - val_categorical_accuracy: 0.6102\n",
      "Epoch 371/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9060 - categorical_accuracy: 0.7758 - val_loss: 1.8172 - val_categorical_accuracy: 0.6488\n",
      "Epoch 372/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8611 - categorical_accuracy: 0.7950 - val_loss: 1.8438 - val_categorical_accuracy: 0.6214\n",
      "Epoch 373/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.9033 - categorical_accuracy: 0.7891 - val_loss: 1.9361 - val_categorical_accuracy: 0.5990\n",
      "Epoch 374/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8228 - categorical_accuracy: 0.8105 - val_loss: 2.0734 - val_categorical_accuracy: 0.5903\n",
      "Epoch 375/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.8392 - categorical_accuracy: 0.7987 - val_loss: 1.9572 - val_categorical_accuracy: 0.6139\n",
      "Epoch 376/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.8389 - categorical_accuracy: 0.8115 - val_loss: 1.8663 - val_categorical_accuracy: 0.6164\n",
      "Epoch 377/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.8034 - categorical_accuracy: 0.8211 - val_loss: 1.9042 - val_categorical_accuracy: 0.6227\n",
      "Epoch 378/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.8440 - categorical_accuracy: 0.8078 - val_loss: 2.0231 - val_categorical_accuracy: 0.5866\n",
      "Epoch 379/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7825 - categorical_accuracy: 0.8259 - val_loss: 1.9227 - val_categorical_accuracy: 0.5928\n",
      "Epoch 380/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7897 - categorical_accuracy: 0.8131 - val_loss: 1.9283 - val_categorical_accuracy: 0.6065\n",
      "Epoch 381/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7623 - categorical_accuracy: 0.8217 - val_loss: 1.9806 - val_categorical_accuracy: 0.6164\n",
      "Epoch 382/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7702 - categorical_accuracy: 0.8313 - val_loss: 2.0252 - val_categorical_accuracy: 0.5816\n",
      "Epoch 383/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7776 - categorical_accuracy: 0.8243 - val_loss: 2.0081 - val_categorical_accuracy: 0.6115\n",
      "Epoch 384/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7656 - categorical_accuracy: 0.8217 - val_loss: 2.0119 - val_categorical_accuracy: 0.6052\n",
      "Epoch 385/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7287 - categorical_accuracy: 0.8441 - val_loss: 1.9682 - val_categorical_accuracy: 0.6090\n",
      "Epoch 386/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7687 - categorical_accuracy: 0.8227 - val_loss: 1.9127 - val_categorical_accuracy: 0.6227\n",
      "Epoch 387/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7713 - categorical_accuracy: 0.8254 - val_loss: 1.9567 - val_categorical_accuracy: 0.6090\n",
      "Epoch 388/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7470 - categorical_accuracy: 0.8441 - val_loss: 2.0037 - val_categorical_accuracy: 0.5990\n",
      "Epoch 389/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7419 - categorical_accuracy: 0.8462 - val_loss: 2.0013 - val_categorical_accuracy: 0.6115\n",
      "Epoch 390/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7252 - categorical_accuracy: 0.8340 - val_loss: 2.1351 - val_categorical_accuracy: 0.6227\n",
      "Epoch 391/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7249 - categorical_accuracy: 0.8302 - val_loss: 2.2369 - val_categorical_accuracy: 0.5940\n",
      "Epoch 392/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7808 - categorical_accuracy: 0.8308 - val_loss: 2.0639 - val_categorical_accuracy: 0.6115\n",
      "Epoch 393/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6991 - categorical_accuracy: 0.8425 - val_loss: 1.9203 - val_categorical_accuracy: 0.6115\n",
      "Epoch 394/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6876 - categorical_accuracy: 0.8521 - val_loss: 2.0119 - val_categorical_accuracy: 0.6152\n",
      "Epoch 395/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7402 - categorical_accuracy: 0.8361 - val_loss: 1.9782 - val_categorical_accuracy: 0.6239\n",
      "Epoch 396/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7253 - categorical_accuracy: 0.8366 - val_loss: 1.9797 - val_categorical_accuracy: 0.6152\n",
      "Epoch 397/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7242 - categorical_accuracy: 0.8393 - val_loss: 2.0341 - val_categorical_accuracy: 0.5978\n",
      "Epoch 398/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7360 - categorical_accuracy: 0.8356 - val_loss: 1.9097 - val_categorical_accuracy: 0.6189\n",
      "Epoch 399/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7383 - categorical_accuracy: 0.8254 - val_loss: 1.9844 - val_categorical_accuracy: 0.6027\n",
      "Epoch 400/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7260 - categorical_accuracy: 0.8404 - val_loss: 1.9505 - val_categorical_accuracy: 0.6127\n",
      "Epoch 401/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7656 - categorical_accuracy: 0.8281 - val_loss: 1.8254 - val_categorical_accuracy: 0.6326\n",
      "Epoch 402/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7387 - categorical_accuracy: 0.8425 - val_loss: 1.8499 - val_categorical_accuracy: 0.6276\n",
      "Epoch 403/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7520 - categorical_accuracy: 0.8377 - val_loss: 1.9071 - val_categorical_accuracy: 0.6115\n",
      "Epoch 404/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6954 - categorical_accuracy: 0.8521 - val_loss: 1.9987 - val_categorical_accuracy: 0.6065\n",
      "Epoch 405/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6853 - categorical_accuracy: 0.8345 - val_loss: 1.9158 - val_categorical_accuracy: 0.6227\n",
      "Epoch 406/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7258 - categorical_accuracy: 0.8441 - val_loss: 2.0642 - val_categorical_accuracy: 0.5803\n",
      "Epoch 407/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7026 - categorical_accuracy: 0.8430 - val_loss: 1.9277 - val_categorical_accuracy: 0.6189\n",
      "Epoch 408/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6845 - categorical_accuracy: 0.8382 - val_loss: 1.9851 - val_categorical_accuracy: 0.6189\n",
      "Epoch 409/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7124 - categorical_accuracy: 0.8516 - val_loss: 2.0640 - val_categorical_accuracy: 0.5903\n",
      "Epoch 410/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7477 - categorical_accuracy: 0.8345 - val_loss: 2.0078 - val_categorical_accuracy: 0.5928\n",
      "Epoch 411/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6956 - categorical_accuracy: 0.8382 - val_loss: 2.1675 - val_categorical_accuracy: 0.5778\n",
      "Epoch 412/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7350 - categorical_accuracy: 0.8404 - val_loss: 2.1551 - val_categorical_accuracy: 0.5803\n",
      "Epoch 413/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7306 - categorical_accuracy: 0.8334 - val_loss: 2.0685 - val_categorical_accuracy: 0.6040\n",
      "Epoch 414/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7054 - categorical_accuracy: 0.8324 - val_loss: 2.0987 - val_categorical_accuracy: 0.6002\n",
      "Epoch 415/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6993 - categorical_accuracy: 0.8254 - val_loss: 1.8412 - val_categorical_accuracy: 0.6239\n",
      "Epoch 416/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6825 - categorical_accuracy: 0.8462 - val_loss: 1.8593 - val_categorical_accuracy: 0.6115\n",
      "Epoch 417/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7068 - categorical_accuracy: 0.8372 - val_loss: 2.0133 - val_categorical_accuracy: 0.5965\n",
      "Epoch 418/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.7176 - categorical_accuracy: 0.8425 - val_loss: 2.1266 - val_categorical_accuracy: 0.5928\n",
      "Epoch 419/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7402 - categorical_accuracy: 0.8313 - val_loss: 2.0048 - val_categorical_accuracy: 0.6127\n",
      "Epoch 420/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7084 - categorical_accuracy: 0.8340 - val_loss: 2.0383 - val_categorical_accuracy: 0.6202\n",
      "Epoch 421/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7422 - categorical_accuracy: 0.8340 - val_loss: 2.0699 - val_categorical_accuracy: 0.5915\n",
      "Epoch 422/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7376 - categorical_accuracy: 0.8286 - val_loss: 2.0213 - val_categorical_accuracy: 0.6065\n",
      "Epoch 423/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7308 - categorical_accuracy: 0.8382 - val_loss: 1.9590 - val_categorical_accuracy: 0.5965\n",
      "Epoch 424/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6990 - categorical_accuracy: 0.8505 - val_loss: 2.0030 - val_categorical_accuracy: 0.5915\n",
      "Epoch 425/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7354 - categorical_accuracy: 0.8254 - val_loss: 2.0908 - val_categorical_accuracy: 0.5940\n",
      "Epoch 426/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6916 - categorical_accuracy: 0.8489 - val_loss: 2.0240 - val_categorical_accuracy: 0.5928\n",
      "Epoch 427/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6623 - categorical_accuracy: 0.8505 - val_loss: 1.9996 - val_categorical_accuracy: 0.6139\n",
      "Epoch 428/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6751 - categorical_accuracy: 0.8494 - val_loss: 2.0562 - val_categorical_accuracy: 0.5978\n",
      "Epoch 429/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7043 - categorical_accuracy: 0.8425 - val_loss: 2.1335 - val_categorical_accuracy: 0.6002\n",
      "Epoch 430/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6842 - categorical_accuracy: 0.8484 - val_loss: 2.0494 - val_categorical_accuracy: 0.6065\n",
      "Epoch 431/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7061 - categorical_accuracy: 0.8345 - val_loss: 2.0259 - val_categorical_accuracy: 0.6239\n",
      "Epoch 432/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7478 - categorical_accuracy: 0.8297 - val_loss: 2.1304 - val_categorical_accuracy: 0.5990\n",
      "Epoch 433/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7125 - categorical_accuracy: 0.8414 - val_loss: 2.0234 - val_categorical_accuracy: 0.5928\n",
      "Epoch 434/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6784 - categorical_accuracy: 0.8462 - val_loss: 2.0310 - val_categorical_accuracy: 0.5953\n",
      "Epoch 435/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7285 - categorical_accuracy: 0.8404 - val_loss: 2.0914 - val_categorical_accuracy: 0.5915\n",
      "Epoch 436/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6990 - categorical_accuracy: 0.8500 - val_loss: 2.1606 - val_categorical_accuracy: 0.6115\n",
      "Epoch 437/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6852 - categorical_accuracy: 0.8489 - val_loss: 2.0254 - val_categorical_accuracy: 0.5940\n",
      "Epoch 438/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6388 - categorical_accuracy: 0.8681 - val_loss: 1.9429 - val_categorical_accuracy: 0.6065\n",
      "Epoch 439/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6875 - categorical_accuracy: 0.8489 - val_loss: 2.1243 - val_categorical_accuracy: 0.5890\n",
      "Epoch 440/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7666 - categorical_accuracy: 0.8446 - val_loss: 2.0274 - val_categorical_accuracy: 0.6027\n",
      "Epoch 441/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6683 - categorical_accuracy: 0.8617 - val_loss: 1.9652 - val_categorical_accuracy: 0.6115\n",
      "Epoch 442/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7548 - categorical_accuracy: 0.8372 - val_loss: 1.9697 - val_categorical_accuracy: 0.6027\n",
      "Epoch 443/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6739 - categorical_accuracy: 0.8420 - val_loss: 1.9838 - val_categorical_accuracy: 0.6002\n",
      "Epoch 444/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6627 - categorical_accuracy: 0.8558 - val_loss: 2.2034 - val_categorical_accuracy: 0.5915\n",
      "Epoch 445/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7122 - categorical_accuracy: 0.8350 - val_loss: 2.1113 - val_categorical_accuracy: 0.6052\n",
      "Epoch 446/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7239 - categorical_accuracy: 0.8356 - val_loss: 2.1618 - val_categorical_accuracy: 0.5978\n",
      "Epoch 447/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6618 - categorical_accuracy: 0.8633 - val_loss: 2.1454 - val_categorical_accuracy: 0.6214\n",
      "Epoch 448/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6460 - categorical_accuracy: 0.8585 - val_loss: 2.2298 - val_categorical_accuracy: 0.5778\n",
      "Epoch 449/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6684 - categorical_accuracy: 0.8676 - val_loss: 2.0961 - val_categorical_accuracy: 0.6115\n",
      "Epoch 450/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6544 - categorical_accuracy: 0.8500 - val_loss: 2.0549 - val_categorical_accuracy: 0.6252\n",
      "Epoch 451/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7250 - categorical_accuracy: 0.8420 - val_loss: 2.0734 - val_categorical_accuracy: 0.5928\n",
      "Epoch 452/5000\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.6444 - categorical_accuracy: 0.8708 - val_loss: 2.0950 - val_categorical_accuracy: 0.5928\n",
      "Epoch 453/5000\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.6561 - categorical_accuracy: 0.8564 - val_loss: 2.1956 - val_categorical_accuracy: 0.5853\n",
      "Epoch 454/5000\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.6924 - categorical_accuracy: 0.8484 - val_loss: 1.9810 - val_categorical_accuracy: 0.6152\n",
      "Epoch 455/5000\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 1.4842 - categorical_accuracy: 0.8553 - val_loss: 2.0558 - val_categorical_accuracy: 0.6040\n",
      "Epoch 456/5000\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.9060 - categorical_accuracy: 0.7971 - val_loss: 2.2799 - val_categorical_accuracy: 0.5342\n",
      "Epoch 457/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.0993 - categorical_accuracy: 0.7363 - val_loss: 2.3163 - val_categorical_accuracy: 0.5168\n",
      "Epoch 458/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.0939 - categorical_accuracy: 0.7395 - val_loss: 2.2294 - val_categorical_accuracy: 0.5342\n",
      "Epoch 459/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.0800 - categorical_accuracy: 0.7443 - val_loss: 2.1505 - val_categorical_accuracy: 0.5579\n",
      "Epoch 460/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.0518 - categorical_accuracy: 0.7597 - val_loss: 2.2848 - val_categorical_accuracy: 0.5442\n",
      "Epoch 461/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.2208 - categorical_accuracy: 0.7085 - val_loss: 2.1781 - val_categorical_accuracy: 0.5330\n",
      "Epoch 462/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.2318 - categorical_accuracy: 0.6946 - val_loss: 2.1128 - val_categorical_accuracy: 0.5504\n",
      "Epoch 463/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.2194 - categorical_accuracy: 0.6951 - val_loss: 1.9602 - val_categorical_accuracy: 0.5629\n",
      "Epoch 464/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.2731 - categorical_accuracy: 0.7154 - val_loss: 2.2671 - val_categorical_accuracy: 0.5106\n",
      "Epoch 465/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 29ms/step - loss: 1.4990 - categorical_accuracy: 0.6369 - val_loss: 2.1277 - val_categorical_accuracy: 0.5467\n",
      "Epoch 466/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.3938 - categorical_accuracy: 0.6514 - val_loss: 1.9833 - val_categorical_accuracy: 0.5579\n",
      "Epoch 467/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.3970 - categorical_accuracy: 0.6594 - val_loss: 1.9575 - val_categorical_accuracy: 0.5567\n",
      "Epoch 468/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.3950 - categorical_accuracy: 0.6679 - val_loss: 1.9613 - val_categorical_accuracy: 0.5554\n",
      "Epoch 469/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.3942 - categorical_accuracy: 0.6684 - val_loss: 1.8228 - val_categorical_accuracy: 0.5890\n",
      "Epoch 470/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.3293 - categorical_accuracy: 0.6765 - val_loss: 1.7895 - val_categorical_accuracy: 0.5853\n",
      "Epoch 471/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.2986 - categorical_accuracy: 0.6957 - val_loss: 1.8702 - val_categorical_accuracy: 0.5741\n",
      "Epoch 472/5000\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 1.5041 - categorical_accuracy: 0.6877 - val_loss: 1.8769 - val_categorical_accuracy: 0.5816\n",
      "Epoch 473/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.2993 - categorical_accuracy: 0.6807 - val_loss: 2.0289 - val_categorical_accuracy: 0.5367\n",
      "Epoch 474/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.4323 - categorical_accuracy: 0.6604 - val_loss: 2.0018 - val_categorical_accuracy: 0.5467\n",
      "Epoch 475/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.3523 - categorical_accuracy: 0.6871 - val_loss: 1.8544 - val_categorical_accuracy: 0.5928\n",
      "Epoch 476/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.4539 - categorical_accuracy: 0.6503 - val_loss: 1.8709 - val_categorical_accuracy: 0.5940\n",
      "Epoch 477/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.3325 - categorical_accuracy: 0.6877 - val_loss: 1.9002 - val_categorical_accuracy: 0.5542\n",
      "Epoch 478/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.2552 - categorical_accuracy: 0.7074 - val_loss: 1.8834 - val_categorical_accuracy: 0.5716\n",
      "Epoch 479/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.2606 - categorical_accuracy: 0.7138 - val_loss: 1.9545 - val_categorical_accuracy: 0.5604\n",
      "Epoch 480/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.2408 - categorical_accuracy: 0.6973 - val_loss: 1.7975 - val_categorical_accuracy: 0.5866\n",
      "Epoch 481/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.2273 - categorical_accuracy: 0.7176 - val_loss: 1.8371 - val_categorical_accuracy: 0.5778\n",
      "Epoch 482/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.1345 - categorical_accuracy: 0.7368 - val_loss: 1.8234 - val_categorical_accuracy: 0.5928\n",
      "Epoch 483/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.1097 - categorical_accuracy: 0.7357 - val_loss: 1.8889 - val_categorical_accuracy: 0.5853\n",
      "Epoch 484/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.1092 - categorical_accuracy: 0.7475 - val_loss: 1.8850 - val_categorical_accuracy: 0.6015\n",
      "Epoch 485/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.1084 - categorical_accuracy: 0.7416 - val_loss: 1.8514 - val_categorical_accuracy: 0.6015\n",
      "Epoch 486/5000\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 1.0616 - categorical_accuracy: 0.7592 - val_loss: 1.8138 - val_categorical_accuracy: 0.6102\n",
      "Epoch 487/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.0568 - categorical_accuracy: 0.7544 - val_loss: 1.8551 - val_categorical_accuracy: 0.6077\n",
      "Epoch 488/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.9844 - categorical_accuracy: 0.7800 - val_loss: 1.8944 - val_categorical_accuracy: 0.6002\n",
      "Epoch 489/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.0134 - categorical_accuracy: 0.7683 - val_loss: 2.0230 - val_categorical_accuracy: 0.6177\n",
      "Epoch 490/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.0188 - categorical_accuracy: 0.7678 - val_loss: 1.9734 - val_categorical_accuracy: 0.5940\n",
      "Epoch 491/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.9712 - categorical_accuracy: 0.7822 - val_loss: 1.9113 - val_categorical_accuracy: 0.6214\n",
      "Epoch 492/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.1418 - categorical_accuracy: 0.7656 - val_loss: 2.3085 - val_categorical_accuracy: 0.5492\n",
      "Epoch 493/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.3114 - categorical_accuracy: 0.6989 - val_loss: 2.2238 - val_categorical_accuracy: 0.5592\n",
      "Epoch 494/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.2705 - categorical_accuracy: 0.7101 - val_loss: 2.0937 - val_categorical_accuracy: 0.5629\n",
      "Epoch 495/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.1995 - categorical_accuracy: 0.7298 - val_loss: 1.9186 - val_categorical_accuracy: 0.5878\n",
      "Epoch 496/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.1756 - categorical_accuracy: 0.7176 - val_loss: 1.8810 - val_categorical_accuracy: 0.5791\n",
      "Epoch 497/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.1789 - categorical_accuracy: 0.7341 - val_loss: 1.8622 - val_categorical_accuracy: 0.6189\n",
      "Epoch 498/5000\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 1.1671 - categorical_accuracy: 0.7277 - val_loss: 1.7341 - val_categorical_accuracy: 0.6413\n",
      "Epoch 499/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.0852 - categorical_accuracy: 0.7555 - val_loss: 1.8374 - val_categorical_accuracy: 0.6077\n",
      "Epoch 500/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.1902 - categorical_accuracy: 0.7427 - val_loss: 1.8171 - val_categorical_accuracy: 0.6077\n",
      "Epoch 501/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0846 - categorical_accuracy: 0.7411 - val_loss: 1.8529 - val_categorical_accuracy: 0.5778\n",
      "Epoch 502/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.0478 - categorical_accuracy: 0.7608 - val_loss: 1.8513 - val_categorical_accuracy: 0.5853\n",
      "Epoch 503/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.0464 - categorical_accuracy: 0.7613 - val_loss: 1.9573 - val_categorical_accuracy: 0.5953\n",
      "Epoch 504/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.0515 - categorical_accuracy: 0.7576 - val_loss: 1.9585 - val_categorical_accuracy: 0.6077\n",
      "Epoch 505/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.0236 - categorical_accuracy: 0.7629 - val_loss: 1.8610 - val_categorical_accuracy: 0.6177\n",
      "Epoch 506/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9965 - categorical_accuracy: 0.7699 - val_loss: 1.9032 - val_categorical_accuracy: 0.5766\n",
      "Epoch 507/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.9709 - categorical_accuracy: 0.7752 - val_loss: 1.8234 - val_categorical_accuracy: 0.6364\n",
      "Epoch 508/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0112 - categorical_accuracy: 0.7662 - val_loss: 1.8742 - val_categorical_accuracy: 0.6015\n",
      "Epoch 509/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.9376 - categorical_accuracy: 0.7854 - val_loss: 1.7785 - val_categorical_accuracy: 0.6252\n",
      "Epoch 510/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.8954 - categorical_accuracy: 0.7966 - val_loss: 1.8233 - val_categorical_accuracy: 0.6115\n",
      "Epoch 511/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.9042 - categorical_accuracy: 0.7795 - val_loss: 1.9344 - val_categorical_accuracy: 0.6090\n",
      "Epoch 512/5000\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.8647 - categorical_accuracy: 0.8083 - val_loss: 2.0110 - val_categorical_accuracy: 0.5990\n",
      "Epoch 513/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.8430 - categorical_accuracy: 0.8105 - val_loss: 1.9976 - val_categorical_accuracy: 0.5978\n",
      "Epoch 514/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.8903 - categorical_accuracy: 0.7971 - val_loss: 2.0068 - val_categorical_accuracy: 0.6077\n",
      "Epoch 515/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.8744 - categorical_accuracy: 0.8003 - val_loss: 1.9050 - val_categorical_accuracy: 0.5990\n",
      "Epoch 516/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.8878 - categorical_accuracy: 0.7960 - val_loss: 1.8941 - val_categorical_accuracy: 0.6127\n",
      "Epoch 517/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.8489 - categorical_accuracy: 0.8121 - val_loss: 1.9769 - val_categorical_accuracy: 0.6127\n",
      "Epoch 518/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.8508 - categorical_accuracy: 0.8046 - val_loss: 1.9790 - val_categorical_accuracy: 0.6052\n",
      "Epoch 519/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7959 - categorical_accuracy: 0.8227 - val_loss: 1.9639 - val_categorical_accuracy: 0.6090\n",
      "Epoch 520/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.8047 - categorical_accuracy: 0.8270 - val_loss: 1.9543 - val_categorical_accuracy: 0.6077\n",
      "Epoch 521/5000\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.8269 - categorical_accuracy: 0.8115 - val_loss: 1.9923 - val_categorical_accuracy: 0.6077\n",
      "Epoch 522/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.8237 - categorical_accuracy: 0.8115 - val_loss: 1.9992 - val_categorical_accuracy: 0.6102\n",
      "Epoch 523/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.8006 - categorical_accuracy: 0.8238 - val_loss: 1.9897 - val_categorical_accuracy: 0.6027\n",
      "Epoch 524/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.8202 - categorical_accuracy: 0.8126 - val_loss: 2.0273 - val_categorical_accuracy: 0.6164\n",
      "Epoch 525/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7730 - categorical_accuracy: 0.8340 - val_loss: 2.0852 - val_categorical_accuracy: 0.5853\n",
      "Epoch 526/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7933 - categorical_accuracy: 0.8222 - val_loss: 2.1125 - val_categorical_accuracy: 0.5990\n",
      "Epoch 527/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7908 - categorical_accuracy: 0.8275 - val_loss: 2.0977 - val_categorical_accuracy: 0.6065\n",
      "Epoch 528/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.8096 - categorical_accuracy: 0.8046 - val_loss: 1.9759 - val_categorical_accuracy: 0.6090\n",
      "Epoch 529/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.8537 - categorical_accuracy: 0.8121 - val_loss: 2.0580 - val_categorical_accuracy: 0.6002\n",
      "Epoch 530/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.8084 - categorical_accuracy: 0.8211 - val_loss: 2.1380 - val_categorical_accuracy: 0.5816\n",
      "Epoch 531/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.8061 - categorical_accuracy: 0.8121 - val_loss: 2.0232 - val_categorical_accuracy: 0.5890\n",
      "Epoch 532/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7331 - categorical_accuracy: 0.8382 - val_loss: 2.0457 - val_categorical_accuracy: 0.5791\n",
      "Epoch 533/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7575 - categorical_accuracy: 0.8233 - val_loss: 2.2323 - val_categorical_accuracy: 0.5517\n",
      "Epoch 534/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7412 - categorical_accuracy: 0.8345 - val_loss: 2.2594 - val_categorical_accuracy: 0.5803\n",
      "Epoch 535/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7502 - categorical_accuracy: 0.8372 - val_loss: 2.0148 - val_categorical_accuracy: 0.6289\n",
      "Epoch 536/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7653 - categorical_accuracy: 0.8350 - val_loss: 2.2127 - val_categorical_accuracy: 0.5915\n",
      "Epoch 537/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7302 - categorical_accuracy: 0.8366 - val_loss: 2.1948 - val_categorical_accuracy: 0.6002\n",
      "Epoch 538/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7239 - categorical_accuracy: 0.8398 - val_loss: 2.3249 - val_categorical_accuracy: 0.5853\n",
      "Epoch 539/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7344 - categorical_accuracy: 0.8313 - val_loss: 2.2807 - val_categorical_accuracy: 0.5878\n",
      "Epoch 540/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7363 - categorical_accuracy: 0.8318 - val_loss: 2.2360 - val_categorical_accuracy: 0.6052\n",
      "Epoch 541/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7635 - categorical_accuracy: 0.8265 - val_loss: 2.0770 - val_categorical_accuracy: 0.6189\n",
      "Epoch 542/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7746 - categorical_accuracy: 0.8292 - val_loss: 2.0715 - val_categorical_accuracy: 0.6289\n",
      "Epoch 543/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7583 - categorical_accuracy: 0.8366 - val_loss: 2.1615 - val_categorical_accuracy: 0.6015\n",
      "Epoch 544/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7460 - categorical_accuracy: 0.8350 - val_loss: 2.1897 - val_categorical_accuracy: 0.6202\n",
      "Epoch 545/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7278 - categorical_accuracy: 0.8409 - val_loss: 2.2460 - val_categorical_accuracy: 0.6040\n",
      "Epoch 546/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7182 - categorical_accuracy: 0.8489 - val_loss: 2.1613 - val_categorical_accuracy: 0.6027\n",
      "Epoch 547/5000\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.7324 - categorical_accuracy: 0.8265 - val_loss: 2.2690 - val_categorical_accuracy: 0.6077\n",
      "Epoch 548/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7371 - categorical_accuracy: 0.8350 - val_loss: 2.2090 - val_categorical_accuracy: 0.6015\n",
      "Epoch 549/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7485 - categorical_accuracy: 0.8430 - val_loss: 2.1791 - val_categorical_accuracy: 0.6214\n",
      "Epoch 550/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6932 - categorical_accuracy: 0.8468 - val_loss: 2.1726 - val_categorical_accuracy: 0.6152\n",
      "Epoch 551/5000\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.7634 - categorical_accuracy: 0.8393 - val_loss: 2.1221 - val_categorical_accuracy: 0.5915\n",
      "Epoch 552/5000\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.7010 - categorical_accuracy: 0.8468 - val_loss: 2.3209 - val_categorical_accuracy: 0.5629\n",
      "Epoch 553/5000\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.7021 - categorical_accuracy: 0.8398 - val_loss: 2.1701 - val_categorical_accuracy: 0.5853\n",
      "Epoch 554/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7417 - categorical_accuracy: 0.8393 - val_loss: 2.2734 - val_categorical_accuracy: 0.5729\n",
      "Epoch 555/5000\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.7152 - categorical_accuracy: 0.8388 - val_loss: 2.4642 - val_categorical_accuracy: 0.5940\n",
      "Epoch 556/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7538 - categorical_accuracy: 0.8372 - val_loss: 2.3626 - val_categorical_accuracy: 0.5940\n",
      "Epoch 557/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7371 - categorical_accuracy: 0.8388 - val_loss: 2.2347 - val_categorical_accuracy: 0.6002\n",
      "Epoch 558/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6988 - categorical_accuracy: 0.8473 - val_loss: 2.3380 - val_categorical_accuracy: 0.5778\n",
      "Epoch 559/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6871 - categorical_accuracy: 0.8548 - val_loss: 2.1806 - val_categorical_accuracy: 0.6065\n",
      "Epoch 560/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7028 - categorical_accuracy: 0.8505 - val_loss: 2.1304 - val_categorical_accuracy: 0.5853\n",
      "Epoch 561/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7355 - categorical_accuracy: 0.8430 - val_loss: 2.3359 - val_categorical_accuracy: 0.5716\n",
      "Epoch 562/5000\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.6797 - categorical_accuracy: 0.8468 - val_loss: 2.0596 - val_categorical_accuracy: 0.5965\n",
      "Epoch 563/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7212 - categorical_accuracy: 0.8377 - val_loss: 2.2593 - val_categorical_accuracy: 0.5753\n",
      "Epoch 564/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6749 - categorical_accuracy: 0.8532 - val_loss: 2.2616 - val_categorical_accuracy: 0.5853\n",
      "Epoch 565/5000\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.7387 - categorical_accuracy: 0.8361 - val_loss: 2.1449 - val_categorical_accuracy: 0.6040\n",
      "Epoch 566/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6872 - categorical_accuracy: 0.8521 - val_loss: 2.1336 - val_categorical_accuracy: 0.5990\n",
      "Epoch 567/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.7145 - categorical_accuracy: 0.8580 - val_loss: 2.1760 - val_categorical_accuracy: 0.5828\n",
      "Epoch 568/5000\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.6856 - categorical_accuracy: 0.8500 - val_loss: 2.3520 - val_categorical_accuracy: 0.5442\n",
      "Epoch 569/5000\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.7075 - categorical_accuracy: 0.8489 - val_loss: 2.0747 - val_categorical_accuracy: 0.6214\n",
      "Epoch 570/5000\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.7141 - categorical_accuracy: 0.8532 - val_loss: 2.1107 - val_categorical_accuracy: 0.6276\n",
      "Epoch 571/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6930 - categorical_accuracy: 0.8532 - val_loss: 2.2078 - val_categorical_accuracy: 0.5878\n",
      "Epoch 572/5000\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.7014 - categorical_accuracy: 0.8462 - val_loss: 2.0369 - val_categorical_accuracy: 0.6102\n",
      "Epoch 573/5000\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.6477 - categorical_accuracy: 0.8623 - val_loss: 2.1847 - val_categorical_accuracy: 0.6289\n",
      "Epoch 574/5000\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.7270 - categorical_accuracy: 0.8457 - val_loss: 2.1759 - val_categorical_accuracy: 0.6127\n",
      "Epoch 575/5000\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.7065 - categorical_accuracy: 0.8462 - val_loss: 2.2577 - val_categorical_accuracy: 0.6227\n",
      "Epoch 576/5000\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.6767 - categorical_accuracy: 0.8564 - val_loss: 2.3248 - val_categorical_accuracy: 0.5928\n",
      "Epoch 577/5000\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.7141 - categorical_accuracy: 0.8462 - val_loss: 2.3375 - val_categorical_accuracy: 0.5616\n",
      "Epoch 578/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6643 - categorical_accuracy: 0.8526 - val_loss: 2.5032 - val_categorical_accuracy: 0.5828\n",
      "Epoch 579/5000\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.6945 - categorical_accuracy: 0.8574 - val_loss: 2.4689 - val_categorical_accuracy: 0.5940\n",
      "Epoch 580/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6663 - categorical_accuracy: 0.8564 - val_loss: 2.4898 - val_categorical_accuracy: 0.5579\n",
      "Epoch 581/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6972 - categorical_accuracy: 0.8537 - val_loss: 2.4308 - val_categorical_accuracy: 0.5878\n",
      "Epoch 582/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7146 - categorical_accuracy: 0.8425 - val_loss: 2.3314 - val_categorical_accuracy: 0.5803\n",
      "Epoch 583/5000\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.6810 - categorical_accuracy: 0.8558 - val_loss: 2.2948 - val_categorical_accuracy: 0.6052\n",
      "Epoch 584/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6864 - categorical_accuracy: 0.8548 - val_loss: 2.2850 - val_categorical_accuracy: 0.6252\n",
      "Epoch 585/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6782 - categorical_accuracy: 0.8671 - val_loss: 2.2794 - val_categorical_accuracy: 0.6077\n",
      "Epoch 586/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6385 - categorical_accuracy: 0.8671 - val_loss: 2.2775 - val_categorical_accuracy: 0.6027\n",
      "Epoch 587/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.7283 - categorical_accuracy: 0.8452 - val_loss: 2.3773 - val_categorical_accuracy: 0.5853\n",
      "Epoch 588/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6868 - categorical_accuracy: 0.8537 - val_loss: 2.5576 - val_categorical_accuracy: 0.5866\n",
      "Epoch 589/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6645 - categorical_accuracy: 0.8532 - val_loss: 2.3314 - val_categorical_accuracy: 0.6214\n",
      "Epoch 590/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.7090 - categorical_accuracy: 0.8612 - val_loss: 2.2068 - val_categorical_accuracy: 0.6189\n",
      "Epoch 591/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6737 - categorical_accuracy: 0.8484 - val_loss: 2.3754 - val_categorical_accuracy: 0.5915\n",
      "Epoch 592/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6926 - categorical_accuracy: 0.8510 - val_loss: 2.4582 - val_categorical_accuracy: 0.5890\n",
      "Epoch 593/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6727 - categorical_accuracy: 0.8601 - val_loss: 2.3957 - val_categorical_accuracy: 0.5990\n",
      "Epoch 594/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6959 - categorical_accuracy: 0.8500 - val_loss: 2.3975 - val_categorical_accuracy: 0.6065\n",
      "Epoch 595/5000\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.6817 - categorical_accuracy: 0.8564 - val_loss: 2.4478 - val_categorical_accuracy: 0.5803\n",
      "Epoch 596/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6224 - categorical_accuracy: 0.8735 - val_loss: 2.4021 - val_categorical_accuracy: 0.6189\n",
      "Epoch 597/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6682 - categorical_accuracy: 0.8542 - val_loss: 2.3142 - val_categorical_accuracy: 0.5753\n",
      "Epoch 598/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6551 - categorical_accuracy: 0.8639 - val_loss: 2.4567 - val_categorical_accuracy: 0.5841\n",
      "Epoch 599/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.6788 - categorical_accuracy: 0.8580 - val_loss: 2.2515 - val_categorical_accuracy: 0.5953\n",
      "Epoch 600/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.6366 - categorical_accuracy: 0.8724 - val_loss: 2.4924 - val_categorical_accuracy: 0.5778\n",
      "Epoch 601/5000\n",
      " 7/15 [=============>................] - ETA: 0s - loss: 0.6493 - categorical_accuracy: 0.8661"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SpatialDropout1D\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential(name='Sequential')\n",
    "act_function = 'selu'\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv1D(filters=50, kernel_size=2, activation=act_function, input_shape=(130, 126)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=100, kernel_size=2, activation=act_function))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=50, kernel_size=2, activation=act_function))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(SpatialDropout1D(0.5))\n",
    "model.add(Conv1D(filters=100, kernel_size=2, activation=act_function))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(SpatialDropout1D(0.5))\n",
    "\n",
    "#model.add(Conv1D(filters=50, kernel_size=2, activation=act_function))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='selu', kernel_regularizer=regularizers.l2(l=0.001)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# droput layer, remove if no work\n",
    "model.add(SpatialDropout1D(0.5))\n",
    "\n",
    "# Flatten the output for the fully connected layers\n",
    "model.add(Flatten())\n",
    "# Add fully connected layers\n",
    "model.add(Dense(40, activation=act_function))\n",
    "model.add(Dense(16, activation=act_function))\n",
    "#model.add(Dense(40, activation=act_function))\n",
    "#model.add(Dense(16, activation=act_function))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='softmax'))  # Output layer\n",
    "optimizer = Lion(learning_rate=.00075)\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(Xtrain, Ytrain, epochs=5000, validation_split=.3, batch_size = 128, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5f15d4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:12:58.507672Z",
     "start_time": "2023-08-11T08:12:19.183612Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_24 (Conv1D)          (None, 129, 50)           12650     \n",
      "                                                                 \n",
      " max_pooling1d_24 (MaxPooli  (None, 64, 50)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_25 (Conv1D)          (None, 62, 64)            9664      \n",
      "                                                                 \n",
      " max_pooling1d_25 (MaxPooli  (None, 31, 64)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " spatial_dropout1d_7 (Spati  (None, 31, 64)            0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1984)              0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 40)                79400     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 50)                2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103764 (405.33 KB)\n",
      "Trainable params: 103764 (405.33 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5000\n",
      "15/15 [==============================] - 3s 113ms/step - loss: 4.1772 - categorical_accuracy: 0.0235 - val_loss: 4.0013 - val_categorical_accuracy: 0.0299\n",
      "Epoch 2/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 3.8523 - categorical_accuracy: 0.0459 - val_loss: 3.8341 - val_categorical_accuracy: 0.0523\n",
      "Epoch 3/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 3.6272 - categorical_accuracy: 0.0796 - val_loss: 3.7826 - val_categorical_accuracy: 0.0610\n",
      "Epoch 4/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 3.4182 - categorical_accuracy: 0.1329 - val_loss: 3.8423 - val_categorical_accuracy: 0.0859\n",
      "Epoch 5/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 3.2161 - categorical_accuracy: 0.1746 - val_loss: 3.6500 - val_categorical_accuracy: 0.1046\n",
      "Epoch 6/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 3.0259 - categorical_accuracy: 0.2162 - val_loss: 3.5139 - val_categorical_accuracy: 0.1407\n",
      "Epoch 7/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 2.8855 - categorical_accuracy: 0.2483 - val_loss: 3.4477 - val_categorical_accuracy: 0.1395\n",
      "Epoch 8/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 2.7008 - categorical_accuracy: 0.2862 - val_loss: 3.3289 - val_categorical_accuracy: 0.1831\n",
      "Epoch 9/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 2.5910 - categorical_accuracy: 0.3043 - val_loss: 3.4034 - val_categorical_accuracy: 0.1756\n",
      "Epoch 10/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 2.3913 - categorical_accuracy: 0.3615 - val_loss: 3.3094 - val_categorical_accuracy: 0.1980\n",
      "Epoch 11/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 2.2151 - categorical_accuracy: 0.3999 - val_loss: 3.0350 - val_categorical_accuracy: 0.2416\n",
      "Epoch 12/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 2.0391 - categorical_accuracy: 0.4549 - val_loss: 2.9838 - val_categorical_accuracy: 0.2640\n",
      "Epoch 13/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.8619 - categorical_accuracy: 0.4949 - val_loss: 3.0342 - val_categorical_accuracy: 0.2528\n",
      "Epoch 14/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.7920 - categorical_accuracy: 0.5190 - val_loss: 2.9157 - val_categorical_accuracy: 0.2690\n",
      "Epoch 15/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.7083 - categorical_accuracy: 0.5216 - val_loss: 2.7542 - val_categorical_accuracy: 0.3225\n",
      "Epoch 16/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.5529 - categorical_accuracy: 0.5638 - val_loss: 2.6641 - val_categorical_accuracy: 0.3387\n",
      "Epoch 17/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.5315 - categorical_accuracy: 0.5659 - val_loss: 2.8326 - val_categorical_accuracy: 0.3064\n",
      "Epoch 18/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.3618 - categorical_accuracy: 0.6103 - val_loss: 2.6436 - val_categorical_accuracy: 0.3362\n",
      "Epoch 19/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.3463 - categorical_accuracy: 0.6140 - val_loss: 2.6974 - val_categorical_accuracy: 0.3549\n",
      "Epoch 20/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2225 - categorical_accuracy: 0.6450 - val_loss: 2.7147 - val_categorical_accuracy: 0.3736\n",
      "Epoch 21/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1270 - categorical_accuracy: 0.6882 - val_loss: 2.9643 - val_categorical_accuracy: 0.3263\n",
      "Epoch 22/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0694 - categorical_accuracy: 0.6903 - val_loss: 2.8445 - val_categorical_accuracy: 0.3437\n",
      "Epoch 23/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0462 - categorical_accuracy: 0.6983 - val_loss: 2.6161 - val_categorical_accuracy: 0.4010\n",
      "Epoch 24/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.9722 - categorical_accuracy: 0.7282 - val_loss: 2.7100 - val_categorical_accuracy: 0.3624\n",
      "Epoch 25/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.8805 - categorical_accuracy: 0.7395 - val_loss: 2.5981 - val_categorical_accuracy: 0.3985\n",
      "Epoch 26/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.8658 - categorical_accuracy: 0.7496 - val_loss: 2.6838 - val_categorical_accuracy: 0.4159\n",
      "Epoch 27/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.8102 - categorical_accuracy: 0.7651 - val_loss: 2.6620 - val_categorical_accuracy: 0.3960\n",
      "Epoch 28/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.7356 - categorical_accuracy: 0.7838 - val_loss: 2.6499 - val_categorical_accuracy: 0.4110\n",
      "Epoch 29/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.7248 - categorical_accuracy: 0.7832 - val_loss: 2.9214 - val_categorical_accuracy: 0.4035\n",
      "Epoch 30/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.7126 - categorical_accuracy: 0.7912 - val_loss: 2.8260 - val_categorical_accuracy: 0.4035\n",
      "Epoch 31/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.6741 - categorical_accuracy: 0.8019 - val_loss: 2.6274 - val_categorical_accuracy: 0.4371\n",
      "Epoch 32/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5959 - categorical_accuracy: 0.8238 - val_loss: 2.6601 - val_categorical_accuracy: 0.4284\n",
      "Epoch 33/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.6275 - categorical_accuracy: 0.8308 - val_loss: 2.9716 - val_categorical_accuracy: 0.4296\n",
      "Epoch 34/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5733 - categorical_accuracy: 0.8259 - val_loss: 2.8937 - val_categorical_accuracy: 0.4458\n",
      "Epoch 35/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5485 - categorical_accuracy: 0.8420 - val_loss: 2.9367 - val_categorical_accuracy: 0.4334\n",
      "Epoch 36/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5533 - categorical_accuracy: 0.8441 - val_loss: 3.2717 - val_categorical_accuracy: 0.3948\n",
      "Epoch 37/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4953 - categorical_accuracy: 0.8553 - val_loss: 3.0682 - val_categorical_accuracy: 0.4234\n",
      "Epoch 38/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5817 - categorical_accuracy: 0.8457 - val_loss: 3.2429 - val_categorical_accuracy: 0.4247\n",
      "Epoch 39/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5283 - categorical_accuracy: 0.8500 - val_loss: 3.0252 - val_categorical_accuracy: 0.4545\n",
      "Epoch 40/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4895 - categorical_accuracy: 0.8751 - val_loss: 3.1316 - val_categorical_accuracy: 0.4483\n",
      "Epoch 41/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4893 - categorical_accuracy: 0.8585 - val_loss: 3.1520 - val_categorical_accuracy: 0.4346\n",
      "Epoch 42/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4993 - categorical_accuracy: 0.8633 - val_loss: 2.9540 - val_categorical_accuracy: 0.4882\n",
      "Epoch 43/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4976 - categorical_accuracy: 0.8569 - val_loss: 3.0553 - val_categorical_accuracy: 0.4745\n",
      "Epoch 44/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4879 - categorical_accuracy: 0.8644 - val_loss: 3.1656 - val_categorical_accuracy: 0.4832\n",
      "Epoch 45/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4413 - categorical_accuracy: 0.8761 - val_loss: 3.0585 - val_categorical_accuracy: 0.4869\n",
      "Epoch 46/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4589 - categorical_accuracy: 0.8735 - val_loss: 3.0901 - val_categorical_accuracy: 0.4819\n",
      "Epoch 47/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4924 - categorical_accuracy: 0.8639 - val_loss: 3.1876 - val_categorical_accuracy: 0.4695\n",
      "Epoch 48/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4579 - categorical_accuracy: 0.8740 - val_loss: 3.2811 - val_categorical_accuracy: 0.4583\n",
      "Epoch 49/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4727 - categorical_accuracy: 0.8767 - val_loss: 3.3767 - val_categorical_accuracy: 0.4595\n",
      "Epoch 50/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4646 - categorical_accuracy: 0.8777 - val_loss: 3.0511 - val_categorical_accuracy: 0.5143\n",
      "Epoch 51/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4224 - categorical_accuracy: 0.8825 - val_loss: 3.3569 - val_categorical_accuracy: 0.4807\n",
      "Epoch 52/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4372 - categorical_accuracy: 0.8825 - val_loss: 3.6110 - val_categorical_accuracy: 0.4433\n",
      "Epoch 53/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4700 - categorical_accuracy: 0.8697 - val_loss: 3.2835 - val_categorical_accuracy: 0.4608\n",
      "Epoch 54/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4081 - categorical_accuracy: 0.8943 - val_loss: 3.4959 - val_categorical_accuracy: 0.4807\n",
      "Epoch 55/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4404 - categorical_accuracy: 0.8857 - val_loss: 3.4979 - val_categorical_accuracy: 0.4695\n",
      "Epoch 56/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4351 - categorical_accuracy: 0.8868 - val_loss: 3.3620 - val_categorical_accuracy: 0.4919\n",
      "Epoch 57/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4317 - categorical_accuracy: 0.8804 - val_loss: 3.2082 - val_categorical_accuracy: 0.5006\n",
      "Epoch 58/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4189 - categorical_accuracy: 0.8943 - val_loss: 3.3537 - val_categorical_accuracy: 0.4844\n",
      "Epoch 59/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4169 - categorical_accuracy: 0.8868 - val_loss: 3.3498 - val_categorical_accuracy: 0.4919\n",
      "Epoch 60/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4608 - categorical_accuracy: 0.8857 - val_loss: 3.2669 - val_categorical_accuracy: 0.5081\n",
      "Epoch 61/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3899 - categorical_accuracy: 0.9071 - val_loss: 3.3708 - val_categorical_accuracy: 0.4882\n",
      "Epoch 62/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3838 - categorical_accuracy: 0.8991 - val_loss: 3.6609 - val_categorical_accuracy: 0.4807\n",
      "Epoch 63/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4174 - categorical_accuracy: 0.8991 - val_loss: 3.4984 - val_categorical_accuracy: 0.5131\n",
      "Epoch 64/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3967 - categorical_accuracy: 0.8996 - val_loss: 3.5126 - val_categorical_accuracy: 0.4956\n",
      "Epoch 65/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4151 - categorical_accuracy: 0.8938 - val_loss: 3.4965 - val_categorical_accuracy: 0.4882\n",
      "Epoch 66/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3975 - categorical_accuracy: 0.9103 - val_loss: 3.8138 - val_categorical_accuracy: 0.4819\n",
      "Epoch 67/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4147 - categorical_accuracy: 0.8916 - val_loss: 3.5076 - val_categorical_accuracy: 0.4869\n",
      "Epoch 68/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4408 - categorical_accuracy: 0.9002 - val_loss: 3.5201 - val_categorical_accuracy: 0.4745\n",
      "Epoch 69/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3711 - categorical_accuracy: 0.9012 - val_loss: 3.7311 - val_categorical_accuracy: 0.5006\n",
      "Epoch 70/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3967 - categorical_accuracy: 0.9130 - val_loss: 3.7075 - val_categorical_accuracy: 0.4919\n",
      "Epoch 71/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4157 - categorical_accuracy: 0.9028 - val_loss: 3.6811 - val_categorical_accuracy: 0.5056\n",
      "Epoch 72/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3963 - categorical_accuracy: 0.9012 - val_loss: 3.4463 - val_categorical_accuracy: 0.5367\n",
      "Epoch 73/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4304 - categorical_accuracy: 0.8975 - val_loss: 4.1766 - val_categorical_accuracy: 0.4720\n",
      "Epoch 74/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3967 - categorical_accuracy: 0.9087 - val_loss: 3.4728 - val_categorical_accuracy: 0.5193\n",
      "Epoch 75/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4171 - categorical_accuracy: 0.9023 - val_loss: 3.4863 - val_categorical_accuracy: 0.5405\n",
      "Epoch 76/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3611 - categorical_accuracy: 0.9130 - val_loss: 3.6687 - val_categorical_accuracy: 0.4944\n",
      "Epoch 77/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4327 - categorical_accuracy: 0.8922 - val_loss: 4.2170 - val_categorical_accuracy: 0.4682\n",
      "Epoch 78/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3829 - categorical_accuracy: 0.9092 - val_loss: 3.7045 - val_categorical_accuracy: 0.5243\n",
      "Epoch 79/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4016 - categorical_accuracy: 0.9071 - val_loss: 3.7706 - val_categorical_accuracy: 0.5131\n",
      "Epoch 80/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4159 - categorical_accuracy: 0.9066 - val_loss: 3.4775 - val_categorical_accuracy: 0.5193\n",
      "Epoch 81/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3985 - categorical_accuracy: 0.9066 - val_loss: 3.4034 - val_categorical_accuracy: 0.5455\n",
      "Epoch 82/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4208 - categorical_accuracy: 0.9087 - val_loss: 3.6701 - val_categorical_accuracy: 0.5455\n",
      "Epoch 83/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3860 - categorical_accuracy: 0.9082 - val_loss: 3.7749 - val_categorical_accuracy: 0.5056\n",
      "Epoch 84/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4111 - categorical_accuracy: 0.9055 - val_loss: 4.1163 - val_categorical_accuracy: 0.4707\n",
      "Epoch 85/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4467 - categorical_accuracy: 0.8959 - val_loss: 3.7191 - val_categorical_accuracy: 0.5044\n",
      "Epoch 86/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4244 - categorical_accuracy: 0.9018 - val_loss: 3.6372 - val_categorical_accuracy: 0.5293\n",
      "Epoch 87/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3781 - categorical_accuracy: 0.9119 - val_loss: 3.6832 - val_categorical_accuracy: 0.5305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4221 - categorical_accuracy: 0.9092 - val_loss: 3.8767 - val_categorical_accuracy: 0.5230\n",
      "Epoch 89/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4622 - categorical_accuracy: 0.8996 - val_loss: 3.7301 - val_categorical_accuracy: 0.5280\n",
      "Epoch 90/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3792 - categorical_accuracy: 0.9151 - val_loss: 4.0435 - val_categorical_accuracy: 0.5367\n",
      "Epoch 91/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3995 - categorical_accuracy: 0.9119 - val_loss: 4.0432 - val_categorical_accuracy: 0.5392\n",
      "Epoch 92/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4471 - categorical_accuracy: 0.9055 - val_loss: 3.8701 - val_categorical_accuracy: 0.5355\n",
      "Epoch 93/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4046 - categorical_accuracy: 0.9103 - val_loss: 3.7944 - val_categorical_accuracy: 0.5542\n",
      "Epoch 94/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4122 - categorical_accuracy: 0.9082 - val_loss: 3.7683 - val_categorical_accuracy: 0.5255\n",
      "Epoch 95/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3831 - categorical_accuracy: 0.9103 - val_loss: 3.9819 - val_categorical_accuracy: 0.5479\n",
      "Epoch 96/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3858 - categorical_accuracy: 0.9178 - val_loss: 3.8396 - val_categorical_accuracy: 0.5504\n",
      "Epoch 97/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3771 - categorical_accuracy: 0.9124 - val_loss: 3.8672 - val_categorical_accuracy: 0.5704\n",
      "Epoch 98/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4099 - categorical_accuracy: 0.9156 - val_loss: 3.7382 - val_categorical_accuracy: 0.5529\n",
      "Epoch 99/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4429 - categorical_accuracy: 0.9060 - val_loss: 4.0531 - val_categorical_accuracy: 0.5492\n",
      "Epoch 100/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4719 - categorical_accuracy: 0.9012 - val_loss: 3.8375 - val_categorical_accuracy: 0.5342\n",
      "Epoch 101/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4846 - categorical_accuracy: 0.9044 - val_loss: 3.9773 - val_categorical_accuracy: 0.4907\n",
      "Epoch 102/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3950 - categorical_accuracy: 0.9130 - val_loss: 3.7843 - val_categorical_accuracy: 0.5205\n",
      "Epoch 103/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4291 - categorical_accuracy: 0.9060 - val_loss: 3.9028 - val_categorical_accuracy: 0.5367\n",
      "Epoch 104/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4059 - categorical_accuracy: 0.9114 - val_loss: 4.1307 - val_categorical_accuracy: 0.5006\n",
      "Epoch 105/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4530 - categorical_accuracy: 0.8996 - val_loss: 3.8821 - val_categorical_accuracy: 0.5517\n",
      "Epoch 106/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3847 - categorical_accuracy: 0.9247 - val_loss: 3.7291 - val_categorical_accuracy: 0.5841\n",
      "Epoch 107/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3701 - categorical_accuracy: 0.9172 - val_loss: 4.1244 - val_categorical_accuracy: 0.5168\n",
      "Epoch 108/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4059 - categorical_accuracy: 0.9183 - val_loss: 4.1931 - val_categorical_accuracy: 0.5305\n",
      "Epoch 109/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4234 - categorical_accuracy: 0.9103 - val_loss: 4.0130 - val_categorical_accuracy: 0.5542\n",
      "Epoch 110/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3951 - categorical_accuracy: 0.9162 - val_loss: 4.3440 - val_categorical_accuracy: 0.5168\n",
      "Epoch 111/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4787 - categorical_accuracy: 0.9114 - val_loss: 4.2079 - val_categorical_accuracy: 0.5579\n",
      "Epoch 112/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4050 - categorical_accuracy: 0.9242 - val_loss: 4.2896 - val_categorical_accuracy: 0.5205\n",
      "Epoch 113/5000\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2663 - categorical_accuracy: 0.9453"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SpatialDropout1D\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential(name='Sequential')\n",
    "act_function = 'selu'\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv1D(filters=50, kernel_size=2, activation=act_function, input_shape=(130, 126)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=100, kernel_size=2, activation=act_function))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Conv1D(filters=50, kernel_size=2, activation=act_function))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(SpatialDropout1D(0.5))\n",
    "#model.add(Conv1D(filters=100, kernel_size=2, activation=act_function))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(SpatialDropout1D(0.5))\n",
    "\n",
    "#model.add(Conv1D(filters=50, kernel_size=2, activation=act_function))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='selu', kernel_regularizer=regularizers.l2(l=0.001)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# droput layer, remove if no work\n",
    "model.add(SpatialDropout1D(0.5))\n",
    "\n",
    "# Flatten the output for the fully connected layers\n",
    "model.add(Flatten())\n",
    "# Add fully connected layers\n",
    "model.add(Dense(40, activation=act_function))\n",
    "#model.add(Dense(16, activation=act_function))\n",
    "#model.add(Dense(40, activation=act_function))\n",
    "#model.add(Dense(16, activation=act_function))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='softmax'))  # Output layer\n",
    "optimizer = Lion(learning_rate=.00075)\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(Xtrain, Ytrain, epochs=5000, validation_split=.3, batch_size = 128, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b360c92b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T08:32:34.748516Z",
     "start_time": "2023-08-11T08:25:04.381674Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_38 (Conv1D)          (None, 129, 25)           6325      \n",
      "                                                                 \n",
      " max_pooling1d_38 (MaxPooli  (None, 64, 25)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_39 (Conv1D)          (None, 63, 50)            2550      \n",
      "                                                                 \n",
      " max_pooling1d_39 (MaxPooli  (None, 31, 50)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_40 (Conv1D)          (None, 29, 25)            3775      \n",
      "                                                                 \n",
      " max_pooling1d_40 (MaxPooli  (None, 14, 25)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " spatial_dropout1d_12 (Spat  (None, 14, 25)            0         \n",
      " ialDropout1D)                                                   \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 350)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 20)                7020      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 50)                1050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20720 (80.94 KB)\n",
      "Trainable params: 20720 (80.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5000\n",
      "15/15 [==============================] - 3s 99ms/step - loss: 4.2832 - categorical_accuracy: 0.0192 - val_loss: 3.9758 - val_categorical_accuracy: 0.0199\n",
      "Epoch 2/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 4.0428 - categorical_accuracy: 0.0272 - val_loss: 3.9588 - val_categorical_accuracy: 0.0237\n",
      "Epoch 3/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 3.9817 - categorical_accuracy: 0.0299 - val_loss: 3.9769 - val_categorical_accuracy: 0.0137\n",
      "Epoch 4/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 3.9207 - categorical_accuracy: 0.0358 - val_loss: 3.9310 - val_categorical_accuracy: 0.0237\n",
      "Epoch 5/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 3.9017 - categorical_accuracy: 0.0411 - val_loss: 3.9435 - val_categorical_accuracy: 0.0386\n",
      "Epoch 6/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 3.8299 - categorical_accuracy: 0.0416 - val_loss: 3.8815 - val_categorical_accuracy: 0.0461\n",
      "Epoch 7/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 3.7667 - categorical_accuracy: 0.0545 - val_loss: 3.8395 - val_categorical_accuracy: 0.0585\n",
      "Epoch 8/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 3.7030 - categorical_accuracy: 0.0667 - val_loss: 3.7598 - val_categorical_accuracy: 0.0623\n",
      "Epoch 9/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 3.6308 - categorical_accuracy: 0.0854 - val_loss: 3.6649 - val_categorical_accuracy: 0.0697\n",
      "Epoch 10/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 3.5592 - categorical_accuracy: 0.0881 - val_loss: 3.5652 - val_categorical_accuracy: 0.0934\n",
      "Epoch 11/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 3.5123 - categorical_accuracy: 0.1025 - val_loss: 3.5717 - val_categorical_accuracy: 0.1034\n",
      "Epoch 12/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 3.4121 - categorical_accuracy: 0.1175 - val_loss: 3.4992 - val_categorical_accuracy: 0.1108\n",
      "Epoch 13/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 3.3448 - categorical_accuracy: 0.1116 - val_loss: 3.4011 - val_categorical_accuracy: 0.1158\n",
      "Epoch 14/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 3.2922 - categorical_accuracy: 0.1361 - val_loss: 3.4400 - val_categorical_accuracy: 0.1158\n",
      "Epoch 15/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 3.2552 - categorical_accuracy: 0.1361 - val_loss: 3.3156 - val_categorical_accuracy: 0.1283\n",
      "Epoch 16/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 3.2077 - categorical_accuracy: 0.1479 - val_loss: 3.3128 - val_categorical_accuracy: 0.1382\n",
      "Epoch 17/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 3.1703 - categorical_accuracy: 0.1463 - val_loss: 3.2568 - val_categorical_accuracy: 0.1370\n",
      "Epoch 18/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 3.0688 - categorical_accuracy: 0.1554 - val_loss: 3.1032 - val_categorical_accuracy: 0.1594\n",
      "Epoch 19/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 3.0894 - categorical_accuracy: 0.1634 - val_loss: 3.1081 - val_categorical_accuracy: 0.1557\n",
      "Epoch 20/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 3.0328 - categorical_accuracy: 0.1676 - val_loss: 3.1578 - val_categorical_accuracy: 0.1494\n",
      "Epoch 21/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.9706 - categorical_accuracy: 0.1895 - val_loss: 2.9519 - val_categorical_accuracy: 0.1806\n",
      "Epoch 22/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.9382 - categorical_accuracy: 0.1922 - val_loss: 3.0513 - val_categorical_accuracy: 0.1731\n",
      "Epoch 23/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.9295 - categorical_accuracy: 0.1895 - val_loss: 3.0065 - val_categorical_accuracy: 0.1731\n",
      "Epoch 24/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.8850 - categorical_accuracy: 0.1975 - val_loss: 2.8829 - val_categorical_accuracy: 0.1856\n",
      "Epoch 25/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.8429 - categorical_accuracy: 0.2066 - val_loss: 2.9116 - val_categorical_accuracy: 0.1719\n",
      "Epoch 26/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.8415 - categorical_accuracy: 0.2034 - val_loss: 2.8058 - val_categorical_accuracy: 0.2179\n",
      "Epoch 27/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.7836 - categorical_accuracy: 0.2280 - val_loss: 2.7596 - val_categorical_accuracy: 0.2304\n",
      "Epoch 28/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.7930 - categorical_accuracy: 0.2130 - val_loss: 2.7306 - val_categorical_accuracy: 0.2242\n",
      "Epoch 29/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.7128 - categorical_accuracy: 0.2387 - val_loss: 2.6887 - val_categorical_accuracy: 0.2179\n",
      "Epoch 30/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.7641 - categorical_accuracy: 0.2317 - val_loss: 2.6767 - val_categorical_accuracy: 0.2466\n",
      "Epoch 31/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.6737 - categorical_accuracy: 0.2493 - val_loss: 2.6699 - val_categorical_accuracy: 0.2154\n",
      "Epoch 32/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.6777 - categorical_accuracy: 0.2456 - val_loss: 2.6220 - val_categorical_accuracy: 0.2142\n",
      "Epoch 33/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.7054 - categorical_accuracy: 0.2397 - val_loss: 2.5521 - val_categorical_accuracy: 0.2441\n",
      "Epoch 34/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.6255 - categorical_accuracy: 0.2541 - val_loss: 2.5343 - val_categorical_accuracy: 0.2391\n",
      "Epoch 35/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 2.6427 - categorical_accuracy: 0.2573 - val_loss: 2.4892 - val_categorical_accuracy: 0.2628\n",
      "Epoch 36/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 2.6016 - categorical_accuracy: 0.2653 - val_loss: 2.4855 - val_categorical_accuracy: 0.2690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.5753 - categorical_accuracy: 0.2702 - val_loss: 2.5617 - val_categorical_accuracy: 0.2354\n",
      "Epoch 38/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.5664 - categorical_accuracy: 0.2696 - val_loss: 2.4536 - val_categorical_accuracy: 0.2615\n",
      "Epoch 39/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.5819 - categorical_accuracy: 0.2600 - val_loss: 2.4138 - val_categorical_accuracy: 0.2777\n",
      "Epoch 40/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.5370 - categorical_accuracy: 0.2712 - val_loss: 2.4642 - val_categorical_accuracy: 0.2528\n",
      "Epoch 41/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.5290 - categorical_accuracy: 0.2782 - val_loss: 2.3691 - val_categorical_accuracy: 0.2976\n",
      "Epoch 42/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.4860 - categorical_accuracy: 0.2712 - val_loss: 2.4598 - val_categorical_accuracy: 0.2777\n",
      "Epoch 43/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.5131 - categorical_accuracy: 0.2653 - val_loss: 2.4121 - val_categorical_accuracy: 0.2927\n",
      "Epoch 44/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.4407 - categorical_accuracy: 0.3017 - val_loss: 2.4240 - val_categorical_accuracy: 0.2727\n",
      "Epoch 45/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.4140 - categorical_accuracy: 0.2974 - val_loss: 2.3600 - val_categorical_accuracy: 0.3176\n",
      "Epoch 46/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.4428 - categorical_accuracy: 0.2942 - val_loss: 2.3530 - val_categorical_accuracy: 0.3176\n",
      "Epoch 47/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.4113 - categorical_accuracy: 0.2814 - val_loss: 2.2694 - val_categorical_accuracy: 0.3412\n",
      "Epoch 48/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.4219 - categorical_accuracy: 0.2915 - val_loss: 2.4221 - val_categorical_accuracy: 0.3039\n",
      "Epoch 49/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.4165 - categorical_accuracy: 0.3065 - val_loss: 2.2490 - val_categorical_accuracy: 0.3462\n",
      "Epoch 50/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.3747 - categorical_accuracy: 0.3123 - val_loss: 2.2630 - val_categorical_accuracy: 0.3437\n",
      "Epoch 51/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.3666 - categorical_accuracy: 0.3155 - val_loss: 2.1967 - val_categorical_accuracy: 0.3524\n",
      "Epoch 52/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.3547 - categorical_accuracy: 0.3193 - val_loss: 2.2110 - val_categorical_accuracy: 0.3649\n",
      "Epoch 53/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.3666 - categorical_accuracy: 0.3091 - val_loss: 2.1387 - val_categorical_accuracy: 0.3736\n",
      "Epoch 54/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.3259 - categorical_accuracy: 0.3294 - val_loss: 2.0954 - val_categorical_accuracy: 0.3773\n",
      "Epoch 55/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.2924 - categorical_accuracy: 0.3219 - val_loss: 2.1684 - val_categorical_accuracy: 0.3524\n",
      "Epoch 56/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.2583 - categorical_accuracy: 0.3406 - val_loss: 2.0955 - val_categorical_accuracy: 0.3786\n",
      "Epoch 57/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.2880 - categorical_accuracy: 0.3374 - val_loss: 2.1367 - val_categorical_accuracy: 0.3724\n",
      "Epoch 58/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.2448 - categorical_accuracy: 0.3438 - val_loss: 2.0766 - val_categorical_accuracy: 0.3861\n",
      "Epoch 59/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.2615 - categorical_accuracy: 0.3380 - val_loss: 2.0463 - val_categorical_accuracy: 0.3885\n",
      "Epoch 60/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.2203 - categorical_accuracy: 0.3513 - val_loss: 2.0455 - val_categorical_accuracy: 0.3973\n",
      "Epoch 61/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.2497 - categorical_accuracy: 0.3262 - val_loss: 2.0593 - val_categorical_accuracy: 0.3985\n",
      "Epoch 62/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.2266 - categorical_accuracy: 0.3412 - val_loss: 2.1268 - val_categorical_accuracy: 0.3786\n",
      "Epoch 63/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.2279 - categorical_accuracy: 0.3508 - val_loss: 2.0445 - val_categorical_accuracy: 0.3985\n",
      "Epoch 64/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.2234 - categorical_accuracy: 0.3316 - val_loss: 2.0166 - val_categorical_accuracy: 0.4072\n",
      "Epoch 65/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.2022 - categorical_accuracy: 0.3524 - val_loss: 2.1285 - val_categorical_accuracy: 0.3462\n",
      "Epoch 66/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.2381 - categorical_accuracy: 0.3241 - val_loss: 1.9869 - val_categorical_accuracy: 0.4047\n",
      "Epoch 67/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.1232 - categorical_accuracy: 0.3588 - val_loss: 1.9630 - val_categorical_accuracy: 0.4234\n",
      "Epoch 68/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.1992 - categorical_accuracy: 0.3369 - val_loss: 1.9894 - val_categorical_accuracy: 0.4097\n",
      "Epoch 69/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.2000 - categorical_accuracy: 0.3412 - val_loss: 1.9686 - val_categorical_accuracy: 0.4047\n",
      "Epoch 70/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.1612 - categorical_accuracy: 0.3540 - val_loss: 2.0100 - val_categorical_accuracy: 0.4147\n",
      "Epoch 71/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.1518 - categorical_accuracy: 0.3871 - val_loss: 1.9536 - val_categorical_accuracy: 0.3973\n",
      "Epoch 72/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 2.1886 - categorical_accuracy: 0.3396 - val_loss: 2.0124 - val_categorical_accuracy: 0.3848\n",
      "Epoch 73/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.1385 - categorical_accuracy: 0.3673 - val_loss: 1.9673 - val_categorical_accuracy: 0.4035\n",
      "Epoch 74/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.1413 - categorical_accuracy: 0.3545 - val_loss: 1.9312 - val_categorical_accuracy: 0.4134\n",
      "Epoch 75/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.1328 - categorical_accuracy: 0.3833 - val_loss: 1.9069 - val_categorical_accuracy: 0.4222\n",
      "Epoch 76/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.1061 - categorical_accuracy: 0.3668 - val_loss: 1.9672 - val_categorical_accuracy: 0.4209\n",
      "Epoch 77/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 2.1344 - categorical_accuracy: 0.3673 - val_loss: 1.8290 - val_categorical_accuracy: 0.4645\n",
      "Epoch 78/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.1152 - categorical_accuracy: 0.3764 - val_loss: 1.8946 - val_categorical_accuracy: 0.4421\n",
      "Epoch 79/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 2.1024 - categorical_accuracy: 0.3796 - val_loss: 1.9664 - val_categorical_accuracy: 0.4022\n",
      "Epoch 80/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.0792 - categorical_accuracy: 0.3743 - val_loss: 1.9028 - val_categorical_accuracy: 0.4234\n",
      "Epoch 81/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.0398 - categorical_accuracy: 0.3930 - val_loss: 1.8784 - val_categorical_accuracy: 0.4521\n",
      "Epoch 82/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.0776 - categorical_accuracy: 0.3855 - val_loss: 1.8391 - val_categorical_accuracy: 0.4645\n",
      "Epoch 83/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.0805 - categorical_accuracy: 0.3833 - val_loss: 1.8785 - val_categorical_accuracy: 0.4496\n",
      "Epoch 84/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.0599 - categorical_accuracy: 0.3983 - val_loss: 1.9090 - val_categorical_accuracy: 0.4259\n",
      "Epoch 85/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.0841 - categorical_accuracy: 0.3737 - val_loss: 1.8008 - val_categorical_accuracy: 0.4695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.0995 - categorical_accuracy: 0.3711 - val_loss: 1.8783 - val_categorical_accuracy: 0.4296\n",
      "Epoch 87/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.0611 - categorical_accuracy: 0.3833 - val_loss: 1.7951 - val_categorical_accuracy: 0.4682\n",
      "Epoch 88/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.9946 - categorical_accuracy: 0.4106 - val_loss: 1.7882 - val_categorical_accuracy: 0.4770\n",
      "Epoch 89/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.0076 - categorical_accuracy: 0.4031 - val_loss: 1.8115 - val_categorical_accuracy: 0.4707\n",
      "Epoch 90/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.0049 - categorical_accuracy: 0.3924 - val_loss: 1.8203 - val_categorical_accuracy: 0.4471\n",
      "Epoch 91/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.0117 - categorical_accuracy: 0.3924 - val_loss: 1.8210 - val_categorical_accuracy: 0.4521\n",
      "Epoch 92/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.0264 - categorical_accuracy: 0.3940 - val_loss: 1.8806 - val_categorical_accuracy: 0.4421\n",
      "Epoch 93/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.9855 - categorical_accuracy: 0.4026 - val_loss: 1.8646 - val_categorical_accuracy: 0.4359\n",
      "Epoch 94/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.0098 - categorical_accuracy: 0.3951 - val_loss: 1.8100 - val_categorical_accuracy: 0.4645\n",
      "Epoch 95/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.0122 - categorical_accuracy: 0.3951 - val_loss: 1.7956 - val_categorical_accuracy: 0.4670\n",
      "Epoch 96/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.9792 - categorical_accuracy: 0.4068 - val_loss: 1.8601 - val_categorical_accuracy: 0.4321\n",
      "Epoch 97/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.9742 - categorical_accuracy: 0.4074 - val_loss: 1.7623 - val_categorical_accuracy: 0.4707\n",
      "Epoch 98/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.9638 - categorical_accuracy: 0.4116 - val_loss: 1.7428 - val_categorical_accuracy: 0.4944\n",
      "Epoch 99/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.9675 - categorical_accuracy: 0.4122 - val_loss: 1.7405 - val_categorical_accuracy: 0.4882\n",
      "Epoch 100/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.0028 - categorical_accuracy: 0.4079 - val_loss: 1.8128 - val_categorical_accuracy: 0.4757\n",
      "Epoch 101/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.9743 - categorical_accuracy: 0.4036 - val_loss: 1.7422 - val_categorical_accuracy: 0.4832\n",
      "Epoch 102/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.9544 - categorical_accuracy: 0.4170 - val_loss: 1.7314 - val_categorical_accuracy: 0.4969\n",
      "Epoch 103/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.9751 - categorical_accuracy: 0.4074 - val_loss: 1.8079 - val_categorical_accuracy: 0.4608\n",
      "Epoch 104/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.9612 - categorical_accuracy: 0.4042 - val_loss: 1.7477 - val_categorical_accuracy: 0.4645\n",
      "Epoch 105/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 2.0083 - categorical_accuracy: 0.4079 - val_loss: 1.7320 - val_categorical_accuracy: 0.4907\n",
      "Epoch 106/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.9321 - categorical_accuracy: 0.4463 - val_loss: 1.7178 - val_categorical_accuracy: 0.5019\n",
      "Epoch 107/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.9118 - categorical_accuracy: 0.4175 - val_loss: 1.8658 - val_categorical_accuracy: 0.4321\n",
      "Epoch 108/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.9154 - categorical_accuracy: 0.4202 - val_loss: 1.7144 - val_categorical_accuracy: 0.4882\n",
      "Epoch 109/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.9236 - categorical_accuracy: 0.4234 - val_loss: 1.7468 - val_categorical_accuracy: 0.4745\n",
      "Epoch 110/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.9061 - categorical_accuracy: 0.4282 - val_loss: 1.7879 - val_categorical_accuracy: 0.4720\n",
      "Epoch 111/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.9197 - categorical_accuracy: 0.4180 - val_loss: 1.6546 - val_categorical_accuracy: 0.5044\n",
      "Epoch 112/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.9138 - categorical_accuracy: 0.4212 - val_loss: 1.6476 - val_categorical_accuracy: 0.4981\n",
      "Epoch 113/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.9369 - categorical_accuracy: 0.4164 - val_loss: 1.6682 - val_categorical_accuracy: 0.4944\n",
      "Epoch 114/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8742 - categorical_accuracy: 0.4287 - val_loss: 1.7177 - val_categorical_accuracy: 0.5031\n",
      "Epoch 115/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.9121 - categorical_accuracy: 0.4266 - val_loss: 1.6451 - val_categorical_accuracy: 0.5081\n",
      "Epoch 116/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8989 - categorical_accuracy: 0.4447 - val_loss: 1.7533 - val_categorical_accuracy: 0.4682\n",
      "Epoch 117/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8621 - categorical_accuracy: 0.4170 - val_loss: 1.7427 - val_categorical_accuracy: 0.4732\n",
      "Epoch 118/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8296 - categorical_accuracy: 0.4554 - val_loss: 1.6231 - val_categorical_accuracy: 0.5131\n",
      "Epoch 119/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8624 - categorical_accuracy: 0.4458 - val_loss: 1.6239 - val_categorical_accuracy: 0.5255\n",
      "Epoch 120/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8630 - categorical_accuracy: 0.4335 - val_loss: 1.7328 - val_categorical_accuracy: 0.4720\n",
      "Epoch 121/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8540 - categorical_accuracy: 0.4485 - val_loss: 1.7012 - val_categorical_accuracy: 0.4981\n",
      "Epoch 122/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8671 - categorical_accuracy: 0.4463 - val_loss: 1.6303 - val_categorical_accuracy: 0.5118\n",
      "Epoch 123/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.8406 - categorical_accuracy: 0.4527 - val_loss: 1.6890 - val_categorical_accuracy: 0.4869\n",
      "Epoch 124/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8563 - categorical_accuracy: 0.4517 - val_loss: 1.5806 - val_categorical_accuracy: 0.5318\n",
      "Epoch 125/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8238 - categorical_accuracy: 0.4602 - val_loss: 1.6313 - val_categorical_accuracy: 0.5031\n",
      "Epoch 126/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8341 - categorical_accuracy: 0.4394 - val_loss: 1.6114 - val_categorical_accuracy: 0.5131\n",
      "Epoch 127/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8852 - categorical_accuracy: 0.4421 - val_loss: 1.7337 - val_categorical_accuracy: 0.4658\n",
      "Epoch 128/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8782 - categorical_accuracy: 0.4250 - val_loss: 1.6415 - val_categorical_accuracy: 0.4894\n",
      "Epoch 129/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8060 - categorical_accuracy: 0.4538 - val_loss: 1.6403 - val_categorical_accuracy: 0.5031\n",
      "Epoch 130/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8516 - categorical_accuracy: 0.4410 - val_loss: 1.6044 - val_categorical_accuracy: 0.5106\n",
      "Epoch 131/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8404 - categorical_accuracy: 0.4399 - val_loss: 1.6671 - val_categorical_accuracy: 0.4969\n",
      "Epoch 132/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8410 - categorical_accuracy: 0.4495 - val_loss: 1.6382 - val_categorical_accuracy: 0.4807\n",
      "Epoch 133/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.8528 - categorical_accuracy: 0.4522 - val_loss: 1.5519 - val_categorical_accuracy: 0.5255\n",
      "Epoch 134/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8408 - categorical_accuracy: 0.4554 - val_loss: 1.6100 - val_categorical_accuracy: 0.5019\n",
      "Epoch 135/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8683 - categorical_accuracy: 0.4261 - val_loss: 1.6312 - val_categorical_accuracy: 0.5106\n",
      "Epoch 136/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.7979 - categorical_accuracy: 0.4527 - val_loss: 1.6465 - val_categorical_accuracy: 0.5019\n",
      "Epoch 137/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7852 - categorical_accuracy: 0.4501 - val_loss: 1.5520 - val_categorical_accuracy: 0.5504\n",
      "Epoch 138/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8865 - categorical_accuracy: 0.4346 - val_loss: 1.5772 - val_categorical_accuracy: 0.5417\n",
      "Epoch 139/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7963 - categorical_accuracy: 0.4522 - val_loss: 1.6043 - val_categorical_accuracy: 0.5305\n",
      "Epoch 140/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7789 - categorical_accuracy: 0.4682 - val_loss: 1.5959 - val_categorical_accuracy: 0.5380\n",
      "Epoch 141/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8160 - categorical_accuracy: 0.4346 - val_loss: 1.6059 - val_categorical_accuracy: 0.5305\n",
      "Epoch 142/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7586 - categorical_accuracy: 0.4549 - val_loss: 1.6323 - val_categorical_accuracy: 0.5156\n",
      "Epoch 143/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7490 - categorical_accuracy: 0.4688 - val_loss: 1.5789 - val_categorical_accuracy: 0.5168\n",
      "Epoch 144/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7370 - categorical_accuracy: 0.4757 - val_loss: 1.5908 - val_categorical_accuracy: 0.5168\n",
      "Epoch 145/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.8078 - categorical_accuracy: 0.4490 - val_loss: 1.5535 - val_categorical_accuracy: 0.5305\n",
      "Epoch 146/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7693 - categorical_accuracy: 0.4709 - val_loss: 1.6111 - val_categorical_accuracy: 0.5093\n",
      "Epoch 147/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.8107 - categorical_accuracy: 0.4581 - val_loss: 1.5578 - val_categorical_accuracy: 0.5181\n",
      "Epoch 148/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7989 - categorical_accuracy: 0.4453 - val_loss: 1.5683 - val_categorical_accuracy: 0.5417\n",
      "Epoch 149/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.8046 - categorical_accuracy: 0.4554 - val_loss: 1.5463 - val_categorical_accuracy: 0.5330\n",
      "Epoch 150/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.7317 - categorical_accuracy: 0.4613 - val_loss: 1.5732 - val_categorical_accuracy: 0.5405\n",
      "Epoch 151/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7780 - categorical_accuracy: 0.4800 - val_loss: 1.6384 - val_categorical_accuracy: 0.4969\n",
      "Epoch 152/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7557 - categorical_accuracy: 0.4768 - val_loss: 1.5653 - val_categorical_accuracy: 0.5280\n",
      "Epoch 153/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7712 - categorical_accuracy: 0.4768 - val_loss: 1.6098 - val_categorical_accuracy: 0.5355\n",
      "Epoch 154/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7371 - categorical_accuracy: 0.4650 - val_loss: 1.6229 - val_categorical_accuracy: 0.5143\n",
      "Epoch 155/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7392 - categorical_accuracy: 0.4682 - val_loss: 1.6521 - val_categorical_accuracy: 0.5031\n",
      "Epoch 156/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7105 - categorical_accuracy: 0.4730 - val_loss: 1.5231 - val_categorical_accuracy: 0.5430\n",
      "Epoch 157/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7573 - categorical_accuracy: 0.4709 - val_loss: 1.5886 - val_categorical_accuracy: 0.5405\n",
      "Epoch 158/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7856 - categorical_accuracy: 0.4693 - val_loss: 1.5244 - val_categorical_accuracy: 0.5230\n",
      "Epoch 159/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7532 - categorical_accuracy: 0.4741 - val_loss: 1.5305 - val_categorical_accuracy: 0.5380\n",
      "Epoch 160/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7573 - categorical_accuracy: 0.4672 - val_loss: 1.5603 - val_categorical_accuracy: 0.5168\n",
      "Epoch 161/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7938 - categorical_accuracy: 0.4506 - val_loss: 1.5831 - val_categorical_accuracy: 0.5093\n",
      "Epoch 162/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7373 - categorical_accuracy: 0.4656 - val_loss: 1.5231 - val_categorical_accuracy: 0.5455\n",
      "Epoch 163/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7692 - categorical_accuracy: 0.4709 - val_loss: 1.5309 - val_categorical_accuracy: 0.5492\n",
      "Epoch 164/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7222 - categorical_accuracy: 0.4816 - val_loss: 1.5561 - val_categorical_accuracy: 0.5380\n",
      "Epoch 165/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7101 - categorical_accuracy: 0.4939 - val_loss: 1.5764 - val_categorical_accuracy: 0.5392\n",
      "Epoch 166/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7180 - categorical_accuracy: 0.4757 - val_loss: 1.6009 - val_categorical_accuracy: 0.5305\n",
      "Epoch 167/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.7324 - categorical_accuracy: 0.4810 - val_loss: 1.5022 - val_categorical_accuracy: 0.5430\n",
      "Epoch 168/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7081 - categorical_accuracy: 0.4901 - val_loss: 1.6597 - val_categorical_accuracy: 0.4981\n",
      "Epoch 169/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7132 - categorical_accuracy: 0.4752 - val_loss: 1.6457 - val_categorical_accuracy: 0.4969\n",
      "Epoch 170/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7499 - categorical_accuracy: 0.4752 - val_loss: 1.5198 - val_categorical_accuracy: 0.5579\n",
      "Epoch 171/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6748 - categorical_accuracy: 0.4885 - val_loss: 1.5833 - val_categorical_accuracy: 0.5330\n",
      "Epoch 172/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7370 - categorical_accuracy: 0.4762 - val_loss: 1.5636 - val_categorical_accuracy: 0.5392\n",
      "Epoch 173/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6909 - categorical_accuracy: 0.4842 - val_loss: 1.5158 - val_categorical_accuracy: 0.5492\n",
      "Epoch 174/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7718 - categorical_accuracy: 0.4688 - val_loss: 1.5044 - val_categorical_accuracy: 0.5479\n",
      "Epoch 175/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.7094 - categorical_accuracy: 0.4869 - val_loss: 1.5965 - val_categorical_accuracy: 0.5255\n",
      "Epoch 176/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6976 - categorical_accuracy: 0.4832 - val_loss: 1.5170 - val_categorical_accuracy: 0.5641\n",
      "Epoch 177/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7438 - categorical_accuracy: 0.4677 - val_loss: 1.5087 - val_categorical_accuracy: 0.5467\n",
      "Epoch 178/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6863 - categorical_accuracy: 0.4885 - val_loss: 1.4757 - val_categorical_accuracy: 0.5592\n",
      "Epoch 179/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.7340 - categorical_accuracy: 0.4810 - val_loss: 1.5336 - val_categorical_accuracy: 0.5355\n",
      "Epoch 180/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6699 - categorical_accuracy: 0.4842 - val_loss: 1.5082 - val_categorical_accuracy: 0.5479\n",
      "Epoch 181/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.6666 - categorical_accuracy: 0.4976 - val_loss: 1.4895 - val_categorical_accuracy: 0.5430\n",
      "Epoch 182/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 21ms/step - loss: 1.6682 - categorical_accuracy: 0.4864 - val_loss: 1.4969 - val_categorical_accuracy: 0.5517\n",
      "Epoch 183/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6944 - categorical_accuracy: 0.4784 - val_loss: 1.5207 - val_categorical_accuracy: 0.5405\n",
      "Epoch 184/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6382 - categorical_accuracy: 0.4891 - val_loss: 1.5049 - val_categorical_accuracy: 0.5467\n",
      "Epoch 185/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6912 - categorical_accuracy: 0.4955 - val_loss: 1.4877 - val_categorical_accuracy: 0.5579\n",
      "Epoch 186/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6767 - categorical_accuracy: 0.4917 - val_loss: 1.5129 - val_categorical_accuracy: 0.5554\n",
      "Epoch 187/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6761 - categorical_accuracy: 0.4837 - val_loss: 1.4896 - val_categorical_accuracy: 0.5255\n",
      "Epoch 188/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6478 - categorical_accuracy: 0.4928 - val_loss: 1.5070 - val_categorical_accuracy: 0.5405\n",
      "Epoch 189/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6869 - categorical_accuracy: 0.4928 - val_loss: 1.4968 - val_categorical_accuracy: 0.5517\n",
      "Epoch 190/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6666 - categorical_accuracy: 0.4907 - val_loss: 1.5424 - val_categorical_accuracy: 0.5392\n",
      "Epoch 191/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.6943 - categorical_accuracy: 0.4842 - val_loss: 1.5151 - val_categorical_accuracy: 0.5616\n",
      "Epoch 192/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6907 - categorical_accuracy: 0.4891 - val_loss: 1.4803 - val_categorical_accuracy: 0.5554\n",
      "Epoch 193/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6894 - categorical_accuracy: 0.4778 - val_loss: 1.4982 - val_categorical_accuracy: 0.5392\n",
      "Epoch 194/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6501 - categorical_accuracy: 0.5045 - val_loss: 1.4978 - val_categorical_accuracy: 0.5504\n",
      "Epoch 195/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6010 - categorical_accuracy: 0.5051 - val_loss: 1.5010 - val_categorical_accuracy: 0.5479\n",
      "Epoch 196/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.5762 - categorical_accuracy: 0.5077 - val_loss: 1.4973 - val_categorical_accuracy: 0.5729\n",
      "Epoch 197/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6204 - categorical_accuracy: 0.5131 - val_loss: 1.5018 - val_categorical_accuracy: 0.5517\n",
      "Epoch 198/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5626 - categorical_accuracy: 0.5083 - val_loss: 1.5056 - val_categorical_accuracy: 0.5616\n",
      "Epoch 199/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6333 - categorical_accuracy: 0.4976 - val_loss: 1.5202 - val_categorical_accuracy: 0.5504\n",
      "Epoch 200/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6232 - categorical_accuracy: 0.5152 - val_loss: 1.5199 - val_categorical_accuracy: 0.5479\n",
      "Epoch 201/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6491 - categorical_accuracy: 0.5019 - val_loss: 1.4614 - val_categorical_accuracy: 0.5616\n",
      "Epoch 202/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6014 - categorical_accuracy: 0.5045 - val_loss: 1.5024 - val_categorical_accuracy: 0.5554\n",
      "Epoch 203/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6667 - categorical_accuracy: 0.4933 - val_loss: 1.4565 - val_categorical_accuracy: 0.5666\n",
      "Epoch 204/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6653 - categorical_accuracy: 0.5072 - val_loss: 1.5020 - val_categorical_accuracy: 0.5604\n",
      "Epoch 205/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6358 - categorical_accuracy: 0.5008 - val_loss: 1.5326 - val_categorical_accuracy: 0.5567\n",
      "Epoch 206/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6907 - categorical_accuracy: 0.4698 - val_loss: 1.4903 - val_categorical_accuracy: 0.5467\n",
      "Epoch 207/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6086 - categorical_accuracy: 0.5131 - val_loss: 1.5238 - val_categorical_accuracy: 0.5330\n",
      "Epoch 208/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.5810 - categorical_accuracy: 0.5147 - val_loss: 1.4571 - val_categorical_accuracy: 0.5716\n",
      "Epoch 209/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6466 - categorical_accuracy: 0.4997 - val_loss: 1.4454 - val_categorical_accuracy: 0.5691\n",
      "Epoch 210/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.5837 - categorical_accuracy: 0.5131 - val_loss: 1.4345 - val_categorical_accuracy: 0.5828\n",
      "Epoch 211/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5900 - categorical_accuracy: 0.5115 - val_loss: 1.5205 - val_categorical_accuracy: 0.5567\n",
      "Epoch 212/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6369 - categorical_accuracy: 0.5051 - val_loss: 1.4380 - val_categorical_accuracy: 0.5816\n",
      "Epoch 213/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.6066 - categorical_accuracy: 0.5072 - val_loss: 1.5187 - val_categorical_accuracy: 0.5529\n",
      "Epoch 214/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6260 - categorical_accuracy: 0.5179 - val_loss: 1.4706 - val_categorical_accuracy: 0.5940\n",
      "Epoch 215/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6083 - categorical_accuracy: 0.5040 - val_loss: 1.5058 - val_categorical_accuracy: 0.5753\n",
      "Epoch 216/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5886 - categorical_accuracy: 0.5061 - val_loss: 1.5779 - val_categorical_accuracy: 0.5205\n",
      "Epoch 217/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5978 - categorical_accuracy: 0.5125 - val_loss: 1.4181 - val_categorical_accuracy: 0.5953\n",
      "Epoch 218/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5859 - categorical_accuracy: 0.5109 - val_loss: 1.3765 - val_categorical_accuracy: 0.6002\n",
      "Epoch 219/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.5827 - categorical_accuracy: 0.5061 - val_loss: 1.3900 - val_categorical_accuracy: 0.5978\n",
      "Epoch 220/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.6112 - categorical_accuracy: 0.5029 - val_loss: 1.4918 - val_categorical_accuracy: 0.5529\n",
      "Epoch 221/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6192 - categorical_accuracy: 0.5083 - val_loss: 1.4448 - val_categorical_accuracy: 0.5629\n",
      "Epoch 222/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5580 - categorical_accuracy: 0.5238 - val_loss: 1.5773 - val_categorical_accuracy: 0.5330\n",
      "Epoch 223/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.5758 - categorical_accuracy: 0.5291 - val_loss: 1.4843 - val_categorical_accuracy: 0.5567\n",
      "Epoch 224/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5573 - categorical_accuracy: 0.5206 - val_loss: 1.4389 - val_categorical_accuracy: 0.5716\n",
      "Epoch 225/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6072 - categorical_accuracy: 0.5227 - val_loss: 1.3985 - val_categorical_accuracy: 0.5778\n",
      "Epoch 226/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6032 - categorical_accuracy: 0.5109 - val_loss: 1.5350 - val_categorical_accuracy: 0.5467\n",
      "Epoch 227/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5977 - categorical_accuracy: 0.5216 - val_loss: 1.4605 - val_categorical_accuracy: 0.5666\n",
      "Epoch 228/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5803 - categorical_accuracy: 0.5120 - val_loss: 1.4431 - val_categorical_accuracy: 0.5716\n",
      "Epoch 229/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5903 - categorical_accuracy: 0.5168 - val_loss: 1.4575 - val_categorical_accuracy: 0.5741\n",
      "Epoch 230/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.5946 - categorical_accuracy: 0.5077 - val_loss: 1.4667 - val_categorical_accuracy: 0.5592\n",
      "Epoch 231/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6110 - categorical_accuracy: 0.5222 - val_loss: 1.4380 - val_categorical_accuracy: 0.5841\n",
      "Epoch 232/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6119 - categorical_accuracy: 0.5152 - val_loss: 1.4765 - val_categorical_accuracy: 0.5679\n",
      "Epoch 233/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.6205 - categorical_accuracy: 0.4981 - val_loss: 1.4830 - val_categorical_accuracy: 0.5691\n",
      "Epoch 234/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5873 - categorical_accuracy: 0.5211 - val_loss: 1.4966 - val_categorical_accuracy: 0.5554\n",
      "Epoch 235/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5577 - categorical_accuracy: 0.5227 - val_loss: 1.4041 - val_categorical_accuracy: 0.5990\n",
      "Epoch 236/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5664 - categorical_accuracy: 0.5259 - val_loss: 1.5900 - val_categorical_accuracy: 0.5293\n",
      "Epoch 237/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5284 - categorical_accuracy: 0.5147 - val_loss: 1.4316 - val_categorical_accuracy: 0.5890\n",
      "Epoch 238/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5397 - categorical_accuracy: 0.5163 - val_loss: 1.4546 - val_categorical_accuracy: 0.5704\n",
      "Epoch 239/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5494 - categorical_accuracy: 0.5264 - val_loss: 1.4284 - val_categorical_accuracy: 0.5778\n",
      "Epoch 240/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5651 - categorical_accuracy: 0.5216 - val_loss: 1.4205 - val_categorical_accuracy: 0.5816\n",
      "Epoch 241/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5789 - categorical_accuracy: 0.5163 - val_loss: 1.4600 - val_categorical_accuracy: 0.5691\n",
      "Epoch 242/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.5799 - categorical_accuracy: 0.5056 - val_loss: 1.4094 - val_categorical_accuracy: 0.5816\n",
      "Epoch 243/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5797 - categorical_accuracy: 0.5216 - val_loss: 1.4683 - val_categorical_accuracy: 0.5691\n",
      "Epoch 244/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5818 - categorical_accuracy: 0.5259 - val_loss: 1.4349 - val_categorical_accuracy: 0.5828\n",
      "Epoch 245/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5570 - categorical_accuracy: 0.5296 - val_loss: 1.4253 - val_categorical_accuracy: 0.5716\n",
      "Epoch 246/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5483 - categorical_accuracy: 0.5222 - val_loss: 1.4304 - val_categorical_accuracy: 0.5641\n",
      "Epoch 247/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5100 - categorical_accuracy: 0.5232 - val_loss: 1.4992 - val_categorical_accuracy: 0.5442\n",
      "Epoch 248/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4905 - categorical_accuracy: 0.5259 - val_loss: 1.4167 - val_categorical_accuracy: 0.5417\n",
      "Epoch 249/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5713 - categorical_accuracy: 0.5206 - val_loss: 1.4444 - val_categorical_accuracy: 0.5641\n",
      "Epoch 250/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5737 - categorical_accuracy: 0.5093 - val_loss: 1.4212 - val_categorical_accuracy: 0.5579\n",
      "Epoch 251/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5515 - categorical_accuracy: 0.5179 - val_loss: 1.3858 - val_categorical_accuracy: 0.5704\n",
      "Epoch 252/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5263 - categorical_accuracy: 0.5302 - val_loss: 1.4165 - val_categorical_accuracy: 0.5666\n",
      "Epoch 253/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5505 - categorical_accuracy: 0.5248 - val_loss: 1.3906 - val_categorical_accuracy: 0.5853\n",
      "Epoch 254/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5039 - categorical_accuracy: 0.5355 - val_loss: 1.4513 - val_categorical_accuracy: 0.5816\n",
      "Epoch 255/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4700 - categorical_accuracy: 0.5360 - val_loss: 1.4318 - val_categorical_accuracy: 0.5691\n",
      "Epoch 256/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5534 - categorical_accuracy: 0.5307 - val_loss: 1.3823 - val_categorical_accuracy: 0.6002\n",
      "Epoch 257/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4702 - categorical_accuracy: 0.5456 - val_loss: 1.4171 - val_categorical_accuracy: 0.5803\n",
      "Epoch 258/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5477 - categorical_accuracy: 0.5248 - val_loss: 1.4606 - val_categorical_accuracy: 0.5753\n",
      "Epoch 259/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5396 - categorical_accuracy: 0.5350 - val_loss: 1.4928 - val_categorical_accuracy: 0.5828\n",
      "Epoch 260/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5319 - categorical_accuracy: 0.5291 - val_loss: 1.4223 - val_categorical_accuracy: 0.5841\n",
      "Epoch 261/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4876 - categorical_accuracy: 0.5366 - val_loss: 1.4476 - val_categorical_accuracy: 0.5778\n",
      "Epoch 262/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5553 - categorical_accuracy: 0.5414 - val_loss: 1.5376 - val_categorical_accuracy: 0.5554\n",
      "Epoch 263/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5675 - categorical_accuracy: 0.5270 - val_loss: 1.4235 - val_categorical_accuracy: 0.5766\n",
      "Epoch 264/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4540 - categorical_accuracy: 0.5521 - val_loss: 1.5108 - val_categorical_accuracy: 0.5716\n",
      "Epoch 265/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4947 - categorical_accuracy: 0.5403 - val_loss: 1.4234 - val_categorical_accuracy: 0.6002\n",
      "Epoch 266/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5088 - categorical_accuracy: 0.5424 - val_loss: 1.5984 - val_categorical_accuracy: 0.5641\n",
      "Epoch 267/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5281 - categorical_accuracy: 0.5371 - val_loss: 1.4486 - val_categorical_accuracy: 0.5953\n",
      "Epoch 268/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5216 - categorical_accuracy: 0.5419 - val_loss: 1.4439 - val_categorical_accuracy: 0.6027\n",
      "Epoch 269/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.4823 - categorical_accuracy: 0.5291 - val_loss: 1.3840 - val_categorical_accuracy: 0.5990\n",
      "Epoch 270/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.5266 - categorical_accuracy: 0.5270 - val_loss: 1.4528 - val_categorical_accuracy: 0.5903\n",
      "Epoch 271/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5118 - categorical_accuracy: 0.5195 - val_loss: 1.4324 - val_categorical_accuracy: 0.5990\n",
      "Epoch 272/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.4896 - categorical_accuracy: 0.5489 - val_loss: 1.4853 - val_categorical_accuracy: 0.5791\n",
      "Epoch 273/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5399 - categorical_accuracy: 0.5296 - val_loss: 1.4608 - val_categorical_accuracy: 0.5741\n",
      "Epoch 274/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4623 - categorical_accuracy: 0.5424 - val_loss: 1.4334 - val_categorical_accuracy: 0.5953\n",
      "Epoch 275/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.5233 - categorical_accuracy: 0.5440 - val_loss: 1.4311 - val_categorical_accuracy: 0.5940\n",
      "Epoch 276/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4846 - categorical_accuracy: 0.5456 - val_loss: 1.5508 - val_categorical_accuracy: 0.5641\n",
      "Epoch 277/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4967 - categorical_accuracy: 0.5382 - val_loss: 1.5185 - val_categorical_accuracy: 0.5666\n",
      "Epoch 278/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5362 - categorical_accuracy: 0.5270 - val_loss: 1.3779 - val_categorical_accuracy: 0.5841\n",
      "Epoch 279/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4595 - categorical_accuracy: 0.5473 - val_loss: 1.4743 - val_categorical_accuracy: 0.5679\n",
      "Epoch 280/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5185 - categorical_accuracy: 0.5286 - val_loss: 1.4176 - val_categorical_accuracy: 0.5890\n",
      "Epoch 281/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.5185 - categorical_accuracy: 0.5243 - val_loss: 1.4560 - val_categorical_accuracy: 0.5841\n",
      "Epoch 282/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5261 - categorical_accuracy: 0.5302 - val_loss: 1.4653 - val_categorical_accuracy: 0.5766\n",
      "Epoch 283/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4677 - categorical_accuracy: 0.5430 - val_loss: 1.4190 - val_categorical_accuracy: 0.5729\n",
      "Epoch 284/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5108 - categorical_accuracy: 0.5296 - val_loss: 1.4545 - val_categorical_accuracy: 0.5741\n",
      "Epoch 285/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.5312 - categorical_accuracy: 0.5478 - val_loss: 1.4472 - val_categorical_accuracy: 0.5504\n",
      "Epoch 286/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4952 - categorical_accuracy: 0.5360 - val_loss: 1.5012 - val_categorical_accuracy: 0.5542\n",
      "Epoch 287/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4364 - categorical_accuracy: 0.5611 - val_loss: 1.4455 - val_categorical_accuracy: 0.5741\n",
      "Epoch 288/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.4699 - categorical_accuracy: 0.5574 - val_loss: 1.4222 - val_categorical_accuracy: 0.5915\n",
      "Epoch 289/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4803 - categorical_accuracy: 0.5371 - val_loss: 1.3957 - val_categorical_accuracy: 0.5766\n",
      "Epoch 290/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4554 - categorical_accuracy: 0.5478 - val_loss: 1.4365 - val_categorical_accuracy: 0.5791\n",
      "Epoch 291/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5066 - categorical_accuracy: 0.5419 - val_loss: 1.3996 - val_categorical_accuracy: 0.5841\n",
      "Epoch 292/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4718 - categorical_accuracy: 0.5355 - val_loss: 1.4455 - val_categorical_accuracy: 0.5803\n",
      "Epoch 293/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4598 - categorical_accuracy: 0.5542 - val_loss: 1.4503 - val_categorical_accuracy: 0.5791\n",
      "Epoch 294/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4630 - categorical_accuracy: 0.5312 - val_loss: 1.4748 - val_categorical_accuracy: 0.5704\n",
      "Epoch 295/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5012 - categorical_accuracy: 0.5350 - val_loss: 1.4160 - val_categorical_accuracy: 0.5803\n",
      "Epoch 296/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4698 - categorical_accuracy: 0.5446 - val_loss: 1.4932 - val_categorical_accuracy: 0.5766\n",
      "Epoch 297/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4404 - categorical_accuracy: 0.5569 - val_loss: 1.4700 - val_categorical_accuracy: 0.5666\n",
      "Epoch 298/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4517 - categorical_accuracy: 0.5451 - val_loss: 1.5042 - val_categorical_accuracy: 0.5579\n",
      "Epoch 299/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5234 - categorical_accuracy: 0.5200 - val_loss: 1.4384 - val_categorical_accuracy: 0.5716\n",
      "Epoch 300/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4641 - categorical_accuracy: 0.5510 - val_loss: 1.4967 - val_categorical_accuracy: 0.5616\n",
      "Epoch 301/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.5193 - categorical_accuracy: 0.5334 - val_loss: 1.4516 - val_categorical_accuracy: 0.5841\n",
      "Epoch 302/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4404 - categorical_accuracy: 0.5697 - val_loss: 1.4119 - val_categorical_accuracy: 0.5753\n",
      "Epoch 303/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.4509 - categorical_accuracy: 0.5456 - val_loss: 1.4530 - val_categorical_accuracy: 0.5778\n",
      "Epoch 304/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4598 - categorical_accuracy: 0.5563 - val_loss: 1.4449 - val_categorical_accuracy: 0.5579\n",
      "Epoch 305/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5241 - categorical_accuracy: 0.5360 - val_loss: 1.3554 - val_categorical_accuracy: 0.6065\n",
      "Epoch 306/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4559 - categorical_accuracy: 0.5585 - val_loss: 1.4434 - val_categorical_accuracy: 0.5704\n",
      "Epoch 307/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4345 - categorical_accuracy: 0.5617 - val_loss: 1.4160 - val_categorical_accuracy: 0.5928\n",
      "Epoch 308/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4537 - categorical_accuracy: 0.5371 - val_loss: 1.4013 - val_categorical_accuracy: 0.5965\n",
      "Epoch 309/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4686 - categorical_accuracy: 0.5473 - val_loss: 1.4198 - val_categorical_accuracy: 0.6015\n",
      "Epoch 310/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.5446 - categorical_accuracy: 0.5451 - val_loss: 1.4070 - val_categorical_accuracy: 0.5803\n",
      "Epoch 311/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4689 - categorical_accuracy: 0.5627 - val_loss: 1.4597 - val_categorical_accuracy: 0.5753\n",
      "Epoch 312/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.4861 - categorical_accuracy: 0.5312 - val_loss: 1.4400 - val_categorical_accuracy: 0.5803\n",
      "Epoch 313/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4726 - categorical_accuracy: 0.5467 - val_loss: 1.4329 - val_categorical_accuracy: 0.5866\n",
      "Epoch 314/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4654 - categorical_accuracy: 0.5595 - val_loss: 1.4467 - val_categorical_accuracy: 0.5778\n",
      "Epoch 315/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4241 - categorical_accuracy: 0.5659 - val_loss: 1.4038 - val_categorical_accuracy: 0.5928\n",
      "Epoch 316/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.4620 - categorical_accuracy: 0.5430 - val_loss: 1.4528 - val_categorical_accuracy: 0.5890\n",
      "Epoch 317/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4633 - categorical_accuracy: 0.5483 - val_loss: 1.4253 - val_categorical_accuracy: 0.6077\n",
      "Epoch 318/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4665 - categorical_accuracy: 0.5579 - val_loss: 1.4543 - val_categorical_accuracy: 0.5729\n",
      "Epoch 319/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4834 - categorical_accuracy: 0.5478 - val_loss: 1.4232 - val_categorical_accuracy: 0.5641\n",
      "Epoch 320/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4491 - categorical_accuracy: 0.5521 - val_loss: 1.4625 - val_categorical_accuracy: 0.5791\n",
      "Epoch 321/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4077 - categorical_accuracy: 0.5825 - val_loss: 1.4431 - val_categorical_accuracy: 0.5978\n",
      "Epoch 322/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4654 - categorical_accuracy: 0.5521 - val_loss: 1.4228 - val_categorical_accuracy: 0.6052\n",
      "Epoch 323/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.4374 - categorical_accuracy: 0.5585 - val_loss: 1.4470 - val_categorical_accuracy: 0.5816\n",
      "Epoch 324/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4420 - categorical_accuracy: 0.5691 - val_loss: 1.3572 - val_categorical_accuracy: 0.6227\n",
      "Epoch 325/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4812 - categorical_accuracy: 0.5590 - val_loss: 1.4472 - val_categorical_accuracy: 0.5915\n",
      "Epoch 326/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.5095 - categorical_accuracy: 0.5430 - val_loss: 1.4727 - val_categorical_accuracy: 0.5778\n",
      "Epoch 327/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4586 - categorical_accuracy: 0.5542 - val_loss: 1.4636 - val_categorical_accuracy: 0.5828\n",
      "Epoch 328/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.3885 - categorical_accuracy: 0.5809 - val_loss: 1.4990 - val_categorical_accuracy: 0.5666\n",
      "Epoch 329/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4191 - categorical_accuracy: 0.5702 - val_loss: 1.4396 - val_categorical_accuracy: 0.5953\n",
      "Epoch 330/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.4498 - categorical_accuracy: 0.5499 - val_loss: 1.4527 - val_categorical_accuracy: 0.5965\n",
      "Epoch 331/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4264 - categorical_accuracy: 0.5510 - val_loss: 1.4398 - val_categorical_accuracy: 0.5716\n",
      "Epoch 332/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.5005 - categorical_accuracy: 0.5280 - val_loss: 1.4822 - val_categorical_accuracy: 0.5604\n",
      "Epoch 333/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.4607 - categorical_accuracy: 0.5553 - val_loss: 1.4518 - val_categorical_accuracy: 0.5716\n",
      "Epoch 334/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4057 - categorical_accuracy: 0.5569 - val_loss: 1.4167 - val_categorical_accuracy: 0.5841\n",
      "Epoch 335/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4301 - categorical_accuracy: 0.5697 - val_loss: 1.4282 - val_categorical_accuracy: 0.5828\n",
      "Epoch 336/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4095 - categorical_accuracy: 0.5622 - val_loss: 1.3734 - val_categorical_accuracy: 0.6152\n",
      "Epoch 337/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.4229 - categorical_accuracy: 0.5638 - val_loss: 1.4511 - val_categorical_accuracy: 0.5828\n",
      "Epoch 338/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4054 - categorical_accuracy: 0.5558 - val_loss: 1.3902 - val_categorical_accuracy: 0.6015\n",
      "Epoch 339/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4034 - categorical_accuracy: 0.5745 - val_loss: 1.4772 - val_categorical_accuracy: 0.5716\n",
      "Epoch 340/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4479 - categorical_accuracy: 0.5547 - val_loss: 1.4314 - val_categorical_accuracy: 0.5828\n",
      "Epoch 341/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.4639 - categorical_accuracy: 0.5419 - val_loss: 1.4390 - val_categorical_accuracy: 0.6052\n",
      "Epoch 342/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4372 - categorical_accuracy: 0.5585 - val_loss: 1.4303 - val_categorical_accuracy: 0.6027\n",
      "Epoch 343/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4224 - categorical_accuracy: 0.5691 - val_loss: 1.4125 - val_categorical_accuracy: 0.6002\n",
      "Epoch 344/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4485 - categorical_accuracy: 0.5553 - val_loss: 1.4454 - val_categorical_accuracy: 0.5803\n",
      "Epoch 345/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.4059 - categorical_accuracy: 0.5569 - val_loss: 1.3393 - val_categorical_accuracy: 0.6189\n",
      "Epoch 346/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4170 - categorical_accuracy: 0.5707 - val_loss: 1.4176 - val_categorical_accuracy: 0.5766\n",
      "Epoch 347/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4488 - categorical_accuracy: 0.5579 - val_loss: 1.4819 - val_categorical_accuracy: 0.5567\n",
      "Epoch 348/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4459 - categorical_accuracy: 0.5585 - val_loss: 1.3989 - val_categorical_accuracy: 0.5853\n",
      "Epoch 349/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3842 - categorical_accuracy: 0.5686 - val_loss: 1.3276 - val_categorical_accuracy: 0.6152\n",
      "Epoch 350/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.4099 - categorical_accuracy: 0.5713 - val_loss: 1.4117 - val_categorical_accuracy: 0.5903\n",
      "Epoch 351/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3853 - categorical_accuracy: 0.5707 - val_loss: 1.4255 - val_categorical_accuracy: 0.5778\n",
      "Epoch 352/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4189 - categorical_accuracy: 0.5681 - val_loss: 1.3858 - val_categorical_accuracy: 0.6002\n",
      "Epoch 353/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3894 - categorical_accuracy: 0.5718 - val_loss: 1.4665 - val_categorical_accuracy: 0.5803\n",
      "Epoch 354/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4039 - categorical_accuracy: 0.5702 - val_loss: 1.3960 - val_categorical_accuracy: 0.5953\n",
      "Epoch 355/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.4073 - categorical_accuracy: 0.5697 - val_loss: 1.3457 - val_categorical_accuracy: 0.6227\n",
      "Epoch 356/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4149 - categorical_accuracy: 0.5681 - val_loss: 1.4185 - val_categorical_accuracy: 0.5978\n",
      "Epoch 357/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3850 - categorical_accuracy: 0.5723 - val_loss: 1.3949 - val_categorical_accuracy: 0.5866\n",
      "Epoch 358/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4092 - categorical_accuracy: 0.5670 - val_loss: 1.4151 - val_categorical_accuracy: 0.5841\n",
      "Epoch 359/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3828 - categorical_accuracy: 0.5659 - val_loss: 1.3690 - val_categorical_accuracy: 0.5940\n",
      "Epoch 360/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4406 - categorical_accuracy: 0.5494 - val_loss: 1.4091 - val_categorical_accuracy: 0.5990\n",
      "Epoch 361/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3979 - categorical_accuracy: 0.5675 - val_loss: 1.4007 - val_categorical_accuracy: 0.6102\n",
      "Epoch 362/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.4074 - categorical_accuracy: 0.5659 - val_loss: 1.3708 - val_categorical_accuracy: 0.6027\n",
      "Epoch 363/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3972 - categorical_accuracy: 0.5777 - val_loss: 1.3818 - val_categorical_accuracy: 0.5953\n",
      "Epoch 364/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4554 - categorical_accuracy: 0.5408 - val_loss: 1.4210 - val_categorical_accuracy: 0.5828\n",
      "Epoch 365/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3683 - categorical_accuracy: 0.5809 - val_loss: 1.4955 - val_categorical_accuracy: 0.5592\n",
      "Epoch 366/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4329 - categorical_accuracy: 0.5622 - val_loss: 1.5279 - val_categorical_accuracy: 0.5392\n",
      "Epoch 367/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3491 - categorical_accuracy: 0.5948 - val_loss: 1.3945 - val_categorical_accuracy: 0.5853\n",
      "Epoch 368/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.4237 - categorical_accuracy: 0.5569 - val_loss: 1.4016 - val_categorical_accuracy: 0.5940\n",
      "Epoch 369/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4012 - categorical_accuracy: 0.5558 - val_loss: 1.3979 - val_categorical_accuracy: 0.5878\n",
      "Epoch 370/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4218 - categorical_accuracy: 0.5569 - val_loss: 1.3948 - val_categorical_accuracy: 0.5965\n",
      "Epoch 371/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4007 - categorical_accuracy: 0.5622 - val_loss: 1.4076 - val_categorical_accuracy: 0.5940\n",
      "Epoch 372/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4186 - categorical_accuracy: 0.5836 - val_loss: 1.4549 - val_categorical_accuracy: 0.5828\n",
      "Epoch 373/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3893 - categorical_accuracy: 0.5681 - val_loss: 1.4121 - val_categorical_accuracy: 0.5978\n",
      "Epoch 374/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3639 - categorical_accuracy: 0.5788 - val_loss: 1.4688 - val_categorical_accuracy: 0.5866\n",
      "Epoch 375/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3793 - categorical_accuracy: 0.5713 - val_loss: 1.5157 - val_categorical_accuracy: 0.5741\n",
      "Epoch 376/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3802 - categorical_accuracy: 0.5766 - val_loss: 1.4542 - val_categorical_accuracy: 0.5753\n",
      "Epoch 377/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3725 - categorical_accuracy: 0.5739 - val_loss: 1.4691 - val_categorical_accuracy: 0.5567\n",
      "Epoch 378/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3869 - categorical_accuracy: 0.5862 - val_loss: 1.3844 - val_categorical_accuracy: 0.6015\n",
      "Epoch 379/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3645 - categorical_accuracy: 0.5804 - val_loss: 1.3622 - val_categorical_accuracy: 0.6102\n",
      "Epoch 380/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.3770 - categorical_accuracy: 0.5932 - val_loss: 1.4233 - val_categorical_accuracy: 0.5878\n",
      "Epoch 381/5000\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 1.3988 - categorical_accuracy: 0.5585 - val_loss: 1.4369 - val_categorical_accuracy: 0.5866\n",
      "Epoch 382/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3659 - categorical_accuracy: 0.5836 - val_loss: 1.4053 - val_categorical_accuracy: 0.5928\n",
      "Epoch 383/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4110 - categorical_accuracy: 0.5729 - val_loss: 1.4353 - val_categorical_accuracy: 0.6015\n",
      "Epoch 384/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4334 - categorical_accuracy: 0.5440 - val_loss: 1.4518 - val_categorical_accuracy: 0.5853\n",
      "Epoch 385/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3841 - categorical_accuracy: 0.5739 - val_loss: 1.4565 - val_categorical_accuracy: 0.5803\n",
      "Epoch 386/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3763 - categorical_accuracy: 0.5649 - val_loss: 1.5281 - val_categorical_accuracy: 0.5554\n",
      "Epoch 387/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3603 - categorical_accuracy: 0.5675 - val_loss: 1.4474 - val_categorical_accuracy: 0.5841\n",
      "Epoch 388/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3998 - categorical_accuracy: 0.5718 - val_loss: 1.4524 - val_categorical_accuracy: 0.5990\n",
      "Epoch 389/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.3291 - categorical_accuracy: 0.6038 - val_loss: 1.4317 - val_categorical_accuracy: 0.5915\n",
      "Epoch 390/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.3725 - categorical_accuracy: 0.5868 - val_loss: 1.4770 - val_categorical_accuracy: 0.5878\n",
      "Epoch 391/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.3922 - categorical_accuracy: 0.5633 - val_loss: 1.4880 - val_categorical_accuracy: 0.5766\n",
      "Epoch 392/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3864 - categorical_accuracy: 0.5713 - val_loss: 1.4191 - val_categorical_accuracy: 0.5928\n",
      "Epoch 393/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3793 - categorical_accuracy: 0.5665 - val_loss: 1.4564 - val_categorical_accuracy: 0.5604\n",
      "Epoch 394/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3129 - categorical_accuracy: 0.5916 - val_loss: 1.4106 - val_categorical_accuracy: 0.5940\n",
      "Epoch 395/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.4063 - categorical_accuracy: 0.5558 - val_loss: 1.5116 - val_categorical_accuracy: 0.5716\n",
      "Epoch 396/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.4228 - categorical_accuracy: 0.5638 - val_loss: 1.4079 - val_categorical_accuracy: 0.5915\n",
      "Epoch 397/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3557 - categorical_accuracy: 0.5793 - val_loss: 1.4474 - val_categorical_accuracy: 0.5890\n",
      "Epoch 398/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.4206 - categorical_accuracy: 0.5563 - val_loss: 1.4072 - val_categorical_accuracy: 0.5878\n",
      "Epoch 399/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3902 - categorical_accuracy: 0.5788 - val_loss: 1.4367 - val_categorical_accuracy: 0.5828\n",
      "Epoch 400/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3714 - categorical_accuracy: 0.5750 - val_loss: 1.4083 - val_categorical_accuracy: 0.6052\n",
      "Epoch 401/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3515 - categorical_accuracy: 0.5825 - val_loss: 1.3813 - val_categorical_accuracy: 0.6127\n",
      "Epoch 402/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3966 - categorical_accuracy: 0.5713 - val_loss: 1.4345 - val_categorical_accuracy: 0.5778\n",
      "Epoch 403/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.3832 - categorical_accuracy: 0.5782 - val_loss: 1.4127 - val_categorical_accuracy: 0.6139\n",
      "Epoch 404/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.3829 - categorical_accuracy: 0.5841 - val_loss: 1.3610 - val_categorical_accuracy: 0.6052\n",
      "Epoch 405/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.4063 - categorical_accuracy: 0.5868 - val_loss: 1.4351 - val_categorical_accuracy: 0.5990\n",
      "Epoch 406/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.3665 - categorical_accuracy: 0.5873 - val_loss: 1.4079 - val_categorical_accuracy: 0.6077\n",
      "Epoch 407/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.4199 - categorical_accuracy: 0.5654 - val_loss: 1.4238 - val_categorical_accuracy: 0.5953\n",
      "Epoch 408/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.4022 - categorical_accuracy: 0.5659 - val_loss: 1.4344 - val_categorical_accuracy: 0.6027\n",
      "Epoch 409/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3262 - categorical_accuracy: 0.5905 - val_loss: 1.4518 - val_categorical_accuracy: 0.5928\n",
      "Epoch 410/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.3607 - categorical_accuracy: 0.5723 - val_loss: 1.5451 - val_categorical_accuracy: 0.5567\n",
      "Epoch 411/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.3488 - categorical_accuracy: 0.5820 - val_loss: 1.5052 - val_categorical_accuracy: 0.5654\n",
      "Epoch 412/5000\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 1.3789 - categorical_accuracy: 0.5670 - val_loss: 1.4812 - val_categorical_accuracy: 0.5940\n",
      "Epoch 413/5000\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 1.4115 - categorical_accuracy: 0.5830 - val_loss: 1.4701 - val_categorical_accuracy: 0.5965\n",
      "Epoch 414/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.4213 - categorical_accuracy: 0.5622 - val_loss: 1.3196 - val_categorical_accuracy: 0.6227\n",
      "Epoch 415/5000\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 1.3877 - categorical_accuracy: 0.5825 - val_loss: 1.3896 - val_categorical_accuracy: 0.6127\n",
      "Epoch 416/5000\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 1.3553 - categorical_accuracy: 0.5745 - val_loss: 1.4475 - val_categorical_accuracy: 0.5791\n",
      "Epoch 417/5000\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.3334 - categorical_accuracy: 0.5953 - val_loss: 1.4942 - val_categorical_accuracy: 0.5791\n",
      "Epoch 418/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.3259 - categorical_accuracy: 0.5921 - val_loss: 1.3593 - val_categorical_accuracy: 0.6164\n",
      "Epoch 419/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.3777 - categorical_accuracy: 0.5745 - val_loss: 1.3603 - val_categorical_accuracy: 0.6115\n",
      "Epoch 420/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3196 - categorical_accuracy: 0.5953 - val_loss: 1.3634 - val_categorical_accuracy: 0.6152\n",
      "Epoch 421/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.3487 - categorical_accuracy: 0.5729 - val_loss: 1.4027 - val_categorical_accuracy: 0.6077\n",
      "Epoch 422/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.3534 - categorical_accuracy: 0.5755 - val_loss: 1.4050 - val_categorical_accuracy: 0.6027\n",
      "Epoch 423/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.3654 - categorical_accuracy: 0.5777 - val_loss: 1.3575 - val_categorical_accuracy: 0.6065\n",
      "Epoch 424/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.3370 - categorical_accuracy: 0.6001 - val_loss: 1.4146 - val_categorical_accuracy: 0.6052\n",
      "Epoch 425/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.3449 - categorical_accuracy: 0.5985 - val_loss: 1.4663 - val_categorical_accuracy: 0.5866\n",
      "Epoch 426/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.3902 - categorical_accuracy: 0.5713 - val_loss: 1.4806 - val_categorical_accuracy: 0.5679\n",
      "Epoch 427/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.3963 - categorical_accuracy: 0.5771 - val_loss: 1.3871 - val_categorical_accuracy: 0.6127\n",
      "Epoch 428/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.3071 - categorical_accuracy: 0.6076 - val_loss: 1.4068 - val_categorical_accuracy: 0.6164\n",
      "Epoch 429/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.3909 - categorical_accuracy: 0.5729 - val_loss: 1.4152 - val_categorical_accuracy: 0.6115\n",
      "Epoch 430/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.3760 - categorical_accuracy: 0.5809 - val_loss: 1.4103 - val_categorical_accuracy: 0.6015\n",
      "Epoch 431/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.3656 - categorical_accuracy: 0.5825 - val_loss: 1.4076 - val_categorical_accuracy: 0.5903\n",
      "Epoch 432/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3024 - categorical_accuracy: 0.5894 - val_loss: 1.3799 - val_categorical_accuracy: 0.6115\n",
      "Epoch 433/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.2835 - categorical_accuracy: 0.5990 - val_loss: 1.4889 - val_categorical_accuracy: 0.5866\n",
      "Epoch 434/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.3332 - categorical_accuracy: 0.5894 - val_loss: 1.4040 - val_categorical_accuracy: 0.6015\n",
      "Epoch 435/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3022 - categorical_accuracy: 0.5958 - val_loss: 1.4521 - val_categorical_accuracy: 0.5841\n",
      "Epoch 436/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.3516 - categorical_accuracy: 0.5889 - val_loss: 1.4260 - val_categorical_accuracy: 0.5828\n",
      "Epoch 437/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.3575 - categorical_accuracy: 0.5884 - val_loss: 1.4580 - val_categorical_accuracy: 0.5828\n",
      "Epoch 438/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3310 - categorical_accuracy: 0.5820 - val_loss: 1.4657 - val_categorical_accuracy: 0.5778\n",
      "Epoch 439/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3270 - categorical_accuracy: 0.5793 - val_loss: 1.4657 - val_categorical_accuracy: 0.5890\n",
      "Epoch 440/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3068 - categorical_accuracy: 0.5953 - val_loss: 1.5230 - val_categorical_accuracy: 0.5579\n",
      "Epoch 441/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.3263 - categorical_accuracy: 0.5942 - val_loss: 1.4420 - val_categorical_accuracy: 0.6040\n",
      "Epoch 442/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3606 - categorical_accuracy: 0.5852 - val_loss: 1.4353 - val_categorical_accuracy: 0.5828\n",
      "Epoch 443/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3714 - categorical_accuracy: 0.5766 - val_loss: 1.4379 - val_categorical_accuracy: 0.5766\n",
      "Epoch 444/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3634 - categorical_accuracy: 0.5878 - val_loss: 1.4731 - val_categorical_accuracy: 0.5691\n",
      "Epoch 445/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3745 - categorical_accuracy: 0.5921 - val_loss: 1.6479 - val_categorical_accuracy: 0.5205\n",
      "Epoch 446/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3121 - categorical_accuracy: 0.5964 - val_loss: 1.4083 - val_categorical_accuracy: 0.5890\n",
      "Epoch 447/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2881 - categorical_accuracy: 0.6070 - val_loss: 1.4411 - val_categorical_accuracy: 0.5878\n",
      "Epoch 448/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3401 - categorical_accuracy: 0.5825 - val_loss: 1.4206 - val_categorical_accuracy: 0.5878\n",
      "Epoch 449/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3460 - categorical_accuracy: 0.5889 - val_loss: 1.4520 - val_categorical_accuracy: 0.5978\n",
      "Epoch 450/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3374 - categorical_accuracy: 0.5948 - val_loss: 1.4071 - val_categorical_accuracy: 0.5953\n",
      "Epoch 451/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3044 - categorical_accuracy: 0.5926 - val_loss: 1.4076 - val_categorical_accuracy: 0.5903\n",
      "Epoch 452/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3464 - categorical_accuracy: 0.5884 - val_loss: 1.3870 - val_categorical_accuracy: 0.6189\n",
      "Epoch 453/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3446 - categorical_accuracy: 0.5916 - val_loss: 1.4201 - val_categorical_accuracy: 0.5953\n",
      "Epoch 454/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3001 - categorical_accuracy: 0.6167 - val_loss: 1.4409 - val_categorical_accuracy: 0.5978\n",
      "Epoch 455/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.3339 - categorical_accuracy: 0.6038 - val_loss: 1.4649 - val_categorical_accuracy: 0.5828\n",
      "Epoch 456/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3596 - categorical_accuracy: 0.5793 - val_loss: 1.4409 - val_categorical_accuracy: 0.5866\n",
      "Epoch 457/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2956 - categorical_accuracy: 0.6119 - val_loss: 1.4355 - val_categorical_accuracy: 0.5853\n",
      "Epoch 458/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3170 - categorical_accuracy: 0.5932 - val_loss: 1.4480 - val_categorical_accuracy: 0.5778\n",
      "Epoch 459/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3352 - categorical_accuracy: 0.5937 - val_loss: 1.4844 - val_categorical_accuracy: 0.5579\n",
      "Epoch 460/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3072 - categorical_accuracy: 0.5964 - val_loss: 1.4561 - val_categorical_accuracy: 0.5965\n",
      "Epoch 461/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3154 - categorical_accuracy: 0.5974 - val_loss: 1.4393 - val_categorical_accuracy: 0.6102\n",
      "Epoch 462/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2973 - categorical_accuracy: 0.6065 - val_loss: 1.4892 - val_categorical_accuracy: 0.5878\n",
      "Epoch 463/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3305 - categorical_accuracy: 0.5889 - val_loss: 1.4559 - val_categorical_accuracy: 0.5978\n",
      "Epoch 464/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3452 - categorical_accuracy: 0.5942 - val_loss: 1.4510 - val_categorical_accuracy: 0.6164\n",
      "Epoch 465/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3212 - categorical_accuracy: 0.5969 - val_loss: 1.4021 - val_categorical_accuracy: 0.5940\n",
      "Epoch 466/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2861 - categorical_accuracy: 0.6044 - val_loss: 1.4535 - val_categorical_accuracy: 0.6065\n",
      "Epoch 467/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3066 - categorical_accuracy: 0.6038 - val_loss: 1.4551 - val_categorical_accuracy: 0.5803\n",
      "Epoch 468/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3261 - categorical_accuracy: 0.6060 - val_loss: 1.6139 - val_categorical_accuracy: 0.5666\n",
      "Epoch 469/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3444 - categorical_accuracy: 0.5809 - val_loss: 1.5166 - val_categorical_accuracy: 0.5778\n",
      "Epoch 470/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3527 - categorical_accuracy: 0.5900 - val_loss: 1.4722 - val_categorical_accuracy: 0.5965\n",
      "Epoch 471/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3097 - categorical_accuracy: 0.5814 - val_loss: 1.5516 - val_categorical_accuracy: 0.5704\n",
      "Epoch 472/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3338 - categorical_accuracy: 0.5905 - val_loss: 1.4407 - val_categorical_accuracy: 0.6077\n",
      "Epoch 473/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3523 - categorical_accuracy: 0.5852 - val_loss: 1.4275 - val_categorical_accuracy: 0.6326\n",
      "Epoch 474/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3136 - categorical_accuracy: 0.5969 - val_loss: 1.4875 - val_categorical_accuracy: 0.6002\n",
      "Epoch 475/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2785 - categorical_accuracy: 0.6167 - val_loss: 1.4270 - val_categorical_accuracy: 0.6040\n",
      "Epoch 476/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3466 - categorical_accuracy: 0.5916 - val_loss: 1.4467 - val_categorical_accuracy: 0.5953\n",
      "Epoch 477/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2712 - categorical_accuracy: 0.6054 - val_loss: 1.4131 - val_categorical_accuracy: 0.6301\n",
      "Epoch 478/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3233 - categorical_accuracy: 0.5974 - val_loss: 1.4182 - val_categorical_accuracy: 0.5990\n",
      "Epoch 479/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3421 - categorical_accuracy: 0.5916 - val_loss: 1.3906 - val_categorical_accuracy: 0.5978\n",
      "Epoch 480/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3090 - categorical_accuracy: 0.6054 - val_loss: 1.4761 - val_categorical_accuracy: 0.5716\n",
      "Epoch 481/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3222 - categorical_accuracy: 0.6044 - val_loss: 1.3979 - val_categorical_accuracy: 0.6002\n",
      "Epoch 482/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3744 - categorical_accuracy: 0.5857 - val_loss: 1.4494 - val_categorical_accuracy: 0.5853\n",
      "Epoch 483/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2290 - categorical_accuracy: 0.6172 - val_loss: 1.4892 - val_categorical_accuracy: 0.5940\n",
      "Epoch 484/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.2723 - categorical_accuracy: 0.5980 - val_loss: 1.4140 - val_categorical_accuracy: 0.6102\n",
      "Epoch 485/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3242 - categorical_accuracy: 0.5969 - val_loss: 1.4263 - val_categorical_accuracy: 0.6252\n",
      "Epoch 486/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3290 - categorical_accuracy: 0.5916 - val_loss: 1.4041 - val_categorical_accuracy: 0.5965\n",
      "Epoch 487/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3099 - categorical_accuracy: 0.5942 - val_loss: 1.4148 - val_categorical_accuracy: 0.5878\n",
      "Epoch 488/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3178 - categorical_accuracy: 0.5937 - val_loss: 1.5053 - val_categorical_accuracy: 0.5542\n",
      "Epoch 489/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2718 - categorical_accuracy: 0.5980 - val_loss: 1.4196 - val_categorical_accuracy: 0.5890\n",
      "Epoch 490/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2676 - categorical_accuracy: 0.6204 - val_loss: 1.4491 - val_categorical_accuracy: 0.5753\n",
      "Epoch 491/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2741 - categorical_accuracy: 0.6054 - val_loss: 1.4345 - val_categorical_accuracy: 0.6090\n",
      "Epoch 492/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2983 - categorical_accuracy: 0.5980 - val_loss: 1.5199 - val_categorical_accuracy: 0.5766\n",
      "Epoch 493/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3622 - categorical_accuracy: 0.5990 - val_loss: 1.4091 - val_categorical_accuracy: 0.6065\n",
      "Epoch 494/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3223 - categorical_accuracy: 0.5841 - val_loss: 1.4080 - val_categorical_accuracy: 0.6139\n",
      "Epoch 495/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3338 - categorical_accuracy: 0.5830 - val_loss: 1.3994 - val_categorical_accuracy: 0.6002\n",
      "Epoch 496/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2449 - categorical_accuracy: 0.6145 - val_loss: 1.4274 - val_categorical_accuracy: 0.5928\n",
      "Epoch 497/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3024 - categorical_accuracy: 0.6001 - val_loss: 1.3971 - val_categorical_accuracy: 0.5878\n",
      "Epoch 498/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3224 - categorical_accuracy: 0.5798 - val_loss: 1.5178 - val_categorical_accuracy: 0.5741\n",
      "Epoch 499/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3054 - categorical_accuracy: 0.6070 - val_loss: 1.4708 - val_categorical_accuracy: 0.5778\n",
      "Epoch 500/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3019 - categorical_accuracy: 0.6038 - val_loss: 1.4218 - val_categorical_accuracy: 0.5903\n",
      "Epoch 501/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2825 - categorical_accuracy: 0.6022 - val_loss: 1.4918 - val_categorical_accuracy: 0.5853\n",
      "Epoch 502/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3334 - categorical_accuracy: 0.5942 - val_loss: 1.4044 - val_categorical_accuracy: 0.6002\n",
      "Epoch 503/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2836 - categorical_accuracy: 0.6060 - val_loss: 1.4709 - val_categorical_accuracy: 0.5878\n",
      "Epoch 504/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3701 - categorical_accuracy: 0.5905 - val_loss: 1.4235 - val_categorical_accuracy: 0.5866\n",
      "Epoch 505/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3208 - categorical_accuracy: 0.6065 - val_loss: 1.4512 - val_categorical_accuracy: 0.5890\n",
      "Epoch 506/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2520 - categorical_accuracy: 0.6236 - val_loss: 1.5227 - val_categorical_accuracy: 0.5367\n",
      "Epoch 507/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.3113 - categorical_accuracy: 0.6017 - val_loss: 1.4398 - val_categorical_accuracy: 0.5878\n",
      "Epoch 508/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2978 - categorical_accuracy: 0.6124 - val_loss: 1.4231 - val_categorical_accuracy: 0.5691\n",
      "Epoch 509/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.2775 - categorical_accuracy: 0.6081 - val_loss: 1.4110 - val_categorical_accuracy: 0.5903\n",
      "Epoch 510/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3324 - categorical_accuracy: 0.5868 - val_loss: 1.4248 - val_categorical_accuracy: 0.5953\n",
      "Epoch 511/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.2784 - categorical_accuracy: 0.6113 - val_loss: 1.4696 - val_categorical_accuracy: 0.5778\n",
      "Epoch 512/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.3098 - categorical_accuracy: 0.6022 - val_loss: 1.4379 - val_categorical_accuracy: 0.6189\n",
      "Epoch 513/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2756 - categorical_accuracy: 0.6033 - val_loss: 1.3954 - val_categorical_accuracy: 0.6115\n",
      "Epoch 514/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3048 - categorical_accuracy: 0.6113 - val_loss: 1.4672 - val_categorical_accuracy: 0.5791\n",
      "Epoch 515/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2973 - categorical_accuracy: 0.6103 - val_loss: 1.4121 - val_categorical_accuracy: 0.5928\n",
      "Epoch 516/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2259 - categorical_accuracy: 0.6151 - val_loss: 1.4561 - val_categorical_accuracy: 0.5940\n",
      "Epoch 517/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2970 - categorical_accuracy: 0.6204 - val_loss: 1.5139 - val_categorical_accuracy: 0.5890\n",
      "Epoch 518/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3167 - categorical_accuracy: 0.5889 - val_loss: 1.4859 - val_categorical_accuracy: 0.5853\n",
      "Epoch 519/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2843 - categorical_accuracy: 0.6001 - val_loss: 1.4867 - val_categorical_accuracy: 0.6065\n",
      "Epoch 520/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2465 - categorical_accuracy: 0.6241 - val_loss: 1.3988 - val_categorical_accuracy: 0.6164\n",
      "Epoch 521/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2980 - categorical_accuracy: 0.6124 - val_loss: 1.4664 - val_categorical_accuracy: 0.6189\n",
      "Epoch 522/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2927 - categorical_accuracy: 0.6177 - val_loss: 1.4624 - val_categorical_accuracy: 0.6077\n",
      "Epoch 523/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3415 - categorical_accuracy: 0.5889 - val_loss: 1.4448 - val_categorical_accuracy: 0.5978\n",
      "Epoch 524/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3167 - categorical_accuracy: 0.5974 - val_loss: 1.5697 - val_categorical_accuracy: 0.5641\n",
      "Epoch 525/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3197 - categorical_accuracy: 0.6049 - val_loss: 1.4871 - val_categorical_accuracy: 0.5704\n",
      "Epoch 526/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2839 - categorical_accuracy: 0.5969 - val_loss: 1.4399 - val_categorical_accuracy: 0.6040\n",
      "Epoch 527/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2834 - categorical_accuracy: 0.6070 - val_loss: 1.4488 - val_categorical_accuracy: 0.6015\n",
      "Epoch 528/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3369 - categorical_accuracy: 0.5921 - val_loss: 1.4746 - val_categorical_accuracy: 0.5866\n",
      "Epoch 529/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2954 - categorical_accuracy: 0.6177 - val_loss: 1.5001 - val_categorical_accuracy: 0.5928\n",
      "Epoch 530/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2630 - categorical_accuracy: 0.6199 - val_loss: 1.4771 - val_categorical_accuracy: 0.6065\n",
      "Epoch 531/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2763 - categorical_accuracy: 0.6070 - val_loss: 1.4231 - val_categorical_accuracy: 0.6040\n",
      "Epoch 532/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3085 - categorical_accuracy: 0.6028 - val_loss: 1.4310 - val_categorical_accuracy: 0.6027\n",
      "Epoch 533/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2598 - categorical_accuracy: 0.6177 - val_loss: 1.3988 - val_categorical_accuracy: 0.6040\n",
      "Epoch 534/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3238 - categorical_accuracy: 0.5894 - val_loss: 1.4147 - val_categorical_accuracy: 0.6027\n",
      "Epoch 535/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2705 - categorical_accuracy: 0.5969 - val_loss: 1.4774 - val_categorical_accuracy: 0.5890\n",
      "Epoch 536/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2571 - categorical_accuracy: 0.5948 - val_loss: 1.5174 - val_categorical_accuracy: 0.5691\n",
      "Epoch 537/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2456 - categorical_accuracy: 0.6177 - val_loss: 1.5207 - val_categorical_accuracy: 0.5878\n",
      "Epoch 538/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2684 - categorical_accuracy: 0.6145 - val_loss: 1.5049 - val_categorical_accuracy: 0.5853\n",
      "Epoch 539/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2591 - categorical_accuracy: 0.6086 - val_loss: 1.4168 - val_categorical_accuracy: 0.6002\n",
      "Epoch 540/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2672 - categorical_accuracy: 0.6108 - val_loss: 1.4954 - val_categorical_accuracy: 0.6015\n",
      "Epoch 541/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2331 - categorical_accuracy: 0.6076 - val_loss: 1.4982 - val_categorical_accuracy: 0.5803\n",
      "Epoch 542/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3055 - categorical_accuracy: 0.6097 - val_loss: 1.5097 - val_categorical_accuracy: 0.5841\n",
      "Epoch 543/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3414 - categorical_accuracy: 0.5852 - val_loss: 1.4559 - val_categorical_accuracy: 0.5965\n",
      "Epoch 544/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2756 - categorical_accuracy: 0.6033 - val_loss: 1.4189 - val_categorical_accuracy: 0.5965\n",
      "Epoch 545/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3107 - categorical_accuracy: 0.5974 - val_loss: 1.4508 - val_categorical_accuracy: 0.6052\n",
      "Epoch 546/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.2846 - categorical_accuracy: 0.6076 - val_loss: 1.4729 - val_categorical_accuracy: 0.5816\n",
      "Epoch 547/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2874 - categorical_accuracy: 0.6006 - val_loss: 1.4765 - val_categorical_accuracy: 0.5691\n",
      "Epoch 548/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2673 - categorical_accuracy: 0.6097 - val_loss: 1.4802 - val_categorical_accuracy: 0.5890\n",
      "Epoch 549/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3132 - categorical_accuracy: 0.5990 - val_loss: 1.4158 - val_categorical_accuracy: 0.5903\n",
      "Epoch 550/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2832 - categorical_accuracy: 0.6081 - val_loss: 1.4155 - val_categorical_accuracy: 0.5878\n",
      "Epoch 551/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2679 - categorical_accuracy: 0.6081 - val_loss: 1.4390 - val_categorical_accuracy: 0.5940\n",
      "Epoch 552/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2381 - categorical_accuracy: 0.6108 - val_loss: 1.4355 - val_categorical_accuracy: 0.5878\n",
      "Epoch 553/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2596 - categorical_accuracy: 0.6108 - val_loss: 1.4773 - val_categorical_accuracy: 0.5791\n",
      "Epoch 554/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2827 - categorical_accuracy: 0.5996 - val_loss: 1.4604 - val_categorical_accuracy: 0.5753\n",
      "Epoch 555/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3138 - categorical_accuracy: 0.6081 - val_loss: 1.4450 - val_categorical_accuracy: 0.5915\n",
      "Epoch 556/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2295 - categorical_accuracy: 0.6268 - val_loss: 1.5140 - val_categorical_accuracy: 0.5654\n",
      "Epoch 557/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3339 - categorical_accuracy: 0.5926 - val_loss: 1.4149 - val_categorical_accuracy: 0.5953\n",
      "Epoch 558/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2441 - categorical_accuracy: 0.6193 - val_loss: 1.4117 - val_categorical_accuracy: 0.6152\n",
      "Epoch 559/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2867 - categorical_accuracy: 0.6076 - val_loss: 1.3865 - val_categorical_accuracy: 0.6264\n",
      "Epoch 560/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2346 - categorical_accuracy: 0.6183 - val_loss: 1.4631 - val_categorical_accuracy: 0.6102\n",
      "Epoch 561/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2824 - categorical_accuracy: 0.6054 - val_loss: 1.5128 - val_categorical_accuracy: 0.6002\n",
      "Epoch 562/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2520 - categorical_accuracy: 0.6113 - val_loss: 1.4718 - val_categorical_accuracy: 0.5990\n",
      "Epoch 563/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2679 - categorical_accuracy: 0.6124 - val_loss: 1.4471 - val_categorical_accuracy: 0.5878\n",
      "Epoch 564/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2847 - categorical_accuracy: 0.6119 - val_loss: 1.4185 - val_categorical_accuracy: 0.6164\n",
      "Epoch 565/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2512 - categorical_accuracy: 0.6145 - val_loss: 1.4990 - val_categorical_accuracy: 0.6139\n",
      "Epoch 566/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2753 - categorical_accuracy: 0.6188 - val_loss: 1.4348 - val_categorical_accuracy: 0.6139\n",
      "Epoch 567/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2537 - categorical_accuracy: 0.6119 - val_loss: 1.4466 - val_categorical_accuracy: 0.6102\n",
      "Epoch 568/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2889 - categorical_accuracy: 0.6097 - val_loss: 1.4145 - val_categorical_accuracy: 0.6040\n",
      "Epoch 569/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2958 - categorical_accuracy: 0.5953 - val_loss: 1.4201 - val_categorical_accuracy: 0.6115\n",
      "Epoch 570/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2784 - categorical_accuracy: 0.6022 - val_loss: 1.4252 - val_categorical_accuracy: 0.5878\n",
      "Epoch 571/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2704 - categorical_accuracy: 0.6129 - val_loss: 1.5247 - val_categorical_accuracy: 0.5753\n",
      "Epoch 572/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2441 - categorical_accuracy: 0.6124 - val_loss: 1.4581 - val_categorical_accuracy: 0.5990\n",
      "Epoch 573/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2739 - categorical_accuracy: 0.6103 - val_loss: 1.4725 - val_categorical_accuracy: 0.5990\n",
      "Epoch 574/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.2540 - categorical_accuracy: 0.6199 - val_loss: 1.4471 - val_categorical_accuracy: 0.6015\n",
      "Epoch 575/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2704 - categorical_accuracy: 0.6209 - val_loss: 1.4812 - val_categorical_accuracy: 0.5803\n",
      "Epoch 576/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.2510 - categorical_accuracy: 0.6279 - val_loss: 1.5323 - val_categorical_accuracy: 0.5704\n",
      "Epoch 577/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2609 - categorical_accuracy: 0.6183 - val_loss: 1.4934 - val_categorical_accuracy: 0.5853\n",
      "Epoch 578/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2880 - categorical_accuracy: 0.6017 - val_loss: 1.4975 - val_categorical_accuracy: 0.5953\n",
      "Epoch 579/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2741 - categorical_accuracy: 0.5958 - val_loss: 1.4201 - val_categorical_accuracy: 0.5928\n",
      "Epoch 580/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3079 - categorical_accuracy: 0.6086 - val_loss: 1.4785 - val_categorical_accuracy: 0.5766\n",
      "Epoch 581/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3061 - categorical_accuracy: 0.6065 - val_loss: 1.4610 - val_categorical_accuracy: 0.5803\n",
      "Epoch 582/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2833 - categorical_accuracy: 0.6076 - val_loss: 1.4106 - val_categorical_accuracy: 0.5940\n",
      "Epoch 583/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3275 - categorical_accuracy: 0.6044 - val_loss: 1.4278 - val_categorical_accuracy: 0.6077\n",
      "Epoch 584/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2620 - categorical_accuracy: 0.6199 - val_loss: 1.4787 - val_categorical_accuracy: 0.6040\n",
      "Epoch 585/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1768 - categorical_accuracy: 0.6247 - val_loss: 1.5087 - val_categorical_accuracy: 0.5741\n",
      "Epoch 586/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2526 - categorical_accuracy: 0.6108 - val_loss: 1.4364 - val_categorical_accuracy: 0.5990\n",
      "Epoch 587/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2640 - categorical_accuracy: 0.6097 - val_loss: 1.4520 - val_categorical_accuracy: 0.5903\n",
      "Epoch 588/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2180 - categorical_accuracy: 0.6183 - val_loss: 1.3971 - val_categorical_accuracy: 0.6102\n",
      "Epoch 589/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2698 - categorical_accuracy: 0.6033 - val_loss: 1.4258 - val_categorical_accuracy: 0.6202\n",
      "Epoch 590/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2748 - categorical_accuracy: 0.6076 - val_loss: 1.4311 - val_categorical_accuracy: 0.6090\n",
      "Epoch 591/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2500 - categorical_accuracy: 0.6108 - val_loss: 1.4045 - val_categorical_accuracy: 0.6115\n",
      "Epoch 592/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2036 - categorical_accuracy: 0.6353 - val_loss: 1.4715 - val_categorical_accuracy: 0.5928\n",
      "Epoch 593/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3037 - categorical_accuracy: 0.6140 - val_loss: 1.4417 - val_categorical_accuracy: 0.5928\n",
      "Epoch 594/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1946 - categorical_accuracy: 0.6407 - val_loss: 1.4014 - val_categorical_accuracy: 0.6015\n",
      "Epoch 595/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2554 - categorical_accuracy: 0.6006 - val_loss: 1.4992 - val_categorical_accuracy: 0.5903\n",
      "Epoch 596/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2244 - categorical_accuracy: 0.6209 - val_loss: 1.4865 - val_categorical_accuracy: 0.5940\n",
      "Epoch 597/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2322 - categorical_accuracy: 0.6311 - val_loss: 1.4435 - val_categorical_accuracy: 0.5940\n",
      "Epoch 598/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2184 - categorical_accuracy: 0.6236 - val_loss: 1.4305 - val_categorical_accuracy: 0.6139\n",
      "Epoch 599/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2505 - categorical_accuracy: 0.6108 - val_loss: 1.4033 - val_categorical_accuracy: 0.6139\n",
      "Epoch 600/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2276 - categorical_accuracy: 0.6177 - val_loss: 1.4427 - val_categorical_accuracy: 0.5990\n",
      "Epoch 601/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2510 - categorical_accuracy: 0.6231 - val_loss: 1.4983 - val_categorical_accuracy: 0.5803\n",
      "Epoch 602/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2613 - categorical_accuracy: 0.6172 - val_loss: 1.4913 - val_categorical_accuracy: 0.5965\n",
      "Epoch 603/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1742 - categorical_accuracy: 0.6300 - val_loss: 1.5285 - val_categorical_accuracy: 0.5704\n",
      "Epoch 604/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2420 - categorical_accuracy: 0.6215 - val_loss: 1.5457 - val_categorical_accuracy: 0.5579\n",
      "Epoch 605/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.1914 - categorical_accuracy: 0.6231 - val_loss: 1.5156 - val_categorical_accuracy: 0.5841\n",
      "Epoch 606/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2498 - categorical_accuracy: 0.6193 - val_loss: 1.4940 - val_categorical_accuracy: 0.5828\n",
      "Epoch 607/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.3167 - categorical_accuracy: 0.5862 - val_loss: 1.4679 - val_categorical_accuracy: 0.5866\n",
      "Epoch 608/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1813 - categorical_accuracy: 0.6418 - val_loss: 1.4973 - val_categorical_accuracy: 0.5915\n",
      "Epoch 609/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2686 - categorical_accuracy: 0.6044 - val_loss: 1.5434 - val_categorical_accuracy: 0.5729\n",
      "Epoch 610/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2415 - categorical_accuracy: 0.6135 - val_loss: 1.5038 - val_categorical_accuracy: 0.5928\n",
      "Epoch 611/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2253 - categorical_accuracy: 0.6113 - val_loss: 1.4563 - val_categorical_accuracy: 0.5890\n",
      "Epoch 612/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3309 - categorical_accuracy: 0.5900 - val_loss: 1.5638 - val_categorical_accuracy: 0.5816\n",
      "Epoch 613/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2432 - categorical_accuracy: 0.6113 - val_loss: 1.5901 - val_categorical_accuracy: 0.5616\n",
      "Epoch 614/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2521 - categorical_accuracy: 0.6193 - val_loss: 1.4770 - val_categorical_accuracy: 0.5853\n",
      "Epoch 615/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2506 - categorical_accuracy: 0.6257 - val_loss: 1.4888 - val_categorical_accuracy: 0.5791\n",
      "Epoch 616/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2681 - categorical_accuracy: 0.6044 - val_loss: 1.5006 - val_categorical_accuracy: 0.5928\n",
      "Epoch 617/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2717 - categorical_accuracy: 0.6241 - val_loss: 1.4925 - val_categorical_accuracy: 0.5915\n",
      "Epoch 618/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2349 - categorical_accuracy: 0.6231 - val_loss: 1.4818 - val_categorical_accuracy: 0.5978\n",
      "Epoch 619/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2201 - categorical_accuracy: 0.6156 - val_loss: 1.5016 - val_categorical_accuracy: 0.5928\n",
      "Epoch 620/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2697 - categorical_accuracy: 0.6113 - val_loss: 1.5413 - val_categorical_accuracy: 0.5940\n",
      "Epoch 621/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.3444 - categorical_accuracy: 0.5958 - val_loss: 1.4938 - val_categorical_accuracy: 0.5903\n",
      "Epoch 622/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1896 - categorical_accuracy: 0.6300 - val_loss: 1.5107 - val_categorical_accuracy: 0.5666\n",
      "Epoch 623/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2408 - categorical_accuracy: 0.6220 - val_loss: 1.5478 - val_categorical_accuracy: 0.5878\n",
      "Epoch 624/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2618 - categorical_accuracy: 0.6119 - val_loss: 1.4729 - val_categorical_accuracy: 0.5878\n",
      "Epoch 625/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2446 - categorical_accuracy: 0.6022 - val_loss: 1.5008 - val_categorical_accuracy: 0.5841\n",
      "Epoch 626/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2563 - categorical_accuracy: 0.6092 - val_loss: 1.4952 - val_categorical_accuracy: 0.5978\n",
      "Epoch 627/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2394 - categorical_accuracy: 0.6151 - val_loss: 1.4808 - val_categorical_accuracy: 0.5853\n",
      "Epoch 628/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2470 - categorical_accuracy: 0.6188 - val_loss: 1.4906 - val_categorical_accuracy: 0.6040\n",
      "Epoch 629/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2483 - categorical_accuracy: 0.6097 - val_loss: 1.5297 - val_categorical_accuracy: 0.5853\n",
      "Epoch 630/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2313 - categorical_accuracy: 0.6268 - val_loss: 1.5108 - val_categorical_accuracy: 0.5853\n",
      "Epoch 631/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2089 - categorical_accuracy: 0.6257 - val_loss: 1.4693 - val_categorical_accuracy: 0.6027\n",
      "Epoch 632/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2063 - categorical_accuracy: 0.6455 - val_loss: 1.4818 - val_categorical_accuracy: 0.5753\n",
      "Epoch 633/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2131 - categorical_accuracy: 0.6273 - val_loss: 1.5080 - val_categorical_accuracy: 0.5853\n",
      "Epoch 634/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2604 - categorical_accuracy: 0.6097 - val_loss: 1.5093 - val_categorical_accuracy: 0.5828\n",
      "Epoch 635/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2502 - categorical_accuracy: 0.6001 - val_loss: 1.5200 - val_categorical_accuracy: 0.5890\n",
      "Epoch 636/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2722 - categorical_accuracy: 0.6086 - val_loss: 1.5014 - val_categorical_accuracy: 0.6002\n",
      "Epoch 637/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1930 - categorical_accuracy: 0.6508 - val_loss: 1.5101 - val_categorical_accuracy: 0.5978\n",
      "Epoch 638/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2601 - categorical_accuracy: 0.6070 - val_loss: 1.4522 - val_categorical_accuracy: 0.5978\n",
      "Epoch 639/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2262 - categorical_accuracy: 0.6236 - val_loss: 1.4756 - val_categorical_accuracy: 0.5903\n",
      "Epoch 640/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2351 - categorical_accuracy: 0.6236 - val_loss: 1.4511 - val_categorical_accuracy: 0.6077\n",
      "Epoch 641/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.2544 - categorical_accuracy: 0.6273 - val_loss: 1.5751 - val_categorical_accuracy: 0.5766\n",
      "Epoch 642/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1984 - categorical_accuracy: 0.6199 - val_loss: 1.4580 - val_categorical_accuracy: 0.5915\n",
      "Epoch 643/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1916 - categorical_accuracy: 0.6284 - val_loss: 1.3935 - val_categorical_accuracy: 0.6152\n",
      "Epoch 644/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2203 - categorical_accuracy: 0.6327 - val_loss: 1.4403 - val_categorical_accuracy: 0.6102\n",
      "Epoch 645/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2262 - categorical_accuracy: 0.6236 - val_loss: 1.4056 - val_categorical_accuracy: 0.5890\n",
      "Epoch 646/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2301 - categorical_accuracy: 0.6167 - val_loss: 1.4495 - val_categorical_accuracy: 0.6239\n",
      "Epoch 647/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2333 - categorical_accuracy: 0.6247 - val_loss: 1.5035 - val_categorical_accuracy: 0.5791\n",
      "Epoch 648/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2673 - categorical_accuracy: 0.6167 - val_loss: 1.4719 - val_categorical_accuracy: 0.6040\n",
      "Epoch 649/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2481 - categorical_accuracy: 0.6156 - val_loss: 1.4557 - val_categorical_accuracy: 0.6102\n",
      "Epoch 650/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1992 - categorical_accuracy: 0.6279 - val_loss: 1.4757 - val_categorical_accuracy: 0.5890\n",
      "Epoch 651/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2399 - categorical_accuracy: 0.6177 - val_loss: 1.4656 - val_categorical_accuracy: 0.5890\n",
      "Epoch 652/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2314 - categorical_accuracy: 0.6241 - val_loss: 1.3980 - val_categorical_accuracy: 0.6115\n",
      "Epoch 653/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2081 - categorical_accuracy: 0.6316 - val_loss: 1.4470 - val_categorical_accuracy: 0.6164\n",
      "Epoch 654/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1893 - categorical_accuracy: 0.6337 - val_loss: 1.5488 - val_categorical_accuracy: 0.5903\n",
      "Epoch 655/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2964 - categorical_accuracy: 0.6124 - val_loss: 1.4355 - val_categorical_accuracy: 0.6090\n",
      "Epoch 656/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2237 - categorical_accuracy: 0.6279 - val_loss: 1.4499 - val_categorical_accuracy: 0.6040\n",
      "Epoch 657/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2643 - categorical_accuracy: 0.6193 - val_loss: 1.4254 - val_categorical_accuracy: 0.5965\n",
      "Epoch 658/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2436 - categorical_accuracy: 0.6172 - val_loss: 1.5207 - val_categorical_accuracy: 0.6040\n",
      "Epoch 659/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2240 - categorical_accuracy: 0.6236 - val_loss: 1.5217 - val_categorical_accuracy: 0.5890\n",
      "Epoch 660/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2051 - categorical_accuracy: 0.6316 - val_loss: 1.4710 - val_categorical_accuracy: 0.6115\n",
      "Epoch 661/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2165 - categorical_accuracy: 0.6289 - val_loss: 1.5584 - val_categorical_accuracy: 0.5766\n",
      "Epoch 662/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2250 - categorical_accuracy: 0.6209 - val_loss: 1.5479 - val_categorical_accuracy: 0.5741\n",
      "Epoch 663/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2431 - categorical_accuracy: 0.6247 - val_loss: 1.4542 - val_categorical_accuracy: 0.6040\n",
      "Epoch 664/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2313 - categorical_accuracy: 0.6241 - val_loss: 1.5035 - val_categorical_accuracy: 0.5890\n",
      "Epoch 665/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2321 - categorical_accuracy: 0.6156 - val_loss: 1.5407 - val_categorical_accuracy: 0.5928\n",
      "Epoch 666/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2156 - categorical_accuracy: 0.6204 - val_loss: 1.4419 - val_categorical_accuracy: 0.6227\n",
      "Epoch 667/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2513 - categorical_accuracy: 0.6209 - val_loss: 1.4988 - val_categorical_accuracy: 0.5853\n",
      "Epoch 668/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.2625 - categorical_accuracy: 0.6119 - val_loss: 1.5273 - val_categorical_accuracy: 0.5753\n",
      "Epoch 669/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2135 - categorical_accuracy: 0.6300 - val_loss: 1.4566 - val_categorical_accuracy: 0.6015\n",
      "Epoch 670/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2348 - categorical_accuracy: 0.6113 - val_loss: 1.4473 - val_categorical_accuracy: 0.6027\n",
      "Epoch 671/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2321 - categorical_accuracy: 0.6311 - val_loss: 1.4438 - val_categorical_accuracy: 0.6152\n",
      "Epoch 672/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2249 - categorical_accuracy: 0.6401 - val_loss: 1.4995 - val_categorical_accuracy: 0.5903\n",
      "Epoch 673/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2032 - categorical_accuracy: 0.6418 - val_loss: 1.5563 - val_categorical_accuracy: 0.5666\n",
      "Epoch 674/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2352 - categorical_accuracy: 0.6108 - val_loss: 1.4802 - val_categorical_accuracy: 0.5828\n",
      "Epoch 675/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1889 - categorical_accuracy: 0.6332 - val_loss: 1.4132 - val_categorical_accuracy: 0.5965\n",
      "Epoch 676/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2146 - categorical_accuracy: 0.6359 - val_loss: 1.4766 - val_categorical_accuracy: 0.5903\n",
      "Epoch 677/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2265 - categorical_accuracy: 0.6220 - val_loss: 1.4513 - val_categorical_accuracy: 0.6164\n",
      "Epoch 678/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2003 - categorical_accuracy: 0.6423 - val_loss: 1.4876 - val_categorical_accuracy: 0.5928\n",
      "Epoch 679/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1983 - categorical_accuracy: 0.6252 - val_loss: 1.4355 - val_categorical_accuracy: 0.6065\n",
      "Epoch 680/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1737 - categorical_accuracy: 0.6305 - val_loss: 1.4586 - val_categorical_accuracy: 0.5890\n",
      "Epoch 681/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2009 - categorical_accuracy: 0.6257 - val_loss: 1.4816 - val_categorical_accuracy: 0.5866\n",
      "Epoch 682/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2109 - categorical_accuracy: 0.6375 - val_loss: 1.4655 - val_categorical_accuracy: 0.6052\n",
      "Epoch 683/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1926 - categorical_accuracy: 0.6327 - val_loss: 1.4134 - val_categorical_accuracy: 0.6027\n",
      "Epoch 684/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2140 - categorical_accuracy: 0.6220 - val_loss: 1.4926 - val_categorical_accuracy: 0.5716\n",
      "Epoch 685/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2254 - categorical_accuracy: 0.6268 - val_loss: 1.4680 - val_categorical_accuracy: 0.6177\n",
      "Epoch 686/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2406 - categorical_accuracy: 0.6215 - val_loss: 1.4728 - val_categorical_accuracy: 0.6152\n",
      "Epoch 687/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2586 - categorical_accuracy: 0.6033 - val_loss: 1.5030 - val_categorical_accuracy: 0.5853\n",
      "Epoch 688/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2191 - categorical_accuracy: 0.6193 - val_loss: 1.4584 - val_categorical_accuracy: 0.6102\n",
      "Epoch 689/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2065 - categorical_accuracy: 0.6337 - val_loss: 1.5405 - val_categorical_accuracy: 0.5828\n",
      "Epoch 690/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2496 - categorical_accuracy: 0.6204 - val_loss: 1.6137 - val_categorical_accuracy: 0.5841\n",
      "Epoch 691/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2391 - categorical_accuracy: 0.6295 - val_loss: 1.5811 - val_categorical_accuracy: 0.5841\n",
      "Epoch 692/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2214 - categorical_accuracy: 0.6273 - val_loss: 1.5659 - val_categorical_accuracy: 0.5903\n",
      "Epoch 693/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2018 - categorical_accuracy: 0.6167 - val_loss: 1.5756 - val_categorical_accuracy: 0.5691\n",
      "Epoch 694/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2320 - categorical_accuracy: 0.6220 - val_loss: 1.4988 - val_categorical_accuracy: 0.6015\n",
      "Epoch 695/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2371 - categorical_accuracy: 0.6236 - val_loss: 1.5059 - val_categorical_accuracy: 0.5866\n",
      "Epoch 696/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1852 - categorical_accuracy: 0.6353 - val_loss: 1.5044 - val_categorical_accuracy: 0.5741\n",
      "Epoch 697/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1971 - categorical_accuracy: 0.6177 - val_loss: 1.5369 - val_categorical_accuracy: 0.5853\n",
      "Epoch 698/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2885 - categorical_accuracy: 0.6172 - val_loss: 1.4903 - val_categorical_accuracy: 0.5853\n",
      "Epoch 699/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2097 - categorical_accuracy: 0.6321 - val_loss: 1.5175 - val_categorical_accuracy: 0.5953\n",
      "Epoch 700/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.2022 - categorical_accuracy: 0.6257 - val_loss: 1.5291 - val_categorical_accuracy: 0.6015\n",
      "Epoch 701/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2176 - categorical_accuracy: 0.6252 - val_loss: 1.6195 - val_categorical_accuracy: 0.5691\n",
      "Epoch 702/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2170 - categorical_accuracy: 0.6263 - val_loss: 1.5128 - val_categorical_accuracy: 0.5978\n",
      "Epoch 703/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1964 - categorical_accuracy: 0.6401 - val_loss: 1.5375 - val_categorical_accuracy: 0.5903\n",
      "Epoch 704/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1898 - categorical_accuracy: 0.6337 - val_loss: 1.5284 - val_categorical_accuracy: 0.5853\n",
      "Epoch 705/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2198 - categorical_accuracy: 0.6305 - val_loss: 1.4843 - val_categorical_accuracy: 0.6164\n",
      "Epoch 706/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2159 - categorical_accuracy: 0.6295 - val_loss: 1.4893 - val_categorical_accuracy: 0.5778\n",
      "Epoch 707/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1737 - categorical_accuracy: 0.6391 - val_loss: 1.4958 - val_categorical_accuracy: 0.5953\n",
      "Epoch 708/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2374 - categorical_accuracy: 0.6263 - val_loss: 1.5470 - val_categorical_accuracy: 0.5853\n",
      "Epoch 709/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1804 - categorical_accuracy: 0.6423 - val_loss: 1.6147 - val_categorical_accuracy: 0.5691\n",
      "Epoch 710/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1469 - categorical_accuracy: 0.6401 - val_loss: 1.7368 - val_categorical_accuracy: 0.5666\n",
      "Epoch 711/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1992 - categorical_accuracy: 0.6466 - val_loss: 1.5414 - val_categorical_accuracy: 0.5978\n",
      "Epoch 712/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2369 - categorical_accuracy: 0.6161 - val_loss: 1.5619 - val_categorical_accuracy: 0.5716\n",
      "Epoch 713/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1778 - categorical_accuracy: 0.6396 - val_loss: 1.5287 - val_categorical_accuracy: 0.5878\n",
      "Epoch 714/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2163 - categorical_accuracy: 0.6305 - val_loss: 1.4334 - val_categorical_accuracy: 0.6252\n",
      "Epoch 715/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1992 - categorical_accuracy: 0.6316 - val_loss: 1.4413 - val_categorical_accuracy: 0.6027\n",
      "Epoch 716/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2009 - categorical_accuracy: 0.6300 - val_loss: 1.4894 - val_categorical_accuracy: 0.5978\n",
      "Epoch 717/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2065 - categorical_accuracy: 0.6311 - val_loss: 1.4699 - val_categorical_accuracy: 0.6015\n",
      "Epoch 718/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2269 - categorical_accuracy: 0.6305 - val_loss: 1.5101 - val_categorical_accuracy: 0.5928\n",
      "Epoch 719/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1190 - categorical_accuracy: 0.6551 - val_loss: 1.4912 - val_categorical_accuracy: 0.5816\n",
      "Epoch 720/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2349 - categorical_accuracy: 0.6140 - val_loss: 1.4630 - val_categorical_accuracy: 0.6027\n",
      "Epoch 721/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2227 - categorical_accuracy: 0.6369 - val_loss: 1.4256 - val_categorical_accuracy: 0.6139\n",
      "Epoch 722/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1879 - categorical_accuracy: 0.6321 - val_loss: 1.4869 - val_categorical_accuracy: 0.6177\n",
      "Epoch 723/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1861 - categorical_accuracy: 0.6423 - val_loss: 1.5687 - val_categorical_accuracy: 0.5691\n",
      "Epoch 724/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2463 - categorical_accuracy: 0.6199 - val_loss: 1.4981 - val_categorical_accuracy: 0.5965\n",
      "Epoch 725/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2064 - categorical_accuracy: 0.6305 - val_loss: 1.4610 - val_categorical_accuracy: 0.5940\n",
      "Epoch 726/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2202 - categorical_accuracy: 0.6263 - val_loss: 1.5167 - val_categorical_accuracy: 0.5841\n",
      "Epoch 727/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2179 - categorical_accuracy: 0.6279 - val_loss: 1.5001 - val_categorical_accuracy: 0.5928\n",
      "Epoch 728/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1952 - categorical_accuracy: 0.6364 - val_loss: 1.4494 - val_categorical_accuracy: 0.6015\n",
      "Epoch 729/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2160 - categorical_accuracy: 0.6236 - val_loss: 1.4427 - val_categorical_accuracy: 0.6052\n",
      "Epoch 730/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2281 - categorical_accuracy: 0.6231 - val_loss: 1.4569 - val_categorical_accuracy: 0.6027\n",
      "Epoch 731/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1821 - categorical_accuracy: 0.6311 - val_loss: 1.5779 - val_categorical_accuracy: 0.5716\n",
      "Epoch 732/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2563 - categorical_accuracy: 0.6119 - val_loss: 1.4117 - val_categorical_accuracy: 0.6027\n",
      "Epoch 733/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.2075 - categorical_accuracy: 0.6220 - val_loss: 1.5230 - val_categorical_accuracy: 0.6102\n",
      "Epoch 734/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2154 - categorical_accuracy: 0.6407 - val_loss: 1.4736 - val_categorical_accuracy: 0.5853\n",
      "Epoch 735/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2074 - categorical_accuracy: 0.6268 - val_loss: 1.5356 - val_categorical_accuracy: 0.5803\n",
      "Epoch 736/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1819 - categorical_accuracy: 0.6236 - val_loss: 1.4602 - val_categorical_accuracy: 0.6139\n",
      "Epoch 737/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2296 - categorical_accuracy: 0.6220 - val_loss: 1.4608 - val_categorical_accuracy: 0.5853\n",
      "Epoch 738/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1902 - categorical_accuracy: 0.6273 - val_loss: 1.5054 - val_categorical_accuracy: 0.5803\n",
      "Epoch 739/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2259 - categorical_accuracy: 0.6209 - val_loss: 1.4565 - val_categorical_accuracy: 0.6077\n",
      "Epoch 740/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1420 - categorical_accuracy: 0.6498 - val_loss: 1.4914 - val_categorical_accuracy: 0.5903\n",
      "Epoch 741/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1964 - categorical_accuracy: 0.6412 - val_loss: 1.5304 - val_categorical_accuracy: 0.5828\n",
      "Epoch 742/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2128 - categorical_accuracy: 0.6353 - val_loss: 1.4935 - val_categorical_accuracy: 0.5890\n",
      "Epoch 743/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1469 - categorical_accuracy: 0.6401 - val_loss: 1.4950 - val_categorical_accuracy: 0.5915\n",
      "Epoch 744/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1971 - categorical_accuracy: 0.6332 - val_loss: 1.5115 - val_categorical_accuracy: 0.5965\n",
      "Epoch 745/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1827 - categorical_accuracy: 0.6375 - val_loss: 1.5346 - val_categorical_accuracy: 0.5841\n",
      "Epoch 746/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2046 - categorical_accuracy: 0.6241 - val_loss: 1.4777 - val_categorical_accuracy: 0.5978\n",
      "Epoch 747/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1838 - categorical_accuracy: 0.6380 - val_loss: 1.5152 - val_categorical_accuracy: 0.6077\n",
      "Epoch 748/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1452 - categorical_accuracy: 0.6455 - val_loss: 1.4486 - val_categorical_accuracy: 0.6314\n",
      "Epoch 749/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2221 - categorical_accuracy: 0.6241 - val_loss: 1.4872 - val_categorical_accuracy: 0.6152\n",
      "Epoch 750/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1658 - categorical_accuracy: 0.6503 - val_loss: 1.4992 - val_categorical_accuracy: 0.6015\n",
      "Epoch 751/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1684 - categorical_accuracy: 0.6364 - val_loss: 1.5369 - val_categorical_accuracy: 0.5791\n",
      "Epoch 752/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1650 - categorical_accuracy: 0.6337 - val_loss: 1.5266 - val_categorical_accuracy: 0.5928\n",
      "Epoch 753/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1900 - categorical_accuracy: 0.6337 - val_loss: 1.5388 - val_categorical_accuracy: 0.6015\n",
      "Epoch 754/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1670 - categorical_accuracy: 0.6530 - val_loss: 1.4974 - val_categorical_accuracy: 0.5965\n",
      "Epoch 755/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2167 - categorical_accuracy: 0.6151 - val_loss: 1.4595 - val_categorical_accuracy: 0.6065\n",
      "Epoch 756/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1714 - categorical_accuracy: 0.6524 - val_loss: 1.4951 - val_categorical_accuracy: 0.5903\n",
      "Epoch 757/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1986 - categorical_accuracy: 0.6407 - val_loss: 1.5029 - val_categorical_accuracy: 0.5978\n",
      "Epoch 758/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 23ms/step - loss: 1.1854 - categorical_accuracy: 0.6380 - val_loss: 1.4942 - val_categorical_accuracy: 0.5816\n",
      "Epoch 759/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2055 - categorical_accuracy: 0.6364 - val_loss: 1.4758 - val_categorical_accuracy: 0.5791\n",
      "Epoch 760/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1506 - categorical_accuracy: 0.6466 - val_loss: 1.4694 - val_categorical_accuracy: 0.5903\n",
      "Epoch 761/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1928 - categorical_accuracy: 0.6321 - val_loss: 1.4240 - val_categorical_accuracy: 0.5878\n",
      "Epoch 762/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1864 - categorical_accuracy: 0.6300 - val_loss: 1.4975 - val_categorical_accuracy: 0.5965\n",
      "Epoch 763/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2039 - categorical_accuracy: 0.6204 - val_loss: 1.5028 - val_categorical_accuracy: 0.5878\n",
      "Epoch 764/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1352 - categorical_accuracy: 0.6530 - val_loss: 1.5962 - val_categorical_accuracy: 0.5841\n",
      "Epoch 765/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1987 - categorical_accuracy: 0.6385 - val_loss: 1.5315 - val_categorical_accuracy: 0.5853\n",
      "Epoch 766/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1958 - categorical_accuracy: 0.6418 - val_loss: 1.4914 - val_categorical_accuracy: 0.5778\n",
      "Epoch 767/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1893 - categorical_accuracy: 0.6183 - val_loss: 1.4314 - val_categorical_accuracy: 0.5978\n",
      "Epoch 768/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1653 - categorical_accuracy: 0.6546 - val_loss: 1.5303 - val_categorical_accuracy: 0.5928\n",
      "Epoch 769/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1223 - categorical_accuracy: 0.6551 - val_loss: 1.4256 - val_categorical_accuracy: 0.6040\n",
      "Epoch 770/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1394 - categorical_accuracy: 0.6434 - val_loss: 1.4454 - val_categorical_accuracy: 0.6065\n",
      "Epoch 771/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1878 - categorical_accuracy: 0.6364 - val_loss: 1.5372 - val_categorical_accuracy: 0.6015\n",
      "Epoch 772/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1621 - categorical_accuracy: 0.6535 - val_loss: 1.4882 - val_categorical_accuracy: 0.6015\n",
      "Epoch 773/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1669 - categorical_accuracy: 0.6487 - val_loss: 1.5234 - val_categorical_accuracy: 0.5791\n",
      "Epoch 774/5000\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.1927 - categorical_accuracy: 0.6514 - val_loss: 1.4038 - val_categorical_accuracy: 0.6115\n",
      "Epoch 775/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1560 - categorical_accuracy: 0.6450 - val_loss: 1.4877 - val_categorical_accuracy: 0.6002\n",
      "Epoch 776/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1791 - categorical_accuracy: 0.6364 - val_loss: 1.4704 - val_categorical_accuracy: 0.6015\n",
      "Epoch 777/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2766 - categorical_accuracy: 0.6049 - val_loss: 1.5473 - val_categorical_accuracy: 0.5890\n",
      "Epoch 778/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1812 - categorical_accuracy: 0.6279 - val_loss: 1.4972 - val_categorical_accuracy: 0.5940\n",
      "Epoch 779/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1316 - categorical_accuracy: 0.6407 - val_loss: 1.5526 - val_categorical_accuracy: 0.5803\n",
      "Epoch 780/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2001 - categorical_accuracy: 0.6434 - val_loss: 1.4813 - val_categorical_accuracy: 0.5853\n",
      "Epoch 781/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2396 - categorical_accuracy: 0.6065 - val_loss: 1.4844 - val_categorical_accuracy: 0.5928\n",
      "Epoch 782/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.2502 - categorical_accuracy: 0.6188 - val_loss: 1.5017 - val_categorical_accuracy: 0.6090\n",
      "Epoch 783/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.1395 - categorical_accuracy: 0.6498 - val_loss: 1.4957 - val_categorical_accuracy: 0.5803\n",
      "Epoch 784/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1192 - categorical_accuracy: 0.6423 - val_loss: 1.5477 - val_categorical_accuracy: 0.5791\n",
      "Epoch 785/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1257 - categorical_accuracy: 0.6460 - val_loss: 1.4743 - val_categorical_accuracy: 0.6052\n",
      "Epoch 786/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1683 - categorical_accuracy: 0.6476 - val_loss: 1.6087 - val_categorical_accuracy: 0.5654\n",
      "Epoch 787/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1969 - categorical_accuracy: 0.6343 - val_loss: 1.5420 - val_categorical_accuracy: 0.5691\n",
      "Epoch 788/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1664 - categorical_accuracy: 0.6391 - val_loss: 1.5317 - val_categorical_accuracy: 0.5791\n",
      "Epoch 789/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.2090 - categorical_accuracy: 0.6439 - val_loss: 1.4856 - val_categorical_accuracy: 0.5841\n",
      "Epoch 790/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1825 - categorical_accuracy: 0.6412 - val_loss: 1.4513 - val_categorical_accuracy: 0.5915\n",
      "Epoch 791/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2329 - categorical_accuracy: 0.6209 - val_loss: 1.4063 - val_categorical_accuracy: 0.6102\n",
      "Epoch 792/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1650 - categorical_accuracy: 0.6385 - val_loss: 1.5202 - val_categorical_accuracy: 0.5866\n",
      "Epoch 793/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1475 - categorical_accuracy: 0.6466 - val_loss: 1.5398 - val_categorical_accuracy: 0.5778\n",
      "Epoch 794/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1870 - categorical_accuracy: 0.6284 - val_loss: 1.5458 - val_categorical_accuracy: 0.5965\n",
      "Epoch 795/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2275 - categorical_accuracy: 0.6289 - val_loss: 1.5061 - val_categorical_accuracy: 0.5990\n",
      "Epoch 796/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1306 - categorical_accuracy: 0.6546 - val_loss: 1.5024 - val_categorical_accuracy: 0.6015\n",
      "Epoch 797/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1826 - categorical_accuracy: 0.6353 - val_loss: 1.4586 - val_categorical_accuracy: 0.6115\n",
      "Epoch 798/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2231 - categorical_accuracy: 0.6369 - val_loss: 1.4552 - val_categorical_accuracy: 0.6090\n",
      "Epoch 799/5000\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 1.1151 - categorical_accuracy: 0.6610 - val_loss: 1.5601 - val_categorical_accuracy: 0.5828\n",
      "Epoch 800/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1711 - categorical_accuracy: 0.6385 - val_loss: 1.5133 - val_categorical_accuracy: 0.5841\n",
      "Epoch 801/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1495 - categorical_accuracy: 0.6401 - val_loss: 1.5591 - val_categorical_accuracy: 0.5816\n",
      "Epoch 802/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1723 - categorical_accuracy: 0.6369 - val_loss: 1.6202 - val_categorical_accuracy: 0.5654\n",
      "Epoch 803/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1476 - categorical_accuracy: 0.6444 - val_loss: 1.5210 - val_categorical_accuracy: 0.5953\n",
      "Epoch 804/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2030 - categorical_accuracy: 0.6199 - val_loss: 1.5150 - val_categorical_accuracy: 0.5816\n",
      "Epoch 805/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2226 - categorical_accuracy: 0.6257 - val_loss: 1.5086 - val_categorical_accuracy: 0.5866\n",
      "Epoch 806/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2104 - categorical_accuracy: 0.6236 - val_loss: 1.5155 - val_categorical_accuracy: 0.6015\n",
      "Epoch 807/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1428 - categorical_accuracy: 0.6524 - val_loss: 1.4864 - val_categorical_accuracy: 0.6002\n",
      "Epoch 808/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1722 - categorical_accuracy: 0.6471 - val_loss: 1.5436 - val_categorical_accuracy: 0.6015\n",
      "Epoch 809/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1927 - categorical_accuracy: 0.6492 - val_loss: 1.5370 - val_categorical_accuracy: 0.6015\n",
      "Epoch 810/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1790 - categorical_accuracy: 0.6385 - val_loss: 1.5425 - val_categorical_accuracy: 0.5940\n",
      "Epoch 811/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1548 - categorical_accuracy: 0.6439 - val_loss: 1.6354 - val_categorical_accuracy: 0.5778\n",
      "Epoch 812/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1798 - categorical_accuracy: 0.6487 - val_loss: 1.5027 - val_categorical_accuracy: 0.6127\n",
      "Epoch 813/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1461 - categorical_accuracy: 0.6412 - val_loss: 1.5239 - val_categorical_accuracy: 0.6189\n",
      "Epoch 814/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1352 - categorical_accuracy: 0.6444 - val_loss: 1.4670 - val_categorical_accuracy: 0.6127\n",
      "Epoch 815/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1366 - categorical_accuracy: 0.6540 - val_loss: 1.5202 - val_categorical_accuracy: 0.5915\n",
      "Epoch 816/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.1358 - categorical_accuracy: 0.6615 - val_loss: 1.5445 - val_categorical_accuracy: 0.5890\n",
      "Epoch 817/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1455 - categorical_accuracy: 0.6476 - val_loss: 1.4807 - val_categorical_accuracy: 0.6040\n",
      "Epoch 818/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1798 - categorical_accuracy: 0.6428 - val_loss: 1.4587 - val_categorical_accuracy: 0.5890\n",
      "Epoch 819/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1041 - categorical_accuracy: 0.6620 - val_loss: 1.5421 - val_categorical_accuracy: 0.5903\n",
      "Epoch 820/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1360 - categorical_accuracy: 0.6482 - val_loss: 1.5138 - val_categorical_accuracy: 0.5853\n",
      "Epoch 821/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1937 - categorical_accuracy: 0.6359 - val_loss: 1.5773 - val_categorical_accuracy: 0.5903\n",
      "Epoch 822/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1579 - categorical_accuracy: 0.6332 - val_loss: 1.4080 - val_categorical_accuracy: 0.6276\n",
      "Epoch 823/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1494 - categorical_accuracy: 0.6466 - val_loss: 1.5218 - val_categorical_accuracy: 0.6252\n",
      "Epoch 824/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1339 - categorical_accuracy: 0.6599 - val_loss: 1.4886 - val_categorical_accuracy: 0.6127\n",
      "Epoch 825/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1473 - categorical_accuracy: 0.6540 - val_loss: 1.5754 - val_categorical_accuracy: 0.5778\n",
      "Epoch 826/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1486 - categorical_accuracy: 0.6455 - val_loss: 1.5724 - val_categorical_accuracy: 0.5990\n",
      "Epoch 827/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1395 - categorical_accuracy: 0.6551 - val_loss: 1.6126 - val_categorical_accuracy: 0.5816\n",
      "Epoch 828/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1253 - categorical_accuracy: 0.6668 - val_loss: 1.6145 - val_categorical_accuracy: 0.5853\n",
      "Epoch 829/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1934 - categorical_accuracy: 0.6460 - val_loss: 1.5149 - val_categorical_accuracy: 0.6077\n",
      "Epoch 830/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1732 - categorical_accuracy: 0.6471 - val_loss: 1.5414 - val_categorical_accuracy: 0.5978\n",
      "Epoch 831/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1649 - categorical_accuracy: 0.6460 - val_loss: 1.5430 - val_categorical_accuracy: 0.5853\n",
      "Epoch 832/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1652 - categorical_accuracy: 0.6439 - val_loss: 1.5258 - val_categorical_accuracy: 0.6065\n",
      "Epoch 833/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1792 - categorical_accuracy: 0.6434 - val_loss: 1.5538 - val_categorical_accuracy: 0.5890\n",
      "Epoch 834/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1233 - categorical_accuracy: 0.6572 - val_loss: 1.5546 - val_categorical_accuracy: 0.5766\n",
      "Epoch 835/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.2105 - categorical_accuracy: 0.6257 - val_loss: 1.5244 - val_categorical_accuracy: 0.5953\n",
      "Epoch 836/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1381 - categorical_accuracy: 0.6466 - val_loss: 1.5467 - val_categorical_accuracy: 0.5828\n",
      "Epoch 837/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1405 - categorical_accuracy: 0.6391 - val_loss: 1.5848 - val_categorical_accuracy: 0.5866\n",
      "Epoch 838/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1291 - categorical_accuracy: 0.6508 - val_loss: 1.5293 - val_categorical_accuracy: 0.5903\n",
      "Epoch 839/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1667 - categorical_accuracy: 0.6503 - val_loss: 1.5871 - val_categorical_accuracy: 0.5816\n",
      "Epoch 840/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1455 - categorical_accuracy: 0.6535 - val_loss: 1.5074 - val_categorical_accuracy: 0.5791\n",
      "Epoch 841/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1450 - categorical_accuracy: 0.6434 - val_loss: 1.5289 - val_categorical_accuracy: 0.6002\n",
      "Epoch 842/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0945 - categorical_accuracy: 0.6588 - val_loss: 1.4615 - val_categorical_accuracy: 0.6052\n",
      "Epoch 843/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1625 - categorical_accuracy: 0.6401 - val_loss: 1.5145 - val_categorical_accuracy: 0.5990\n",
      "Epoch 844/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1716 - categorical_accuracy: 0.6471 - val_loss: 1.6397 - val_categorical_accuracy: 0.5741\n",
      "Epoch 845/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1913 - categorical_accuracy: 0.6375 - val_loss: 1.5656 - val_categorical_accuracy: 0.5828\n",
      "Epoch 846/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1790 - categorical_accuracy: 0.6337 - val_loss: 1.5673 - val_categorical_accuracy: 0.5853\n",
      "Epoch 847/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1788 - categorical_accuracy: 0.6514 - val_loss: 1.6420 - val_categorical_accuracy: 0.5679\n",
      "Epoch 848/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2163 - categorical_accuracy: 0.6316 - val_loss: 1.5207 - val_categorical_accuracy: 0.5978\n",
      "Epoch 849/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.1674 - categorical_accuracy: 0.6396 - val_loss: 1.4926 - val_categorical_accuracy: 0.6090\n",
      "Epoch 850/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1646 - categorical_accuracy: 0.6337 - val_loss: 1.4702 - val_categorical_accuracy: 0.6127\n",
      "Epoch 851/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0946 - categorical_accuracy: 0.6684 - val_loss: 1.4557 - val_categorical_accuracy: 0.6139\n",
      "Epoch 852/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1641 - categorical_accuracy: 0.6556 - val_loss: 1.5401 - val_categorical_accuracy: 0.6015\n",
      "Epoch 853/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1658 - categorical_accuracy: 0.6428 - val_loss: 1.5470 - val_categorical_accuracy: 0.5953\n",
      "Epoch 854/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1311 - categorical_accuracy: 0.6562 - val_loss: 1.4914 - val_categorical_accuracy: 0.6077\n",
      "Epoch 855/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1551 - categorical_accuracy: 0.6508 - val_loss: 1.5170 - val_categorical_accuracy: 0.5878\n",
      "Epoch 856/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1670 - categorical_accuracy: 0.6455 - val_loss: 1.4760 - val_categorical_accuracy: 0.5978\n",
      "Epoch 857/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1615 - categorical_accuracy: 0.6396 - val_loss: 1.4893 - val_categorical_accuracy: 0.6090\n",
      "Epoch 858/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1639 - categorical_accuracy: 0.6439 - val_loss: 1.4940 - val_categorical_accuracy: 0.5990\n",
      "Epoch 859/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1343 - categorical_accuracy: 0.6514 - val_loss: 1.5191 - val_categorical_accuracy: 0.5890\n",
      "Epoch 860/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1169 - categorical_accuracy: 0.6476 - val_loss: 1.4832 - val_categorical_accuracy: 0.6127\n",
      "Epoch 861/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1381 - categorical_accuracy: 0.6567 - val_loss: 1.4798 - val_categorical_accuracy: 0.6127\n",
      "Epoch 862/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1142 - categorical_accuracy: 0.6610 - val_loss: 1.5539 - val_categorical_accuracy: 0.5816\n",
      "Epoch 863/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1468 - categorical_accuracy: 0.6487 - val_loss: 1.5295 - val_categorical_accuracy: 0.5928\n",
      "Epoch 864/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1445 - categorical_accuracy: 0.6401 - val_loss: 1.5488 - val_categorical_accuracy: 0.5903\n",
      "Epoch 865/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1565 - categorical_accuracy: 0.6556 - val_loss: 1.5899 - val_categorical_accuracy: 0.5915\n",
      "Epoch 866/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1446 - categorical_accuracy: 0.6385 - val_loss: 1.4860 - val_categorical_accuracy: 0.6015\n",
      "Epoch 867/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1321 - categorical_accuracy: 0.6620 - val_loss: 1.5170 - val_categorical_accuracy: 0.5766\n",
      "Epoch 868/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1704 - categorical_accuracy: 0.6380 - val_loss: 1.5230 - val_categorical_accuracy: 0.6077\n",
      "Epoch 869/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1700 - categorical_accuracy: 0.6471 - val_loss: 1.5021 - val_categorical_accuracy: 0.5890\n",
      "Epoch 870/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1209 - categorical_accuracy: 0.6556 - val_loss: 1.4455 - val_categorical_accuracy: 0.6077\n",
      "Epoch 871/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1989 - categorical_accuracy: 0.6231 - val_loss: 1.5541 - val_categorical_accuracy: 0.5766\n",
      "Epoch 872/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1902 - categorical_accuracy: 0.6396 - val_loss: 1.4809 - val_categorical_accuracy: 0.5878\n",
      "Epoch 873/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1654 - categorical_accuracy: 0.6466 - val_loss: 1.6469 - val_categorical_accuracy: 0.5691\n",
      "Epoch 874/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1460 - categorical_accuracy: 0.6508 - val_loss: 1.4676 - val_categorical_accuracy: 0.6152\n",
      "Epoch 875/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1601 - categorical_accuracy: 0.6418 - val_loss: 1.4762 - val_categorical_accuracy: 0.6052\n",
      "Epoch 876/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1711 - categorical_accuracy: 0.6300 - val_loss: 1.6369 - val_categorical_accuracy: 0.5666\n",
      "Epoch 877/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1604 - categorical_accuracy: 0.6519 - val_loss: 1.5501 - val_categorical_accuracy: 0.5828\n",
      "Epoch 878/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1129 - categorical_accuracy: 0.6652 - val_loss: 1.5512 - val_categorical_accuracy: 0.5579\n",
      "Epoch 879/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1549 - categorical_accuracy: 0.6380 - val_loss: 1.5584 - val_categorical_accuracy: 0.5716\n",
      "Epoch 880/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1338 - categorical_accuracy: 0.6578 - val_loss: 1.4963 - val_categorical_accuracy: 0.5990\n",
      "Epoch 881/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1812 - categorical_accuracy: 0.6412 - val_loss: 1.5930 - val_categorical_accuracy: 0.5766\n",
      "Epoch 882/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1578 - categorical_accuracy: 0.6594 - val_loss: 1.6475 - val_categorical_accuracy: 0.5654\n",
      "Epoch 883/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1273 - categorical_accuracy: 0.6530 - val_loss: 1.5394 - val_categorical_accuracy: 0.5940\n",
      "Epoch 884/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1924 - categorical_accuracy: 0.6412 - val_loss: 1.5110 - val_categorical_accuracy: 0.6152\n",
      "Epoch 885/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1107 - categorical_accuracy: 0.6588 - val_loss: 1.6331 - val_categorical_accuracy: 0.5654\n",
      "Epoch 886/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.1577 - categorical_accuracy: 0.6407 - val_loss: 1.4832 - val_categorical_accuracy: 0.6127\n",
      "Epoch 887/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1606 - categorical_accuracy: 0.6546 - val_loss: 1.5190 - val_categorical_accuracy: 0.6127\n",
      "Epoch 888/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1551 - categorical_accuracy: 0.6482 - val_loss: 1.5894 - val_categorical_accuracy: 0.5791\n",
      "Epoch 889/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1947 - categorical_accuracy: 0.6385 - val_loss: 1.5798 - val_categorical_accuracy: 0.5741\n",
      "Epoch 890/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1279 - categorical_accuracy: 0.6604 - val_loss: 1.4335 - val_categorical_accuracy: 0.6264\n",
      "Epoch 891/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1323 - categorical_accuracy: 0.6375 - val_loss: 1.4879 - val_categorical_accuracy: 0.6077\n",
      "Epoch 892/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1434 - categorical_accuracy: 0.6684 - val_loss: 1.4843 - val_categorical_accuracy: 0.6301\n",
      "Epoch 893/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1517 - categorical_accuracy: 0.6471 - val_loss: 1.5293 - val_categorical_accuracy: 0.5853\n",
      "Epoch 894/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1395 - categorical_accuracy: 0.6540 - val_loss: 1.5776 - val_categorical_accuracy: 0.5990\n",
      "Epoch 895/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1269 - categorical_accuracy: 0.6610 - val_loss: 1.6181 - val_categorical_accuracy: 0.5803\n",
      "Epoch 896/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1609 - categorical_accuracy: 0.6359 - val_loss: 1.5012 - val_categorical_accuracy: 0.6027\n",
      "Epoch 897/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0714 - categorical_accuracy: 0.6652 - val_loss: 1.5031 - val_categorical_accuracy: 0.5878\n",
      "Epoch 898/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1195 - categorical_accuracy: 0.6556 - val_loss: 1.4821 - val_categorical_accuracy: 0.6115\n",
      "Epoch 899/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1206 - categorical_accuracy: 0.6508 - val_loss: 1.4738 - val_categorical_accuracy: 0.6127\n",
      "Epoch 900/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1360 - categorical_accuracy: 0.6556 - val_loss: 1.5350 - val_categorical_accuracy: 0.5791\n",
      "Epoch 901/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1460 - categorical_accuracy: 0.6487 - val_loss: 1.5265 - val_categorical_accuracy: 0.5890\n",
      "Epoch 902/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1693 - categorical_accuracy: 0.6460 - val_loss: 1.5490 - val_categorical_accuracy: 0.6027\n",
      "Epoch 903/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1228 - categorical_accuracy: 0.6652 - val_loss: 1.5220 - val_categorical_accuracy: 0.5766\n",
      "Epoch 904/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1541 - categorical_accuracy: 0.6524 - val_loss: 1.5576 - val_categorical_accuracy: 0.5816\n",
      "Epoch 905/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1595 - categorical_accuracy: 0.6305 - val_loss: 1.6468 - val_categorical_accuracy: 0.5616\n",
      "Epoch 906/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1309 - categorical_accuracy: 0.6551 - val_loss: 1.5207 - val_categorical_accuracy: 0.5990\n",
      "Epoch 907/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1492 - categorical_accuracy: 0.6551 - val_loss: 1.5758 - val_categorical_accuracy: 0.5778\n",
      "Epoch 908/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1433 - categorical_accuracy: 0.6503 - val_loss: 1.5354 - val_categorical_accuracy: 0.5940\n",
      "Epoch 909/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1534 - categorical_accuracy: 0.6540 - val_loss: 1.5021 - val_categorical_accuracy: 0.6090\n",
      "Epoch 910/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0830 - categorical_accuracy: 0.6727 - val_loss: 1.5527 - val_categorical_accuracy: 0.5928\n",
      "Epoch 911/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1036 - categorical_accuracy: 0.6636 - val_loss: 1.5318 - val_categorical_accuracy: 0.5940\n",
      "Epoch 912/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0788 - categorical_accuracy: 0.6535 - val_loss: 1.5075 - val_categorical_accuracy: 0.5953\n",
      "Epoch 913/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1041 - categorical_accuracy: 0.6658 - val_loss: 1.5633 - val_categorical_accuracy: 0.5940\n",
      "Epoch 914/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1332 - categorical_accuracy: 0.6434 - val_loss: 1.5632 - val_categorical_accuracy: 0.6090\n",
      "Epoch 915/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1504 - categorical_accuracy: 0.6503 - val_loss: 1.6679 - val_categorical_accuracy: 0.5803\n",
      "Epoch 916/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.2157 - categorical_accuracy: 0.6434 - val_loss: 1.5252 - val_categorical_accuracy: 0.6065\n",
      "Epoch 917/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1222 - categorical_accuracy: 0.6588 - val_loss: 1.5688 - val_categorical_accuracy: 0.5828\n",
      "Epoch 918/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1379 - categorical_accuracy: 0.6375 - val_loss: 1.5294 - val_categorical_accuracy: 0.6090\n",
      "Epoch 919/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1609 - categorical_accuracy: 0.6460 - val_loss: 1.5081 - val_categorical_accuracy: 0.6090\n",
      "Epoch 920/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1299 - categorical_accuracy: 0.6551 - val_loss: 1.4871 - val_categorical_accuracy: 0.6152\n",
      "Epoch 921/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1237 - categorical_accuracy: 0.6535 - val_loss: 1.5418 - val_categorical_accuracy: 0.6027\n",
      "Epoch 922/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0765 - categorical_accuracy: 0.6829 - val_loss: 1.5185 - val_categorical_accuracy: 0.6077\n",
      "Epoch 923/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1798 - categorical_accuracy: 0.6401 - val_loss: 1.5536 - val_categorical_accuracy: 0.5803\n",
      "Epoch 924/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1596 - categorical_accuracy: 0.6508 - val_loss: 1.4798 - val_categorical_accuracy: 0.5890\n",
      "Epoch 925/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1509 - categorical_accuracy: 0.6466 - val_loss: 1.5409 - val_categorical_accuracy: 0.6015\n",
      "Epoch 926/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1556 - categorical_accuracy: 0.6466 - val_loss: 1.5180 - val_categorical_accuracy: 0.6027\n",
      "Epoch 927/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0619 - categorical_accuracy: 0.6807 - val_loss: 1.4820 - val_categorical_accuracy: 0.6090\n",
      "Epoch 928/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1540 - categorical_accuracy: 0.6391 - val_loss: 1.5260 - val_categorical_accuracy: 0.5965\n",
      "Epoch 929/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0729 - categorical_accuracy: 0.6642 - val_loss: 1.5620 - val_categorical_accuracy: 0.5853\n",
      "Epoch 930/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1313 - categorical_accuracy: 0.6604 - val_loss: 1.5741 - val_categorical_accuracy: 0.5978\n",
      "Epoch 931/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1142 - categorical_accuracy: 0.6503 - val_loss: 1.5186 - val_categorical_accuracy: 0.5841\n",
      "Epoch 932/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0855 - categorical_accuracy: 0.6583 - val_loss: 1.5020 - val_categorical_accuracy: 0.6040\n",
      "Epoch 933/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1264 - categorical_accuracy: 0.6540 - val_loss: 1.5302 - val_categorical_accuracy: 0.6015\n",
      "Epoch 934/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1257 - categorical_accuracy: 0.6418 - val_loss: 1.5389 - val_categorical_accuracy: 0.5878\n",
      "Epoch 935/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1192 - categorical_accuracy: 0.6642 - val_loss: 1.6006 - val_categorical_accuracy: 0.6027\n",
      "Epoch 936/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1189 - categorical_accuracy: 0.6439 - val_loss: 1.4924 - val_categorical_accuracy: 0.6276\n",
      "Epoch 937/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1296 - categorical_accuracy: 0.6594 - val_loss: 1.5349 - val_categorical_accuracy: 0.6027\n",
      "Epoch 938/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1264 - categorical_accuracy: 0.6524 - val_loss: 1.5002 - val_categorical_accuracy: 0.6065\n",
      "Epoch 939/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1825 - categorical_accuracy: 0.6401 - val_loss: 1.4822 - val_categorical_accuracy: 0.6052\n",
      "Epoch 940/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1415 - categorical_accuracy: 0.6551 - val_loss: 1.4804 - val_categorical_accuracy: 0.6077\n",
      "Epoch 941/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1506 - categorical_accuracy: 0.6503 - val_loss: 1.5312 - val_categorical_accuracy: 0.5953\n",
      "Epoch 942/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1216 - categorical_accuracy: 0.6492 - val_loss: 1.4919 - val_categorical_accuracy: 0.6127\n",
      "Epoch 943/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1074 - categorical_accuracy: 0.6636 - val_loss: 1.5073 - val_categorical_accuracy: 0.5915\n",
      "Epoch 944/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0966 - categorical_accuracy: 0.6636 - val_loss: 1.5066 - val_categorical_accuracy: 0.6015\n",
      "Epoch 945/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1716 - categorical_accuracy: 0.6407 - val_loss: 1.5544 - val_categorical_accuracy: 0.6090\n",
      "Epoch 946/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1230 - categorical_accuracy: 0.6594 - val_loss: 1.5443 - val_categorical_accuracy: 0.5990\n",
      "Epoch 947/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1263 - categorical_accuracy: 0.6599 - val_loss: 1.5867 - val_categorical_accuracy: 0.5990\n",
      "Epoch 948/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1897 - categorical_accuracy: 0.6471 - val_loss: 1.5115 - val_categorical_accuracy: 0.6015\n",
      "Epoch 949/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1218 - categorical_accuracy: 0.6604 - val_loss: 1.5112 - val_categorical_accuracy: 0.6002\n",
      "Epoch 950/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1299 - categorical_accuracy: 0.6487 - val_loss: 1.5196 - val_categorical_accuracy: 0.6139\n",
      "Epoch 951/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0893 - categorical_accuracy: 0.6690 - val_loss: 1.5795 - val_categorical_accuracy: 0.5903\n",
      "Epoch 952/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1499 - categorical_accuracy: 0.6482 - val_loss: 1.5668 - val_categorical_accuracy: 0.5803\n",
      "Epoch 953/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1408 - categorical_accuracy: 0.6418 - val_loss: 1.5107 - val_categorical_accuracy: 0.6027\n",
      "Epoch 954/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1414 - categorical_accuracy: 0.6599 - val_loss: 1.4785 - val_categorical_accuracy: 0.6276\n",
      "Epoch 955/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1298 - categorical_accuracy: 0.6562 - val_loss: 1.4746 - val_categorical_accuracy: 0.6139\n",
      "Epoch 956/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1057 - categorical_accuracy: 0.6743 - val_loss: 1.5967 - val_categorical_accuracy: 0.5915\n",
      "Epoch 957/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1144 - categorical_accuracy: 0.6652 - val_loss: 1.6603 - val_categorical_accuracy: 0.5753\n",
      "Epoch 958/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0778 - categorical_accuracy: 0.6700 - val_loss: 1.6006 - val_categorical_accuracy: 0.5729\n",
      "Epoch 959/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1125 - categorical_accuracy: 0.6594 - val_loss: 1.6043 - val_categorical_accuracy: 0.5816\n",
      "Epoch 960/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1932 - categorical_accuracy: 0.6300 - val_loss: 1.5947 - val_categorical_accuracy: 0.5953\n",
      "Epoch 961/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1353 - categorical_accuracy: 0.6604 - val_loss: 1.5658 - val_categorical_accuracy: 0.5853\n",
      "Epoch 962/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0553 - categorical_accuracy: 0.6743 - val_loss: 1.6006 - val_categorical_accuracy: 0.5654\n",
      "Epoch 963/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1200 - categorical_accuracy: 0.6599 - val_loss: 1.6313 - val_categorical_accuracy: 0.5592\n",
      "Epoch 964/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1126 - categorical_accuracy: 0.6610 - val_loss: 1.6011 - val_categorical_accuracy: 0.5878\n",
      "Epoch 965/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1036 - categorical_accuracy: 0.6567 - val_loss: 1.6048 - val_categorical_accuracy: 0.5853\n",
      "Epoch 966/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1183 - categorical_accuracy: 0.6583 - val_loss: 1.5756 - val_categorical_accuracy: 0.5903\n",
      "Epoch 967/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0746 - categorical_accuracy: 0.6791 - val_loss: 1.6154 - val_categorical_accuracy: 0.5828\n",
      "Epoch 968/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0951 - categorical_accuracy: 0.6716 - val_loss: 1.7110 - val_categorical_accuracy: 0.5741\n",
      "Epoch 969/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1249 - categorical_accuracy: 0.6519 - val_loss: 1.5660 - val_categorical_accuracy: 0.5978\n",
      "Epoch 970/5000\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 1.0762 - categorical_accuracy: 0.6626 - val_loss: 1.5592 - val_categorical_accuracy: 0.6077\n",
      "Epoch 971/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0786 - categorical_accuracy: 0.6727 - val_loss: 1.5796 - val_categorical_accuracy: 0.5778\n",
      "Epoch 972/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1038 - categorical_accuracy: 0.6583 - val_loss: 1.5876 - val_categorical_accuracy: 0.5853\n",
      "Epoch 973/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0703 - categorical_accuracy: 0.6727 - val_loss: 1.5688 - val_categorical_accuracy: 0.6214\n",
      "Epoch 974/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1173 - categorical_accuracy: 0.6482 - val_loss: 1.5357 - val_categorical_accuracy: 0.6115\n",
      "Epoch 975/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0837 - categorical_accuracy: 0.6663 - val_loss: 1.4910 - val_categorical_accuracy: 0.6115\n",
      "Epoch 976/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1059 - categorical_accuracy: 0.6562 - val_loss: 1.5872 - val_categorical_accuracy: 0.5791\n",
      "Epoch 977/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0922 - categorical_accuracy: 0.6759 - val_loss: 1.5053 - val_categorical_accuracy: 0.6152\n",
      "Epoch 978/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1460 - categorical_accuracy: 0.6450 - val_loss: 1.6120 - val_categorical_accuracy: 0.6090\n",
      "Epoch 979/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1608 - categorical_accuracy: 0.6471 - val_loss: 1.5885 - val_categorical_accuracy: 0.5940\n",
      "Epoch 980/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1275 - categorical_accuracy: 0.6514 - val_loss: 1.5142 - val_categorical_accuracy: 0.6152\n",
      "Epoch 981/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.1603 - categorical_accuracy: 0.6604 - val_loss: 1.5237 - val_categorical_accuracy: 0.6077\n",
      "Epoch 982/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0838 - categorical_accuracy: 0.6700 - val_loss: 1.5082 - val_categorical_accuracy: 0.6214\n",
      "Epoch 983/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1670 - categorical_accuracy: 0.6567 - val_loss: 1.5469 - val_categorical_accuracy: 0.5778\n",
      "Epoch 984/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0755 - categorical_accuracy: 0.6647 - val_loss: 1.5458 - val_categorical_accuracy: 0.5953\n",
      "Epoch 985/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1093 - categorical_accuracy: 0.6711 - val_loss: 1.6129 - val_categorical_accuracy: 0.5766\n",
      "Epoch 986/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0776 - categorical_accuracy: 0.6620 - val_loss: 1.5701 - val_categorical_accuracy: 0.5666\n",
      "Epoch 987/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1092 - categorical_accuracy: 0.6588 - val_loss: 1.5731 - val_categorical_accuracy: 0.5753\n",
      "Epoch 988/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1558 - categorical_accuracy: 0.6434 - val_loss: 1.6116 - val_categorical_accuracy: 0.5741\n",
      "Epoch 989/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0641 - categorical_accuracy: 0.6578 - val_loss: 1.5383 - val_categorical_accuracy: 0.5965\n",
      "Epoch 990/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0803 - categorical_accuracy: 0.6690 - val_loss: 1.5674 - val_categorical_accuracy: 0.6065\n",
      "Epoch 991/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1346 - categorical_accuracy: 0.6460 - val_loss: 1.6376 - val_categorical_accuracy: 0.5841\n",
      "Epoch 992/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1320 - categorical_accuracy: 0.6535 - val_loss: 1.5260 - val_categorical_accuracy: 0.6115\n",
      "Epoch 993/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1336 - categorical_accuracy: 0.6540 - val_loss: 1.5833 - val_categorical_accuracy: 0.5915\n",
      "Epoch 994/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1175 - categorical_accuracy: 0.6610 - val_loss: 1.5728 - val_categorical_accuracy: 0.5841\n",
      "Epoch 995/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1328 - categorical_accuracy: 0.6508 - val_loss: 1.5991 - val_categorical_accuracy: 0.5816\n",
      "Epoch 996/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0782 - categorical_accuracy: 0.6663 - val_loss: 1.5188 - val_categorical_accuracy: 0.6139\n",
      "Epoch 997/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1481 - categorical_accuracy: 0.6466 - val_loss: 1.5476 - val_categorical_accuracy: 0.6127\n",
      "Epoch 998/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1241 - categorical_accuracy: 0.6578 - val_loss: 1.5610 - val_categorical_accuracy: 0.6177\n",
      "Epoch 999/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1268 - categorical_accuracy: 0.6482 - val_loss: 1.6197 - val_categorical_accuracy: 0.5953\n",
      "Epoch 1000/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0944 - categorical_accuracy: 0.6658 - val_loss: 1.6772 - val_categorical_accuracy: 0.5741\n",
      "Epoch 1001/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0696 - categorical_accuracy: 0.6759 - val_loss: 1.6151 - val_categorical_accuracy: 0.5903\n",
      "Epoch 1002/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1576 - categorical_accuracy: 0.6604 - val_loss: 1.5518 - val_categorical_accuracy: 0.6152\n",
      "Epoch 1003/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1046 - categorical_accuracy: 0.6578 - val_loss: 1.6868 - val_categorical_accuracy: 0.5778\n",
      "Epoch 1004/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0682 - categorical_accuracy: 0.6738 - val_loss: 1.6476 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1005/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0870 - categorical_accuracy: 0.6706 - val_loss: 1.6303 - val_categorical_accuracy: 0.5841\n",
      "Epoch 1006/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1557 - categorical_accuracy: 0.6492 - val_loss: 1.6271 - val_categorical_accuracy: 0.5803\n",
      "Epoch 1007/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0535 - categorical_accuracy: 0.6850 - val_loss: 1.5598 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1008/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0918 - categorical_accuracy: 0.6599 - val_loss: 1.5872 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1009/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1040 - categorical_accuracy: 0.6567 - val_loss: 1.5625 - val_categorical_accuracy: 0.6189\n",
      "Epoch 1010/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.1232 - categorical_accuracy: 0.6610 - val_loss: 1.5594 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1011/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0716 - categorical_accuracy: 0.6700 - val_loss: 1.6695 - val_categorical_accuracy: 0.5915\n",
      "Epoch 1012/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0871 - categorical_accuracy: 0.6679 - val_loss: 1.5877 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1013/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1365 - categorical_accuracy: 0.6594 - val_loss: 1.5408 - val_categorical_accuracy: 0.6189\n",
      "Epoch 1014/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1172 - categorical_accuracy: 0.6418 - val_loss: 1.6006 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1015/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0939 - categorical_accuracy: 0.6668 - val_loss: 1.5443 - val_categorical_accuracy: 0.6127\n",
      "Epoch 1016/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0464 - categorical_accuracy: 0.6855 - val_loss: 1.6078 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1017/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1075 - categorical_accuracy: 0.6556 - val_loss: 1.6564 - val_categorical_accuracy: 0.5903\n",
      "Epoch 1018/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1057 - categorical_accuracy: 0.6711 - val_loss: 1.6293 - val_categorical_accuracy: 0.5940\n",
      "Epoch 1019/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1803 - categorical_accuracy: 0.6487 - val_loss: 1.5652 - val_categorical_accuracy: 0.6202\n",
      "Epoch 1020/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0604 - categorical_accuracy: 0.6775 - val_loss: 1.6171 - val_categorical_accuracy: 0.5953\n",
      "Epoch 1021/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1500 - categorical_accuracy: 0.6508 - val_loss: 1.5864 - val_categorical_accuracy: 0.5828\n",
      "Epoch 1022/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0717 - categorical_accuracy: 0.6706 - val_loss: 1.5743 - val_categorical_accuracy: 0.5915\n",
      "Epoch 1023/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0877 - categorical_accuracy: 0.6754 - val_loss: 1.5890 - val_categorical_accuracy: 0.5903\n",
      "Epoch 1024/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1333 - categorical_accuracy: 0.6588 - val_loss: 1.6331 - val_categorical_accuracy: 0.5828\n",
      "Epoch 1025/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1324 - categorical_accuracy: 0.6599 - val_loss: 1.7404 - val_categorical_accuracy: 0.5729\n",
      "Epoch 1026/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1171 - categorical_accuracy: 0.6572 - val_loss: 1.6044 - val_categorical_accuracy: 0.5803\n",
      "Epoch 1027/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1032 - categorical_accuracy: 0.6578 - val_loss: 1.6909 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1028/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1846 - categorical_accuracy: 0.6375 - val_loss: 1.5825 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1029/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1306 - categorical_accuracy: 0.6519 - val_loss: 1.6121 - val_categorical_accuracy: 0.6040\n",
      "Epoch 1030/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0594 - categorical_accuracy: 0.6781 - val_loss: 1.5908 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1031/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0999 - categorical_accuracy: 0.6765 - val_loss: 1.5861 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1032/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1417 - categorical_accuracy: 0.6524 - val_loss: 1.6067 - val_categorical_accuracy: 0.5766\n",
      "Epoch 1033/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0868 - categorical_accuracy: 0.6674 - val_loss: 1.6251 - val_categorical_accuracy: 0.5791\n",
      "Epoch 1034/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0981 - categorical_accuracy: 0.6668 - val_loss: 1.6064 - val_categorical_accuracy: 0.5766\n",
      "Epoch 1035/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1349 - categorical_accuracy: 0.6450 - val_loss: 1.6971 - val_categorical_accuracy: 0.5542\n",
      "Epoch 1036/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0500 - categorical_accuracy: 0.6759 - val_loss: 1.7136 - val_categorical_accuracy: 0.5517\n",
      "Epoch 1037/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1064 - categorical_accuracy: 0.6519 - val_loss: 1.5475 - val_categorical_accuracy: 0.5940\n",
      "Epoch 1038/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.1359 - categorical_accuracy: 0.6530 - val_loss: 1.5790 - val_categorical_accuracy: 0.5903\n",
      "Epoch 1039/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1411 - categorical_accuracy: 0.6434 - val_loss: 1.5798 - val_categorical_accuracy: 0.5890\n",
      "Epoch 1040/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1083 - categorical_accuracy: 0.6722 - val_loss: 1.5619 - val_categorical_accuracy: 0.5915\n",
      "Epoch 1041/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1163 - categorical_accuracy: 0.6471 - val_loss: 1.5198 - val_categorical_accuracy: 0.6227\n",
      "Epoch 1042/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1284 - categorical_accuracy: 0.6530 - val_loss: 1.5666 - val_categorical_accuracy: 0.5928\n",
      "Epoch 1043/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1054 - categorical_accuracy: 0.6578 - val_loss: 1.5566 - val_categorical_accuracy: 0.6027\n",
      "Epoch 1044/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1391 - categorical_accuracy: 0.6551 - val_loss: 1.5606 - val_categorical_accuracy: 0.5841\n",
      "Epoch 1045/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0348 - categorical_accuracy: 0.6861 - val_loss: 1.4297 - val_categorical_accuracy: 0.6276\n",
      "Epoch 1046/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0903 - categorical_accuracy: 0.6620 - val_loss: 1.5023 - val_categorical_accuracy: 0.6040\n",
      "Epoch 1047/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0600 - categorical_accuracy: 0.6749 - val_loss: 1.5135 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1048/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0544 - categorical_accuracy: 0.6818 - val_loss: 1.5399 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1049/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0949 - categorical_accuracy: 0.6690 - val_loss: 1.5727 - val_categorical_accuracy: 0.6189\n",
      "Epoch 1050/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1319 - categorical_accuracy: 0.6626 - val_loss: 1.5247 - val_categorical_accuracy: 0.6177\n",
      "Epoch 1051/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0607 - categorical_accuracy: 0.6572 - val_loss: 1.5553 - val_categorical_accuracy: 0.5940\n",
      "Epoch 1052/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0480 - categorical_accuracy: 0.6823 - val_loss: 1.5426 - val_categorical_accuracy: 0.6115\n",
      "Epoch 1053/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0366 - categorical_accuracy: 0.6903 - val_loss: 1.5917 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1054/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0987 - categorical_accuracy: 0.6546 - val_loss: 1.6094 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1055/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0947 - categorical_accuracy: 0.6647 - val_loss: 1.6195 - val_categorical_accuracy: 0.5841\n",
      "Epoch 1056/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1038 - categorical_accuracy: 0.6551 - val_loss: 1.6235 - val_categorical_accuracy: 0.5766\n",
      "Epoch 1057/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1299 - categorical_accuracy: 0.6482 - val_loss: 1.7727 - val_categorical_accuracy: 0.5604\n",
      "Epoch 1058/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0819 - categorical_accuracy: 0.6583 - val_loss: 1.5568 - val_categorical_accuracy: 0.6040\n",
      "Epoch 1059/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0566 - categorical_accuracy: 0.6759 - val_loss: 1.6255 - val_categorical_accuracy: 0.6027\n",
      "Epoch 1060/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0991 - categorical_accuracy: 0.6604 - val_loss: 1.5165 - val_categorical_accuracy: 0.6289\n",
      "Epoch 1061/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1492 - categorical_accuracy: 0.6337 - val_loss: 1.5711 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1062/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1127 - categorical_accuracy: 0.6647 - val_loss: 1.5924 - val_categorical_accuracy: 0.6040\n",
      "Epoch 1063/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1194 - categorical_accuracy: 0.6514 - val_loss: 1.5912 - val_categorical_accuracy: 0.6040\n",
      "Epoch 1064/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0911 - categorical_accuracy: 0.6668 - val_loss: 1.6251 - val_categorical_accuracy: 0.5729\n",
      "Epoch 1065/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1001 - categorical_accuracy: 0.6759 - val_loss: 1.6387 - val_categorical_accuracy: 0.6065\n",
      "Epoch 1066/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0631 - categorical_accuracy: 0.6684 - val_loss: 1.5800 - val_categorical_accuracy: 0.5853\n",
      "Epoch 1067/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0711 - categorical_accuracy: 0.6599 - val_loss: 1.8418 - val_categorical_accuracy: 0.5567\n",
      "Epoch 1068/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1018 - categorical_accuracy: 0.6604 - val_loss: 1.5809 - val_categorical_accuracy: 0.6065\n",
      "Epoch 1069/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0798 - categorical_accuracy: 0.6716 - val_loss: 1.5792 - val_categorical_accuracy: 0.5978\n",
      "Epoch 1070/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0621 - categorical_accuracy: 0.6711 - val_loss: 1.6094 - val_categorical_accuracy: 0.5791\n",
      "Epoch 1071/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0483 - categorical_accuracy: 0.6716 - val_loss: 1.5484 - val_categorical_accuracy: 0.6090\n",
      "Epoch 1072/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0564 - categorical_accuracy: 0.6818 - val_loss: 1.5691 - val_categorical_accuracy: 0.6040\n",
      "Epoch 1073/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.0999 - categorical_accuracy: 0.6695 - val_loss: 1.5534 - val_categorical_accuracy: 0.6077\n",
      "Epoch 1074/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0419 - categorical_accuracy: 0.6807 - val_loss: 1.5888 - val_categorical_accuracy: 0.5953\n",
      "Epoch 1075/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1478 - categorical_accuracy: 0.6551 - val_loss: 1.5885 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1076/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1098 - categorical_accuracy: 0.6706 - val_loss: 1.5436 - val_categorical_accuracy: 0.6040\n",
      "Epoch 1077/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0712 - categorical_accuracy: 0.6663 - val_loss: 1.5946 - val_categorical_accuracy: 0.5940\n",
      "Epoch 1078/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0572 - categorical_accuracy: 0.6716 - val_loss: 1.6354 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1079/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1088 - categorical_accuracy: 0.6556 - val_loss: 1.4814 - val_categorical_accuracy: 0.6326\n",
      "Epoch 1080/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.9935 - categorical_accuracy: 0.6898 - val_loss: 1.5318 - val_categorical_accuracy: 0.6177\n",
      "Epoch 1081/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0677 - categorical_accuracy: 0.6711 - val_loss: 1.5212 - val_categorical_accuracy: 0.6102\n",
      "Epoch 1082/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1129 - categorical_accuracy: 0.6482 - val_loss: 1.5202 - val_categorical_accuracy: 0.6177\n",
      "Epoch 1083/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0725 - categorical_accuracy: 0.6706 - val_loss: 1.6231 - val_categorical_accuracy: 0.5903\n",
      "Epoch 1084/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1270 - categorical_accuracy: 0.6642 - val_loss: 1.6327 - val_categorical_accuracy: 0.5928\n",
      "Epoch 1085/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0563 - categorical_accuracy: 0.6834 - val_loss: 1.5536 - val_categorical_accuracy: 0.6127\n",
      "Epoch 1086/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0724 - categorical_accuracy: 0.6850 - val_loss: 1.5715 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1087/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0987 - categorical_accuracy: 0.6781 - val_loss: 1.6290 - val_categorical_accuracy: 0.5691\n",
      "Epoch 1088/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0573 - categorical_accuracy: 0.6770 - val_loss: 1.5520 - val_categorical_accuracy: 0.6127\n",
      "Epoch 1089/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1434 - categorical_accuracy: 0.6567 - val_loss: 1.5391 - val_categorical_accuracy: 0.6276\n",
      "Epoch 1090/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0783 - categorical_accuracy: 0.6700 - val_loss: 1.5689 - val_categorical_accuracy: 0.6276\n",
      "Epoch 1091/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0825 - categorical_accuracy: 0.6749 - val_loss: 1.5176 - val_categorical_accuracy: 0.6239\n",
      "Epoch 1092/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0777 - categorical_accuracy: 0.6684 - val_loss: 1.5832 - val_categorical_accuracy: 0.5890\n",
      "Epoch 1093/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0588 - categorical_accuracy: 0.6765 - val_loss: 1.5846 - val_categorical_accuracy: 0.6065\n",
      "Epoch 1094/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0533 - categorical_accuracy: 0.6658 - val_loss: 1.6214 - val_categorical_accuracy: 0.5928\n",
      "Epoch 1095/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0583 - categorical_accuracy: 0.6781 - val_loss: 1.6903 - val_categorical_accuracy: 0.5841\n",
      "Epoch 1096/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0906 - categorical_accuracy: 0.6636 - val_loss: 1.6448 - val_categorical_accuracy: 0.5753\n",
      "Epoch 1097/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0352 - categorical_accuracy: 0.6855 - val_loss: 1.5271 - val_categorical_accuracy: 0.5940\n",
      "Epoch 1098/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0672 - categorical_accuracy: 0.6738 - val_loss: 1.5147 - val_categorical_accuracy: 0.6164\n",
      "Epoch 1099/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0677 - categorical_accuracy: 0.6839 - val_loss: 1.6390 - val_categorical_accuracy: 0.5953\n",
      "Epoch 1100/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0583 - categorical_accuracy: 0.6813 - val_loss: 1.6321 - val_categorical_accuracy: 0.5853\n",
      "Epoch 1101/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0386 - categorical_accuracy: 0.6781 - val_loss: 1.5867 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1102/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0549 - categorical_accuracy: 0.6781 - val_loss: 1.6292 - val_categorical_accuracy: 0.5753\n",
      "Epoch 1103/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0774 - categorical_accuracy: 0.6775 - val_loss: 1.6563 - val_categorical_accuracy: 0.6189\n",
      "Epoch 1104/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0775 - categorical_accuracy: 0.6754 - val_loss: 1.7242 - val_categorical_accuracy: 0.5853\n",
      "Epoch 1105/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0909 - categorical_accuracy: 0.6652 - val_loss: 1.6884 - val_categorical_accuracy: 0.5940\n",
      "Epoch 1106/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0396 - categorical_accuracy: 0.6754 - val_loss: 1.6802 - val_categorical_accuracy: 0.5616\n",
      "Epoch 1107/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1135 - categorical_accuracy: 0.6620 - val_loss: 1.6603 - val_categorical_accuracy: 0.5903\n",
      "Epoch 1108/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1173 - categorical_accuracy: 0.6636 - val_loss: 1.7382 - val_categorical_accuracy: 0.5753\n",
      "Epoch 1109/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0633 - categorical_accuracy: 0.6610 - val_loss: 1.6616 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1110/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0990 - categorical_accuracy: 0.6578 - val_loss: 1.5218 - val_categorical_accuracy: 0.5915\n",
      "Epoch 1111/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1054 - categorical_accuracy: 0.6594 - val_loss: 1.5788 - val_categorical_accuracy: 0.5853\n",
      "Epoch 1112/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1049 - categorical_accuracy: 0.6674 - val_loss: 1.5959 - val_categorical_accuracy: 0.5841\n",
      "Epoch 1113/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0845 - categorical_accuracy: 0.6610 - val_loss: 1.6030 - val_categorical_accuracy: 0.5679\n",
      "Epoch 1114/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0935 - categorical_accuracy: 0.6759 - val_loss: 1.6558 - val_categorical_accuracy: 0.5729\n",
      "Epoch 1115/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1114 - categorical_accuracy: 0.6588 - val_loss: 1.6486 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1116/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0700 - categorical_accuracy: 0.6765 - val_loss: 1.6323 - val_categorical_accuracy: 0.5953\n",
      "Epoch 1117/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0896 - categorical_accuracy: 0.6626 - val_loss: 1.6103 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1118/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0951 - categorical_accuracy: 0.6668 - val_loss: 1.5507 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1119/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0333 - categorical_accuracy: 0.6754 - val_loss: 1.6062 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1120/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1443 - categorical_accuracy: 0.6439 - val_loss: 1.5813 - val_categorical_accuracy: 0.6102\n",
      "Epoch 1121/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.0535 - categorical_accuracy: 0.6818 - val_loss: 1.6651 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1122/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.0855 - categorical_accuracy: 0.6674 - val_loss: 1.6027 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1123/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0423 - categorical_accuracy: 0.6823 - val_loss: 1.6310 - val_categorical_accuracy: 0.5816\n",
      "Epoch 1124/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0645 - categorical_accuracy: 0.6716 - val_loss: 1.6085 - val_categorical_accuracy: 0.5890\n",
      "Epoch 1125/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.0488 - categorical_accuracy: 0.6733 - val_loss: 1.5437 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1126/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.1247 - categorical_accuracy: 0.6524 - val_loss: 1.5830 - val_categorical_accuracy: 0.5903\n",
      "Epoch 1127/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0629 - categorical_accuracy: 0.6727 - val_loss: 1.6094 - val_categorical_accuracy: 0.5978\n",
      "Epoch 1128/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.1189 - categorical_accuracy: 0.6636 - val_loss: 1.6385 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1129/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0507 - categorical_accuracy: 0.6636 - val_loss: 1.6819 - val_categorical_accuracy: 0.5704\n",
      "Epoch 1130/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0709 - categorical_accuracy: 0.6567 - val_loss: 1.6511 - val_categorical_accuracy: 0.5803\n",
      "Epoch 1131/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0044 - categorical_accuracy: 0.6893 - val_loss: 1.6208 - val_categorical_accuracy: 0.5791\n",
      "Epoch 1132/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0117 - categorical_accuracy: 0.6887 - val_loss: 1.6203 - val_categorical_accuracy: 0.5828\n",
      "Epoch 1133/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1054 - categorical_accuracy: 0.6620 - val_loss: 1.6126 - val_categorical_accuracy: 0.5816\n",
      "Epoch 1134/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0762 - categorical_accuracy: 0.6690 - val_loss: 1.5804 - val_categorical_accuracy: 0.5915\n",
      "Epoch 1135/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0664 - categorical_accuracy: 0.6636 - val_loss: 1.6642 - val_categorical_accuracy: 0.5691\n",
      "Epoch 1136/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0751 - categorical_accuracy: 0.6727 - val_loss: 1.6754 - val_categorical_accuracy: 0.5654\n",
      "Epoch 1137/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0542 - categorical_accuracy: 0.6786 - val_loss: 1.6351 - val_categorical_accuracy: 0.6027\n",
      "Epoch 1138/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0763 - categorical_accuracy: 0.6823 - val_loss: 1.6270 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1139/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0535 - categorical_accuracy: 0.6818 - val_loss: 1.5959 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1140/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1008 - categorical_accuracy: 0.6642 - val_loss: 1.6355 - val_categorical_accuracy: 0.5741\n",
      "Epoch 1141/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0476 - categorical_accuracy: 0.6690 - val_loss: 1.6509 - val_categorical_accuracy: 0.5629\n",
      "Epoch 1142/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0817 - categorical_accuracy: 0.6733 - val_loss: 1.7245 - val_categorical_accuracy: 0.5641\n",
      "Epoch 1143/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0609 - categorical_accuracy: 0.6797 - val_loss: 1.5893 - val_categorical_accuracy: 0.5915\n",
      "Epoch 1144/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0695 - categorical_accuracy: 0.6695 - val_loss: 1.5543 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1145/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1450 - categorical_accuracy: 0.6615 - val_loss: 1.5271 - val_categorical_accuracy: 0.6027\n",
      "Epoch 1146/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0497 - categorical_accuracy: 0.6775 - val_loss: 1.6026 - val_categorical_accuracy: 0.5729\n",
      "Epoch 1147/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0893 - categorical_accuracy: 0.6642 - val_loss: 1.5892 - val_categorical_accuracy: 0.5928\n",
      "Epoch 1148/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0960 - categorical_accuracy: 0.6636 - val_loss: 1.6036 - val_categorical_accuracy: 0.5828\n",
      "Epoch 1149/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0715 - categorical_accuracy: 0.6706 - val_loss: 1.5841 - val_categorical_accuracy: 0.5791\n",
      "Epoch 1150/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0707 - categorical_accuracy: 0.6770 - val_loss: 1.6921 - val_categorical_accuracy: 0.5716\n",
      "Epoch 1151/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0629 - categorical_accuracy: 0.6797 - val_loss: 1.6036 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1152/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0739 - categorical_accuracy: 0.6738 - val_loss: 1.6108 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1153/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1136 - categorical_accuracy: 0.6567 - val_loss: 1.5641 - val_categorical_accuracy: 0.6065\n",
      "Epoch 1154/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.9886 - categorical_accuracy: 0.6930 - val_loss: 1.6373 - val_categorical_accuracy: 0.5928\n",
      "Epoch 1155/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.0206 - categorical_accuracy: 0.6834 - val_loss: 1.6822 - val_categorical_accuracy: 0.5778\n",
      "Epoch 1156/5000\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.0374 - categorical_accuracy: 0.6765 - val_loss: 1.6434 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1157/5000\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 1.0505 - categorical_accuracy: 0.6754 - val_loss: 1.6665 - val_categorical_accuracy: 0.5903\n",
      "Epoch 1158/5000\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.0753 - categorical_accuracy: 0.6674 - val_loss: 1.7127 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1159/5000\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 1.0682 - categorical_accuracy: 0.6647 - val_loss: 1.6360 - val_categorical_accuracy: 0.6227\n",
      "Epoch 1160/5000\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 1.0623 - categorical_accuracy: 0.6765 - val_loss: 1.6076 - val_categorical_accuracy: 0.5978\n",
      "Epoch 1161/5000\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 1.0925 - categorical_accuracy: 0.6861 - val_loss: 1.5634 - val_categorical_accuracy: 0.6077\n",
      "Epoch 1162/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.1212 - categorical_accuracy: 0.6631 - val_loss: 1.7458 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1163/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.0791 - categorical_accuracy: 0.6743 - val_loss: 1.7262 - val_categorical_accuracy: 0.5666\n",
      "Epoch 1164/5000\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 1.0669 - categorical_accuracy: 0.6716 - val_loss: 1.6493 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1165/5000\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.1789 - categorical_accuracy: 0.6401 - val_loss: 1.6636 - val_categorical_accuracy: 0.5978\n",
      "Epoch 1166/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1117 - categorical_accuracy: 0.6583 - val_loss: 1.6100 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1167/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0732 - categorical_accuracy: 0.6684 - val_loss: 1.6113 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1168/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0167 - categorical_accuracy: 0.6802 - val_loss: 1.6508 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1169/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1052 - categorical_accuracy: 0.6690 - val_loss: 1.6177 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1170/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0577 - categorical_accuracy: 0.6855 - val_loss: 1.5527 - val_categorical_accuracy: 0.6065\n",
      "Epoch 1171/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0811 - categorical_accuracy: 0.6754 - val_loss: 1.7110 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1172/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1007 - categorical_accuracy: 0.6658 - val_loss: 1.6171 - val_categorical_accuracy: 0.5890\n",
      "Epoch 1173/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0797 - categorical_accuracy: 0.6620 - val_loss: 1.6167 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1174/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0711 - categorical_accuracy: 0.6540 - val_loss: 1.6698 - val_categorical_accuracy: 0.5940\n",
      "Epoch 1175/5000\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.0522 - categorical_accuracy: 0.6797 - val_loss: 1.6124 - val_categorical_accuracy: 0.5928\n",
      "Epoch 1176/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0898 - categorical_accuracy: 0.6700 - val_loss: 1.6278 - val_categorical_accuracy: 0.6077\n",
      "Epoch 1177/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1024 - categorical_accuracy: 0.6706 - val_loss: 1.6294 - val_categorical_accuracy: 0.5903\n",
      "Epoch 1178/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0804 - categorical_accuracy: 0.6711 - val_loss: 1.6038 - val_categorical_accuracy: 0.5915\n",
      "Epoch 1179/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0519 - categorical_accuracy: 0.6807 - val_loss: 1.6470 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1180/5000\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.1042 - categorical_accuracy: 0.6578 - val_loss: 1.6482 - val_categorical_accuracy: 0.5953\n",
      "Epoch 1181/5000\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.1014 - categorical_accuracy: 0.6738 - val_loss: 1.6488 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1182/5000\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 1.0349 - categorical_accuracy: 0.6855 - val_loss: 1.5916 - val_categorical_accuracy: 0.5890\n",
      "Epoch 1183/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0093 - categorical_accuracy: 0.6818 - val_loss: 1.6468 - val_categorical_accuracy: 0.5853\n",
      "Epoch 1184/5000\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.0765 - categorical_accuracy: 0.6711 - val_loss: 1.6162 - val_categorical_accuracy: 0.5928\n",
      "Epoch 1185/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0302 - categorical_accuracy: 0.6765 - val_loss: 1.6254 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1186/5000\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.0703 - categorical_accuracy: 0.6711 - val_loss: 1.6922 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1187/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.1140 - categorical_accuracy: 0.6572 - val_loss: 1.6497 - val_categorical_accuracy: 0.5953\n",
      "Epoch 1188/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.0524 - categorical_accuracy: 0.6749 - val_loss: 1.5915 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1189/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0491 - categorical_accuracy: 0.6759 - val_loss: 1.6621 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1190/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1021 - categorical_accuracy: 0.6636 - val_loss: 1.6738 - val_categorical_accuracy: 0.5841\n",
      "Epoch 1191/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0696 - categorical_accuracy: 0.6791 - val_loss: 1.7059 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1192/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1169 - categorical_accuracy: 0.6620 - val_loss: 1.6187 - val_categorical_accuracy: 0.5853\n",
      "Epoch 1193/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0292 - categorical_accuracy: 0.6877 - val_loss: 1.7701 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1194/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0806 - categorical_accuracy: 0.6567 - val_loss: 1.6252 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1195/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0865 - categorical_accuracy: 0.6765 - val_loss: 1.6087 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1196/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0128 - categorical_accuracy: 0.6877 - val_loss: 1.6180 - val_categorical_accuracy: 0.5978\n",
      "Epoch 1197/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0083 - categorical_accuracy: 0.6850 - val_loss: 1.7085 - val_categorical_accuracy: 0.5654\n",
      "Epoch 1198/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0617 - categorical_accuracy: 0.6829 - val_loss: 1.6528 - val_categorical_accuracy: 0.5791\n",
      "Epoch 1199/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0558 - categorical_accuracy: 0.6668 - val_loss: 1.8241 - val_categorical_accuracy: 0.5467\n",
      "Epoch 1200/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0867 - categorical_accuracy: 0.6722 - val_loss: 1.6149 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1201/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0661 - categorical_accuracy: 0.6706 - val_loss: 1.6857 - val_categorical_accuracy: 0.5816\n",
      "Epoch 1202/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0288 - categorical_accuracy: 0.6786 - val_loss: 1.6300 - val_categorical_accuracy: 0.6027\n",
      "Epoch 1203/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0247 - categorical_accuracy: 0.6914 - val_loss: 1.7028 - val_categorical_accuracy: 0.5791\n",
      "Epoch 1204/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0849 - categorical_accuracy: 0.6567 - val_loss: 1.6171 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1205/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0953 - categorical_accuracy: 0.6588 - val_loss: 1.6287 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1206/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0549 - categorical_accuracy: 0.6909 - val_loss: 1.6622 - val_categorical_accuracy: 0.6027\n",
      "Epoch 1207/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0496 - categorical_accuracy: 0.6829 - val_loss: 1.8221 - val_categorical_accuracy: 0.5816\n",
      "Epoch 1208/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0834 - categorical_accuracy: 0.6631 - val_loss: 1.7169 - val_categorical_accuracy: 0.5766\n",
      "Epoch 1209/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0000 - categorical_accuracy: 0.6893 - val_loss: 1.6592 - val_categorical_accuracy: 0.6040\n",
      "Epoch 1210/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0566 - categorical_accuracy: 0.6775 - val_loss: 1.6487 - val_categorical_accuracy: 0.6065\n",
      "Epoch 1211/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0654 - categorical_accuracy: 0.6850 - val_loss: 1.5918 - val_categorical_accuracy: 0.6102\n",
      "Epoch 1212/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0424 - categorical_accuracy: 0.6877 - val_loss: 1.6243 - val_categorical_accuracy: 0.6065\n",
      "Epoch 1213/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0266 - categorical_accuracy: 0.6781 - val_loss: 1.6091 - val_categorical_accuracy: 0.6115\n",
      "Epoch 1214/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0506 - categorical_accuracy: 0.6829 - val_loss: 1.5441 - val_categorical_accuracy: 0.6065\n",
      "Epoch 1215/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0338 - categorical_accuracy: 0.6781 - val_loss: 1.6032 - val_categorical_accuracy: 0.6040\n",
      "Epoch 1216/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0179 - categorical_accuracy: 0.6925 - val_loss: 1.6329 - val_categorical_accuracy: 0.6139\n",
      "Epoch 1217/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9995 - categorical_accuracy: 0.6951 - val_loss: 1.6217 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1218/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0598 - categorical_accuracy: 0.6765 - val_loss: 1.5933 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1219/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0817 - categorical_accuracy: 0.6711 - val_loss: 1.5993 - val_categorical_accuracy: 0.6102\n",
      "Epoch 1220/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0484 - categorical_accuracy: 0.6861 - val_loss: 1.5474 - val_categorical_accuracy: 0.6189\n",
      "Epoch 1221/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0512 - categorical_accuracy: 0.6903 - val_loss: 1.5847 - val_categorical_accuracy: 0.6264\n",
      "Epoch 1222/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0766 - categorical_accuracy: 0.6989 - val_loss: 1.6072 - val_categorical_accuracy: 0.6164\n",
      "Epoch 1223/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0400 - categorical_accuracy: 0.6834 - val_loss: 1.6431 - val_categorical_accuracy: 0.5903\n",
      "Epoch 1224/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0669 - categorical_accuracy: 0.6807 - val_loss: 1.6487 - val_categorical_accuracy: 0.6027\n",
      "Epoch 1225/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0283 - categorical_accuracy: 0.6829 - val_loss: 1.6502 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1226/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0615 - categorical_accuracy: 0.6813 - val_loss: 1.6362 - val_categorical_accuracy: 0.6102\n",
      "Epoch 1227/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0012 - categorical_accuracy: 0.6839 - val_loss: 1.6141 - val_categorical_accuracy: 0.6152\n",
      "Epoch 1228/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0153 - categorical_accuracy: 0.6759 - val_loss: 1.6798 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1229/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.1091 - categorical_accuracy: 0.6636 - val_loss: 1.6275 - val_categorical_accuracy: 0.5716\n",
      "Epoch 1230/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0816 - categorical_accuracy: 0.6668 - val_loss: 1.6655 - val_categorical_accuracy: 0.5654\n",
      "Epoch 1231/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0425 - categorical_accuracy: 0.6743 - val_loss: 1.7101 - val_categorical_accuracy: 0.5915\n",
      "Epoch 1232/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0373 - categorical_accuracy: 0.6909 - val_loss: 1.6740 - val_categorical_accuracy: 0.5903\n",
      "Epoch 1233/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0940 - categorical_accuracy: 0.6700 - val_loss: 1.6789 - val_categorical_accuracy: 0.5729\n",
      "Epoch 1234/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0285 - categorical_accuracy: 0.6893 - val_loss: 1.6430 - val_categorical_accuracy: 0.5940\n",
      "Epoch 1235/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0938 - categorical_accuracy: 0.6679 - val_loss: 1.6246 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1236/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0257 - categorical_accuracy: 0.6893 - val_loss: 1.6811 - val_categorical_accuracy: 0.6139\n",
      "Epoch 1237/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0297 - categorical_accuracy: 0.6775 - val_loss: 1.6452 - val_categorical_accuracy: 0.6127\n",
      "Epoch 1238/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0600 - categorical_accuracy: 0.6690 - val_loss: 1.6291 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1239/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0414 - categorical_accuracy: 0.6786 - val_loss: 1.6310 - val_categorical_accuracy: 0.5828\n",
      "Epoch 1240/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0410 - categorical_accuracy: 0.6749 - val_loss: 1.6239 - val_categorical_accuracy: 0.6326\n",
      "Epoch 1241/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0484 - categorical_accuracy: 0.6743 - val_loss: 1.5934 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1242/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0519 - categorical_accuracy: 0.6695 - val_loss: 1.5753 - val_categorical_accuracy: 0.6127\n",
      "Epoch 1243/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0009 - categorical_accuracy: 0.6925 - val_loss: 1.6795 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1244/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0407 - categorical_accuracy: 0.6786 - val_loss: 1.6832 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1245/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0372 - categorical_accuracy: 0.6797 - val_loss: 1.6318 - val_categorical_accuracy: 0.6027\n",
      "Epoch 1246/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0913 - categorical_accuracy: 0.6706 - val_loss: 1.5892 - val_categorical_accuracy: 0.6065\n",
      "Epoch 1247/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0677 - categorical_accuracy: 0.6684 - val_loss: 1.5952 - val_categorical_accuracy: 0.6139\n",
      "Epoch 1248/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0273 - categorical_accuracy: 0.6919 - val_loss: 1.6035 - val_categorical_accuracy: 0.6040\n",
      "Epoch 1249/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0395 - categorical_accuracy: 0.6845 - val_loss: 1.7065 - val_categorical_accuracy: 0.5953\n",
      "Epoch 1250/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0164 - categorical_accuracy: 0.6813 - val_loss: 1.5726 - val_categorical_accuracy: 0.6040\n",
      "Epoch 1251/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.9947 - categorical_accuracy: 0.6941 - val_loss: 1.5716 - val_categorical_accuracy: 0.5928\n",
      "Epoch 1252/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0900 - categorical_accuracy: 0.6743 - val_loss: 1.7445 - val_categorical_accuracy: 0.5679\n",
      "Epoch 1253/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0987 - categorical_accuracy: 0.6551 - val_loss: 1.5787 - val_categorical_accuracy: 0.5928\n",
      "Epoch 1254/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0505 - categorical_accuracy: 0.6797 - val_loss: 1.5621 - val_categorical_accuracy: 0.5890\n",
      "Epoch 1255/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0382 - categorical_accuracy: 0.6871 - val_loss: 1.5692 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1256/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0510 - categorical_accuracy: 0.6893 - val_loss: 1.6749 - val_categorical_accuracy: 0.5753\n",
      "Epoch 1257/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0652 - categorical_accuracy: 0.6759 - val_loss: 1.7018 - val_categorical_accuracy: 0.5915\n",
      "Epoch 1258/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9838 - categorical_accuracy: 0.7015 - val_loss: 1.6477 - val_categorical_accuracy: 0.6177\n",
      "Epoch 1259/5000\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 1.0961 - categorical_accuracy: 0.6636 - val_loss: 1.5977 - val_categorical_accuracy: 0.6065\n",
      "Epoch 1260/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0423 - categorical_accuracy: 0.6823 - val_loss: 1.6796 - val_categorical_accuracy: 0.5853\n",
      "Epoch 1261/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0303 - categorical_accuracy: 0.6743 - val_loss: 1.5996 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1262/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0545 - categorical_accuracy: 0.6690 - val_loss: 1.6621 - val_categorical_accuracy: 0.5841\n",
      "Epoch 1263/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0668 - categorical_accuracy: 0.6738 - val_loss: 1.6396 - val_categorical_accuracy: 0.5641\n",
      "Epoch 1264/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0451 - categorical_accuracy: 0.6743 - val_loss: 1.6871 - val_categorical_accuracy: 0.5828\n",
      "Epoch 1265/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0475 - categorical_accuracy: 0.6733 - val_loss: 1.6149 - val_categorical_accuracy: 0.5928\n",
      "Epoch 1266/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0297 - categorical_accuracy: 0.6818 - val_loss: 1.5678 - val_categorical_accuracy: 0.5953\n",
      "Epoch 1267/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0266 - categorical_accuracy: 0.6855 - val_loss: 1.7034 - val_categorical_accuracy: 0.5816\n",
      "Epoch 1268/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0829 - categorical_accuracy: 0.6786 - val_loss: 1.6397 - val_categorical_accuracy: 0.5766\n",
      "Epoch 1269/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0249 - categorical_accuracy: 0.6909 - val_loss: 1.6227 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1270/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9974 - categorical_accuracy: 0.6845 - val_loss: 1.6289 - val_categorical_accuracy: 0.5828\n",
      "Epoch 1271/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0687 - categorical_accuracy: 0.6807 - val_loss: 1.6136 - val_categorical_accuracy: 0.5940\n",
      "Epoch 1272/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0203 - categorical_accuracy: 0.6903 - val_loss: 1.6368 - val_categorical_accuracy: 0.5953\n",
      "Epoch 1273/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0129 - categorical_accuracy: 0.6941 - val_loss: 1.5901 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1274/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0218 - categorical_accuracy: 0.6898 - val_loss: 1.6192 - val_categorical_accuracy: 0.5791\n",
      "Epoch 1275/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0701 - categorical_accuracy: 0.6733 - val_loss: 1.7435 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1276/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0608 - categorical_accuracy: 0.6813 - val_loss: 1.6661 - val_categorical_accuracy: 0.5791\n",
      "Epoch 1277/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0341 - categorical_accuracy: 0.6797 - val_loss: 1.6241 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1278/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0893 - categorical_accuracy: 0.6642 - val_loss: 1.7179 - val_categorical_accuracy: 0.5928\n",
      "Epoch 1279/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0026 - categorical_accuracy: 0.6871 - val_loss: 1.6887 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1280/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0293 - categorical_accuracy: 0.6791 - val_loss: 1.6789 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1281/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0192 - categorical_accuracy: 0.6839 - val_loss: 1.6249 - val_categorical_accuracy: 0.5928\n",
      "Epoch 1282/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0299 - categorical_accuracy: 0.6914 - val_loss: 1.6536 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1283/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0729 - categorical_accuracy: 0.6722 - val_loss: 1.7295 - val_categorical_accuracy: 0.5803\n",
      "Epoch 1284/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0214 - categorical_accuracy: 0.6935 - val_loss: 1.7461 - val_categorical_accuracy: 0.5778\n",
      "Epoch 1285/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0086 - categorical_accuracy: 0.6882 - val_loss: 1.7628 - val_categorical_accuracy: 0.5915\n",
      "Epoch 1286/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0576 - categorical_accuracy: 0.6839 - val_loss: 1.7917 - val_categorical_accuracy: 0.5666\n",
      "Epoch 1287/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0336 - categorical_accuracy: 0.6946 - val_loss: 1.7098 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1288/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0241 - categorical_accuracy: 0.6716 - val_loss: 1.6921 - val_categorical_accuracy: 0.5928\n",
      "Epoch 1289/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0325 - categorical_accuracy: 0.6845 - val_loss: 1.6965 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1290/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0344 - categorical_accuracy: 0.6759 - val_loss: 1.7012 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1291/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0453 - categorical_accuracy: 0.6765 - val_loss: 1.6324 - val_categorical_accuracy: 0.6077\n",
      "Epoch 1292/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0640 - categorical_accuracy: 0.6668 - val_loss: 1.5716 - val_categorical_accuracy: 0.6276\n",
      "Epoch 1293/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0486 - categorical_accuracy: 0.6759 - val_loss: 1.6161 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1294/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0140 - categorical_accuracy: 0.6882 - val_loss: 1.6657 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1295/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0606 - categorical_accuracy: 0.6658 - val_loss: 1.6835 - val_categorical_accuracy: 0.5828\n",
      "Epoch 1296/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0100 - categorical_accuracy: 0.6935 - val_loss: 1.6340 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1297/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0514 - categorical_accuracy: 0.6861 - val_loss: 1.6523 - val_categorical_accuracy: 0.5890\n",
      "Epoch 1298/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0267 - categorical_accuracy: 0.6903 - val_loss: 1.7198 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1299/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0298 - categorical_accuracy: 0.6807 - val_loss: 1.6579 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1300/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9850 - categorical_accuracy: 0.7112 - val_loss: 1.7293 - val_categorical_accuracy: 0.5679\n",
      "Epoch 1301/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0769 - categorical_accuracy: 0.6765 - val_loss: 1.5805 - val_categorical_accuracy: 0.6139\n",
      "Epoch 1302/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0666 - categorical_accuracy: 0.6818 - val_loss: 1.6437 - val_categorical_accuracy: 0.5940\n",
      "Epoch 1303/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0563 - categorical_accuracy: 0.6823 - val_loss: 1.7055 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1304/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.9723 - categorical_accuracy: 0.6962 - val_loss: 1.6868 - val_categorical_accuracy: 0.6077\n",
      "Epoch 1305/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0732 - categorical_accuracy: 0.6668 - val_loss: 1.6817 - val_categorical_accuracy: 0.5915\n",
      "Epoch 1306/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0191 - categorical_accuracy: 0.6850 - val_loss: 1.6834 - val_categorical_accuracy: 0.5915\n",
      "Epoch 1307/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0528 - categorical_accuracy: 0.6781 - val_loss: 1.7216 - val_categorical_accuracy: 0.5903\n",
      "Epoch 1308/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9996 - categorical_accuracy: 0.6909 - val_loss: 1.6675 - val_categorical_accuracy: 0.5940\n",
      "Epoch 1309/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0421 - categorical_accuracy: 0.6850 - val_loss: 1.7019 - val_categorical_accuracy: 0.5803\n",
      "Epoch 1310/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0375 - categorical_accuracy: 0.6770 - val_loss: 1.6536 - val_categorical_accuracy: 0.5778\n",
      "Epoch 1311/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0319 - categorical_accuracy: 0.6903 - val_loss: 1.6402 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1312/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9920 - categorical_accuracy: 0.6946 - val_loss: 1.6510 - val_categorical_accuracy: 0.5803\n",
      "Epoch 1313/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0239 - categorical_accuracy: 0.6743 - val_loss: 1.6332 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1314/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0215 - categorical_accuracy: 0.6818 - val_loss: 1.6535 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1315/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0369 - categorical_accuracy: 0.6807 - val_loss: 1.6592 - val_categorical_accuracy: 0.5940\n",
      "Epoch 1316/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0417 - categorical_accuracy: 0.6733 - val_loss: 1.6695 - val_categorical_accuracy: 0.6040\n",
      "Epoch 1317/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0451 - categorical_accuracy: 0.6818 - val_loss: 1.6967 - val_categorical_accuracy: 0.6027\n",
      "Epoch 1318/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9732 - categorical_accuracy: 0.7069 - val_loss: 1.7213 - val_categorical_accuracy: 0.5978\n",
      "Epoch 1319/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0170 - categorical_accuracy: 0.6834 - val_loss: 1.6891 - val_categorical_accuracy: 0.6027\n",
      "Epoch 1320/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0360 - categorical_accuracy: 0.6882 - val_loss: 1.6794 - val_categorical_accuracy: 0.5915\n",
      "Epoch 1321/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0078 - categorical_accuracy: 0.7064 - val_loss: 1.7046 - val_categorical_accuracy: 0.5853\n",
      "Epoch 1322/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0322 - categorical_accuracy: 0.6770 - val_loss: 1.6578 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1323/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1020 - categorical_accuracy: 0.6690 - val_loss: 1.7129 - val_categorical_accuracy: 0.5679\n",
      "Epoch 1324/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0450 - categorical_accuracy: 0.6690 - val_loss: 1.7244 - val_categorical_accuracy: 0.5816\n",
      "Epoch 1325/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0373 - categorical_accuracy: 0.6855 - val_loss: 1.7934 - val_categorical_accuracy: 0.5691\n",
      "Epoch 1326/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.0674 - categorical_accuracy: 0.6770 - val_loss: 1.6741 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1327/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0251 - categorical_accuracy: 0.6935 - val_loss: 1.7089 - val_categorical_accuracy: 0.6065\n",
      "Epoch 1328/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0213 - categorical_accuracy: 0.6930 - val_loss: 1.7905 - val_categorical_accuracy: 0.5753\n",
      "Epoch 1329/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.0320 - categorical_accuracy: 0.6775 - val_loss: 1.8202 - val_categorical_accuracy: 0.5753\n",
      "Epoch 1330/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0457 - categorical_accuracy: 0.6909 - val_loss: 1.7973 - val_categorical_accuracy: 0.5816\n",
      "Epoch 1331/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0300 - categorical_accuracy: 0.6829 - val_loss: 1.6812 - val_categorical_accuracy: 0.5666\n",
      "Epoch 1332/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0039 - categorical_accuracy: 0.6893 - val_loss: 1.7086 - val_categorical_accuracy: 0.5716\n",
      "Epoch 1333/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0574 - categorical_accuracy: 0.6738 - val_loss: 1.8927 - val_categorical_accuracy: 0.5355\n",
      "Epoch 1334/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0277 - categorical_accuracy: 0.6930 - val_loss: 1.7427 - val_categorical_accuracy: 0.5841\n",
      "Epoch 1335/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0459 - categorical_accuracy: 0.6813 - val_loss: 1.6568 - val_categorical_accuracy: 0.6027\n",
      "Epoch 1336/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0215 - categorical_accuracy: 0.6946 - val_loss: 1.7343 - val_categorical_accuracy: 0.5704\n",
      "Epoch 1337/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0455 - categorical_accuracy: 0.6898 - val_loss: 1.6967 - val_categorical_accuracy: 0.5766\n",
      "Epoch 1338/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0652 - categorical_accuracy: 0.6866 - val_loss: 1.7232 - val_categorical_accuracy: 0.5890\n",
      "Epoch 1339/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0314 - categorical_accuracy: 0.6893 - val_loss: 1.7443 - val_categorical_accuracy: 0.6027\n",
      "Epoch 1340/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.9524 - categorical_accuracy: 0.6983 - val_loss: 1.7182 - val_categorical_accuracy: 0.6127\n",
      "Epoch 1341/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0347 - categorical_accuracy: 0.6861 - val_loss: 1.7136 - val_categorical_accuracy: 0.5729\n",
      "Epoch 1342/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0141 - categorical_accuracy: 0.6802 - val_loss: 1.6842 - val_categorical_accuracy: 0.5853\n",
      "Epoch 1343/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0096 - categorical_accuracy: 0.6818 - val_loss: 1.7983 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1344/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0298 - categorical_accuracy: 0.6775 - val_loss: 1.6855 - val_categorical_accuracy: 0.5816\n",
      "Epoch 1345/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0794 - categorical_accuracy: 0.6871 - val_loss: 1.8041 - val_categorical_accuracy: 0.5915\n",
      "Epoch 1346/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0617 - categorical_accuracy: 0.6882 - val_loss: 1.7257 - val_categorical_accuracy: 0.6027\n",
      "Epoch 1347/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.9883 - categorical_accuracy: 0.7032 - val_loss: 1.6653 - val_categorical_accuracy: 0.6164\n",
      "Epoch 1348/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0598 - categorical_accuracy: 0.6765 - val_loss: 1.7013 - val_categorical_accuracy: 0.6065\n",
      "Epoch 1349/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0217 - categorical_accuracy: 0.6765 - val_loss: 1.6337 - val_categorical_accuracy: 0.6115\n",
      "Epoch 1350/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0234 - categorical_accuracy: 0.6834 - val_loss: 1.8076 - val_categorical_accuracy: 0.5816\n",
      "Epoch 1351/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.9874 - categorical_accuracy: 0.6893 - val_loss: 1.7806 - val_categorical_accuracy: 0.5679\n",
      "Epoch 1352/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.9964 - categorical_accuracy: 0.6967 - val_loss: 1.7166 - val_categorical_accuracy: 0.5928\n",
      "Epoch 1353/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0128 - categorical_accuracy: 0.6871 - val_loss: 1.6529 - val_categorical_accuracy: 0.6077\n",
      "Epoch 1354/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0516 - categorical_accuracy: 0.6903 - val_loss: 1.7532 - val_categorical_accuracy: 0.5803\n",
      "Epoch 1355/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0021 - categorical_accuracy: 0.6941 - val_loss: 1.6803 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1356/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0427 - categorical_accuracy: 0.6759 - val_loss: 1.6716 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1357/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.9793 - categorical_accuracy: 0.7069 - val_loss: 1.6153 - val_categorical_accuracy: 0.6102\n",
      "Epoch 1358/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0960 - categorical_accuracy: 0.6818 - val_loss: 1.7165 - val_categorical_accuracy: 0.5629\n",
      "Epoch 1359/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0215 - categorical_accuracy: 0.6887 - val_loss: 1.6459 - val_categorical_accuracy: 0.5791\n",
      "Epoch 1360/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0301 - categorical_accuracy: 0.6749 - val_loss: 1.6391 - val_categorical_accuracy: 0.5890\n",
      "Epoch 1361/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0319 - categorical_accuracy: 0.6845 - val_loss: 1.7629 - val_categorical_accuracy: 0.5816\n",
      "Epoch 1362/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0362 - categorical_accuracy: 0.6807 - val_loss: 1.6825 - val_categorical_accuracy: 0.5766\n",
      "Epoch 1363/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0059 - categorical_accuracy: 0.6925 - val_loss: 1.6977 - val_categorical_accuracy: 0.5940\n",
      "Epoch 1364/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.9844 - categorical_accuracy: 0.7064 - val_loss: 1.7119 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1365/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.9968 - categorical_accuracy: 0.6946 - val_loss: 1.7063 - val_categorical_accuracy: 0.5841\n",
      "Epoch 1366/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.9753 - categorical_accuracy: 0.7053 - val_loss: 1.6970 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1367/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.9563 - categorical_accuracy: 0.6989 - val_loss: 1.7381 - val_categorical_accuracy: 0.5841\n",
      "Epoch 1368/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0319 - categorical_accuracy: 0.6765 - val_loss: 1.8621 - val_categorical_accuracy: 0.5230\n",
      "Epoch 1369/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.9798 - categorical_accuracy: 0.6775 - val_loss: 1.7230 - val_categorical_accuracy: 0.6065\n",
      "Epoch 1370/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.9960 - categorical_accuracy: 0.7005 - val_loss: 1.7386 - val_categorical_accuracy: 0.5890\n",
      "Epoch 1371/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.9849 - categorical_accuracy: 0.7021 - val_loss: 1.7037 - val_categorical_accuracy: 0.5766\n",
      "Epoch 1372/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.9875 - categorical_accuracy: 0.6962 - val_loss: 1.7480 - val_categorical_accuracy: 0.5816\n",
      "Epoch 1373/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0407 - categorical_accuracy: 0.6893 - val_loss: 1.7013 - val_categorical_accuracy: 0.5766\n",
      "Epoch 1374/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0485 - categorical_accuracy: 0.6893 - val_loss: 1.7958 - val_categorical_accuracy: 0.5753\n",
      "Epoch 1375/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0560 - categorical_accuracy: 0.6839 - val_loss: 1.6720 - val_categorical_accuracy: 0.6102\n",
      "Epoch 1376/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0375 - categorical_accuracy: 0.6845 - val_loss: 1.6619 - val_categorical_accuracy: 0.5953\n",
      "Epoch 1377/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.9908 - categorical_accuracy: 0.6919 - val_loss: 1.7576 - val_categorical_accuracy: 0.6090\n",
      "Epoch 1378/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0665 - categorical_accuracy: 0.6733 - val_loss: 1.7577 - val_categorical_accuracy: 0.5953\n",
      "Epoch 1379/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.9634 - categorical_accuracy: 0.7032 - val_loss: 1.7011 - val_categorical_accuracy: 0.5928\n",
      "Epoch 1380/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.9907 - categorical_accuracy: 0.6946 - val_loss: 1.7315 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1381/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0204 - categorical_accuracy: 0.6887 - val_loss: 1.6865 - val_categorical_accuracy: 0.6077\n",
      "Epoch 1382/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0358 - categorical_accuracy: 0.6759 - val_loss: 1.6957 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1383/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0346 - categorical_accuracy: 0.6829 - val_loss: 1.6571 - val_categorical_accuracy: 0.6040\n",
      "Epoch 1384/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0449 - categorical_accuracy: 0.6818 - val_loss: 1.6127 - val_categorical_accuracy: 0.6027\n",
      "Epoch 1385/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.9780 - categorical_accuracy: 0.7064 - val_loss: 1.6898 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1386/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0384 - categorical_accuracy: 0.6946 - val_loss: 1.6101 - val_categorical_accuracy: 0.6164\n",
      "Epoch 1387/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.9954 - categorical_accuracy: 0.6935 - val_loss: 1.6720 - val_categorical_accuracy: 0.5978\n",
      "Epoch 1388/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.9621 - categorical_accuracy: 0.7186 - val_loss: 1.7051 - val_categorical_accuracy: 0.6027\n",
      "Epoch 1389/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.0156 - categorical_accuracy: 0.6887 - val_loss: 1.7125 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1390/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.0110 - categorical_accuracy: 0.6743 - val_loss: 1.7274 - val_categorical_accuracy: 0.5853\n",
      "Epoch 1391/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0184 - categorical_accuracy: 0.6829 - val_loss: 1.7144 - val_categorical_accuracy: 0.5978\n",
      "Epoch 1392/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0414 - categorical_accuracy: 0.6775 - val_loss: 1.6851 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1393/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0254 - categorical_accuracy: 0.6759 - val_loss: 1.7652 - val_categorical_accuracy: 0.5778\n",
      "Epoch 1394/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0081 - categorical_accuracy: 0.6866 - val_loss: 1.7240 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1395/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9824 - categorical_accuracy: 0.7064 - val_loss: 1.7001 - val_categorical_accuracy: 0.5803\n",
      "Epoch 1396/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9745 - categorical_accuracy: 0.6983 - val_loss: 1.7203 - val_categorical_accuracy: 0.5978\n",
      "Epoch 1397/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0388 - categorical_accuracy: 0.6893 - val_loss: 1.7159 - val_categorical_accuracy: 0.5928\n",
      "Epoch 1398/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9707 - categorical_accuracy: 0.6951 - val_loss: 1.8764 - val_categorical_accuracy: 0.5753\n",
      "Epoch 1399/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0316 - categorical_accuracy: 0.6829 - val_loss: 1.6412 - val_categorical_accuracy: 0.5915\n",
      "Epoch 1400/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0095 - categorical_accuracy: 0.6957 - val_loss: 1.6860 - val_categorical_accuracy: 0.5890\n",
      "Epoch 1401/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9812 - categorical_accuracy: 0.7015 - val_loss: 1.6863 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1402/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9665 - categorical_accuracy: 0.7090 - val_loss: 1.7556 - val_categorical_accuracy: 0.5729\n",
      "Epoch 1403/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9948 - categorical_accuracy: 0.6983 - val_loss: 1.6783 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1404/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0116 - categorical_accuracy: 0.6999 - val_loss: 1.6838 - val_categorical_accuracy: 0.5978\n",
      "Epoch 1405/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9935 - categorical_accuracy: 0.6871 - val_loss: 1.6830 - val_categorical_accuracy: 0.6077\n",
      "Epoch 1406/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9987 - categorical_accuracy: 0.6925 - val_loss: 1.8006 - val_categorical_accuracy: 0.5641\n",
      "Epoch 1407/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0373 - categorical_accuracy: 0.6877 - val_loss: 1.8009 - val_categorical_accuracy: 0.5766\n",
      "Epoch 1408/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0300 - categorical_accuracy: 0.6935 - val_loss: 1.7494 - val_categorical_accuracy: 0.5766\n",
      "Epoch 1409/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0364 - categorical_accuracy: 0.6882 - val_loss: 1.8135 - val_categorical_accuracy: 0.5803\n",
      "Epoch 1410/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0299 - categorical_accuracy: 0.6855 - val_loss: 1.7507 - val_categorical_accuracy: 0.5716\n",
      "Epoch 1411/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0694 - categorical_accuracy: 0.6770 - val_loss: 1.7267 - val_categorical_accuracy: 0.5828\n",
      "Epoch 1412/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0209 - categorical_accuracy: 0.6925 - val_loss: 1.6862 - val_categorical_accuracy: 0.5853\n",
      "Epoch 1413/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0344 - categorical_accuracy: 0.6818 - val_loss: 1.7471 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1414/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0175 - categorical_accuracy: 0.6791 - val_loss: 1.6742 - val_categorical_accuracy: 0.6077\n",
      "Epoch 1415/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0040 - categorical_accuracy: 0.6877 - val_loss: 1.7648 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1416/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0069 - categorical_accuracy: 0.6834 - val_loss: 1.6876 - val_categorical_accuracy: 0.5666\n",
      "Epoch 1417/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9504 - categorical_accuracy: 0.7096 - val_loss: 1.7159 - val_categorical_accuracy: 0.5953\n",
      "Epoch 1418/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9938 - categorical_accuracy: 0.6989 - val_loss: 1.6814 - val_categorical_accuracy: 0.5828\n",
      "Epoch 1419/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9835 - categorical_accuracy: 0.6983 - val_loss: 1.7422 - val_categorical_accuracy: 0.5953\n",
      "Epoch 1420/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0291 - categorical_accuracy: 0.6791 - val_loss: 1.7472 - val_categorical_accuracy: 0.5853\n",
      "Epoch 1421/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9781 - categorical_accuracy: 0.7010 - val_loss: 1.8324 - val_categorical_accuracy: 0.5616\n",
      "Epoch 1422/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.9949 - categorical_accuracy: 0.7064 - val_loss: 1.6565 - val_categorical_accuracy: 0.5816\n",
      "Epoch 1423/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0257 - categorical_accuracy: 0.6887 - val_loss: 1.7215 - val_categorical_accuracy: 0.5853\n",
      "Epoch 1424/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0077 - categorical_accuracy: 0.6887 - val_loss: 1.7325 - val_categorical_accuracy: 0.5890\n",
      "Epoch 1425/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0026 - categorical_accuracy: 0.6898 - val_loss: 1.7107 - val_categorical_accuracy: 0.5828\n",
      "Epoch 1426/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0076 - categorical_accuracy: 0.6919 - val_loss: 1.8172 - val_categorical_accuracy: 0.5791\n",
      "Epoch 1427/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0406 - categorical_accuracy: 0.6967 - val_loss: 1.7881 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1428/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9573 - categorical_accuracy: 0.7010 - val_loss: 1.7431 - val_categorical_accuracy: 0.5890\n",
      "Epoch 1429/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9522 - categorical_accuracy: 0.7048 - val_loss: 1.6515 - val_categorical_accuracy: 0.6214\n",
      "Epoch 1430/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0586 - categorical_accuracy: 0.6556 - val_loss: 1.7025 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1431/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0143 - categorical_accuracy: 0.6951 - val_loss: 1.6708 - val_categorical_accuracy: 0.5816\n",
      "Epoch 1432/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.9942 - categorical_accuracy: 0.6930 - val_loss: 1.6965 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1433/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9989 - categorical_accuracy: 0.6930 - val_loss: 1.7009 - val_categorical_accuracy: 0.5791\n",
      "Epoch 1434/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0130 - categorical_accuracy: 0.6765 - val_loss: 1.6842 - val_categorical_accuracy: 0.5978\n",
      "Epoch 1435/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9938 - categorical_accuracy: 0.6957 - val_loss: 1.6977 - val_categorical_accuracy: 0.6164\n",
      "Epoch 1436/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9835 - categorical_accuracy: 0.6983 - val_loss: 1.6671 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1437/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0633 - categorical_accuracy: 0.6663 - val_loss: 1.6743 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1438/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.1107 - categorical_accuracy: 0.6786 - val_loss: 1.7173 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1439/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0010 - categorical_accuracy: 0.6951 - val_loss: 1.7110 - val_categorical_accuracy: 0.5691\n",
      "Epoch 1440/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0255 - categorical_accuracy: 0.6781 - val_loss: 1.6716 - val_categorical_accuracy: 0.6015\n",
      "Epoch 1441/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0291 - categorical_accuracy: 0.6829 - val_loss: 1.6799 - val_categorical_accuracy: 0.5940\n",
      "Epoch 1442/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0088 - categorical_accuracy: 0.6919 - val_loss: 1.6094 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1443/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9717 - categorical_accuracy: 0.7005 - val_loss: 1.7557 - val_categorical_accuracy: 0.5729\n",
      "Epoch 1444/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.9851 - categorical_accuracy: 0.6967 - val_loss: 1.7586 - val_categorical_accuracy: 0.5529\n",
      "Epoch 1445/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0217 - categorical_accuracy: 0.6882 - val_loss: 1.7539 - val_categorical_accuracy: 0.5716\n",
      "Epoch 1446/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0173 - categorical_accuracy: 0.6909 - val_loss: 1.7702 - val_categorical_accuracy: 0.5766\n",
      "Epoch 1447/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9442 - categorical_accuracy: 0.7080 - val_loss: 1.7342 - val_categorical_accuracy: 0.5741\n",
      "Epoch 1448/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.9811 - categorical_accuracy: 0.7058 - val_loss: 1.6617 - val_categorical_accuracy: 0.6040\n",
      "Epoch 1449/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9483 - categorical_accuracy: 0.7053 - val_loss: 1.8995 - val_categorical_accuracy: 0.5293\n",
      "Epoch 1450/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9923 - categorical_accuracy: 0.6951 - val_loss: 1.7541 - val_categorical_accuracy: 0.5654\n",
      "Epoch 1451/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0733 - categorical_accuracy: 0.6829 - val_loss: 1.6699 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1452/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9728 - categorical_accuracy: 0.7005 - val_loss: 1.6956 - val_categorical_accuracy: 0.5990\n",
      "Epoch 1453/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9907 - categorical_accuracy: 0.6941 - val_loss: 1.7620 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1454/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9821 - categorical_accuracy: 0.6994 - val_loss: 1.8004 - val_categorical_accuracy: 0.5641\n",
      "Epoch 1455/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.0062 - categorical_accuracy: 0.6823 - val_loss: 1.7373 - val_categorical_accuracy: 0.5753\n",
      "Epoch 1456/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9995 - categorical_accuracy: 0.7015 - val_loss: 1.7270 - val_categorical_accuracy: 0.5704\n",
      "Epoch 1457/5000\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.9862 - categorical_accuracy: 0.7128 - val_loss: 1.7236 - val_categorical_accuracy: 0.5679\n",
      "Epoch 1458/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.0055 - categorical_accuracy: 0.6893 - val_loss: 1.7243 - val_categorical_accuracy: 0.6002\n",
      "Epoch 1459/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9448 - categorical_accuracy: 0.7080 - val_loss: 1.7102 - val_categorical_accuracy: 0.5816\n",
      "Epoch 1460/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9658 - categorical_accuracy: 0.7005 - val_loss: 1.7004 - val_categorical_accuracy: 0.5828\n",
      "Epoch 1461/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.9971 - categorical_accuracy: 0.6834 - val_loss: 1.8030 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1462/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0010 - categorical_accuracy: 0.7010 - val_loss: 1.7556 - val_categorical_accuracy: 0.5965\n",
      "Epoch 1463/5000\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9279 - categorical_accuracy: 0.7192 - val_loss: 1.6833 - val_categorical_accuracy: 0.5866\n",
      "Epoch 1464/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0051 - categorical_accuracy: 0.6994 - val_loss: 1.8222 - val_categorical_accuracy: 0.5542\n",
      "Epoch 1465/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.9947 - categorical_accuracy: 0.7037 - val_loss: 1.6988 - val_categorical_accuracy: 0.5791\n",
      "Epoch 1466/5000\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.0117 - categorical_accuracy: 0.6935 - val_loss: 1.6581 - val_categorical_accuracy: 0.5766\n",
      "Epoch 1467/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.9763 - categorical_accuracy: 0.6957 - val_loss: 1.7299 - val_categorical_accuracy: 0.5641\n",
      "Epoch 1468/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.9959 - categorical_accuracy: 0.6951 - val_loss: 1.7648 - val_categorical_accuracy: 0.5616\n",
      "Epoch 1469/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.9664 - categorical_accuracy: 0.6946 - val_loss: 1.7599 - val_categorical_accuracy: 0.5729\n",
      "Epoch 1470/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.0230 - categorical_accuracy: 0.6978 - val_loss: 1.6814 - val_categorical_accuracy: 0.5853\n",
      "Epoch 1471/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.0158 - categorical_accuracy: 0.6861 - val_loss: 1.6986 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1472/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.9765 - categorical_accuracy: 0.7101 - val_loss: 1.6353 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1473/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.9664 - categorical_accuracy: 0.7122 - val_loss: 1.6992 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1474/5000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.9459 - categorical_accuracy: 0.7064 - val_loss: 1.7292 - val_categorical_accuracy: 0.5878\n",
      "Epoch 1475/5000\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.9802 - categorical_accuracy: 0.6925 - val_loss: 1.6689 - val_categorical_accuracy: 0.6077\n",
      "Epoch 1476/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0029 - categorical_accuracy: 0.6914 - val_loss: 1.7706 - val_categorical_accuracy: 0.5803\n",
      "Epoch 1477/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0403 - categorical_accuracy: 0.6813 - val_loss: 1.6170 - val_categorical_accuracy: 0.6052\n",
      "Epoch 1478/5000\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.0356 - categorical_accuracy: 0.6919 - val_loss: 1.6811 - val_categorical_accuracy: 0.6214\n",
      "Epoch 1479/5000\n",
      "13/15 [=========================>....] - ETA: 0s - loss: 1.0040 - categorical_accuracy: 0.6935"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1791\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1777\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1778\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1789\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1790\u001b[0m     )\n\u001b[0;32m-> 1791\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1800\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1802\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1804\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1806\u001b[0m }\n\u001b[1;32m   1807\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:2200\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2196\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   2197\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2198\u001b[0m             ):\n\u001b[1;32m   2199\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2200\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2201\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2202\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2203\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2204\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2205\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2207\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2208\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:4000\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   3999\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4000\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4001\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   4002\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:864\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    862\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 864\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SpatialDropout1D\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential(name='Sequential')\n",
    "act_function = 'selu'\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv1D(filters=25, kernel_size=2, activation=act_function, input_shape=(130, 126)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=50, kernel_size=2, activation=act_function))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=25, kernel_size=3, activation='selu', kernel_regularizer=regularizers.l2(l=0.001)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# droput layer, remove if no work\n",
    "model.add(SpatialDropout1D(0.7))\n",
    "\n",
    "# Flatten the output for the fully connected layers\n",
    "model.add(Flatten())\n",
    "# Add fully connected layers\n",
    "model.add(Dense(20, activation=act_function))\n",
    "#model.add(Dense(16, activation=act_function))\n",
    "#model.add(Dense(40, activation=act_function))\n",
    "#model.add(Dense(16, activation=act_function))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation='softmax'))  # Output layer\n",
    "optimizer = Lion(learning_rate=.00075)\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(Xtrain, Ytrain, epochs=5000, validation_split=.3, batch_size = 128, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a537883d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T09:08:40.078634Z",
     "start_time": "2023-08-11T09:08:27.538693Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 129, 50)           12650     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPoolin  (None, 64, 50)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 63, 100)           10100     \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPoolin  (None, 31, 100)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 30, 50)            10050     \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPoolin  (None, 15, 50)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spati  (None, 15, 50)            0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 750)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 40)                30040     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 40)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64890 (253.48 KB)\n",
      "Trainable params: 64890 (253.48 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96209/3719245833.py:3: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import HyperModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "15/15 [==============================] - 3s 155ms/step - loss: 5.0549 - categorical_accuracy: 0.0208 - val_loss: 4.2104 - val_categorical_accuracy: 0.0162\n",
      "Epoch 2/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 4.4412 - categorical_accuracy: 0.0235 - val_loss: 4.0798 - val_categorical_accuracy: 0.0311\n",
      "Epoch 3/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 4.2043 - categorical_accuracy: 0.0235 - val_loss: 4.0172 - val_categorical_accuracy: 0.0349\n",
      "Epoch 4/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 4.1881 - categorical_accuracy: 0.0246 - val_loss: 4.0117 - val_categorical_accuracy: 0.0274\n",
      "Epoch 5/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 4.0956 - categorical_accuracy: 0.0294 - val_loss: 4.0021 - val_categorical_accuracy: 0.0299\n",
      "Epoch 6/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 4.0365 - categorical_accuracy: 0.0352 - val_loss: 3.9790 - val_categorical_accuracy: 0.0311\n",
      "Epoch 7/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 4.0254 - categorical_accuracy: 0.0294 - val_loss: 3.9808 - val_categorical_accuracy: 0.0411\n",
      "Epoch 8/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 3.9856 - categorical_accuracy: 0.0363 - val_loss: 3.9575 - val_categorical_accuracy: 0.0386\n",
      "Epoch 9/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 3.9531 - categorical_accuracy: 0.0432 - val_loss: 3.9634 - val_categorical_accuracy: 0.0473\n",
      "Epoch 10/5000\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 3.9043 - categorical_accuracy: 0.0513 - val_loss: 3.9313 - val_categorical_accuracy: 0.0535\n",
      "Epoch 11/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 3.8678 - categorical_accuracy: 0.0539 - val_loss: 3.9001 - val_categorical_accuracy: 0.0598\n",
      "Epoch 12/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 3.8305 - categorical_accuracy: 0.0603 - val_loss: 3.8615 - val_categorical_accuracy: 0.0760\n",
      "Epoch 13/5000\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 3.8119 - categorical_accuracy: 0.0699 - val_loss: 3.8601 - val_categorical_accuracy: 0.0735\n",
      "Epoch 14/5000\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 3.7701 - categorical_accuracy: 0.0715 - val_loss: 3.8363 - val_categorical_accuracy: 0.0822\n",
      "Epoch 15/5000\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 3.7154 - categorical_accuracy: 0.0966 - val_loss: 3.8147 - val_categorical_accuracy: 0.0797\n",
      "Epoch 16/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 3.6762 - categorical_accuracy: 0.0961 - val_loss: 3.7933 - val_categorical_accuracy: 0.0785\n",
      "Epoch 17/5000\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 3.6552 - categorical_accuracy: 0.0950 - val_loss: 3.7577 - val_categorical_accuracy: 0.0822\n",
      "Epoch 18/5000\n",
      " 4/15 [=======>......................] - ETA: 0s - loss: 3.6357 - categorical_accuracy: 0.1016"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1748\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1746\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1747\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1748\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/tf_utils.py:694\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/nest.py:624\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    540\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 624\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1054\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \n\u001b[1;32m    959\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1054\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/tf_utils.py:687\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 687\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1141\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m \n\u001b[1;32m   1120\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1107\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1106\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1108\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SpatialDropout1D\n",
    "from kerastuner import HyperModel\n",
    "\n",
    "#supercool\n",
    "# Define the CNN model\n",
    "model = Sequential(name='Sequential')\n",
    "act_function = 'selu'\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv1D(filters=50, kernel_size=2, activation=act_function, input_shape=(130, 126)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=100, kernel_size=2, activation=act_function))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=50, kernel_size=2, activation='selu', kernel_regularizer=regularizers.l2(l=0.001)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# droput layer, remove if no work\n",
    "model.add(SpatialDropout1D(0.7))\n",
    "\n",
    "# Flatten the output for the fully connected layers\n",
    "model.add(Flatten())\n",
    "# Add fully connected layers\n",
    "model.add(Dense(40, activation=act_function))\n",
    "#model.add(Dense(16, activation=act_function))\n",
    "#model.add(Dense(40, activation=act_function))\n",
    "#model.add(Dense(16, activation=act_function))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation='softmax'))  # Output layer\n",
    "optimizer = Lion(learning_rate=.0001)\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(Xtrain, Ytrain, epochs=5000, validation_split=.3, batch_size = 128, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f484a8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T09:02:05.022311Z",
     "start_time": "2023-08-11T09:02:04.289367Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/6 [====>.........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 10:02:04.577965: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 10:02:04.804407: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.24GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c783812d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T09:03:23.231574Z",
     "start_time": "2023-08-11T09:03:23.227144Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(res[101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c98fe8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T09:03:20.415209Z",
     "start_time": "2023-08-11T09:03:20.411376Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Yval[101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61b5ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SpatialDropout1D\n",
    "from kerastuner import HyperModel\n",
    "\n",
    "#supercool hyperparameter\n",
    "# Define the CNN model\n",
    "model = Sequential(name='Sequential')\n",
    "act_function = 'selu'\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv1D(filters=50, kernel_size=2, activation=act_function, input_shape=(130, 126)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=100, kernel_size=2, activation=act_function))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=50, kernel_size=2, activation='selu', kernel_regularizer=regularizers.l2(l=0.001)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# droput layer, remove if no work\n",
    "model.add(SpatialDropout1D(0.7))\n",
    "\n",
    "# Flatten the output for the fully connected layers\n",
    "model.add(Flatten())\n",
    "# Add fully connected layers\n",
    "model.add(Dense(40, activation=act_function))\n",
    "#model.add(Dense(16, activation=act_function))\n",
    "#model.add(Dense(40, activation=act_function))\n",
    "#model.add(Dense(16, activation=act_function))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation='softmax'))  # Output layer\n",
    "optimizer = Lion(learning_rate=.0001)\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(Xtrain, Ytrain, epochs=5000, validation_split=.3, batch_size = 128, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf684f7f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Hyperparameter Tunning 3 1D CNN Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "18fcbdba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T09:41:45.126766Z",
     "start_time": "2023-08-22T09:41:45.119367Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SpatialDropout1D\n",
    "from keras_tuner import HyperModel\n",
    "from kerastuner.tuners import Hyperband\n",
    "\n",
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        act_function = hp.Choice('dense_activation',values=['selu','LeakyReLU','gelu','elu'],default='selu')\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=hp.Choice('num_filters',values=[50,75, 100],default=50,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(filters=hp.Choice('num_filters',values=[50,75, 100],default=50,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(filters=hp.Choice('num_filters',values=[50,75, 100],default=50,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_1',min_value=0.0,max_value=0.7,default=0.25,step=0.05,)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=hp.Int('units',min_value=20,max_value=100,step=20,default=40),activation=act_function))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_2',min_value=0.0,max_value=0.7,default=0.25,step=0.05,)))\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(Adam(hp.Float('learning_rate',min_value=1e-4,max_value=1e-3,sampling='LOG',default=1e-4)),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "hypermodel = CNNHyperModel(input_shape=(130,126), num_classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b694401f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T09:41:46.500625Z",
     "start_time": "2023-08-22T09:41:46.391797Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "HYPERBAND_MAX_EPOCHS = 100\n",
    "#MAX_TRIALS = 20\n",
    "EXECUTION_PER_TRIAL = 2\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    max_epochs=HYPERBAND_MAX_EPOCHS,\n",
    "    objective='val_loss',\n",
    "    seed=10,\n",
    "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "    directory='/media/kristian/HDD/ASL_Citizen/Mediapipe/hyperband/',\n",
    "    project_name='test',\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "917508ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T09:41:49.063540Z",
     "start_time": "2023-08-22T09:41:49.060429Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "dense_activation (Choice)\n",
      "{'default': 'selu', 'conditions': [], 'values': ['selu', 'LeakyReLU', 'gelu', 'elu'], 'ordered': False}\n",
      "num_filters (Choice)\n",
      "{'default': 50, 'conditions': [], 'values': [50, 75, 100], 'ordered': True}\n",
      "dropout_1 (Float)\n",
      "{'default': 0.25, 'conditions': [], 'min_value': 0.0, 'max_value': 0.7, 'step': 0.05, 'sampling': 'linear'}\n",
      "units (Int)\n",
      "{'default': 40, 'conditions': [], 'min_value': 20, 'max_value': 100, 'step': 20, 'sampling': 'linear'}\n",
      "dropout_2 (Float)\n",
      "{'default': 0.25, 'conditions': [], 'min_value': 0.0, 'max_value': 0.7, 'step': 0.05, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.001, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "ccccd49f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T10:57:48.674440Z",
     "start_time": "2023-08-22T09:41:52.005276Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 01m 47s]\n",
      "val_loss: 1.861035704612732\n",
      "\n",
      "Best val_loss So Far: 1.0614820718765259\n",
      "Total elapsed time: 01h 15m 57s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(Xtrain, Ytrain, epochs=1000, validation_data = (Xval,Yval),batch_size=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "e41cfe5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T18:12:46.406305Z",
     "start_time": "2023-08-22T18:12:45.611570Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "e32bcc34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T18:10:20.242556Z",
     "start_time": "2023-08-22T18:10:20.239200Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7ff068cdece0>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a8992922",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T18:10:21.353964Z",
     "start_time": "2023-08-22T18:10:21.349948Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in /media/kristian/HDD/ASL_Citizen/Mediapipe/hyperband/test\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 0245 summary\n",
      "Hyperparameters:\n",
      "dense_activation: elu\n",
      "num_filters: 75\n",
      "dropout_1: 0.65\n",
      "units: 60\n",
      "dropout_2: 0.25\n",
      "learning_rate: 0.0008273819395816823\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0240\n",
      "Score: 1.0614820718765259\n",
      "\n",
      "Trial 0234 summary\n",
      "Hyperparameters:\n",
      "dense_activation: gelu\n",
      "num_filters: 100\n",
      "dropout_1: 0.6000000000000001\n",
      "units: 80\n",
      "dropout_2: 0.4\n",
      "learning_rate: 0.0009614293649008687\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0229\n",
      "Score: 1.1105559468269348\n",
      "\n",
      "Trial 0229 summary\n",
      "Hyperparameters:\n",
      "dense_activation: gelu\n",
      "num_filters: 100\n",
      "dropout_1: 0.6000000000000001\n",
      "units: 80\n",
      "dropout_2: 0.4\n",
      "learning_rate: 0.0009614293649008687\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0222\n",
      "Score: 1.1415437459945679\n",
      "\n",
      "Trial 0240 summary\n",
      "Hyperparameters:\n",
      "dense_activation: elu\n",
      "num_filters: 75\n",
      "dropout_1: 0.65\n",
      "units: 60\n",
      "dropout_2: 0.25\n",
      "learning_rate: 0.0008273819395816823\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 1.1845629215240479\n",
      "\n",
      "Trial 0208 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters: 100\n",
      "dropout_1: 0.45\n",
      "units: 100\n",
      "dropout_2: 0.45\n",
      "learning_rate: 0.00039367080662741427\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0206\n",
      "Score: 1.2080861926078796\n",
      "\n",
      "Trial 0235 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters: 100\n",
      "dropout_1: 0.35000000000000003\n",
      "units: 100\n",
      "dropout_2: 0.45\n",
      "learning_rate: 0.00043198733632898343\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0230\n",
      "Score: 1.2184789180755615\n",
      "\n",
      "Trial 0246 summary\n",
      "Hyperparameters:\n",
      "dense_activation: elu\n",
      "num_filters: 50\n",
      "dropout_1: 0.6000000000000001\n",
      "units: 60\n",
      "dropout_2: 0.1\n",
      "learning_rate: 0.0006044312152549279\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0243\n",
      "Score: 1.2285688519477844\n",
      "\n",
      "Trial 0230 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters: 100\n",
      "dropout_1: 0.35000000000000003\n",
      "units: 100\n",
      "dropout_2: 0.45\n",
      "learning_rate: 0.00043198733632898343\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0223\n",
      "Score: 1.2289357781410217\n",
      "\n",
      "Trial 0143 summary\n",
      "Hyperparameters:\n",
      "dense_activation: elu\n",
      "num_filters: 50\n",
      "dropout_1: 0.6000000000000001\n",
      "units: 80\n",
      "dropout_2: 0.2\n",
      "learning_rate: 0.0009505915500498618\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 4\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0136\n",
      "Score: 1.234882652759552\n",
      "\n",
      "Trial 0206 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters: 100\n",
      "dropout_1: 0.45\n",
      "units: 100\n",
      "dropout_2: 0.45\n",
      "learning_rate: 0.00039367080662741427\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0193\n",
      "Score: 1.2593937516212463\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "11164e42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T18:12:56.037571Z",
     "start_time": "2023-08-22T18:12:55.536363Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0974 - accuracy: 0.7747\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = best_model.evaluate(Xval, Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f18b2751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T18:23:45.942065Z",
     "start_time": "2023-08-22T18:23:40.773437Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step\n",
      "11/11 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93         8\n",
      "           1       0.80      0.67      0.73         6\n",
      "           2       1.00      1.00      1.00        10\n",
      "           3       1.00      0.60      0.75        10\n",
      "           4       1.00      0.50      0.67         4\n",
      "           5       0.73      1.00      0.84         8\n",
      "           6       0.38      0.50      0.43         6\n",
      "           7       0.67      1.00      0.80         8\n",
      "           8       0.50      0.33      0.40         6\n",
      "           9       0.67      1.00      0.80         6\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       0.83      0.83      0.83         6\n",
      "          12       1.00      0.67      0.80         6\n",
      "          13       1.00      0.38      0.55         8\n",
      "          14       0.75      0.50      0.60         6\n",
      "          15       0.78      0.88      0.82         8\n",
      "          16       1.00      0.83      0.91         6\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       0.60      0.75      0.67         4\n",
      "          19       0.75      1.00      0.86         6\n",
      "          20       0.75      1.00      0.86         6\n",
      "          21       0.73      1.00      0.84         8\n",
      "          22       1.00      1.00      1.00         4\n",
      "          23       1.00      0.25      0.40         4\n",
      "          24       0.57      0.67      0.62         6\n",
      "          25       1.00      0.62      0.77         8\n",
      "          26       0.73      1.00      0.84         8\n",
      "          27       0.83      0.83      0.83         6\n",
      "          28       1.00      0.50      0.67         4\n",
      "          29       1.00      0.50      0.67         4\n",
      "          30       0.50      0.50      0.50         4\n",
      "          31       0.50      0.38      0.43         8\n",
      "          32       1.00      0.62      0.77         8\n",
      "          33       0.67      1.00      0.80         4\n",
      "          34       0.86      1.00      0.92         6\n",
      "          35       0.67      1.00      0.80         4\n",
      "          36       0.60      0.38      0.46         8\n",
      "          37       0.70      0.88      0.78         8\n",
      "          38       0.73      1.00      0.84         8\n",
      "          39       0.73      1.00      0.84         8\n",
      "          40       1.00      1.00      1.00         6\n",
      "          41       0.50      0.50      0.50         4\n",
      "          42       0.75      1.00      0.86         6\n",
      "          43       0.80      1.00      0.89         8\n",
      "          44       1.00      0.80      0.89        10\n",
      "          45       0.50      0.33      0.40         6\n",
      "          46       0.00      0.00      0.00         4\n",
      "          47       0.67      0.50      0.57         4\n",
      "          48       0.89      1.00      0.94         8\n",
      "          49       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.77       324\n",
      "   macro avg       0.78      0.75      0.74       324\n",
      "weighted avg       0.80      0.77      0.76       324\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(np.argmax(Yval, axis=1), np.argmax(best_model.predict(Xval), axis=1))\n",
    "\n",
    "sns.heatmap(cm, annot = True)\n",
    "\n",
    "print(classification_report(np.argmax(Yval, axis=1), np.argmax(best_model.predict(Xval), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "538a4f53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T18:18:12.093827Z",
     "start_time": "2023-08-22T18:18:12.090443Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7ff0501bf190>\n"
     ]
    }
   ],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters(1)[0]\n",
    "print(best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "179352d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T18:40:50.272383Z",
     "start_time": "2023-08-11T18:40:50.270003Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import kerastuner as kt\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=30,\n",
    "    hyperband_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "e80a7202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T18:18:25.995881Z",
     "start_time": "2023-08-22T18:18:25.992376Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7ff0501bf190>\n"
     ]
    }
   ],
   "source": [
    "print(tuner.get_best_hyperparameters(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7c65601f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T12:00:59.513449Z",
     "start_time": "2023-08-23T11:54:52.276252Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 129, 125)          31625     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 64, 125)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 63, 125)           31375     \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 31, 125)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 30, 125)           31375     \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 15, 125)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 15, 125)           0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1875)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 80)                150080    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                4050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 248,505\n",
      "Trainable params: 248,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "28/28 [==============================] - 3s 48ms/step - loss: 4.1224 - f1_score: 0.0176 - val_loss: 3.8702 - val_f1_score: 0.0478\n",
      "Epoch 2/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 3.9954 - f1_score: 0.0215 - val_loss: 3.8139 - val_f1_score: 0.0415\n",
      "Epoch 3/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 3.9291 - f1_score: 0.0296 - val_loss: 3.7541 - val_f1_score: 0.0642\n",
      "Epoch 4/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 3.8592 - f1_score: 0.0428 - val_loss: 3.7018 - val_f1_score: 0.0705\n",
      "Epoch 5/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 3.7898 - f1_score: 0.0523 - val_loss: 3.6109 - val_f1_score: 0.0724\n",
      "Epoch 6/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 3.7076 - f1_score: 0.0661 - val_loss: 3.5313 - val_f1_score: 0.0918\n",
      "Epoch 7/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 3.6600 - f1_score: 0.0697 - val_loss: 3.4135 - val_f1_score: 0.1272\n",
      "Epoch 8/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 3.5805 - f1_score: 0.0781 - val_loss: 3.3313 - val_f1_score: 0.1050\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 3.5301 - f1_score: 0.0883 - val_loss: 3.1748 - val_f1_score: 0.2414\n",
      "Epoch 10/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 3.4551 - f1_score: 0.1030 - val_loss: 3.0968 - val_f1_score: 0.2038\n",
      "Epoch 11/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 3.3517 - f1_score: 0.1151 - val_loss: 3.0597 - val_f1_score: 0.2131\n",
      "Epoch 12/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 3.3038 - f1_score: 0.1288 - val_loss: 2.9113 - val_f1_score: 0.2749\n",
      "Epoch 13/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 3.2342 - f1_score: 0.1400 - val_loss: 2.8336 - val_f1_score: 0.2737\n",
      "Epoch 14/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 3.1841 - f1_score: 0.1390 - val_loss: 2.6941 - val_f1_score: 0.3729\n",
      "Epoch 15/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 3.0830 - f1_score: 0.1644 - val_loss: 2.6702 - val_f1_score: 0.3213\n",
      "Epoch 16/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 3.0857 - f1_score: 0.1620 - val_loss: 2.5919 - val_f1_score: 0.3774\n",
      "Epoch 17/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.9946 - f1_score: 0.1778 - val_loss: 2.6537 - val_f1_score: 0.3357\n",
      "Epoch 18/500\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.9239 - f1_score: 0.2018 - val_loss: 2.4162 - val_f1_score: 0.4391\n",
      "Epoch 19/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.9244 - f1_score: 0.1959 - val_loss: 2.3893 - val_f1_score: 0.3870\n",
      "Epoch 20/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 2.7803 - f1_score: 0.2243 - val_loss: 2.2679 - val_f1_score: 0.4180\n",
      "Epoch 21/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.7411 - f1_score: 0.2321 - val_loss: 2.2201 - val_f1_score: 0.4559\n",
      "Epoch 22/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.7370 - f1_score: 0.2396 - val_loss: 2.1784 - val_f1_score: 0.4509\n",
      "Epoch 23/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 2.6785 - f1_score: 0.2447 - val_loss: 2.0870 - val_f1_score: 0.5074\n",
      "Epoch 24/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 2.5757 - f1_score: 0.2738 - val_loss: 1.9972 - val_f1_score: 0.5213\n",
      "Epoch 25/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.5640 - f1_score: 0.2666 - val_loss: 1.9479 - val_f1_score: 0.5560\n",
      "Epoch 26/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 2.4889 - f1_score: 0.2906 - val_loss: 2.0322 - val_f1_score: 0.4756\n",
      "Epoch 27/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 2.5403 - f1_score: 0.2723 - val_loss: 1.8902 - val_f1_score: 0.5226\n",
      "Epoch 28/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.4917 - f1_score: 0.2748 - val_loss: 1.8941 - val_f1_score: 0.5309\n",
      "Epoch 29/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 2.4401 - f1_score: 0.2885 - val_loss: 1.9367 - val_f1_score: 0.5009\n",
      "Epoch 30/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 2.4081 - f1_score: 0.3029 - val_loss: 1.7926 - val_f1_score: 0.5783\n",
      "Epoch 31/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.3598 - f1_score: 0.3150 - val_loss: 1.9237 - val_f1_score: 0.4759\n",
      "Epoch 32/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 2.3629 - f1_score: 0.3341 - val_loss: 1.8217 - val_f1_score: 0.5375\n",
      "Epoch 33/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.3115 - f1_score: 0.3174 - val_loss: 1.8081 - val_f1_score: 0.5232\n",
      "Epoch 34/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.3121 - f1_score: 0.3332 - val_loss: 1.6844 - val_f1_score: 0.5764\n",
      "Epoch 35/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 2.3048 - f1_score: 0.3362 - val_loss: 1.7629 - val_f1_score: 0.5239\n",
      "Epoch 36/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 2.2378 - f1_score: 0.3460 - val_loss: 1.7317 - val_f1_score: 0.5682\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.2463 - f1_score: 0.3585 - val_loss: 1.7527 - val_f1_score: 0.5374\n",
      "Epoch 38/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.1961 - f1_score: 0.3647 - val_loss: 1.6334 - val_f1_score: 0.5864\n",
      "Epoch 39/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 2.2106 - f1_score: 0.3553 - val_loss: 1.5690 - val_f1_score: 0.5761\n",
      "Epoch 40/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.1226 - f1_score: 0.3799 - val_loss: 1.5479 - val_f1_score: 0.6029\n",
      "Epoch 41/500\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 2.1547 - f1_score: 0.3719 - val_loss: 1.5615 - val_f1_score: 0.5907\n",
      "Epoch 42/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.1407 - f1_score: 0.3651 - val_loss: 1.5534 - val_f1_score: 0.6073\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.0801 - f1_score: 0.3891 - val_loss: 1.6347 - val_f1_score: 0.5694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.0918 - f1_score: 0.3834 - val_loss: 1.5365 - val_f1_score: 0.6179\n",
      "Epoch 45/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.0865 - f1_score: 0.3753 - val_loss: 1.5811 - val_f1_score: 0.5754\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.0244 - f1_score: 0.3971 - val_loss: 1.5359 - val_f1_score: 0.5827\n",
      "Epoch 47/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 2.1067 - f1_score: 0.3972 - val_loss: 1.5295 - val_f1_score: 0.5951\n",
      "Epoch 48/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.9666 - f1_score: 0.4229 - val_loss: 1.5604 - val_f1_score: 0.6111\n",
      "Epoch 49/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.0078 - f1_score: 0.4276 - val_loss: 1.5114 - val_f1_score: 0.5636\n",
      "Epoch 50/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 2.0150 - f1_score: 0.4126 - val_loss: 1.4760 - val_f1_score: 0.6087\n",
      "Epoch 51/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.9833 - f1_score: 0.4122 - val_loss: 1.4992 - val_f1_score: 0.6265\n",
      "Epoch 52/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.9733 - f1_score: 0.4049 - val_loss: 1.4334 - val_f1_score: 0.6475\n",
      "Epoch 53/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.9327 - f1_score: 0.4365 - val_loss: 1.4912 - val_f1_score: 0.5886\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.9249 - f1_score: 0.4270 - val_loss: 1.4986 - val_f1_score: 0.6262\n",
      "Epoch 55/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.9349 - f1_score: 0.4212 - val_loss: 1.3847 - val_f1_score: 0.6288\n",
      "Epoch 56/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.9491 - f1_score: 0.4263 - val_loss: 1.4003 - val_f1_score: 0.6246\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.9195 - f1_score: 0.4500 - val_loss: 1.4042 - val_f1_score: 0.6203\n",
      "Epoch 58/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.8905 - f1_score: 0.4562 - val_loss: 1.4030 - val_f1_score: 0.6356\n",
      "Epoch 59/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.9131 - f1_score: 0.4343 - val_loss: 1.4473 - val_f1_score: 0.5986\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.8774 - f1_score: 0.4484 - val_loss: 1.4689 - val_f1_score: 0.5928\n",
      "Epoch 61/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.9045 - f1_score: 0.4413 - val_loss: 1.4542 - val_f1_score: 0.5647\n",
      "Epoch 62/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.8801 - f1_score: 0.4371 - val_loss: 1.4220 - val_f1_score: 0.6083\n",
      "Epoch 63/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.8649 - f1_score: 0.4417 - val_loss: 1.3708 - val_f1_score: 0.6137\n",
      "Epoch 64/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.7900 - f1_score: 0.4863 - val_loss: 1.3362 - val_f1_score: 0.6469\n",
      "Epoch 65/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.8576 - f1_score: 0.4529 - val_loss: 1.3889 - val_f1_score: 0.6626\n",
      "Epoch 66/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.7889 - f1_score: 0.4772 - val_loss: 1.3124 - val_f1_score: 0.6608\n",
      "Epoch 67/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.8228 - f1_score: 0.4580 - val_loss: 1.3441 - val_f1_score: 0.6684\n",
      "Epoch 68/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.8016 - f1_score: 0.4658 - val_loss: 1.3941 - val_f1_score: 0.6283\n",
      "Epoch 69/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.8015 - f1_score: 0.4649 - val_loss: 1.3016 - val_f1_score: 0.6712\n",
      "Epoch 70/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.7436 - f1_score: 0.4764 - val_loss: 1.3577 - val_f1_score: 0.6430\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.7365 - f1_score: 0.4699 - val_loss: 1.3046 - val_f1_score: 0.6661\n",
      "Epoch 72/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.7846 - f1_score: 0.4629 - val_loss: 1.3151 - val_f1_score: 0.6672\n",
      "Epoch 73/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.7724 - f1_score: 0.4775 - val_loss: 1.2719 - val_f1_score: 0.6677\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.7806 - f1_score: 0.4705 - val_loss: 1.3231 - val_f1_score: 0.6487\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.7198 - f1_score: 0.4956 - val_loss: 1.2888 - val_f1_score: 0.6402\n",
      "Epoch 76/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.6922 - f1_score: 0.4948 - val_loss: 1.2738 - val_f1_score: 0.6771\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.7006 - f1_score: 0.4921 - val_loss: 1.2808 - val_f1_score: 0.6779\n",
      "Epoch 78/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.7635 - f1_score: 0.4597 - val_loss: 1.2566 - val_f1_score: 0.6523\n",
      "Epoch 79/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.6818 - f1_score: 0.4852 - val_loss: 1.2362 - val_f1_score: 0.6626\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.6857 - f1_score: 0.4989 - val_loss: 1.4085 - val_f1_score: 0.6229\n",
      "Epoch 81/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.6814 - f1_score: 0.4914 - val_loss: 1.3221 - val_f1_score: 0.6673\n",
      "Epoch 82/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.6507 - f1_score: 0.5083 - val_loss: 1.2191 - val_f1_score: 0.7018\n",
      "Epoch 83/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.6851 - f1_score: 0.4890 - val_loss: 1.2762 - val_f1_score: 0.6689\n",
      "Epoch 84/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.6641 - f1_score: 0.4962 - val_loss: 1.2075 - val_f1_score: 0.6743\n",
      "Epoch 85/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.6214 - f1_score: 0.5087 - val_loss: 1.3137 - val_f1_score: 0.6620\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.6776 - f1_score: 0.4859 - val_loss: 1.2623 - val_f1_score: 0.6805\n",
      "Epoch 87/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.6064 - f1_score: 0.5154 - val_loss: 1.3400 - val_f1_score: 0.6490\n",
      "Epoch 88/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.6523 - f1_score: 0.4983 - val_loss: 1.2295 - val_f1_score: 0.6790\n",
      "Epoch 89/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.6426 - f1_score: 0.5022 - val_loss: 1.2430 - val_f1_score: 0.6690\n",
      "Epoch 90/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.6504 - f1_score: 0.4863 - val_loss: 1.2102 - val_f1_score: 0.7029\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.5943 - f1_score: 0.5179 - val_loss: 1.2023 - val_f1_score: 0.6912\n",
      "Epoch 92/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.6118 - f1_score: 0.5168 - val_loss: 1.2086 - val_f1_score: 0.6812\n",
      "Epoch 93/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.5639 - f1_score: 0.5210 - val_loss: 1.1939 - val_f1_score: 0.6853\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.5761 - f1_score: 0.5289 - val_loss: 1.4273 - val_f1_score: 0.6020\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.6166 - f1_score: 0.5062 - val_loss: 1.2289 - val_f1_score: 0.6767\n",
      "Epoch 96/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.5882 - f1_score: 0.5149 - val_loss: 1.1782 - val_f1_score: 0.7192\n",
      "Epoch 97/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.5535 - f1_score: 0.5297 - val_loss: 1.2180 - val_f1_score: 0.6877\n",
      "Epoch 98/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.5675 - f1_score: 0.5281 - val_loss: 1.2368 - val_f1_score: 0.6789\n",
      "Epoch 99/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.5382 - f1_score: 0.5231 - val_loss: 1.2310 - val_f1_score: 0.6874\n",
      "Epoch 100/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.5600 - f1_score: 0.5118 - val_loss: 1.1719 - val_f1_score: 0.7071\n",
      "Epoch 101/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.5542 - f1_score: 0.5340 - val_loss: 1.1924 - val_f1_score: 0.6924\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.4960 - f1_score: 0.5339 - val_loss: 1.1606 - val_f1_score: 0.6934\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.5057 - f1_score: 0.5414 - val_loss: 1.1426 - val_f1_score: 0.6929\n",
      "Epoch 104/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.5338 - f1_score: 0.5308 - val_loss: 1.1808 - val_f1_score: 0.6791\n",
      "Epoch 105/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.4864 - f1_score: 0.5304 - val_loss: 1.1725 - val_f1_score: 0.7199\n",
      "Epoch 106/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.4861 - f1_score: 0.5508 - val_loss: 1.1712 - val_f1_score: 0.6935\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.5477 - f1_score: 0.5317 - val_loss: 1.2228 - val_f1_score: 0.6829\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.4554 - f1_score: 0.5499 - val_loss: 1.1533 - val_f1_score: 0.7188\n",
      "Epoch 109/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.4664 - f1_score: 0.5526 - val_loss: 1.2746 - val_f1_score: 0.6875\n",
      "Epoch 110/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.4884 - f1_score: 0.5381 - val_loss: 1.2224 - val_f1_score: 0.6865\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.4899 - f1_score: 0.5489 - val_loss: 1.1718 - val_f1_score: 0.6983\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.5016 - f1_score: 0.5551 - val_loss: 1.2161 - val_f1_score: 0.7073\n",
      "Epoch 113/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.4529 - f1_score: 0.5595 - val_loss: 1.1424 - val_f1_score: 0.7042\n",
      "Epoch 114/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.4488 - f1_score: 0.5549 - val_loss: 1.1716 - val_f1_score: 0.6857\n",
      "Epoch 115/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.4860 - f1_score: 0.5385 - val_loss: 1.2891 - val_f1_score: 0.6531\n",
      "Epoch 116/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.4222 - f1_score: 0.5548 - val_loss: 1.2324 - val_f1_score: 0.6741\n",
      "Epoch 117/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.4045 - f1_score: 0.5634 - val_loss: 1.1524 - val_f1_score: 0.7028\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.4484 - f1_score: 0.5486 - val_loss: 1.1822 - val_f1_score: 0.7130\n",
      "Epoch 119/500\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.4221 - f1_score: 0.5621 - val_loss: 1.1266 - val_f1_score: 0.7129\n",
      "Epoch 120/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.4367 - f1_score: 0.5532 - val_loss: 1.1786 - val_f1_score: 0.6985\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3885 - f1_score: 0.5688 - val_loss: 1.1502 - val_f1_score: 0.7135\n",
      "Epoch 122/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.4107 - f1_score: 0.5582 - val_loss: 1.1560 - val_f1_score: 0.7134\n",
      "Epoch 123/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.4228 - f1_score: 0.5522 - val_loss: 1.0882 - val_f1_score: 0.7076\n",
      "Epoch 124/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.4101 - f1_score: 0.5550 - val_loss: 1.2725 - val_f1_score: 0.6912\n",
      "Epoch 125/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.3557 - f1_score: 0.5774 - val_loss: 1.1068 - val_f1_score: 0.7312\n",
      "Epoch 126/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.4123 - f1_score: 0.5602 - val_loss: 1.1357 - val_f1_score: 0.6929\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.3845 - f1_score: 0.5845 - val_loss: 1.1310 - val_f1_score: 0.7138\n",
      "Epoch 128/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3694 - f1_score: 0.5647 - val_loss: 1.2562 - val_f1_score: 0.6838\n",
      "Epoch 129/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.3802 - f1_score: 0.5743 - val_loss: 1.0461 - val_f1_score: 0.7626\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3449 - f1_score: 0.5698 - val_loss: 1.0785 - val_f1_score: 0.7106\n",
      "Epoch 131/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3988 - f1_score: 0.5625 - val_loss: 1.1200 - val_f1_score: 0.7196\n",
      "Epoch 132/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3668 - f1_score: 0.5788 - val_loss: 1.0676 - val_f1_score: 0.7417\n",
      "Epoch 133/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3434 - f1_score: 0.5772 - val_loss: 1.1252 - val_f1_score: 0.7333\n",
      "Epoch 134/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3426 - f1_score: 0.5673 - val_loss: 1.0543 - val_f1_score: 0.7462\n",
      "Epoch 135/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3359 - f1_score: 0.5791 - val_loss: 1.1645 - val_f1_score: 0.7018\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3483 - f1_score: 0.5710 - val_loss: 1.1852 - val_f1_score: 0.7066\n",
      "Epoch 137/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3539 - f1_score: 0.5845 - val_loss: 1.1195 - val_f1_score: 0.7062\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.4062 - f1_score: 0.5659 - val_loss: 1.1762 - val_f1_score: 0.6972\n",
      "Epoch 139/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3281 - f1_score: 0.5800 - val_loss: 1.1448 - val_f1_score: 0.7199\n",
      "Epoch 140/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3465 - f1_score: 0.5641 - val_loss: 1.1231 - val_f1_score: 0.7345\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3214 - f1_score: 0.5865 - val_loss: 1.0480 - val_f1_score: 0.7778\n",
      "Epoch 142/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.3611 - f1_score: 0.5678 - val_loss: 1.1466 - val_f1_score: 0.7168\n",
      "Epoch 143/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3212 - f1_score: 0.5835 - val_loss: 1.0850 - val_f1_score: 0.7398\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.2826 - f1_score: 0.5879 - val_loss: 1.0523 - val_f1_score: 0.7490\n",
      "Epoch 145/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3128 - f1_score: 0.5854 - val_loss: 1.0931 - val_f1_score: 0.7149\n",
      "Epoch 146/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3099 - f1_score: 0.5791 - val_loss: 1.0820 - val_f1_score: 0.7501\n",
      "Epoch 147/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2887 - f1_score: 0.5838 - val_loss: 1.1011 - val_f1_score: 0.7390\n",
      "Epoch 148/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3383 - f1_score: 0.5870 - val_loss: 1.0618 - val_f1_score: 0.7268\n",
      "Epoch 149/500\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.3355 - f1_score: 0.5937 - val_loss: 1.1275 - val_f1_score: 0.7248\n",
      "Epoch 150/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2811 - f1_score: 0.6095 - val_loss: 1.0503 - val_f1_score: 0.7451\n",
      "Epoch 151/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2666 - f1_score: 0.6030 - val_loss: 1.0665 - val_f1_score: 0.7557\n",
      "Epoch 152/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2686 - f1_score: 0.6005 - val_loss: 1.1276 - val_f1_score: 0.7305\n",
      "Epoch 153/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2514 - f1_score: 0.6050 - val_loss: 1.1040 - val_f1_score: 0.7520\n",
      "Epoch 154/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.3145 - f1_score: 0.5884 - val_loss: 1.0394 - val_f1_score: 0.7435\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2527 - f1_score: 0.6101 - val_loss: 1.1351 - val_f1_score: 0.7092\n",
      "Epoch 156/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2655 - f1_score: 0.6008 - val_loss: 1.0553 - val_f1_score: 0.7212\n",
      "Epoch 157/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2932 - f1_score: 0.5928 - val_loss: 1.1441 - val_f1_score: 0.7120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2623 - f1_score: 0.5945 - val_loss: 1.0093 - val_f1_score: 0.7471\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.2509 - f1_score: 0.5914 - val_loss: 1.0791 - val_f1_score: 0.7531\n",
      "Epoch 160/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2447 - f1_score: 0.6127 - val_loss: 1.0285 - val_f1_score: 0.7657\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.2130 - f1_score: 0.6147 - val_loss: 1.1312 - val_f1_score: 0.7282\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2235 - f1_score: 0.5995 - val_loss: 1.0494 - val_f1_score: 0.7354\n",
      "Epoch 163/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2629 - f1_score: 0.5982 - val_loss: 1.0416 - val_f1_score: 0.7616\n",
      "Epoch 164/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2293 - f1_score: 0.6165 - val_loss: 1.1879 - val_f1_score: 0.6935\n",
      "Epoch 165/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2379 - f1_score: 0.6117 - val_loss: 1.1009 - val_f1_score: 0.7259\n",
      "Epoch 166/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2349 - f1_score: 0.6033 - val_loss: 1.1203 - val_f1_score: 0.7108\n",
      "Epoch 167/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2265 - f1_score: 0.6090 - val_loss: 1.0694 - val_f1_score: 0.7295\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2271 - f1_score: 0.6190 - val_loss: 1.0868 - val_f1_score: 0.7198\n",
      "Epoch 169/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2006 - f1_score: 0.6047 - val_loss: 1.1610 - val_f1_score: 0.7073\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2248 - f1_score: 0.6089 - val_loss: 1.1575 - val_f1_score: 0.7063\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2504 - f1_score: 0.6003 - val_loss: 1.0543 - val_f1_score: 0.7454\n",
      "Epoch 172/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2313 - f1_score: 0.6008 - val_loss: 1.1521 - val_f1_score: 0.7309\n",
      "Epoch 173/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1786 - f1_score: 0.6158 - val_loss: 1.0137 - val_f1_score: 0.7343\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2270 - f1_score: 0.6064 - val_loss: 1.1406 - val_f1_score: 0.7379\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2041 - f1_score: 0.6215 - val_loss: 1.0738 - val_f1_score: 0.7369\n",
      "Epoch 176/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2159 - f1_score: 0.6072 - val_loss: 1.1399 - val_f1_score: 0.7276\n",
      "Epoch 177/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1885 - f1_score: 0.6200 - val_loss: 1.0822 - val_f1_score: 0.7379\n",
      "Epoch 178/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1896 - f1_score: 0.6271 - val_loss: 1.1220 - val_f1_score: 0.7495\n",
      "Epoch 179/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2554 - f1_score: 0.6113 - val_loss: 1.0632 - val_f1_score: 0.7448\n",
      "Epoch 180/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1909 - f1_score: 0.6133 - val_loss: 1.0313 - val_f1_score: 0.7544\n",
      "Epoch 181/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.1834 - f1_score: 0.6347 - val_loss: 1.0771 - val_f1_score: 0.7268\n",
      "Epoch 182/500\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 1.1739 - f1_score: 0.6234 - val_loss: 1.0853 - val_f1_score: 0.7187\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1633 - f1_score: 0.6328 - val_loss: 1.0310 - val_f1_score: 0.7358\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1279 - f1_score: 0.6389 - val_loss: 1.0861 - val_f1_score: 0.7317\n",
      "Epoch 185/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2028 - f1_score: 0.6081 - val_loss: 1.0791 - val_f1_score: 0.7513\n",
      "Epoch 186/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.1468 - f1_score: 0.6378 - val_loss: 1.0570 - val_f1_score: 0.7411\n",
      "Epoch 187/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1232 - f1_score: 0.6475 - val_loss: 1.0548 - val_f1_score: 0.7313\n",
      "Epoch 188/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1362 - f1_score: 0.6251 - val_loss: 1.0535 - val_f1_score: 0.7261\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1182 - f1_score: 0.6392 - val_loss: 1.0460 - val_f1_score: 0.7514\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1724 - f1_score: 0.6250 - val_loss: 1.0816 - val_f1_score: 0.7427\n",
      "Epoch 191/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1154 - f1_score: 0.6257 - val_loss: 1.0157 - val_f1_score: 0.7712\n",
      "Epoch 192/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.2261 - f1_score: 0.6128 - val_loss: 1.0634 - val_f1_score: 0.7521\n",
      "Epoch 193/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1129 - f1_score: 0.6481 - val_loss: 1.0924 - val_f1_score: 0.7437\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1037 - f1_score: 0.6385 - val_loss: 1.0540 - val_f1_score: 0.7583\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1289 - f1_score: 0.6373 - val_loss: 1.1028 - val_f1_score: 0.7500\n",
      "Epoch 196/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1133 - f1_score: 0.6223 - val_loss: 1.0670 - val_f1_score: 0.7360\n",
      "Epoch 197/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1118 - f1_score: 0.6400 - val_loss: 1.0981 - val_f1_score: 0.7332\n",
      "Epoch 198/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1279 - f1_score: 0.6421 - val_loss: 1.1295 - val_f1_score: 0.7150\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1005 - f1_score: 0.6482 - val_loss: 1.1202 - val_f1_score: 0.7373\n",
      "Epoch 200/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1080 - f1_score: 0.6548 - val_loss: 1.0282 - val_f1_score: 0.7499\n",
      "Epoch 201/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1155 - f1_score: 0.6384 - val_loss: 1.1004 - val_f1_score: 0.7416\n",
      "Epoch 202/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.1699 - f1_score: 0.6299 - val_loss: 1.0186 - val_f1_score: 0.7620\n",
      "Epoch 203/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1284 - f1_score: 0.6422 - val_loss: 1.1045 - val_f1_score: 0.7111\n",
      "Epoch 204/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1317 - f1_score: 0.6437 - val_loss: 1.0427 - val_f1_score: 0.7483\n",
      "Epoch 205/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1364 - f1_score: 0.6298 - val_loss: 1.0175 - val_f1_score: 0.7577\n",
      "Epoch 206/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1012 - f1_score: 0.6406 - val_loss: 1.0738 - val_f1_score: 0.7407\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0557 - f1_score: 0.6634 - val_loss: 1.0095 - val_f1_score: 0.7418\n",
      "Epoch 208/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0753 - f1_score: 0.6550 - val_loss: 1.0469 - val_f1_score: 0.7400\n",
      "Epoch 209/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0885 - f1_score: 0.6478 - val_loss: 1.0623 - val_f1_score: 0.7760\n",
      "Epoch 210/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0917 - f1_score: 0.6496 - val_loss: 1.1144 - val_f1_score: 0.7278\n",
      "Epoch 211/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0522 - f1_score: 0.6605 - val_loss: 1.1722 - val_f1_score: 0.7119\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0877 - f1_score: 0.6537 - val_loss: 1.0789 - val_f1_score: 0.7538\n",
      "Epoch 213/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1422 - f1_score: 0.6416 - val_loss: 1.0239 - val_f1_score: 0.7590\n",
      "Epoch 214/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0314 - f1_score: 0.6660 - val_loss: 1.0879 - val_f1_score: 0.7067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/500\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.0097 - f1_score: 0.6772 - val_loss: 1.0341 - val_f1_score: 0.7570\n",
      "Epoch 216/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1064 - f1_score: 0.6385 - val_loss: 1.0741 - val_f1_score: 0.7541\n",
      "Epoch 217/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0776 - f1_score: 0.6499 - val_loss: 1.0728 - val_f1_score: 0.7546\n",
      "Epoch 218/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1262 - f1_score: 0.6479 - val_loss: 1.0388 - val_f1_score: 0.7542\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1070 - f1_score: 0.6497 - val_loss: 1.0383 - val_f1_score: 0.7714\n",
      "Epoch 220/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.0551 - f1_score: 0.6671 - val_loss: 1.0413 - val_f1_score: 0.7444\n",
      "Epoch 221/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0530 - f1_score: 0.6608 - val_loss: 1.0520 - val_f1_score: 0.7520\n",
      "Epoch 222/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0740 - f1_score: 0.6480 - val_loss: 1.1325 - val_f1_score: 0.7537\n",
      "Epoch 223/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0595 - f1_score: 0.6618 - val_loss: 1.0825 - val_f1_score: 0.7317\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0932 - f1_score: 0.6513 - val_loss: 1.0289 - val_f1_score: 0.7758\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0825 - f1_score: 0.6593 - val_loss: 1.0693 - val_f1_score: 0.7577\n",
      "Epoch 226/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.1130 - f1_score: 0.6446 - val_loss: 1.0777 - val_f1_score: 0.7642\n",
      "Epoch 227/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0602 - f1_score: 0.6591 - val_loss: 1.0459 - val_f1_score: 0.7560\n",
      "Epoch 228/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0762 - f1_score: 0.6561 - val_loss: 1.0097 - val_f1_score: 0.7625\n",
      "Epoch 229/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0544 - f1_score: 0.6603 - val_loss: 1.0178 - val_f1_score: 0.7752\n",
      "Epoch 230/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0346 - f1_score: 0.6673 - val_loss: 1.0723 - val_f1_score: 0.7479\n",
      "Epoch 231/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0218 - f1_score: 0.6705 - val_loss: 1.0866 - val_f1_score: 0.7409\n",
      "Epoch 232/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0092 - f1_score: 0.6722 - val_loss: 1.0249 - val_f1_score: 0.7489\n",
      "Epoch 233/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0417 - f1_score: 0.6617 - val_loss: 1.0928 - val_f1_score: 0.7208\n",
      "Epoch 234/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0199 - f1_score: 0.6615 - val_loss: 1.0900 - val_f1_score: 0.7665\n",
      "Epoch 235/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0608 - f1_score: 0.6579 - val_loss: 1.0558 - val_f1_score: 0.7526\n",
      "Epoch 236/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0581 - f1_score: 0.6600 - val_loss: 1.0241 - val_f1_score: 0.7728\n",
      "Epoch 237/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0184 - f1_score: 0.6729 - val_loss: 1.0559 - val_f1_score: 0.7500\n",
      "Epoch 238/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0412 - f1_score: 0.6593 - val_loss: 1.0736 - val_f1_score: 0.7562\n",
      "Epoch 239/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0315 - f1_score: 0.6702 - val_loss: 1.0465 - val_f1_score: 0.7509\n",
      "Epoch 240/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0305 - f1_score: 0.6600 - val_loss: 1.0752 - val_f1_score: 0.7383\n",
      "Epoch 241/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9723 - f1_score: 0.6894 - val_loss: 1.0595 - val_f1_score: 0.7661\n",
      "Epoch 242/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9759 - f1_score: 0.6845 - val_loss: 1.0663 - val_f1_score: 0.7449\n",
      "Epoch 243/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0623 - f1_score: 0.6483 - val_loss: 1.0083 - val_f1_score: 0.7899\n",
      "Epoch 244/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0482 - f1_score: 0.6681 - val_loss: 1.0124 - val_f1_score: 0.7599\n",
      "Epoch 245/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0041 - f1_score: 0.6729 - val_loss: 1.0409 - val_f1_score: 0.7639\n",
      "Epoch 246/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0216 - f1_score: 0.6720 - val_loss: 1.0154 - val_f1_score: 0.7532\n",
      "Epoch 247/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0225 - f1_score: 0.6788 - val_loss: 1.1054 - val_f1_score: 0.7370\n",
      "Epoch 248/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0389 - f1_score: 0.6633 - val_loss: 1.0355 - val_f1_score: 0.7734\n",
      "Epoch 249/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9682 - f1_score: 0.6894 - val_loss: 1.0866 - val_f1_score: 0.7568\n",
      "Epoch 250/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9616 - f1_score: 0.6903 - val_loss: 1.1668 - val_f1_score: 0.7161\n",
      "Epoch 251/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9678 - f1_score: 0.6891 - val_loss: 1.1089 - val_f1_score: 0.7542\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9969 - f1_score: 0.6777 - val_loss: 1.0433 - val_f1_score: 0.7499\n",
      "Epoch 253/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.0466 - f1_score: 0.6712 - val_loss: 1.0229 - val_f1_score: 0.7667\n",
      "Epoch 254/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9904 - f1_score: 0.6730 - val_loss: 1.0954 - val_f1_score: 0.7607\n",
      "Epoch 255/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9897 - f1_score: 0.6784 - val_loss: 1.0189 - val_f1_score: 0.7518\n",
      "Epoch 256/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9328 - f1_score: 0.6866 - val_loss: 1.0441 - val_f1_score: 0.7486\n",
      "Epoch 257/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9857 - f1_score: 0.6918 - val_loss: 1.0730 - val_f1_score: 0.7562\n",
      "Epoch 258/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9994 - f1_score: 0.6752 - val_loss: 1.1132 - val_f1_score: 0.7283\n",
      "Epoch 259/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.0052 - f1_score: 0.6614 - val_loss: 1.0592 - val_f1_score: 0.7457\n",
      "Epoch 260/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9919 - f1_score: 0.6737 - val_loss: 1.0214 - val_f1_score: 0.7527\n",
      "Epoch 261/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.0054 - f1_score: 0.6757 - val_loss: 1.0455 - val_f1_score: 0.7488\n",
      "Epoch 262/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.0005 - f1_score: 0.6746 - val_loss: 1.0066 - val_f1_score: 0.7642\n",
      "Epoch 263/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9263 - f1_score: 0.6966 - val_loss: 1.1068 - val_f1_score: 0.7523\n",
      "Epoch 264/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9204 - f1_score: 0.6992 - val_loss: 1.1063 - val_f1_score: 0.7344\n",
      "Epoch 265/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9440 - f1_score: 0.6936 - val_loss: 1.0592 - val_f1_score: 0.7710\n",
      "Epoch 266/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9156 - f1_score: 0.6871 - val_loss: 1.1219 - val_f1_score: 0.7524\n",
      "Epoch 267/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9489 - f1_score: 0.6928 - val_loss: 1.0515 - val_f1_score: 0.7674\n",
      "Epoch 268/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9510 - f1_score: 0.6843 - val_loss: 1.0543 - val_f1_score: 0.7748\n",
      "Epoch 269/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9233 - f1_score: 0.6957 - val_loss: 1.0858 - val_f1_score: 0.7359\n",
      "Epoch 270/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9230 - f1_score: 0.7031 - val_loss: 1.0922 - val_f1_score: 0.7399\n",
      "Epoch 271/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9367 - f1_score: 0.7035 - val_loss: 1.1849 - val_f1_score: 0.7395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9261 - f1_score: 0.6968 - val_loss: 1.0509 - val_f1_score: 0.7793\n",
      "Epoch 273/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9655 - f1_score: 0.6924 - val_loss: 1.1830 - val_f1_score: 0.7384\n",
      "Epoch 274/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9163 - f1_score: 0.6876 - val_loss: 1.0750 - val_f1_score: 0.7590\n",
      "Epoch 275/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9526 - f1_score: 0.6960 - val_loss: 1.0866 - val_f1_score: 0.7364\n",
      "Epoch 276/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9660 - f1_score: 0.6810 - val_loss: 1.0787 - val_f1_score: 0.7204\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9471 - f1_score: 0.7004 - val_loss: 1.0305 - val_f1_score: 0.7441\n",
      "Epoch 278/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9255 - f1_score: 0.6991 - val_loss: 1.0790 - val_f1_score: 0.7661\n",
      "Epoch 279/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9379 - f1_score: 0.6934 - val_loss: 1.1210 - val_f1_score: 0.7354\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9576 - f1_score: 0.6876 - val_loss: 1.0601 - val_f1_score: 0.7477\n",
      "Epoch 281/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9188 - f1_score: 0.6917 - val_loss: 1.1165 - val_f1_score: 0.7398\n",
      "Epoch 282/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9233 - f1_score: 0.7019 - val_loss: 1.0857 - val_f1_score: 0.7356\n",
      "Epoch 283/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8950 - f1_score: 0.7069 - val_loss: 1.0792 - val_f1_score: 0.7592\n",
      "Epoch 284/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9064 - f1_score: 0.7153 - val_loss: 1.0667 - val_f1_score: 0.7690\n",
      "Epoch 285/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9394 - f1_score: 0.6990 - val_loss: 1.0167 - val_f1_score: 0.7856\n",
      "Epoch 286/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.8661 - f1_score: 0.7163 - val_loss: 1.0679 - val_f1_score: 0.7805\n",
      "Epoch 287/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9205 - f1_score: 0.7100 - val_loss: 1.0277 - val_f1_score: 0.7761\n",
      "Epoch 288/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9414 - f1_score: 0.6936 - val_loss: 1.0981 - val_f1_score: 0.7522\n",
      "Epoch 289/500\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.9629 - f1_score: 0.6911 - val_loss: 1.1733 - val_f1_score: 0.7479\n",
      "Epoch 290/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9228 - f1_score: 0.6981 - val_loss: 1.0518 - val_f1_score: 0.7502\n",
      "Epoch 291/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9178 - f1_score: 0.6926 - val_loss: 1.0517 - val_f1_score: 0.7505\n",
      "Epoch 292/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9516 - f1_score: 0.6908 - val_loss: 1.0962 - val_f1_score: 0.7250\n",
      "Epoch 293/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9110 - f1_score: 0.7064 - val_loss: 1.0016 - val_f1_score: 0.7750\n",
      "Epoch 294/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9206 - f1_score: 0.7060 - val_loss: 1.0777 - val_f1_score: 0.7486\n",
      "Epoch 295/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9309 - f1_score: 0.6985 - val_loss: 1.0310 - val_f1_score: 0.8019\n",
      "Epoch 296/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9118 - f1_score: 0.6947 - val_loss: 1.1182 - val_f1_score: 0.7313\n",
      "Epoch 297/500\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.8981 - f1_score: 0.7024 - val_loss: 1.0733 - val_f1_score: 0.7761\n",
      "Epoch 298/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8683 - f1_score: 0.7225 - val_loss: 1.0576 - val_f1_score: 0.7532\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9371 - f1_score: 0.6969 - val_loss: 1.0877 - val_f1_score: 0.7549\n",
      "Epoch 300/500\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.9067 - f1_score: 0.7113 - val_loss: 1.1455 - val_f1_score: 0.7362\n",
      "Epoch 301/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9126 - f1_score: 0.7076 - val_loss: 1.0870 - val_f1_score: 0.7497\n",
      "Epoch 302/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8666 - f1_score: 0.7084 - val_loss: 1.1479 - val_f1_score: 0.7587\n",
      "Epoch 303/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9294 - f1_score: 0.7032 - val_loss: 1.0508 - val_f1_score: 0.7450\n",
      "Epoch 304/500\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.9044 - f1_score: 0.7006 - val_loss: 1.0229 - val_f1_score: 0.7754\n",
      "Epoch 305/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9185 - f1_score: 0.6941 - val_loss: 1.0215 - val_f1_score: 0.7776\n",
      "Epoch 306/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9029 - f1_score: 0.7120 - val_loss: 1.0347 - val_f1_score: 0.7762\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8615 - f1_score: 0.7173 - val_loss: 1.0938 - val_f1_score: 0.7498\n",
      "Epoch 308/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9022 - f1_score: 0.7056 - val_loss: 1.0493 - val_f1_score: 0.7714\n",
      "Epoch 309/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8997 - f1_score: 0.7055 - val_loss: 1.0421 - val_f1_score: 0.7748\n",
      "Epoch 310/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8641 - f1_score: 0.7076 - val_loss: 1.0903 - val_f1_score: 0.7334\n",
      "Epoch 311/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8686 - f1_score: 0.7177 - val_loss: 1.0193 - val_f1_score: 0.7880\n",
      "Epoch 312/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8956 - f1_score: 0.7120 - val_loss: 1.1848 - val_f1_score: 0.7770\n",
      "Epoch 313/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.9020 - f1_score: 0.7141 - val_loss: 1.0651 - val_f1_score: 0.7563\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.8896 - f1_score: 0.7212 - val_loss: 1.0186 - val_f1_score: 0.7788\n",
      "Epoch 315/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8777 - f1_score: 0.7117 - val_loss: 1.0411 - val_f1_score: 0.7573\n",
      "Epoch 316/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8806 - f1_score: 0.7074 - val_loss: 1.1642 - val_f1_score: 0.7467\n",
      "Epoch 317/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8916 - f1_score: 0.6947 - val_loss: 1.0758 - val_f1_score: 0.7578\n",
      "Epoch 318/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8508 - f1_score: 0.7076 - val_loss: 1.0677 - val_f1_score: 0.7638\n",
      "Epoch 319/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8801 - f1_score: 0.7038 - val_loss: 1.1240 - val_f1_score: 0.7705\n",
      "Epoch 320/500\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.8561 - f1_score: 0.7230 - val_loss: 1.0740 - val_f1_score: 0.7716\n",
      "Epoch 321/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8704 - f1_score: 0.7120 - val_loss: 1.1027 - val_f1_score: 0.7529\n",
      "Epoch 322/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8698 - f1_score: 0.7169 - val_loss: 1.0533 - val_f1_score: 0.7934\n",
      "Epoch 323/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8948 - f1_score: 0.7068 - val_loss: 1.0442 - val_f1_score: 0.7939\n",
      "Epoch 324/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8921 - f1_score: 0.7021 - val_loss: 1.0449 - val_f1_score: 0.7822\n",
      "Epoch 325/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8915 - f1_score: 0.7125 - val_loss: 1.0909 - val_f1_score: 0.7499\n",
      "Epoch 326/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8762 - f1_score: 0.7147 - val_loss: 1.0676 - val_f1_score: 0.7640\n",
      "Epoch 327/500\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.8824 - f1_score: 0.7108 - val_loss: 1.0577 - val_f1_score: 0.7575\n",
      "Epoch 328/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9104 - f1_score: 0.6997 - val_loss: 1.0972 - val_f1_score: 0.7723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8695 - f1_score: 0.7123 - val_loss: 1.0940 - val_f1_score: 0.7528\n",
      "Epoch 330/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8902 - f1_score: 0.7117 - val_loss: 1.0979 - val_f1_score: 0.7510\n",
      "Epoch 331/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8418 - f1_score: 0.7211 - val_loss: 1.0925 - val_f1_score: 0.7739\n",
      "Epoch 332/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8367 - f1_score: 0.7076 - val_loss: 1.0999 - val_f1_score: 0.7625\n",
      "Epoch 333/500\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.8498 - f1_score: 0.7210 - val_loss: 1.0997 - val_f1_score: 0.7805\n",
      "Epoch 334/500\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.8312 - f1_score: 0.7283 - val_loss: 1.1690 - val_f1_score: 0.7508\n",
      "Epoch 335/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9017 - f1_score: 0.7072 - val_loss: 1.1327 - val_f1_score: 0.7550\n",
      "Epoch 336/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8526 - f1_score: 0.7106 - val_loss: 1.0395 - val_f1_score: 0.7658\n",
      "Epoch 337/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8339 - f1_score: 0.7148 - val_loss: 1.0878 - val_f1_score: 0.7803\n",
      "Epoch 338/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8884 - f1_score: 0.7156 - val_loss: 1.1055 - val_f1_score: 0.7639\n",
      "Epoch 339/500\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.8700 - f1_score: 0.7128 - val_loss: 1.0831 - val_f1_score: 0.7617\n",
      "Epoch 340/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.8122 - f1_score: 0.7336 - val_loss: 1.0806 - val_f1_score: 0.7593\n",
      "Epoch 341/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.8249 - f1_score: 0.7271 - val_loss: 1.1313 - val_f1_score: 0.7813\n",
      "Epoch 342/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.8253 - f1_score: 0.7287 - val_loss: 1.1618 - val_f1_score: 0.7407\n",
      "Epoch 343/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8610 - f1_score: 0.7209 - val_loss: 1.0891 - val_f1_score: 0.7540\n",
      "Epoch 344/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8509 - f1_score: 0.7302 - val_loss: 1.0794 - val_f1_score: 0.7679\n",
      "Epoch 345/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8822 - f1_score: 0.7119 - val_loss: 1.0772 - val_f1_score: 0.7397\n",
      "Epoch 346/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8190 - f1_score: 0.7173 - val_loss: 1.1576 - val_f1_score: 0.7718\n",
      "Epoch 347/500\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.8144 - f1_score: 0.7360 - val_loss: 1.0777 - val_f1_score: 0.7725\n",
      "Epoch 348/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.8350 - f1_score: 0.7311 - val_loss: 1.1277 - val_f1_score: 0.7472\n",
      "Epoch 349/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.8685 - f1_score: 0.7087 - val_loss: 1.0660 - val_f1_score: 0.7549\n",
      "Epoch 350/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8572 - f1_score: 0.7109 - val_loss: 1.1475 - val_f1_score: 0.7648\n",
      "Epoch 351/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8185 - f1_score: 0.7319 - val_loss: 1.1597 - val_f1_score: 0.7707\n",
      "Epoch 352/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8131 - f1_score: 0.7316 - val_loss: 1.2251 - val_f1_score: 0.7148\n",
      "Epoch 353/500\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.8749 - f1_score: 0.7217 - val_loss: 1.1309 - val_f1_score: 0.7816\n",
      "Epoch 354/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7981 - f1_score: 0.7307 - val_loss: 1.1202 - val_f1_score: 0.7765\n",
      "Epoch 355/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8492 - f1_score: 0.7154 - val_loss: 1.0924 - val_f1_score: 0.7935\n",
      "Epoch 356/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8117 - f1_score: 0.7350 - val_loss: 1.0678 - val_f1_score: 0.7892\n",
      "Epoch 357/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8585 - f1_score: 0.7176 - val_loss: 1.1500 - val_f1_score: 0.7460\n",
      "Epoch 358/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8318 - f1_score: 0.7350 - val_loss: 1.2665 - val_f1_score: 0.7496\n",
      "Epoch 359/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8116 - f1_score: 0.7417 - val_loss: 1.1410 - val_f1_score: 0.7633\n",
      "Epoch 360/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8195 - f1_score: 0.7395 - val_loss: 1.1483 - val_f1_score: 0.7536\n",
      "Epoch 361/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8135 - f1_score: 0.7354 - val_loss: 1.1022 - val_f1_score: 0.7728\n",
      "Epoch 362/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7767 - f1_score: 0.7322 - val_loss: 1.1639 - val_f1_score: 0.7443\n",
      "Epoch 363/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7736 - f1_score: 0.7479 - val_loss: 1.1964 - val_f1_score: 0.7747\n",
      "Epoch 364/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8096 - f1_score: 0.7257 - val_loss: 1.1228 - val_f1_score: 0.7756\n",
      "Epoch 365/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.8541 - f1_score: 0.7245 - val_loss: 1.1400 - val_f1_score: 0.7538\n",
      "Epoch 366/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8462 - f1_score: 0.7123 - val_loss: 1.1118 - val_f1_score: 0.7609\n",
      "Epoch 367/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8518 - f1_score: 0.7312 - val_loss: 1.1562 - val_f1_score: 0.7960\n",
      "Epoch 368/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7769 - f1_score: 0.7436 - val_loss: 1.0996 - val_f1_score: 0.7713\n",
      "Epoch 369/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8508 - f1_score: 0.7237 - val_loss: 1.1830 - val_f1_score: 0.7654\n",
      "Epoch 370/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.8203 - f1_score: 0.7288 - val_loss: 1.1126 - val_f1_score: 0.8072\n",
      "Epoch 371/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7808 - f1_score: 0.7497 - val_loss: 1.1291 - val_f1_score: 0.7546\n",
      "Epoch 372/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8375 - f1_score: 0.7259 - val_loss: 1.1351 - val_f1_score: 0.7678\n",
      "Epoch 373/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8603 - f1_score: 0.7167 - val_loss: 1.2457 - val_f1_score: 0.7736\n",
      "Epoch 374/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7738 - f1_score: 0.7318 - val_loss: 1.1462 - val_f1_score: 0.7681\n",
      "Epoch 375/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7894 - f1_score: 0.7265 - val_loss: 1.0842 - val_f1_score: 0.7801\n",
      "Epoch 376/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8006 - f1_score: 0.7327 - val_loss: 1.1440 - val_f1_score: 0.7906\n",
      "Epoch 377/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7897 - f1_score: 0.7355 - val_loss: 1.1490 - val_f1_score: 0.7730\n",
      "Epoch 378/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8141 - f1_score: 0.7413 - val_loss: 1.1241 - val_f1_score: 0.7726\n",
      "Epoch 379/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8036 - f1_score: 0.7282 - val_loss: 1.1635 - val_f1_score: 0.7643\n",
      "Epoch 380/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8273 - f1_score: 0.7279 - val_loss: 1.1086 - val_f1_score: 0.7894\n",
      "Epoch 381/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8154 - f1_score: 0.7316 - val_loss: 1.1385 - val_f1_score: 0.7630\n",
      "Epoch 382/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7898 - f1_score: 0.7355 - val_loss: 1.1515 - val_f1_score: 0.7512\n",
      "Epoch 383/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8197 - f1_score: 0.7330 - val_loss: 1.1150 - val_f1_score: 0.7866\n",
      "Epoch 384/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7899 - f1_score: 0.7455 - val_loss: 1.2125 - val_f1_score: 0.7601\n",
      "Epoch 385/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8229 - f1_score: 0.7370 - val_loss: 1.1862 - val_f1_score: 0.7789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7639 - f1_score: 0.7347 - val_loss: 1.1928 - val_f1_score: 0.7519\n",
      "Epoch 387/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.8017 - f1_score: 0.7320 - val_loss: 1.1767 - val_f1_score: 0.7845\n",
      "Epoch 388/500\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.7990 - f1_score: 0.7381 - val_loss: 1.0505 - val_f1_score: 0.8025\n",
      "Epoch 389/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7803 - f1_score: 0.7382 - val_loss: 1.1526 - val_f1_score: 0.7657\n",
      "Epoch 390/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8065 - f1_score: 0.7298 - val_loss: 1.0953 - val_f1_score: 0.7790\n",
      "Epoch 391/500\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.8081 - f1_score: 0.7295 - val_loss: 1.1342 - val_f1_score: 0.7762\n",
      "Epoch 392/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8303 - f1_score: 0.7317 - val_loss: 1.1665 - val_f1_score: 0.7794\n",
      "Epoch 393/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8231 - f1_score: 0.7350 - val_loss: 1.0869 - val_f1_score: 0.7913\n",
      "Epoch 394/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7402 - f1_score: 0.7442 - val_loss: 1.2127 - val_f1_score: 0.7670\n",
      "Epoch 395/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7905 - f1_score: 0.7310 - val_loss: 1.2029 - val_f1_score: 0.7597\n",
      "Epoch 396/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7628 - f1_score: 0.7543 - val_loss: 1.2366 - val_f1_score: 0.7677\n",
      "Epoch 397/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.8309 - f1_score: 0.7319 - val_loss: 1.1187 - val_f1_score: 0.7505\n",
      "Epoch 398/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7983 - f1_score: 0.7287 - val_loss: 1.1720 - val_f1_score: 0.7539\n",
      "Epoch 399/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.8004 - f1_score: 0.7409 - val_loss: 1.0888 - val_f1_score: 0.7753\n",
      "Epoch 400/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7969 - f1_score: 0.7236 - val_loss: 1.2581 - val_f1_score: 0.7409\n",
      "Epoch 401/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7731 - f1_score: 0.7407 - val_loss: 1.2070 - val_f1_score: 0.7382\n",
      "Epoch 402/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7941 - f1_score: 0.7369 - val_loss: 1.1620 - val_f1_score: 0.7687\n",
      "Epoch 403/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7561 - f1_score: 0.7594 - val_loss: 1.1441 - val_f1_score: 0.7531\n",
      "Epoch 404/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7551 - f1_score: 0.7447 - val_loss: 1.1789 - val_f1_score: 0.7512\n",
      "Epoch 405/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7800 - f1_score: 0.7413 - val_loss: 1.2046 - val_f1_score: 0.7778\n",
      "Epoch 406/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7621 - f1_score: 0.7559 - val_loss: 1.2249 - val_f1_score: 0.7671\n",
      "Epoch 407/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7741 - f1_score: 0.7516 - val_loss: 1.1696 - val_f1_score: 0.7499\n",
      "Epoch 408/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.8115 - f1_score: 0.7379 - val_loss: 1.1456 - val_f1_score: 0.7673\n",
      "Epoch 409/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7526 - f1_score: 0.7568 - val_loss: 1.1305 - val_f1_score: 0.7889\n",
      "Epoch 410/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7871 - f1_score: 0.7334 - val_loss: 1.2526 - val_f1_score: 0.7514\n",
      "Epoch 411/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.8015 - f1_score: 0.7380 - val_loss: 1.2296 - val_f1_score: 0.7596\n",
      "Epoch 412/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7508 - f1_score: 0.7491 - val_loss: 1.2232 - val_f1_score: 0.7672\n",
      "Epoch 413/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7414 - f1_score: 0.7541 - val_loss: 1.1379 - val_f1_score: 0.7694\n",
      "Epoch 414/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7663 - f1_score: 0.7534 - val_loss: 1.1986 - val_f1_score: 0.7487\n",
      "Epoch 415/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7538 - f1_score: 0.7511 - val_loss: 1.1383 - val_f1_score: 0.7681\n",
      "Epoch 416/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7734 - f1_score: 0.7453 - val_loss: 1.2499 - val_f1_score: 0.7791\n",
      "Epoch 417/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7878 - f1_score: 0.7360 - val_loss: 1.2037 - val_f1_score: 0.7714\n",
      "Epoch 418/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7734 - f1_score: 0.7450 - val_loss: 1.1997 - val_f1_score: 0.7653\n",
      "Epoch 419/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7730 - f1_score: 0.7479 - val_loss: 1.1862 - val_f1_score: 0.7756\n",
      "Epoch 420/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7943 - f1_score: 0.7573 - val_loss: 1.2504 - val_f1_score: 0.7391\n",
      "Epoch 421/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7488 - f1_score: 0.7604 - val_loss: 1.1029 - val_f1_score: 0.7923\n",
      "Epoch 422/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7348 - f1_score: 0.7642 - val_loss: 1.1769 - val_f1_score: 0.7821\n",
      "Epoch 423/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7462 - f1_score: 0.7421 - val_loss: 1.2889 - val_f1_score: 0.7709\n",
      "Epoch 424/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7601 - f1_score: 0.7518 - val_loss: 1.2979 - val_f1_score: 0.7523\n",
      "Epoch 425/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7639 - f1_score: 0.7493 - val_loss: 1.1640 - val_f1_score: 0.7718\n",
      "Epoch 426/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7390 - f1_score: 0.7551 - val_loss: 1.1758 - val_f1_score: 0.7595\n",
      "Epoch 427/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7555 - f1_score: 0.7550 - val_loss: 1.0987 - val_f1_score: 0.7906\n",
      "Epoch 428/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7704 - f1_score: 0.7454 - val_loss: 1.1356 - val_f1_score: 0.7584\n",
      "Epoch 429/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7956 - f1_score: 0.7425 - val_loss: 1.1800 - val_f1_score: 0.7738\n",
      "Epoch 430/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7725 - f1_score: 0.7452 - val_loss: 1.1618 - val_f1_score: 0.7776\n",
      "Epoch 431/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7408 - f1_score: 0.7516 - val_loss: 1.2039 - val_f1_score: 0.7725\n",
      "Epoch 432/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7612 - f1_score: 0.7522 - val_loss: 1.1745 - val_f1_score: 0.7959\n",
      "Epoch 433/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7543 - f1_score: 0.7553 - val_loss: 1.1057 - val_f1_score: 0.8059\n",
      "Epoch 434/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7523 - f1_score: 0.7513 - val_loss: 1.3219 - val_f1_score: 0.7430\n",
      "Epoch 435/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7549 - f1_score: 0.7499 - val_loss: 1.1239 - val_f1_score: 0.7877\n",
      "Epoch 436/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7292 - f1_score: 0.7740 - val_loss: 1.1815 - val_f1_score: 0.7932\n",
      "Epoch 437/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7411 - f1_score: 0.7566 - val_loss: 1.1689 - val_f1_score: 0.7551\n",
      "Epoch 438/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7312 - f1_score: 0.7533 - val_loss: 1.1865 - val_f1_score: 0.7658\n",
      "Epoch 439/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7458 - f1_score: 0.7481 - val_loss: 1.1225 - val_f1_score: 0.7803\n",
      "Epoch 440/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7289 - f1_score: 0.7477 - val_loss: 1.1624 - val_f1_score: 0.7654\n",
      "Epoch 441/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7624 - f1_score: 0.7480 - val_loss: 1.2700 - val_f1_score: 0.7539\n",
      "Epoch 442/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7211 - f1_score: 0.7550 - val_loss: 1.1895 - val_f1_score: 0.7707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7806 - f1_score: 0.7346 - val_loss: 1.1357 - val_f1_score: 0.8071\n",
      "Epoch 444/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7871 - f1_score: 0.7543 - val_loss: 1.2192 - val_f1_score: 0.7755\n",
      "Epoch 445/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7597 - f1_score: 0.7553 - val_loss: 1.2551 - val_f1_score: 0.7256\n",
      "Epoch 446/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7540 - f1_score: 0.7520 - val_loss: 1.1727 - val_f1_score: 0.7942\n",
      "Epoch 447/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7496 - f1_score: 0.7557 - val_loss: 1.1845 - val_f1_score: 0.7893\n",
      "Epoch 448/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7366 - f1_score: 0.7496 - val_loss: 1.1567 - val_f1_score: 0.7720\n",
      "Epoch 449/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7551 - f1_score: 0.7451 - val_loss: 1.1566 - val_f1_score: 0.7851\n",
      "Epoch 450/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7660 - f1_score: 0.7393 - val_loss: 1.2083 - val_f1_score: 0.7725\n",
      "Epoch 451/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7446 - f1_score: 0.7501 - val_loss: 1.2280 - val_f1_score: 0.7474\n",
      "Epoch 452/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7795 - f1_score: 0.7518 - val_loss: 1.1675 - val_f1_score: 0.8040\n",
      "Epoch 453/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7503 - f1_score: 0.7541 - val_loss: 1.2195 - val_f1_score: 0.7471\n",
      "Epoch 454/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7825 - f1_score: 0.7338 - val_loss: 1.1478 - val_f1_score: 0.7721\n",
      "Epoch 455/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7230 - f1_score: 0.7737 - val_loss: 1.2582 - val_f1_score: 0.7499\n",
      "Epoch 456/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7381 - f1_score: 0.7466 - val_loss: 1.2932 - val_f1_score: 0.7645\n",
      "Epoch 457/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7475 - f1_score: 0.7539 - val_loss: 1.1911 - val_f1_score: 0.7958\n",
      "Epoch 458/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7277 - f1_score: 0.7650 - val_loss: 1.1751 - val_f1_score: 0.7692\n",
      "Epoch 459/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7520 - f1_score: 0.7579 - val_loss: 1.1480 - val_f1_score: 0.7839\n",
      "Epoch 460/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7263 - f1_score: 0.7610 - val_loss: 1.2570 - val_f1_score: 0.7692\n",
      "Epoch 461/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7099 - f1_score: 0.7574 - val_loss: 1.2238 - val_f1_score: 0.7809\n",
      "Epoch 462/500\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.6726 - f1_score: 0.7698 - val_loss: 1.2651 - val_f1_score: 0.7790\n",
      "Epoch 463/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7696 - f1_score: 0.7558 - val_loss: 1.1559 - val_f1_score: 0.7796\n",
      "Epoch 464/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.6858 - f1_score: 0.7763 - val_loss: 1.2353 - val_f1_score: 0.7466\n",
      "Epoch 465/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7365 - f1_score: 0.7568 - val_loss: 1.2006 - val_f1_score: 0.7705\n",
      "Epoch 466/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7289 - f1_score: 0.7628 - val_loss: 1.2539 - val_f1_score: 0.7719\n",
      "Epoch 467/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.6921 - f1_score: 0.7630 - val_loss: 1.2695 - val_f1_score: 0.7805\n",
      "Epoch 468/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7263 - f1_score: 0.7593 - val_loss: 1.2309 - val_f1_score: 0.7633\n",
      "Epoch 469/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7102 - f1_score: 0.7465 - val_loss: 1.2486 - val_f1_score: 0.7844\n",
      "Epoch 470/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7102 - f1_score: 0.7645 - val_loss: 1.1904 - val_f1_score: 0.7962\n",
      "Epoch 471/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7471 - f1_score: 0.7475 - val_loss: 1.2549 - val_f1_score: 0.7731\n",
      "Epoch 472/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7582 - f1_score: 0.7517 - val_loss: 1.1994 - val_f1_score: 0.7682\n",
      "Epoch 473/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7553 - f1_score: 0.7474 - val_loss: 1.2068 - val_f1_score: 0.7750\n",
      "Epoch 474/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7029 - f1_score: 0.7662 - val_loss: 1.2230 - val_f1_score: 0.7962\n",
      "Epoch 475/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7031 - f1_score: 0.7686 - val_loss: 1.2561 - val_f1_score: 0.7733\n",
      "Epoch 476/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7384 - f1_score: 0.7522 - val_loss: 1.1980 - val_f1_score: 0.7970\n",
      "Epoch 477/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7264 - f1_score: 0.7679 - val_loss: 1.2240 - val_f1_score: 0.7513\n",
      "Epoch 478/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7680 - f1_score: 0.7433 - val_loss: 1.1663 - val_f1_score: 0.8107\n",
      "Epoch 479/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7205 - f1_score: 0.7643 - val_loss: 1.1549 - val_f1_score: 0.8087\n",
      "Epoch 480/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7751 - f1_score: 0.7528 - val_loss: 1.1310 - val_f1_score: 0.7861\n",
      "Epoch 481/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7166 - f1_score: 0.7654 - val_loss: 1.2595 - val_f1_score: 0.7974\n",
      "Epoch 482/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7516 - f1_score: 0.7581 - val_loss: 1.2234 - val_f1_score: 0.8015\n",
      "Epoch 483/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7448 - f1_score: 0.7550 - val_loss: 1.1527 - val_f1_score: 0.7693\n",
      "Epoch 484/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.6738 - f1_score: 0.7842 - val_loss: 1.1879 - val_f1_score: 0.7752\n",
      "Epoch 485/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7084 - f1_score: 0.7616 - val_loss: 1.2528 - val_f1_score: 0.7937\n",
      "Epoch 486/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.6833 - f1_score: 0.7785 - val_loss: 1.2485 - val_f1_score: 0.7795\n",
      "Epoch 487/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7433 - f1_score: 0.7632 - val_loss: 1.2187 - val_f1_score: 0.7835\n",
      "Epoch 488/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7550 - f1_score: 0.7521 - val_loss: 1.1773 - val_f1_score: 0.8108\n",
      "Epoch 489/500\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.7144 - f1_score: 0.7570 - val_loss: 1.2640 - val_f1_score: 0.7761\n",
      "Epoch 490/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7491 - f1_score: 0.7483 - val_loss: 1.2708 - val_f1_score: 0.7877\n",
      "Epoch 491/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7347 - f1_score: 0.7592 - val_loss: 1.1448 - val_f1_score: 0.7640\n",
      "Epoch 492/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.6740 - f1_score: 0.7714 - val_loss: 1.2770 - val_f1_score: 0.7702\n",
      "Epoch 493/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7161 - f1_score: 0.7661 - val_loss: 1.1808 - val_f1_score: 0.7726\n",
      "Epoch 494/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7042 - f1_score: 0.7635 - val_loss: 1.1995 - val_f1_score: 0.7938\n",
      "Epoch 495/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7164 - f1_score: 0.7598 - val_loss: 1.2363 - val_f1_score: 0.7874\n",
      "Epoch 496/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7173 - f1_score: 0.7634 - val_loss: 1.1984 - val_f1_score: 0.7995\n",
      "Epoch 497/500\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.7243 - f1_score: 0.7579 - val_loss: 1.2534 - val_f1_score: 0.7979\n",
      "Epoch 498/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7029 - f1_score: 0.7640 - val_loss: 1.2468 - val_f1_score: 0.7778\n",
      "Epoch 499/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.6926 - f1_score: 0.7690 - val_loss: 1.2074 - val_f1_score: 0.7876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.7168 - f1_score: 0.7671 - val_loss: 1.1581 - val_f1_score: 0.7873\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SpatialDropout1D\n",
    "from kerastuner import HyperModel\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "#supercool hyperparameter\n",
    "# Define the CNN model\n",
    "model = Sequential(name='Sequential')\n",
    "act_function = 'elu'\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv1D(filters=125, kernel_size=2, activation=act_function, input_shape=(130, 126)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=125, kernel_size=2, activation=act_function))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=125, kernel_size=2, activation=act_function))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Conv1D(filters=100, kernel_size=2, activation=act_function))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Conv1D(filters=75, kernel_size=2, activation=act_function))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# droput layer, remove if no work\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "\n",
    "# Flatten the output for the fully connected layers\n",
    "model.add(Flatten())\n",
    "# Add fully connected layers\n",
    "model.add(Dense(80, activation=act_function))\n",
    "#model.add(Dense(16, activation=act_function))\n",
    "#model.add(Dense(40, activation=act_function))\n",
    "#model.add(Dense(16, activation=act_function))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(50, activation='softmax'))  # Output layer\n",
    "optimizer = Nadam(learning_rate=.0008273819395816823)\n",
    "# Compile the model\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[tfa.metrics.F1Score(num_classes=50, average='macro')])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(Xtrain, Ytrain, epochs=500, validation_data=(Xval,Yval), batch_size = 96, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "880742e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T22:36:02.313283Z",
     "start_time": "2023-08-11T22:36:01.994542Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "80256eb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T22:42:34.538802Z",
     "start_time": "2023-08-11T22:42:34.534841Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(res[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "27319198",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T21:47:17.963593Z",
     "start_time": "2023-08-22T21:47:17.960029Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Yval[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ae27e702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T21:46:25.536051Z",
     "start_time": "2023-08-22T21:46:25.532056Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yval[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a6800bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T22:42:12.307705Z",
     "start_time": "2023-08-11T22:42:12.008405Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "res = best_model.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "811767c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T12:01:05.269958Z",
     "start_time": "2023-08-23T12:01:04.614796Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 13ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84         8\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       0.83      1.00      0.91        10\n",
      "           3       0.88      0.70      0.78        10\n",
      "           4       0.80      1.00      0.89         4\n",
      "           5       0.73      1.00      0.84         8\n",
      "           6       0.62      0.83      0.71         6\n",
      "           7       0.88      0.88      0.88         8\n",
      "           8       0.00      0.00      0.00         6\n",
      "           9       0.62      0.83      0.71         6\n",
      "          10       0.80      1.00      0.89         4\n",
      "          11       1.00      0.83      0.91         6\n",
      "          12       1.00      0.67      0.80         6\n",
      "          13       0.71      0.62      0.67         8\n",
      "          14       0.50      0.33      0.40         6\n",
      "          15       0.88      0.88      0.88         8\n",
      "          16       0.75      1.00      0.86         6\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       0.60      0.75      0.67         4\n",
      "          19       0.86      1.00      0.92         6\n",
      "          20       1.00      1.00      1.00         6\n",
      "          21       1.00      1.00      1.00         8\n",
      "          22       1.00      1.00      1.00         4\n",
      "          23       0.67      0.50      0.57         4\n",
      "          24       0.57      0.67      0.62         6\n",
      "          25       1.00      0.88      0.93         8\n",
      "          26       1.00      0.88      0.93         8\n",
      "          27       1.00      0.83      0.91         6\n",
      "          28       1.00      0.50      0.67         4\n",
      "          29       1.00      0.50      0.67         4\n",
      "          30       1.00      0.50      0.67         4\n",
      "          31       1.00      0.62      0.77         8\n",
      "          32       1.00      0.50      0.67         8\n",
      "          33       0.50      0.75      0.60         4\n",
      "          34       0.67      1.00      0.80         6\n",
      "          35       1.00      1.00      1.00         4\n",
      "          36       0.86      0.75      0.80         8\n",
      "          37       0.60      0.75      0.67         8\n",
      "          38       0.73      1.00      0.84         8\n",
      "          39       1.00      0.75      0.86         8\n",
      "          40       0.60      1.00      0.75         6\n",
      "          41       0.75      0.75      0.75         4\n",
      "          42       0.67      1.00      0.80         6\n",
      "          43       0.89      1.00      0.94         8\n",
      "          44       1.00      0.70      0.82        10\n",
      "          45       0.75      0.50      0.60         6\n",
      "          46       0.67      0.50      0.57         4\n",
      "          47       0.57      1.00      0.73         4\n",
      "          48       1.00      0.88      0.93         8\n",
      "          49       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.81       324\n",
      "   macro avg       0.81      0.80      0.79       324\n",
      "weighted avg       0.82      0.81      0.80       324\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristian/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kristian/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kristian/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(np.argmax(Yval, axis=1), np.argmax(model.predict(Xval), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bd6bdd57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T22:46:13.337833Z",
     "start_time": "2023-08-11T22:46:13.328033Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SpatialDropout1D\n",
    "from keras_tuner import HyperModel\n",
    "from kerastuner.tuners import Hyperband\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        act_function = hp.Choice('dense_activation',values=['relu','selu','LeakyReLU'],default='selu')\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=hp.Choice('num_filters_1',values=[25,50, 100],default=50,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(filters=hp.Choice('num_filters_2',values=[25,50, 100],default=50,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(filters=hp.Choice('num_filters_3',values=[25,50, 100],default=50,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_1',min_value=0.0,max_value=0.7,default=0.25,step=0.05,)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=hp.Int('units',min_value=20,max_value=100,step=20,default=40),activation=act_function))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_2',min_value=0.0,max_value=0.7,default=0.25,step=0.05,)))\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(Lion(hp.Float('learning_rate',min_value=1e-5,max_value=1e-3,sampling='LOG',default=1e-5)),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "hypermodel = CNNHyperModel(input_shape=(130,126), num_classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a2182a59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T22:46:17.862451Z",
     "start_time": "2023-08-11T22:46:15.404906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "HYPERBAND_MAX_EPOCHS = 100\n",
    "#MAX_TRIALS = 20\n",
    "EXECUTION_PER_TRIAL = 2\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    max_epochs=HYPERBAND_MAX_EPOCHS,\n",
    "    objective='val_loss',\n",
    "    seed=10,\n",
    "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "    directory='hyperband',\n",
    "    project_name='test2',\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5ba56655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-11T22:46:20.898035Z",
     "start_time": "2023-08-11T22:46:20.894847Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 8\n",
      "dense_activation (Choice)\n",
      "{'default': 'selu', 'conditions': [], 'values': ['relu', 'selu', 'LeakyReLU'], 'ordered': False}\n",
      "num_filters_1 (Choice)\n",
      "{'default': 50, 'conditions': [], 'values': [25, 50, 100], 'ordered': True}\n",
      "num_filters_2 (Choice)\n",
      "{'default': 50, 'conditions': [], 'values': [25, 50, 100], 'ordered': True}\n",
      "num_filters_3 (Choice)\n",
      "{'default': 50, 'conditions': [], 'values': [25, 50, 100], 'ordered': True}\n",
      "dropout_1 (Float)\n",
      "{'default': 0.25, 'conditions': [], 'min_value': 0.0, 'max_value': 0.7, 'step': 0.05, 'sampling': 'linear'}\n",
      "units (Int)\n",
      "{'default': 40, 'conditions': [], 'min_value': 20, 'max_value': 100, 'step': 20, 'sampling': 'linear'}\n",
      "dropout_2 (Float)\n",
      "{'default': 0.25, 'conditions': [], 'min_value': 0.0, 'max_value': 0.7, 'step': 0.05, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.001, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "49371794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T02:13:00.969542Z",
     "start_time": "2023-08-11T22:46:52.136825Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 05m 55s]\n",
      "val_loss: 3.711934208869934\n",
      "\n",
      "Best val_loss So Far: 0.5881174206733704\n",
      "Total elapsed time: 03h 26m 05s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(Xtrain, Ytrain, epochs=1000, validation_split=0.15,batch_size=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3aa99737",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T07:31:25.047726Z",
     "start_time": "2023-08-12T07:31:24.310971Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6f5e3610",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T06:37:01.544865Z",
     "start_time": "2023-08-12T06:37:01.540285Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in hyperband/test2\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 0146 summary\n",
      "Hyperparameters:\n",
      "dense_activation: LeakyReLU\n",
      "num_filters_1: 100\n",
      "num_filters_2: 50\n",
      "num_filters_3: 25\n",
      "dropout_1: 0.55\n",
      "units: 60\n",
      "dropout_2: 0.0\n",
      "learning_rate: 0.0008623436067374464\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 4\n",
      "tuner/round: 4\n",
      "tuner/trial_id: 0144\n",
      "Score: 0.5881174206733704\n",
      "\n",
      "Trial 0208 summary\n",
      "Hyperparameters:\n",
      "dense_activation: LeakyReLU\n",
      "num_filters_1: 50\n",
      "num_filters_2: 100\n",
      "num_filters_3: 50\n",
      "dropout_1: 0.6000000000000001\n",
      "units: 40\n",
      "dropout_2: 0.15000000000000002\n",
      "learning_rate: 0.0008453355630521282\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0203\n",
      "Score: 0.6373574137687683\n",
      "\n",
      "Trial 0247 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 50\n",
      "num_filters_2: 25\n",
      "num_filters_3: 50\n",
      "dropout_1: 0.55\n",
      "units: 60\n",
      "dropout_2: 0.1\n",
      "learning_rate: 0.00011684126260235347\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0242\n",
      "Score: 0.7295390367507935\n",
      "\n",
      "Trial 0246 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 50\n",
      "num_filters_2: 25\n",
      "num_filters_3: 50\n",
      "dropout_1: 0.45\n",
      "units: 80\n",
      "dropout_2: 0.35000000000000003\n",
      "learning_rate: 0.00017199099695109802\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0244\n",
      "Score: 0.7739558219909668\n",
      "\n",
      "Trial 0209 summary\n",
      "Hyperparameters:\n",
      "dense_activation: LeakyReLU\n",
      "num_filters_1: 25\n",
      "num_filters_2: 100\n",
      "num_filters_3: 50\n",
      "dropout_1: 0.1\n",
      "units: 80\n",
      "dropout_2: 0.5\n",
      "learning_rate: 0.0003920143237423156\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0204\n",
      "Score: 0.8750218749046326\n",
      "\n",
      "Trial 0234 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 25\n",
      "num_filters_2: 100\n",
      "num_filters_3: 25\n",
      "dropout_1: 0.15000000000000002\n",
      "units: 60\n",
      "dropout_2: 0.05\n",
      "learning_rate: 0.0005864842412780541\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0228\n",
      "Score: 0.965071439743042\n",
      "\n",
      "Trial 0228 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 25\n",
      "num_filters_2: 100\n",
      "num_filters_3: 25\n",
      "dropout_1: 0.15000000000000002\n",
      "units: 60\n",
      "dropout_2: 0.05\n",
      "learning_rate: 0.0005864842412780541\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0210\n",
      "Score: 1.0085859298706055\n",
      "\n",
      "Trial 0144 summary\n",
      "Hyperparameters:\n",
      "dense_activation: LeakyReLU\n",
      "num_filters_1: 100\n",
      "num_filters_2: 50\n",
      "num_filters_3: 25\n",
      "dropout_1: 0.55\n",
      "units: 60\n",
      "dropout_2: 0.0\n",
      "learning_rate: 0.0008623436067374464\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 4\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0133\n",
      "Score: 1.120571494102478\n",
      "\n",
      "Trial 0251 summary\n",
      "Hyperparameters:\n",
      "dense_activation: LeakyReLU\n",
      "num_filters_1: 25\n",
      "num_filters_2: 100\n",
      "num_filters_3: 100\n",
      "dropout_1: 0.35000000000000003\n",
      "units: 60\n",
      "dropout_2: 0.15000000000000002\n",
      "learning_rate: 0.00015041993987227918\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 1.203498899936676\n",
      "\n",
      "Trial 0203 summary\n",
      "Hyperparameters:\n",
      "dense_activation: LeakyReLU\n",
      "num_filters_1: 50\n",
      "num_filters_2: 100\n",
      "num_filters_3: 50\n",
      "dropout_1: 0.6000000000000001\n",
      "units: 40\n",
      "dropout_2: 0.15000000000000002\n",
      "learning_rate: 0.0008453355630521282\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0189\n",
      "Score: 1.2128181457519531\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "24ca0cb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T07:47:05.084548Z",
     "start_time": "2023-08-12T07:47:05.081878Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bestHP = tuner.get_best_hyperparameters(num_trials=2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b49dd56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T09:39:14.483220Z",
     "start_time": "2023-08-12T09:39:14.480251Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\",patience=20,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b6fba9d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T07:49:18.362874Z",
     "start_time": "2023-08-12T07:48:43.248067Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the best model...\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 2s 25ms/step - loss: 3.9155 - accuracy: 0.0164 - val_loss: 3.8558 - val_accuracy: 0.0123\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 3.8114 - accuracy: 0.0374 - val_loss: 3.6777 - val_accuracy: 0.0617\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 3.5656 - accuracy: 0.0803 - val_loss: 3.4296 - val_accuracy: 0.0556\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 3.3048 - accuracy: 0.1110 - val_loss: 3.1529 - val_accuracy: 0.1358\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 3.0500 - accuracy: 0.1416 - val_loss: 2.9998 - val_accuracy: 0.1698\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 2.8309 - accuracy: 0.1977 - val_loss: 2.9745 - val_accuracy: 0.1821\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 2.6850 - accuracy: 0.2351 - val_loss: 2.8642 - val_accuracy: 0.1759\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 2.5459 - accuracy: 0.2687 - val_loss: 2.8134 - val_accuracy: 0.2099\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 2.4007 - accuracy: 0.3031 - val_loss: 2.7086 - val_accuracy: 0.2377\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.2695 - accuracy: 0.3274 - val_loss: 2.7176 - val_accuracy: 0.2438\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 2.1748 - accuracy: 0.3498 - val_loss: 2.7088 - val_accuracy: 0.2963\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 2.0285 - accuracy: 0.3875 - val_loss: 2.8246 - val_accuracy: 0.2809\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.9664 - accuracy: 0.4096 - val_loss: 2.5296 - val_accuracy: 0.3426\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.9009 - accuracy: 0.4249 - val_loss: 2.5813 - val_accuracy: 0.3241\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.7932 - accuracy: 0.4529 - val_loss: 2.4985 - val_accuracy: 0.3827\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.7711 - accuracy: 0.4604 - val_loss: 2.4895 - val_accuracy: 0.3920\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.7158 - accuracy: 0.4813 - val_loss: 2.4121 - val_accuracy: 0.4105\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.6510 - accuracy: 0.4918 - val_loss: 2.5202 - val_accuracy: 0.3981\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5599 - accuracy: 0.5258 - val_loss: 2.5331 - val_accuracy: 0.4167\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5224 - accuracy: 0.5235 - val_loss: 2.5268 - val_accuracy: 0.4012\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4433 - accuracy: 0.5516 - val_loss: 2.2770 - val_accuracy: 0.4722\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4298 - accuracy: 0.5661 - val_loss: 2.2052 - val_accuracy: 0.5062\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4137 - accuracy: 0.5632 - val_loss: 2.2530 - val_accuracy: 0.5062\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.3775 - accuracy: 0.5871 - val_loss: 2.3258 - val_accuracy: 0.4877\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.3043 - accuracy: 0.5945 - val_loss: 2.4890 - val_accuracy: 0.4568\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.2707 - accuracy: 0.5998 - val_loss: 2.3506 - val_accuracy: 0.5216\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.2254 - accuracy: 0.6173 - val_loss: 2.2473 - val_accuracy: 0.4846\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.2376 - accuracy: 0.6308 - val_loss: 2.4927 - val_accuracy: 0.4383\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.2265 - accuracy: 0.6252 - val_loss: 2.3636 - val_accuracy: 0.4969\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.1474 - accuracy: 0.6379 - val_loss: 2.3344 - val_accuracy: 0.5432\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.1318 - accuracy: 0.6506 - val_loss: 2.1440 - val_accuracy: 0.4938\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.0963 - accuracy: 0.6584 - val_loss: 2.2990 - val_accuracy: 0.5278\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.0633 - accuracy: 0.6685 - val_loss: 2.3200 - val_accuracy: 0.5247\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.0858 - accuracy: 0.6584 - val_loss: 2.3579 - val_accuracy: 0.5525\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.0321 - accuracy: 0.6637 - val_loss: 2.5023 - val_accuracy: 0.5031\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.0071 - accuracy: 0.6898 - val_loss: 2.2249 - val_accuracy: 0.5617\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.9970 - accuracy: 0.6868 - val_loss: 2.4561 - val_accuracy: 0.5401\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.0011 - accuracy: 0.6846 - val_loss: 2.2555 - val_accuracy: 0.5586\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.9676 - accuracy: 0.6999 - val_loss: 2.3252 - val_accuracy: 0.5772\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.9652 - accuracy: 0.6984 - val_loss: 2.2783 - val_accuracy: 0.5309\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.9286 - accuracy: 0.7044 - val_loss: 2.4668 - val_accuracy: 0.5340\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.9171 - accuracy: 0.7059 - val_loss: 2.6330 - val_accuracy: 0.5216\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.9405 - accuracy: 0.7010 - val_loss: 2.4023 - val_accuracy: 0.5463\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.9014 - accuracy: 0.7152 - val_loss: 2.1885 - val_accuracy: 0.5309\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.9118 - accuracy: 0.7141 - val_loss: 2.2189 - val_accuracy: 0.5833\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8529 - accuracy: 0.7250 - val_loss: 2.4980 - val_accuracy: 0.5370\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8713 - accuracy: 0.7347 - val_loss: 2.2916 - val_accuracy: 0.5432\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.9023 - accuracy: 0.7138 - val_loss: 2.3840 - val_accuracy: 0.5401\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8366 - accuracy: 0.7354 - val_loss: 2.2724 - val_accuracy: 0.5988\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8498 - accuracy: 0.7280 - val_loss: 2.2587 - val_accuracy: 0.5340\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8365 - accuracy: 0.7395 - val_loss: 2.1622 - val_accuracy: 0.5926\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.8236 - accuracy: 0.7321 - val_loss: 2.1906 - val_accuracy: 0.6049\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8206 - accuracy: 0.7429 - val_loss: 2.1784 - val_accuracy: 0.6080\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7860 - accuracy: 0.7485 - val_loss: 2.4267 - val_accuracy: 0.5556\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7735 - accuracy: 0.7530 - val_loss: 2.5939 - val_accuracy: 0.5710\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7902 - accuracy: 0.7470 - val_loss: 2.5393 - val_accuracy: 0.5432\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.7549 - accuracy: 0.7642 - val_loss: 2.4519 - val_accuracy: 0.5833\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7596 - accuracy: 0.7541 - val_loss: 2.7369 - val_accuracy: 0.5370\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.7369 - accuracy: 0.7664 - val_loss: 2.5344 - val_accuracy: 0.5741\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7423 - accuracy: 0.7590 - val_loss: 2.9337 - val_accuracy: 0.5278\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7542 - accuracy: 0.7616 - val_loss: 3.1673 - val_accuracy: 0.4815\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.7518 - accuracy: 0.7616 - val_loss: 3.1181 - val_accuracy: 0.5185\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7073 - accuracy: 0.7732 - val_loss: 3.0228 - val_accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7723 - accuracy: 0.7496 - val_loss: 2.8489 - val_accuracy: 0.5432\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7118 - accuracy: 0.7717 - val_loss: 2.4877 - val_accuracy: 0.6049\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6768 - accuracy: 0.7930 - val_loss: 2.6278 - val_accuracy: 0.5772\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6734 - accuracy: 0.7799 - val_loss: 2.9773 - val_accuracy: 0.5340\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6892 - accuracy: 0.7762 - val_loss: 2.4302 - val_accuracy: 0.5957\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6895 - accuracy: 0.7870 - val_loss: 3.0719 - val_accuracy: 0.5494\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6893 - accuracy: 0.7777 - val_loss: 2.8473 - val_accuracy: 0.5710\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6827 - accuracy: 0.7829 - val_loss: 3.0668 - val_accuracy: 0.5278\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6747 - accuracy: 0.7851 - val_loss: 2.9819 - val_accuracy: 0.5525\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6988 - accuracy: 0.7836 - val_loss: 2.5891 - val_accuracy: 0.5802\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training the best model...\")\n",
    "model = tuner.hypermodel.build(bestHP)\n",
    "History = model.fit(x=Xtrain, y=Ytrain,validation_data= (Xval,Yval), batch_size=96,epochs=200, callbacks=[es], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b216d088",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T07:49:24.026686Z",
     "start_time": "2023-08-12T07:49:23.871296Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step - loss: 2.1784 - accuracy: 0.6080\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(Xval, Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "62c00dff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T07:03:58.304580Z",
     "start_time": "2023-08-12T07:03:57.763619Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6d5252b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T07:05:09.876776Z",
     "start_time": "2023-08-12T07:05:09.872994Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(res[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1ff2531b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T07:05:06.572458Z",
     "start_time": "2023-08-12T07:05:06.568274Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Yval[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9f244553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T07:05:12.700230Z",
     "start_time": "2023-08-12T07:05:12.532743Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step - loss: 6.4985 - categorical_accuracy: 0.5833\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(Xval, Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65393248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T15:43:53.187896Z",
     "start_time": "2023-08-13T15:43:51.105530Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6797/979066352.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import Hyperband\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SpatialDropout1D\n",
    "from keras_tuner import HyperModel\n",
    "from kerastuner.tuners import Hyperband\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        act_function = hp.Choice('dense_activation',values=['elu','selu','gelu','LeakyReLU'],default='selu')\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=hp.Choice('num_filters_1',values=[25,50, 100,150],default=50,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(filters=hp.Choice('num_filters_2',values=[25,50, 100,150],default=50,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(filters=hp.Choice('num_filters_3',values=[25,50, 100,150],default=50,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_1',min_value=0.0,max_value=0.7,default=0.25,step=0.05,)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=hp.Int('units',min_value=20,max_value=120,step=20,default=40),activation=act_function))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_2',min_value=0.0,max_value=0.7,default=0.25,step=0.05,)))\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(Lion(hp.Float('learning_rate',min_value=1e-5,max_value=1e-3,sampling='LOG',default=1e-5)),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "hypermodel = CNNHyperModel(input_shape=(130,126), num_classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0f6dc6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T15:44:01.212310Z",
     "start_time": "2023-08-13T15:43:57.760164Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 16:44:00.341249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1739 MB memory:  -> device: 0, name: NVIDIA GeForce MX250, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "HYPERBAND_MAX_EPOCHS = 100\n",
    "#MAX_TRIALS = 20\n",
    "EXECUTION_PER_TRIAL = 2\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    max_epochs=HYPERBAND_MAX_EPOCHS,\n",
    "    objective='val_loss',\n",
    "    seed=10,\n",
    "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "    directory='hyperband',\n",
    "    project_name='test3',\n",
    "    overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a39fc80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T15:44:26.240083Z",
     "start_time": "2023-08-13T15:44:26.236469Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 8\n",
      "dense_activation (Choice)\n",
      "{'default': 'selu', 'conditions': [], 'values': ['elu', 'selu', 'gelu', 'LeakyReLU'], 'ordered': False}\n",
      "num_filters_1 (Choice)\n",
      "{'default': 50, 'conditions': [], 'values': [25, 50, 100, 150], 'ordered': True}\n",
      "num_filters_2 (Choice)\n",
      "{'default': 50, 'conditions': [], 'values': [25, 50, 100, 150], 'ordered': True}\n",
      "num_filters_3 (Choice)\n",
      "{'default': 50, 'conditions': [], 'values': [25, 50, 100, 150], 'ordered': True}\n",
      "dropout_1 (Float)\n",
      "{'default': 0.25, 'conditions': [], 'min_value': 0.0, 'max_value': 0.7, 'step': 0.05, 'sampling': 'linear'}\n",
      "units (Int)\n",
      "{'default': 40, 'conditions': [], 'min_value': 20, 'max_value': 120, 'step': 20, 'sampling': 'linear'}\n",
      "dropout_2 (Float)\n",
      "{'default': 0.25, 'conditions': [], 'min_value': 0.0, 'max_value': 0.7, 'step': 0.05, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.001, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "10efc9c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T13:12:06.798275Z",
     "start_time": "2023-08-12T09:39:30.822055Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 09m 04s]\n",
      "val_loss: 3.1169066429138184\n",
      "\n",
      "Best val_loss So Far: 1.811120629310608\n",
      "Total elapsed time: 03h 32m 27s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(Xtrain, Ytrain, epochs=1000, validation_data=(Xval,Yval),batch_size=96,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c9cc9bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T15:44:40.889495Z",
     "start_time": "2023-08-13T15:44:40.886451Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in hyperband/test3\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ddbd28bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T18:17:53.816316Z",
     "start_time": "2023-08-12T18:17:43.448035Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea1ca916",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T18:18:03.944658Z",
     "start_time": "2023-08-12T18:18:03.139478Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 22ms/step - loss: 1.8111 - accuracy: 0.5586\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = best_model.evaluate(Xval, Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e906dfeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T18:56:39.938603Z",
     "start_time": "2023-08-12T18:56:39.779767Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "res = best_model.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "08c0a27f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T18:44:24.604839Z",
     "start_time": "2023-08-12T18:44:24.602065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bestHP = tuner.get_best_hyperparameters(num_trials=2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "555d945a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T19:19:47.067327Z",
     "start_time": "2023-08-12T19:15:24.145675Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the best model...\n",
      "Epoch 1/500\n",
      "28/28 [==============================] - 2s 24ms/step - loss: 3.9340 - accuracy: 0.0194 - val_loss: 3.9039 - val_accuracy: 0.0247\n",
      "Epoch 2/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 3.9069 - accuracy: 0.0295 - val_loss: 3.8650 - val_accuracy: 0.0432\n",
      "Epoch 3/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 3.8578 - accuracy: 0.0396 - val_loss: 3.7671 - val_accuracy: 0.0617\n",
      "Epoch 4/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 3.7790 - accuracy: 0.0546 - val_loss: 3.6556 - val_accuracy: 0.0679\n",
      "Epoch 5/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 3.6996 - accuracy: 0.0534 - val_loss: 3.5803 - val_accuracy: 0.0710\n",
      "Epoch 6/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 3.5841 - accuracy: 0.0736 - val_loss: 3.4399 - val_accuracy: 0.0772\n",
      "Epoch 7/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 3.4903 - accuracy: 0.0856 - val_loss: 3.3465 - val_accuracy: 0.0957\n",
      "Epoch 8/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 3.4007 - accuracy: 0.0972 - val_loss: 3.2864 - val_accuracy: 0.1235\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 3.3146 - accuracy: 0.1147 - val_loss: 3.1659 - val_accuracy: 0.1636\n",
      "Epoch 10/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 3.1812 - accuracy: 0.1386 - val_loss: 3.0844 - val_accuracy: 0.1790\n",
      "Epoch 11/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 3.0813 - accuracy: 0.1570 - val_loss: 3.0441 - val_accuracy: 0.1852\n",
      "Epoch 12/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 3.0154 - accuracy: 0.1719 - val_loss: 2.9212 - val_accuracy: 0.2068\n",
      "Epoch 13/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.8991 - accuracy: 0.1932 - val_loss: 2.8791 - val_accuracy: 0.2191\n",
      "Epoch 14/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 2.8380 - accuracy: 0.1966 - val_loss: 2.8293 - val_accuracy: 0.2315\n",
      "Epoch 15/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.7524 - accuracy: 0.2138 - val_loss: 2.7479 - val_accuracy: 0.2407\n",
      "Epoch 16/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.6858 - accuracy: 0.2235 - val_loss: 2.6849 - val_accuracy: 0.2531\n",
      "Epoch 17/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.5980 - accuracy: 0.2519 - val_loss: 2.6342 - val_accuracy: 0.2562\n",
      "Epoch 18/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.5503 - accuracy: 0.2556 - val_loss: 2.6354 - val_accuracy: 0.2654\n",
      "Epoch 19/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.4657 - accuracy: 0.2735 - val_loss: 2.5597 - val_accuracy: 0.2685\n",
      "Epoch 20/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.4247 - accuracy: 0.2855 - val_loss: 2.5080 - val_accuracy: 0.3025\n",
      "Epoch 21/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.3760 - accuracy: 0.2933 - val_loss: 2.5189 - val_accuracy: 0.2809\n",
      "Epoch 22/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.2904 - accuracy: 0.3064 - val_loss: 2.4090 - val_accuracy: 0.3148\n",
      "Epoch 23/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 2.2755 - accuracy: 0.3117 - val_loss: 2.3385 - val_accuracy: 0.3333\n",
      "Epoch 24/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.2390 - accuracy: 0.3345 - val_loss: 2.3986 - val_accuracy: 0.2963\n",
      "Epoch 25/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.1785 - accuracy: 0.3408 - val_loss: 2.3714 - val_accuracy: 0.3241\n",
      "Epoch 26/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.1480 - accuracy: 0.3520 - val_loss: 2.3874 - val_accuracy: 0.3549\n",
      "Epoch 27/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.1052 - accuracy: 0.3602 - val_loss: 2.3278 - val_accuracy: 0.3488\n",
      "Epoch 28/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.0610 - accuracy: 0.3640 - val_loss: 2.3445 - val_accuracy: 0.3704\n",
      "Epoch 29/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.0656 - accuracy: 0.3681 - val_loss: 2.2865 - val_accuracy: 0.3796\n",
      "Epoch 30/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.0102 - accuracy: 0.3763 - val_loss: 2.1519 - val_accuracy: 0.4167\n",
      "Epoch 31/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.9674 - accuracy: 0.4002 - val_loss: 2.1828 - val_accuracy: 0.3735\n",
      "Epoch 32/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.9779 - accuracy: 0.3827 - val_loss: 2.2120 - val_accuracy: 0.4321\n",
      "Epoch 33/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.9611 - accuracy: 0.4070 - val_loss: 2.2736 - val_accuracy: 0.3951\n",
      "Epoch 34/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.9022 - accuracy: 0.4256 - val_loss: 2.0891 - val_accuracy: 0.4537\n",
      "Epoch 35/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.9179 - accuracy: 0.4025 - val_loss: 2.2256 - val_accuracy: 0.3858\n",
      "Epoch 36/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.8613 - accuracy: 0.4283 - val_loss: 2.3044 - val_accuracy: 0.3488\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.8500 - accuracy: 0.4365 - val_loss: 2.0620 - val_accuracy: 0.4259\n",
      "Epoch 38/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.8185 - accuracy: 0.4350 - val_loss: 2.1107 - val_accuracy: 0.4383\n",
      "Epoch 39/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.8198 - accuracy: 0.4443 - val_loss: 1.9336 - val_accuracy: 0.4722\n",
      "Epoch 40/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.7888 - accuracy: 0.4428 - val_loss: 2.1685 - val_accuracy: 0.4259\n",
      "Epoch 41/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.7842 - accuracy: 0.4492 - val_loss: 2.3019 - val_accuracy: 0.4043\n",
      "Epoch 42/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.7398 - accuracy: 0.4540 - val_loss: 2.3972 - val_accuracy: 0.3796\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.7192 - accuracy: 0.4697 - val_loss: 2.1679 - val_accuracy: 0.4352\n",
      "Epoch 44/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.6942 - accuracy: 0.4865 - val_loss: 2.0842 - val_accuracy: 0.4475\n",
      "Epoch 45/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.7093 - accuracy: 0.4705 - val_loss: 1.9675 - val_accuracy: 0.4877\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.6369 - accuracy: 0.4970 - val_loss: 1.9624 - val_accuracy: 0.5062\n",
      "Epoch 47/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.6644 - accuracy: 0.4907 - val_loss: 2.2930 - val_accuracy: 0.4136\n",
      "Epoch 48/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.6083 - accuracy: 0.4813 - val_loss: 1.9709 - val_accuracy: 0.4969\n",
      "Epoch 49/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.6042 - accuracy: 0.4966 - val_loss: 1.9445 - val_accuracy: 0.5031\n",
      "Epoch 50/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.5666 - accuracy: 0.5138 - val_loss: 2.0696 - val_accuracy: 0.4599\n",
      "Epoch 51/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.5708 - accuracy: 0.5235 - val_loss: 1.9679 - val_accuracy: 0.4877\n",
      "Epoch 52/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.5498 - accuracy: 0.5191 - val_loss: 2.1243 - val_accuracy: 0.4568\n",
      "Epoch 53/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.5391 - accuracy: 0.5220 - val_loss: 2.0682 - val_accuracy: 0.4877\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.5452 - accuracy: 0.5179 - val_loss: 1.9368 - val_accuracy: 0.5216\n",
      "Epoch 55/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.5367 - accuracy: 0.5202 - val_loss: 1.9778 - val_accuracy: 0.4938\n",
      "Epoch 56/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.4786 - accuracy: 0.5348 - val_loss: 1.8463 - val_accuracy: 0.4969\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.4804 - accuracy: 0.5291 - val_loss: 1.8833 - val_accuracy: 0.5093\n",
      "Epoch 58/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.4373 - accuracy: 0.5389 - val_loss: 1.9200 - val_accuracy: 0.5031\n",
      "Epoch 59/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.4706 - accuracy: 0.5377 - val_loss: 1.9691 - val_accuracy: 0.5031\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.4475 - accuracy: 0.5433 - val_loss: 1.9349 - val_accuracy: 0.5062\n",
      "Epoch 61/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.4169 - accuracy: 0.5392 - val_loss: 1.9055 - val_accuracy: 0.5463\n",
      "Epoch 62/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.3874 - accuracy: 0.5721 - val_loss: 1.7367 - val_accuracy: 0.5957\n",
      "Epoch 63/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.4373 - accuracy: 0.5433 - val_loss: 2.0099 - val_accuracy: 0.5062\n",
      "Epoch 64/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.3603 - accuracy: 0.5624 - val_loss: 1.8422 - val_accuracy: 0.5432\n",
      "Epoch 65/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.3785 - accuracy: 0.5650 - val_loss: 1.7090 - val_accuracy: 0.5957\n",
      "Epoch 66/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.3578 - accuracy: 0.5710 - val_loss: 1.9111 - val_accuracy: 0.4815\n",
      "Epoch 67/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.3249 - accuracy: 0.5852 - val_loss: 1.8616 - val_accuracy: 0.5401\n",
      "Epoch 68/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.3822 - accuracy: 0.5714 - val_loss: 1.6852 - val_accuracy: 0.5772\n",
      "Epoch 69/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.3307 - accuracy: 0.5766 - val_loss: 1.8001 - val_accuracy: 0.5309\n",
      "Epoch 70/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.3106 - accuracy: 0.5886 - val_loss: 1.8329 - val_accuracy: 0.5309\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.2748 - accuracy: 0.5901 - val_loss: 1.9126 - val_accuracy: 0.5247\n",
      "Epoch 72/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.3083 - accuracy: 0.5669 - val_loss: 1.8493 - val_accuracy: 0.5957\n",
      "Epoch 73/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.3065 - accuracy: 0.5949 - val_loss: 1.6959 - val_accuracy: 0.6049\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.2780 - accuracy: 0.5942 - val_loss: 1.6179 - val_accuracy: 0.6080\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.2387 - accuracy: 0.6143 - val_loss: 1.8715 - val_accuracy: 0.5401\n",
      "Epoch 76/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.2463 - accuracy: 0.6054 - val_loss: 1.6800 - val_accuracy: 0.5833\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.2536 - accuracy: 0.6050 - val_loss: 1.5808 - val_accuracy: 0.6019\n",
      "Epoch 78/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.2432 - accuracy: 0.6050 - val_loss: 1.8057 - val_accuracy: 0.5586\n",
      "Epoch 79/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.2136 - accuracy: 0.6151 - val_loss: 1.7883 - val_accuracy: 0.5802\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.2460 - accuracy: 0.6136 - val_loss: 1.8286 - val_accuracy: 0.5679\n",
      "Epoch 81/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.1753 - accuracy: 0.6248 - val_loss: 1.8074 - val_accuracy: 0.5556\n",
      "Epoch 82/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.1952 - accuracy: 0.6065 - val_loss: 1.6421 - val_accuracy: 0.6327\n",
      "Epoch 83/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.2091 - accuracy: 0.6121 - val_loss: 1.6175 - val_accuracy: 0.6204\n",
      "Epoch 84/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.1592 - accuracy: 0.6185 - val_loss: 1.6995 - val_accuracy: 0.6142\n",
      "Epoch 85/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.1925 - accuracy: 0.6203 - val_loss: 1.6482 - val_accuracy: 0.6142\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.2052 - accuracy: 0.6054 - val_loss: 1.7226 - val_accuracy: 0.5895\n",
      "Epoch 87/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.1555 - accuracy: 0.6203 - val_loss: 1.7062 - val_accuracy: 0.6111\n",
      "Epoch 88/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.1937 - accuracy: 0.6203 - val_loss: 1.8023 - val_accuracy: 0.6111\n",
      "Epoch 89/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.1523 - accuracy: 0.6300 - val_loss: 1.5190 - val_accuracy: 0.6667\n",
      "Epoch 90/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.1081 - accuracy: 0.6461 - val_loss: 1.5704 - val_accuracy: 0.6358\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.1183 - accuracy: 0.6282 - val_loss: 1.6050 - val_accuracy: 0.6111\n",
      "Epoch 92/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.1570 - accuracy: 0.6431 - val_loss: 1.7725 - val_accuracy: 0.5772\n",
      "Epoch 93/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.1364 - accuracy: 0.6274 - val_loss: 1.6470 - val_accuracy: 0.6265\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.0629 - accuracy: 0.6540 - val_loss: 1.7325 - val_accuracy: 0.6049\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.1011 - accuracy: 0.6424 - val_loss: 1.7299 - val_accuracy: 0.6080\n",
      "Epoch 96/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.0708 - accuracy: 0.6480 - val_loss: 1.7679 - val_accuracy: 0.6142\n",
      "Epoch 97/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.0647 - accuracy: 0.6614 - val_loss: 1.7030 - val_accuracy: 0.6204\n",
      "Epoch 98/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.0612 - accuracy: 0.6555 - val_loss: 1.6046 - val_accuracy: 0.6543\n",
      "Epoch 99/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.0972 - accuracy: 0.6592 - val_loss: 1.7325 - val_accuracy: 0.6605\n",
      "Epoch 100/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.1132 - accuracy: 0.6379 - val_loss: 1.8982 - val_accuracy: 0.6173\n",
      "Epoch 101/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.0635 - accuracy: 0.6540 - val_loss: 1.8038 - val_accuracy: 0.6235\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.0790 - accuracy: 0.6611 - val_loss: 1.6307 - val_accuracy: 0.6327\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.0744 - accuracy: 0.6667 - val_loss: 1.6970 - val_accuracy: 0.6235\n",
      "Epoch 104/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.0725 - accuracy: 0.6502 - val_loss: 1.7691 - val_accuracy: 0.6142\n",
      "Epoch 105/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.0606 - accuracy: 0.6592 - val_loss: 1.7180 - val_accuracy: 0.6080\n",
      "Epoch 106/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.0420 - accuracy: 0.6633 - val_loss: 1.6931 - val_accuracy: 0.6512\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.0553 - accuracy: 0.6764 - val_loss: 1.6655 - val_accuracy: 0.6327\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.0472 - accuracy: 0.6689 - val_loss: 1.9532 - val_accuracy: 0.5864\n",
      "Epoch 109/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.0063 - accuracy: 0.6756 - val_loss: 1.9882 - val_accuracy: 0.5772\n",
      "Epoch 110/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.0101 - accuracy: 0.6745 - val_loss: 1.8847 - val_accuracy: 0.5802\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.0011 - accuracy: 0.6674 - val_loss: 1.8679 - val_accuracy: 0.6204\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.9911 - accuracy: 0.6779 - val_loss: 2.1654 - val_accuracy: 0.5864\n",
      "Epoch 113/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.0135 - accuracy: 0.6719 - val_loss: 1.8014 - val_accuracy: 0.6327\n",
      "Epoch 114/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9882 - accuracy: 0.6854 - val_loss: 2.5315 - val_accuracy: 0.5216\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9780 - accuracy: 0.6809 - val_loss: 1.8858 - val_accuracy: 0.6636\n",
      "Epoch 116/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.0004 - accuracy: 0.6741 - val_loss: 2.0265 - val_accuracy: 0.6173\n",
      "Epoch 117/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9997 - accuracy: 0.6846 - val_loss: 1.7123 - val_accuracy: 0.6543\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.9669 - accuracy: 0.6805 - val_loss: 1.7534 - val_accuracy: 0.6451\n",
      "Epoch 119/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9562 - accuracy: 0.6928 - val_loss: 2.0635 - val_accuracy: 0.6173\n",
      "Epoch 120/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9709 - accuracy: 0.6801 - val_loss: 1.9979 - val_accuracy: 0.5957\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9878 - accuracy: 0.6910 - val_loss: 1.9819 - val_accuracy: 0.6019\n",
      "Epoch 122/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9423 - accuracy: 0.6981 - val_loss: 1.9793 - val_accuracy: 0.6173\n",
      "Epoch 123/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9814 - accuracy: 0.6876 - val_loss: 2.0252 - val_accuracy: 0.6265\n",
      "Epoch 124/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9578 - accuracy: 0.6969 - val_loss: 1.9985 - val_accuracy: 0.6142\n",
      "Epoch 125/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9402 - accuracy: 0.7022 - val_loss: 1.9087 - val_accuracy: 0.6451\n",
      "Epoch 126/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9449 - accuracy: 0.7070 - val_loss: 1.7312 - val_accuracy: 0.6667\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9291 - accuracy: 0.7025 - val_loss: 2.0407 - val_accuracy: 0.6173\n",
      "Epoch 128/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9533 - accuracy: 0.7022 - val_loss: 1.9823 - val_accuracy: 0.6574\n",
      "Epoch 129/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.9212 - accuracy: 0.6962 - val_loss: 1.9877 - val_accuracy: 0.6358\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9138 - accuracy: 0.7010 - val_loss: 1.9012 - val_accuracy: 0.6543\n",
      "Epoch 131/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9121 - accuracy: 0.7067 - val_loss: 1.9920 - val_accuracy: 0.6574\n",
      "Epoch 132/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9044 - accuracy: 0.7070 - val_loss: 1.7798 - val_accuracy: 0.6698\n",
      "Epoch 133/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9037 - accuracy: 0.7119 - val_loss: 1.8392 - val_accuracy: 0.6389\n",
      "Epoch 134/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8879 - accuracy: 0.7123 - val_loss: 1.7375 - val_accuracy: 0.6605\n",
      "Epoch 135/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8952 - accuracy: 0.7007 - val_loss: 1.9872 - val_accuracy: 0.5957\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.8753 - accuracy: 0.7220 - val_loss: 1.8825 - val_accuracy: 0.6389\n",
      "Epoch 137/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8887 - accuracy: 0.7134 - val_loss: 1.8710 - val_accuracy: 0.6389\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8756 - accuracy: 0.7164 - val_loss: 2.2942 - val_accuracy: 0.5586\n",
      "Epoch 139/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.9246 - accuracy: 0.6925 - val_loss: 2.0467 - val_accuracy: 0.6080\n",
      "Epoch 140/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8808 - accuracy: 0.7085 - val_loss: 1.9324 - val_accuracy: 0.6481\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8789 - accuracy: 0.7175 - val_loss: 2.0823 - val_accuracy: 0.6142\n",
      "Epoch 142/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8780 - accuracy: 0.7246 - val_loss: 2.2208 - val_accuracy: 0.5926\n",
      "Epoch 143/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8695 - accuracy: 0.7141 - val_loss: 1.9605 - val_accuracy: 0.6204\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8674 - accuracy: 0.7227 - val_loss: 1.8838 - val_accuracy: 0.6451\n",
      "Epoch 145/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.8218 - accuracy: 0.7242 - val_loss: 2.2436 - val_accuracy: 0.6019\n",
      "Epoch 146/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8534 - accuracy: 0.7186 - val_loss: 2.0799 - val_accuracy: 0.6605\n",
      "Epoch 147/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8868 - accuracy: 0.7167 - val_loss: 1.8979 - val_accuracy: 0.6451\n",
      "Epoch 148/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8374 - accuracy: 0.7294 - val_loss: 1.8252 - val_accuracy: 0.6636\n",
      "Epoch 149/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8844 - accuracy: 0.7164 - val_loss: 1.6152 - val_accuracy: 0.7099\n",
      "Epoch 150/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8476 - accuracy: 0.7190 - val_loss: 2.0534 - val_accuracy: 0.6327\n",
      "Epoch 151/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8950 - accuracy: 0.7067 - val_loss: 1.8590 - val_accuracy: 0.6574\n",
      "Epoch 152/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.8378 - accuracy: 0.7268 - val_loss: 2.0039 - val_accuracy: 0.6265\n",
      "Epoch 153/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8674 - accuracy: 0.7186 - val_loss: 1.9876 - val_accuracy: 0.6759\n",
      "Epoch 154/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.8183 - accuracy: 0.7317 - val_loss: 1.9627 - val_accuracy: 0.6543\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8659 - accuracy: 0.7100 - val_loss: 1.9019 - val_accuracy: 0.6790\n",
      "Epoch 156/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.8287 - accuracy: 0.7343 - val_loss: 1.9606 - val_accuracy: 0.6790\n",
      "Epoch 157/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8762 - accuracy: 0.7138 - val_loss: 2.1300 - val_accuracy: 0.6327\n",
      "Epoch 158/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8214 - accuracy: 0.7291 - val_loss: 1.9197 - val_accuracy: 0.6883\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8220 - accuracy: 0.7369 - val_loss: 2.1644 - val_accuracy: 0.6481\n",
      "Epoch 160/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7986 - accuracy: 0.7365 - val_loss: 2.0627 - val_accuracy: 0.6327\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7687 - accuracy: 0.7384 - val_loss: 1.9450 - val_accuracy: 0.6883\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8102 - accuracy: 0.7343 - val_loss: 1.9917 - val_accuracy: 0.6667\n",
      "Epoch 163/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.8059 - accuracy: 0.7399 - val_loss: 1.9527 - val_accuracy: 0.6975\n",
      "Epoch 164/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8488 - accuracy: 0.7156 - val_loss: 1.9095 - val_accuracy: 0.6852\n",
      "Epoch 165/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.8036 - accuracy: 0.7302 - val_loss: 2.1585 - val_accuracy: 0.6605\n",
      "Epoch 166/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7724 - accuracy: 0.7440 - val_loss: 1.9293 - val_accuracy: 0.6698\n",
      "Epoch 167/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.8159 - accuracy: 0.7276 - val_loss: 2.1950 - val_accuracy: 0.6142\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8229 - accuracy: 0.7373 - val_loss: 1.8149 - val_accuracy: 0.6975\n",
      "Epoch 169/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7735 - accuracy: 0.7436 - val_loss: 1.9242 - val_accuracy: 0.6728\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7785 - accuracy: 0.7414 - val_loss: 1.7913 - val_accuracy: 0.6975\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.8310 - accuracy: 0.7317 - val_loss: 1.9546 - val_accuracy: 0.6759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7722 - accuracy: 0.7474 - val_loss: 1.9057 - val_accuracy: 0.7099\n",
      "Epoch 173/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8160 - accuracy: 0.7354 - val_loss: 1.8212 - val_accuracy: 0.7099\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7991 - accuracy: 0.7339 - val_loss: 1.8918 - val_accuracy: 0.6759\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7624 - accuracy: 0.7470 - val_loss: 1.8620 - val_accuracy: 0.6728\n",
      "Epoch 176/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7808 - accuracy: 0.7283 - val_loss: 1.7157 - val_accuracy: 0.7068\n",
      "Epoch 177/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7678 - accuracy: 0.7440 - val_loss: 1.8266 - val_accuracy: 0.6914\n",
      "Epoch 178/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.8177 - accuracy: 0.7347 - val_loss: 1.7192 - val_accuracy: 0.6636\n",
      "Epoch 179/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7792 - accuracy: 0.7504 - val_loss: 1.6642 - val_accuracy: 0.6883\n",
      "Epoch 180/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7970 - accuracy: 0.7388 - val_loss: 1.7713 - val_accuracy: 0.6914\n",
      "Epoch 181/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7716 - accuracy: 0.7403 - val_loss: 1.8583 - val_accuracy: 0.6790\n",
      "Epoch 182/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7439 - accuracy: 0.7646 - val_loss: 1.8277 - val_accuracy: 0.6883\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7454 - accuracy: 0.7616 - val_loss: 1.9831 - val_accuracy: 0.6883\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7887 - accuracy: 0.7478 - val_loss: 1.9298 - val_accuracy: 0.7006\n",
      "Epoch 185/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7604 - accuracy: 0.7571 - val_loss: 2.0494 - val_accuracy: 0.6667\n",
      "Epoch 186/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7673 - accuracy: 0.7616 - val_loss: 2.1683 - val_accuracy: 0.6698\n",
      "Epoch 187/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7706 - accuracy: 0.7478 - val_loss: 2.0751 - val_accuracy: 0.6667\n",
      "Epoch 188/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7669 - accuracy: 0.7470 - val_loss: 2.0847 - val_accuracy: 0.6111\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7537 - accuracy: 0.7500 - val_loss: 1.9511 - val_accuracy: 0.6975\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7890 - accuracy: 0.7545 - val_loss: 1.8688 - val_accuracy: 0.7191\n",
      "Epoch 191/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7287 - accuracy: 0.7635 - val_loss: 1.9342 - val_accuracy: 0.6574\n",
      "Epoch 192/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7752 - accuracy: 0.7422 - val_loss: 2.0567 - val_accuracy: 0.6728\n",
      "Epoch 193/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7453 - accuracy: 0.7448 - val_loss: 1.8567 - val_accuracy: 0.7130\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7446 - accuracy: 0.7507 - val_loss: 2.1466 - val_accuracy: 0.6389\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7530 - accuracy: 0.7478 - val_loss: 1.9187 - val_accuracy: 0.6944\n",
      "Epoch 196/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7632 - accuracy: 0.7571 - val_loss: 1.8123 - val_accuracy: 0.7037\n",
      "Epoch 197/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7304 - accuracy: 0.7608 - val_loss: 1.9147 - val_accuracy: 0.6914\n",
      "Epoch 198/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.7646 - accuracy: 0.7552 - val_loss: 1.9767 - val_accuracy: 0.6728\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7334 - accuracy: 0.7552 - val_loss: 1.9756 - val_accuracy: 0.6944\n",
      "Epoch 200/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7624 - accuracy: 0.7489 - val_loss: 1.8318 - val_accuracy: 0.7222\n",
      "Epoch 201/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7713 - accuracy: 0.7556 - val_loss: 1.9415 - val_accuracy: 0.6852\n",
      "Epoch 202/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7334 - accuracy: 0.7683 - val_loss: 2.0819 - val_accuracy: 0.6543\n",
      "Epoch 203/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7534 - accuracy: 0.7504 - val_loss: 2.1292 - val_accuracy: 0.6852\n",
      "Epoch 204/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7484 - accuracy: 0.7571 - val_loss: 2.3220 - val_accuracy: 0.6451\n",
      "Epoch 205/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7249 - accuracy: 0.7694 - val_loss: 2.2495 - val_accuracy: 0.6605\n",
      "Epoch 206/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7564 - accuracy: 0.7631 - val_loss: 2.2051 - val_accuracy: 0.6451\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7410 - accuracy: 0.7552 - val_loss: 2.1487 - val_accuracy: 0.6790\n",
      "Epoch 208/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7313 - accuracy: 0.7552 - val_loss: 2.1900 - val_accuracy: 0.6636\n",
      "Epoch 209/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7309 - accuracy: 0.7672 - val_loss: 2.2600 - val_accuracy: 0.6574\n",
      "Epoch 210/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6825 - accuracy: 0.7698 - val_loss: 2.1053 - val_accuracy: 0.6698\n",
      "Epoch 211/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7373 - accuracy: 0.7616 - val_loss: 2.2877 - val_accuracy: 0.6080\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7390 - accuracy: 0.7676 - val_loss: 2.1040 - val_accuracy: 0.6821\n",
      "Epoch 213/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.6982 - accuracy: 0.7799 - val_loss: 2.1350 - val_accuracy: 0.7006\n",
      "Epoch 214/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7006 - accuracy: 0.7657 - val_loss: 2.6407 - val_accuracy: 0.5772\n",
      "Epoch 215/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7240 - accuracy: 0.7668 - val_loss: 2.3086 - val_accuracy: 0.6975\n",
      "Epoch 216/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7295 - accuracy: 0.7657 - val_loss: 2.2674 - val_accuracy: 0.6852\n",
      "Epoch 217/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.6966 - accuracy: 0.7780 - val_loss: 2.3896 - val_accuracy: 0.6512\n",
      "Epoch 218/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7192 - accuracy: 0.7653 - val_loss: 2.2347 - val_accuracy: 0.6790\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.6906 - accuracy: 0.7758 - val_loss: 2.2642 - val_accuracy: 0.6451\n",
      "Epoch 220/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.6920 - accuracy: 0.7728 - val_loss: 2.2590 - val_accuracy: 0.6389\n",
      "Epoch 221/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7217 - accuracy: 0.7642 - val_loss: 2.0142 - val_accuracy: 0.6790\n",
      "Epoch 222/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7005 - accuracy: 0.7803 - val_loss: 2.3059 - val_accuracy: 0.6358\n",
      "Epoch 223/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6948 - accuracy: 0.7791 - val_loss: 2.0047 - val_accuracy: 0.7006\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.6838 - accuracy: 0.7698 - val_loss: 2.2386 - val_accuracy: 0.6636\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7212 - accuracy: 0.7627 - val_loss: 1.9612 - val_accuracy: 0.7315\n",
      "Epoch 226/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.6549 - accuracy: 0.7825 - val_loss: 2.1521 - val_accuracy: 0.6944\n",
      "Epoch 227/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.6657 - accuracy: 0.7877 - val_loss: 2.2184 - val_accuracy: 0.6759\n",
      "Epoch 228/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.6799 - accuracy: 0.7694 - val_loss: 2.0022 - val_accuracy: 0.7068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.6798 - accuracy: 0.7788 - val_loss: 2.3628 - val_accuracy: 0.6327\n",
      "Epoch 230/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6414 - accuracy: 0.7806 - val_loss: 2.0518 - val_accuracy: 0.6975\n",
      "Epoch 231/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7028 - accuracy: 0.7777 - val_loss: 1.9602 - val_accuracy: 0.7006\n",
      "Epoch 232/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7119 - accuracy: 0.7679 - val_loss: 2.0242 - val_accuracy: 0.7191\n",
      "Epoch 233/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7203 - accuracy: 0.7623 - val_loss: 2.3282 - val_accuracy: 0.6296\n",
      "Epoch 234/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7091 - accuracy: 0.7750 - val_loss: 2.2333 - val_accuracy: 0.6574\n",
      "Epoch 235/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7208 - accuracy: 0.7597 - val_loss: 2.1238 - val_accuracy: 0.6914\n",
      "Epoch 236/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.6917 - accuracy: 0.7724 - val_loss: 2.0901 - val_accuracy: 0.6975\n",
      "Epoch 237/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7014 - accuracy: 0.7683 - val_loss: 1.9995 - val_accuracy: 0.7284\n",
      "Epoch 238/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6761 - accuracy: 0.7791 - val_loss: 2.0732 - val_accuracy: 0.7130\n",
      "Epoch 239/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7026 - accuracy: 0.7810 - val_loss: 2.0585 - val_accuracy: 0.7099\n",
      "Epoch 240/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6707 - accuracy: 0.7799 - val_loss: 2.2047 - val_accuracy: 0.6574\n",
      "Epoch 241/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6909 - accuracy: 0.7664 - val_loss: 2.4299 - val_accuracy: 0.6235\n",
      "Epoch 242/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6944 - accuracy: 0.7728 - val_loss: 2.1598 - val_accuracy: 0.6852\n",
      "Epoch 243/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7111 - accuracy: 0.7702 - val_loss: 2.2362 - val_accuracy: 0.6821\n",
      "Epoch 244/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7027 - accuracy: 0.7769 - val_loss: 2.3224 - val_accuracy: 0.6296\n",
      "Epoch 245/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7054 - accuracy: 0.7657 - val_loss: 2.3386 - val_accuracy: 0.6265\n",
      "Epoch 246/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6327 - accuracy: 0.7821 - val_loss: 2.1943 - val_accuracy: 0.6543\n",
      "Epoch 247/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6485 - accuracy: 0.7806 - val_loss: 2.0651 - val_accuracy: 0.7006\n",
      "Epoch 248/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6810 - accuracy: 0.7866 - val_loss: 2.2852 - val_accuracy: 0.6790\n",
      "Epoch 249/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7040 - accuracy: 0.7795 - val_loss: 2.1257 - val_accuracy: 0.6543\n",
      "Epoch 250/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7058 - accuracy: 0.7679 - val_loss: 2.0696 - val_accuracy: 0.6883\n",
      "Epoch 251/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6477 - accuracy: 0.7747 - val_loss: 2.0732 - val_accuracy: 0.6883\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.6595 - accuracy: 0.7821 - val_loss: 2.3776 - val_accuracy: 0.6451\n",
      "Epoch 253/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6462 - accuracy: 0.7859 - val_loss: 2.2638 - val_accuracy: 0.7037\n",
      "Epoch 254/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.7123 - accuracy: 0.7743 - val_loss: 2.2137 - val_accuracy: 0.7006\n",
      "Epoch 255/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6417 - accuracy: 0.7930 - val_loss: 2.1466 - val_accuracy: 0.6728\n",
      "Epoch 256/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6748 - accuracy: 0.7810 - val_loss: 1.9044 - val_accuracy: 0.7068\n",
      "Epoch 257/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.6755 - accuracy: 0.7803 - val_loss: 2.2266 - val_accuracy: 0.6883\n",
      "Epoch 258/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6711 - accuracy: 0.7859 - val_loss: 2.3104 - val_accuracy: 0.6883\n",
      "Epoch 259/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.7129 - accuracy: 0.7679 - val_loss: 2.2660 - val_accuracy: 0.6605\n",
      "Epoch 260/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6705 - accuracy: 0.7777 - val_loss: 2.1151 - val_accuracy: 0.6667\n",
      "Epoch 261/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6670 - accuracy: 0.7732 - val_loss: 2.2075 - val_accuracy: 0.6759\n",
      "Epoch 262/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.6761 - accuracy: 0.7747 - val_loss: 2.1009 - val_accuracy: 0.7099\n",
      "Epoch 263/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6384 - accuracy: 0.7874 - val_loss: 1.9969 - val_accuracy: 0.7099\n",
      "Epoch 264/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6396 - accuracy: 0.7874 - val_loss: 2.2257 - val_accuracy: 0.7160\n",
      "Epoch 265/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6405 - accuracy: 0.7851 - val_loss: 2.2406 - val_accuracy: 0.6667\n",
      "Epoch 266/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6786 - accuracy: 0.7724 - val_loss: 2.1273 - val_accuracy: 0.7037\n",
      "Epoch 267/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6268 - accuracy: 0.7986 - val_loss: 2.4235 - val_accuracy: 0.6605\n",
      "Epoch 268/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6700 - accuracy: 0.7810 - val_loss: 2.2364 - val_accuracy: 0.6944\n",
      "Epoch 269/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.6435 - accuracy: 0.7758 - val_loss: 2.2953 - val_accuracy: 0.6821\n",
      "Epoch 270/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6986 - accuracy: 0.7758 - val_loss: 2.3224 - val_accuracy: 0.6883\n",
      "Epoch 271/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6665 - accuracy: 0.7825 - val_loss: 2.4348 - val_accuracy: 0.6574\n",
      "Epoch 272/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6672 - accuracy: 0.7829 - val_loss: 2.4635 - val_accuracy: 0.6451\n",
      "Epoch 273/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6752 - accuracy: 0.7743 - val_loss: 2.2453 - val_accuracy: 0.6481\n",
      "Epoch 274/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6286 - accuracy: 0.7900 - val_loss: 2.4927 - val_accuracy: 0.6111\n",
      "Epoch 275/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6299 - accuracy: 0.7874 - val_loss: 2.4186 - val_accuracy: 0.6574\n",
      "Epoch 276/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6483 - accuracy: 0.7915 - val_loss: 2.3708 - val_accuracy: 0.6605\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6818 - accuracy: 0.7795 - val_loss: 2.3404 - val_accuracy: 0.6790\n",
      "Epoch 278/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.6232 - accuracy: 0.7982 - val_loss: 2.3410 - val_accuracy: 0.6914\n",
      "Epoch 279/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6059 - accuracy: 0.7862 - val_loss: 2.3779 - val_accuracy: 0.7006\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6632 - accuracy: 0.7821 - val_loss: 2.2251 - val_accuracy: 0.7438\n",
      "Epoch 281/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6521 - accuracy: 0.7892 - val_loss: 2.1925 - val_accuracy: 0.7222\n",
      "Epoch 282/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6389 - accuracy: 0.7997 - val_loss: 2.1358 - val_accuracy: 0.7006\n",
      "Epoch 283/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6577 - accuracy: 0.7885 - val_loss: 2.3150 - val_accuracy: 0.7284\n",
      "Epoch 284/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6478 - accuracy: 0.7926 - val_loss: 2.2646 - val_accuracy: 0.7222\n",
      "Epoch 285/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6289 - accuracy: 0.7982 - val_loss: 2.6463 - val_accuracy: 0.6759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6236 - accuracy: 0.7941 - val_loss: 2.1563 - val_accuracy: 0.6790\n",
      "Epoch 287/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6367 - accuracy: 0.7933 - val_loss: 2.3089 - val_accuracy: 0.6790\n",
      "Epoch 288/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6302 - accuracy: 0.7948 - val_loss: 2.3395 - val_accuracy: 0.6914\n",
      "Epoch 289/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6355 - accuracy: 0.7862 - val_loss: 2.0399 - val_accuracy: 0.7160\n",
      "Epoch 290/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6529 - accuracy: 0.7900 - val_loss: 2.0723 - val_accuracy: 0.7222\n",
      "Epoch 291/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6512 - accuracy: 0.7889 - val_loss: 2.3631 - val_accuracy: 0.6636\n",
      "Epoch 292/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6396 - accuracy: 0.7877 - val_loss: 2.3959 - val_accuracy: 0.6265\n",
      "Epoch 293/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6255 - accuracy: 0.7945 - val_loss: 2.2323 - val_accuracy: 0.7099\n",
      "Epoch 294/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6093 - accuracy: 0.8004 - val_loss: 2.5090 - val_accuracy: 0.6759\n",
      "Epoch 295/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5979 - accuracy: 0.7986 - val_loss: 2.5206 - val_accuracy: 0.6883\n",
      "Epoch 296/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.6350 - accuracy: 0.7960 - val_loss: 2.5660 - val_accuracy: 0.6790\n",
      "Epoch 297/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6878 - accuracy: 0.7810 - val_loss: 2.4078 - val_accuracy: 0.7315\n",
      "Epoch 298/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5987 - accuracy: 0.8087 - val_loss: 2.2874 - val_accuracy: 0.6883\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6154 - accuracy: 0.7956 - val_loss: 2.1804 - val_accuracy: 0.7006\n",
      "Epoch 300/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6035 - accuracy: 0.7978 - val_loss: 2.1968 - val_accuracy: 0.7222\n",
      "Epoch 301/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6258 - accuracy: 0.7919 - val_loss: 2.0861 - val_accuracy: 0.7006\n",
      "Epoch 302/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6131 - accuracy: 0.7948 - val_loss: 2.0301 - val_accuracy: 0.7099\n",
      "Epoch 303/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6461 - accuracy: 0.7930 - val_loss: 2.0842 - val_accuracy: 0.7068\n",
      "Epoch 304/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6230 - accuracy: 0.7967 - val_loss: 2.2587 - val_accuracy: 0.6698\n",
      "Epoch 305/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6270 - accuracy: 0.7993 - val_loss: 2.3700 - val_accuracy: 0.6914\n",
      "Epoch 306/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6546 - accuracy: 0.7877 - val_loss: 2.1974 - val_accuracy: 0.6852\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5924 - accuracy: 0.8023 - val_loss: 2.2918 - val_accuracy: 0.6944\n",
      "Epoch 308/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6219 - accuracy: 0.8023 - val_loss: 2.2373 - val_accuracy: 0.6975\n",
      "Epoch 309/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6259 - accuracy: 0.7975 - val_loss: 2.1363 - val_accuracy: 0.6883\n",
      "Epoch 310/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6089 - accuracy: 0.7982 - val_loss: 2.1848 - val_accuracy: 0.7130\n",
      "Epoch 311/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5972 - accuracy: 0.8083 - val_loss: 2.3926 - val_accuracy: 0.6790\n",
      "Epoch 312/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6322 - accuracy: 0.7889 - val_loss: 2.2680 - val_accuracy: 0.6914\n",
      "Epoch 313/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6425 - accuracy: 0.7945 - val_loss: 2.3561 - val_accuracy: 0.6790\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6320 - accuracy: 0.7933 - val_loss: 2.2682 - val_accuracy: 0.7191\n",
      "Epoch 315/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6339 - accuracy: 0.7978 - val_loss: 2.4121 - val_accuracy: 0.6852\n",
      "Epoch 316/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.6175 - accuracy: 0.7933 - val_loss: 2.4945 - val_accuracy: 0.6852\n",
      "Epoch 317/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6220 - accuracy: 0.7919 - val_loss: 2.3818 - val_accuracy: 0.6790\n",
      "Epoch 318/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6178 - accuracy: 0.7952 - val_loss: 2.4059 - val_accuracy: 0.6698\n",
      "Epoch 319/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6197 - accuracy: 0.8046 - val_loss: 2.5304 - val_accuracy: 0.6451\n",
      "Epoch 320/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6348 - accuracy: 0.8023 - val_loss: 2.1403 - val_accuracy: 0.7160\n",
      "Epoch 321/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6291 - accuracy: 0.8016 - val_loss: 2.3266 - val_accuracy: 0.7253\n",
      "Epoch 322/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6228 - accuracy: 0.8004 - val_loss: 2.5510 - val_accuracy: 0.6389\n",
      "Epoch 323/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6211 - accuracy: 0.8038 - val_loss: 2.2973 - val_accuracy: 0.6852\n",
      "Epoch 324/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6399 - accuracy: 0.7881 - val_loss: 2.2437 - val_accuracy: 0.6975\n",
      "Epoch 325/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6112 - accuracy: 0.7960 - val_loss: 2.0201 - val_accuracy: 0.7191\n",
      "Epoch 326/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6204 - accuracy: 0.7941 - val_loss: 2.0655 - val_accuracy: 0.7531\n",
      "Epoch 327/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5937 - accuracy: 0.8068 - val_loss: 2.1374 - val_accuracy: 0.7315\n",
      "Epoch 328/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6081 - accuracy: 0.8117 - val_loss: 2.2951 - val_accuracy: 0.6883\n",
      "Epoch 329/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5857 - accuracy: 0.7956 - val_loss: 2.5334 - val_accuracy: 0.6327\n",
      "Epoch 330/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5868 - accuracy: 0.8079 - val_loss: 2.2929 - val_accuracy: 0.6914\n",
      "Epoch 331/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5611 - accuracy: 0.8113 - val_loss: 2.3885 - val_accuracy: 0.6821\n",
      "Epoch 332/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5704 - accuracy: 0.8217 - val_loss: 2.3792 - val_accuracy: 0.7037\n",
      "Epoch 333/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6407 - accuracy: 0.7904 - val_loss: 2.1101 - val_accuracy: 0.6883\n",
      "Epoch 334/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6275 - accuracy: 0.7933 - val_loss: 2.1952 - val_accuracy: 0.6636\n",
      "Epoch 335/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6009 - accuracy: 0.7986 - val_loss: 2.5030 - val_accuracy: 0.6759\n",
      "Epoch 336/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6093 - accuracy: 0.7997 - val_loss: 2.3920 - val_accuracy: 0.6883\n",
      "Epoch 337/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5989 - accuracy: 0.8046 - val_loss: 2.3822 - val_accuracy: 0.7222\n",
      "Epoch 338/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6131 - accuracy: 0.8068 - val_loss: 2.3816 - val_accuracy: 0.6852\n",
      "Epoch 339/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5944 - accuracy: 0.8046 - val_loss: 2.2813 - val_accuracy: 0.7222\n",
      "Epoch 340/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5965 - accuracy: 0.7907 - val_loss: 2.3017 - val_accuracy: 0.7130\n",
      "Epoch 341/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5934 - accuracy: 0.8072 - val_loss: 2.2710 - val_accuracy: 0.7099\n",
      "Epoch 342/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6221 - accuracy: 0.7922 - val_loss: 2.3629 - val_accuracy: 0.7130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6469 - accuracy: 0.7967 - val_loss: 2.2998 - val_accuracy: 0.7469\n",
      "Epoch 344/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6197 - accuracy: 0.8008 - val_loss: 2.0798 - val_accuracy: 0.7284\n",
      "Epoch 345/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6025 - accuracy: 0.8061 - val_loss: 2.4137 - val_accuracy: 0.7037\n",
      "Epoch 346/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6232 - accuracy: 0.8008 - val_loss: 2.3309 - val_accuracy: 0.6790\n",
      "Epoch 347/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6091 - accuracy: 0.8124 - val_loss: 2.6325 - val_accuracy: 0.6698\n",
      "Epoch 348/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5655 - accuracy: 0.8161 - val_loss: 2.2502 - val_accuracy: 0.7160\n",
      "Epoch 349/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5889 - accuracy: 0.8034 - val_loss: 2.4137 - val_accuracy: 0.6944\n",
      "Epoch 350/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5967 - accuracy: 0.8019 - val_loss: 2.3626 - val_accuracy: 0.6914\n",
      "Epoch 351/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6390 - accuracy: 0.7978 - val_loss: 2.3740 - val_accuracy: 0.6944\n",
      "Epoch 352/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5914 - accuracy: 0.8087 - val_loss: 2.1508 - val_accuracy: 0.7222\n",
      "Epoch 353/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6158 - accuracy: 0.7952 - val_loss: 2.1965 - val_accuracy: 0.7377\n",
      "Epoch 354/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6316 - accuracy: 0.7933 - val_loss: 2.4823 - val_accuracy: 0.6944\n",
      "Epoch 355/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5814 - accuracy: 0.8150 - val_loss: 2.4211 - val_accuracy: 0.7068\n",
      "Epoch 356/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5965 - accuracy: 0.8143 - val_loss: 2.4071 - val_accuracy: 0.6944\n",
      "Epoch 357/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5810 - accuracy: 0.8150 - val_loss: 2.6125 - val_accuracy: 0.6728\n",
      "Epoch 358/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5878 - accuracy: 0.8087 - val_loss: 2.2917 - val_accuracy: 0.7130\n",
      "Epoch 359/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6130 - accuracy: 0.8046 - val_loss: 2.0872 - val_accuracy: 0.7284\n",
      "Epoch 360/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5998 - accuracy: 0.8057 - val_loss: 2.4997 - val_accuracy: 0.6543\n",
      "Epoch 361/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6158 - accuracy: 0.8042 - val_loss: 2.2113 - val_accuracy: 0.7346\n",
      "Epoch 362/500\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.6179 - accuracy: 0.7945 - val_loss: 2.2159 - val_accuracy: 0.7469\n",
      "Epoch 363/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6149 - accuracy: 0.8068 - val_loss: 2.4957 - val_accuracy: 0.6944\n",
      "Epoch 364/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5930 - accuracy: 0.8064 - val_loss: 2.4317 - val_accuracy: 0.7160\n",
      "Epoch 365/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5783 - accuracy: 0.8068 - val_loss: 2.7846 - val_accuracy: 0.6759\n",
      "Epoch 366/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5875 - accuracy: 0.8087 - val_loss: 2.4300 - val_accuracy: 0.7006\n",
      "Epoch 367/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5779 - accuracy: 0.8150 - val_loss: 2.3733 - val_accuracy: 0.7222\n",
      "Epoch 368/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6369 - accuracy: 0.8031 - val_loss: 2.3116 - val_accuracy: 0.6821\n",
      "Epoch 369/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6045 - accuracy: 0.8087 - val_loss: 2.5349 - val_accuracy: 0.6728\n",
      "Epoch 370/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5808 - accuracy: 0.8139 - val_loss: 2.7150 - val_accuracy: 0.6852\n",
      "Epoch 371/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6294 - accuracy: 0.7975 - val_loss: 2.6490 - val_accuracy: 0.6728\n",
      "Epoch 372/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5966 - accuracy: 0.8146 - val_loss: 2.3400 - val_accuracy: 0.7191\n",
      "Epoch 373/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5777 - accuracy: 0.8135 - val_loss: 2.1635 - val_accuracy: 0.7160\n",
      "Epoch 374/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5860 - accuracy: 0.8012 - val_loss: 2.7713 - val_accuracy: 0.6667\n",
      "Epoch 375/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5885 - accuracy: 0.8105 - val_loss: 2.1234 - val_accuracy: 0.7284\n",
      "Epoch 376/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6190 - accuracy: 0.8031 - val_loss: 2.2859 - val_accuracy: 0.7130\n",
      "Epoch 377/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5663 - accuracy: 0.8210 - val_loss: 2.5295 - val_accuracy: 0.6698\n",
      "Epoch 378/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5598 - accuracy: 0.8191 - val_loss: 2.6090 - val_accuracy: 0.6914\n",
      "Epoch 379/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5814 - accuracy: 0.8146 - val_loss: 2.4513 - val_accuracy: 0.7068\n",
      "Epoch 380/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5876 - accuracy: 0.8109 - val_loss: 2.4019 - val_accuracy: 0.6975\n",
      "Epoch 381/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5660 - accuracy: 0.8120 - val_loss: 2.5581 - val_accuracy: 0.7068\n",
      "Epoch 382/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5795 - accuracy: 0.8176 - val_loss: 2.6218 - val_accuracy: 0.6543\n",
      "Epoch 383/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5595 - accuracy: 0.8176 - val_loss: 2.2943 - val_accuracy: 0.6914\n",
      "Epoch 384/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5526 - accuracy: 0.8188 - val_loss: 2.4813 - val_accuracy: 0.6944\n",
      "Epoch 385/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5858 - accuracy: 0.8158 - val_loss: 2.6990 - val_accuracy: 0.6142\n",
      "Epoch 386/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6048 - accuracy: 0.8075 - val_loss: 2.4708 - val_accuracy: 0.7037\n",
      "Epoch 387/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5798 - accuracy: 0.8146 - val_loss: 2.7304 - val_accuracy: 0.6481\n",
      "Epoch 388/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5596 - accuracy: 0.8132 - val_loss: 2.3595 - val_accuracy: 0.6883\n",
      "Epoch 389/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5593 - accuracy: 0.8161 - val_loss: 2.3630 - val_accuracy: 0.7438\n",
      "Epoch 390/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5565 - accuracy: 0.8180 - val_loss: 2.4753 - val_accuracy: 0.7130\n",
      "Epoch 391/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5548 - accuracy: 0.8165 - val_loss: 2.5552 - val_accuracy: 0.7099\n",
      "Epoch 392/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5909 - accuracy: 0.8053 - val_loss: 2.5785 - val_accuracy: 0.6944\n",
      "Epoch 393/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5473 - accuracy: 0.8251 - val_loss: 2.4396 - val_accuracy: 0.7099\n",
      "Epoch 394/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5698 - accuracy: 0.8176 - val_loss: 2.6707 - val_accuracy: 0.6728\n",
      "Epoch 395/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6052 - accuracy: 0.8001 - val_loss: 2.6102 - val_accuracy: 0.6852\n",
      "Epoch 396/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5923 - accuracy: 0.8105 - val_loss: 3.2382 - val_accuracy: 0.6389\n",
      "Epoch 397/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5643 - accuracy: 0.8210 - val_loss: 2.7137 - val_accuracy: 0.6883\n",
      "Epoch 398/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5601 - accuracy: 0.8184 - val_loss: 2.8381 - val_accuracy: 0.6636\n",
      "Epoch 399/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6318 - accuracy: 0.8064 - val_loss: 2.5008 - val_accuracy: 0.6790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6045 - accuracy: 0.7997 - val_loss: 2.6240 - val_accuracy: 0.6574\n",
      "Epoch 401/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5980 - accuracy: 0.8165 - val_loss: 2.7850 - val_accuracy: 0.6389\n",
      "Epoch 402/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5915 - accuracy: 0.8083 - val_loss: 2.4213 - val_accuracy: 0.6883\n",
      "Epoch 403/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5798 - accuracy: 0.8124 - val_loss: 2.2786 - val_accuracy: 0.7037\n",
      "Epoch 404/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5729 - accuracy: 0.8214 - val_loss: 2.4126 - val_accuracy: 0.6883\n",
      "Epoch 405/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5833 - accuracy: 0.8150 - val_loss: 2.6340 - val_accuracy: 0.6728\n",
      "Epoch 406/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5530 - accuracy: 0.8195 - val_loss: 2.6447 - val_accuracy: 0.6759\n",
      "Epoch 407/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5778 - accuracy: 0.8090 - val_loss: 2.8364 - val_accuracy: 0.6481\n",
      "Epoch 408/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5495 - accuracy: 0.8232 - val_loss: 2.4109 - val_accuracy: 0.7222\n",
      "Epoch 409/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5660 - accuracy: 0.8206 - val_loss: 2.5368 - val_accuracy: 0.6975\n",
      "Epoch 410/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5748 - accuracy: 0.8150 - val_loss: 2.4294 - val_accuracy: 0.6975\n",
      "Epoch 411/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6154 - accuracy: 0.7990 - val_loss: 2.4235 - val_accuracy: 0.7130\n",
      "Epoch 412/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5468 - accuracy: 0.8262 - val_loss: 2.2727 - val_accuracy: 0.7068\n",
      "Epoch 413/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5576 - accuracy: 0.8139 - val_loss: 2.4718 - val_accuracy: 0.6698\n",
      "Epoch 414/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5274 - accuracy: 0.8285 - val_loss: 2.7585 - val_accuracy: 0.6481\n",
      "Epoch 415/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5602 - accuracy: 0.8292 - val_loss: 2.5252 - val_accuracy: 0.6790\n",
      "Epoch 416/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5634 - accuracy: 0.8105 - val_loss: 2.6803 - val_accuracy: 0.6790\n",
      "Epoch 417/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.6140 - accuracy: 0.8057 - val_loss: 2.4220 - val_accuracy: 0.6975\n",
      "Epoch 418/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5640 - accuracy: 0.8169 - val_loss: 2.7195 - val_accuracy: 0.6698\n",
      "Epoch 419/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5920 - accuracy: 0.8120 - val_loss: 2.7894 - val_accuracy: 0.6975\n",
      "Epoch 420/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.5700 - accuracy: 0.8225 - val_loss: 2.5839 - val_accuracy: 0.7191\n",
      "Epoch 421/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.5875 - accuracy: 0.7997 - val_loss: 2.5437 - val_accuracy: 0.6790\n",
      "Epoch 422/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5765 - accuracy: 0.8146 - val_loss: 2.3081 - val_accuracy: 0.7284\n",
      "Epoch 423/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6066 - accuracy: 0.8094 - val_loss: 2.6295 - val_accuracy: 0.7130\n",
      "Epoch 424/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5659 - accuracy: 0.8191 - val_loss: 3.0058 - val_accuracy: 0.6821\n",
      "Epoch 425/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5718 - accuracy: 0.8161 - val_loss: 2.5829 - val_accuracy: 0.7099\n",
      "Epoch 426/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5395 - accuracy: 0.8288 - val_loss: 2.9213 - val_accuracy: 0.6698\n",
      "Epoch 427/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6020 - accuracy: 0.8117 - val_loss: 2.8268 - val_accuracy: 0.6944\n",
      "Epoch 428/500\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5518 - accuracy: 0.8303 - val_loss: 2.8325 - val_accuracy: 0.6821\n",
      "Epoch 429/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5624 - accuracy: 0.8109 - val_loss: 2.7103 - val_accuracy: 0.6698\n",
      "Epoch 430/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5763 - accuracy: 0.8191 - val_loss: 2.5690 - val_accuracy: 0.7130\n",
      "Epoch 431/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5563 - accuracy: 0.8221 - val_loss: 2.7745 - val_accuracy: 0.7191\n",
      "Epoch 432/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5825 - accuracy: 0.8143 - val_loss: 2.6622 - val_accuracy: 0.6914\n",
      "Epoch 433/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5827 - accuracy: 0.8139 - val_loss: 2.5694 - val_accuracy: 0.7006\n",
      "Epoch 434/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5718 - accuracy: 0.8251 - val_loss: 2.6562 - val_accuracy: 0.6852\n",
      "Epoch 435/500\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5713 - accuracy: 0.8210 - val_loss: 2.4185 - val_accuracy: 0.7191\n",
      "Epoch 436/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5873 - accuracy: 0.8090 - val_loss: 2.6272 - val_accuracy: 0.6759\n",
      "Epoch 437/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.6021 - accuracy: 0.8158 - val_loss: 2.6397 - val_accuracy: 0.6821\n",
      "Epoch 438/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5854 - accuracy: 0.8180 - val_loss: 2.4745 - val_accuracy: 0.6883\n",
      "Epoch 439/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5419 - accuracy: 0.8341 - val_loss: 2.5471 - val_accuracy: 0.7099\n",
      "Epoch 440/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5963 - accuracy: 0.8109 - val_loss: 2.6351 - val_accuracy: 0.6883\n",
      "Epoch 441/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5466 - accuracy: 0.8225 - val_loss: 2.5615 - val_accuracy: 0.7099\n",
      "Epoch 442/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5680 - accuracy: 0.8262 - val_loss: 2.7356 - val_accuracy: 0.7006\n",
      "Epoch 443/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5430 - accuracy: 0.8315 - val_loss: 2.4776 - val_accuracy: 0.7191\n",
      "Epoch 444/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5181 - accuracy: 0.8337 - val_loss: 2.7635 - val_accuracy: 0.6667\n",
      "Epoch 445/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5852 - accuracy: 0.8285 - val_loss: 2.3396 - val_accuracy: 0.7253\n",
      "Epoch 446/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5693 - accuracy: 0.8098 - val_loss: 2.3556 - val_accuracy: 0.7191\n",
      "Epoch 447/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5707 - accuracy: 0.8173 - val_loss: 2.3549 - val_accuracy: 0.7284\n",
      "Epoch 448/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5748 - accuracy: 0.8244 - val_loss: 2.7080 - val_accuracy: 0.6821\n",
      "Epoch 449/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5134 - accuracy: 0.8356 - val_loss: 2.9238 - val_accuracy: 0.6605\n",
      "Epoch 450/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5579 - accuracy: 0.8210 - val_loss: 2.6237 - val_accuracy: 0.6759\n",
      "Epoch 451/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5559 - accuracy: 0.8199 - val_loss: 2.6215 - val_accuracy: 0.6883\n",
      "Epoch 452/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5699 - accuracy: 0.8169 - val_loss: 2.7450 - val_accuracy: 0.6759\n",
      "Epoch 453/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5751 - accuracy: 0.8180 - val_loss: 2.6098 - val_accuracy: 0.7160\n",
      "Epoch 454/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5153 - accuracy: 0.8296 - val_loss: 2.4748 - val_accuracy: 0.7006\n",
      "Epoch 455/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5474 - accuracy: 0.8244 - val_loss: 2.4458 - val_accuracy: 0.7037\n",
      "Epoch 456/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5398 - accuracy: 0.8300 - val_loss: 2.6015 - val_accuracy: 0.6975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5216 - accuracy: 0.8315 - val_loss: 2.4650 - val_accuracy: 0.6821\n",
      "Epoch 458/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5114 - accuracy: 0.8281 - val_loss: 2.6585 - val_accuracy: 0.6543\n",
      "Epoch 459/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5285 - accuracy: 0.8255 - val_loss: 2.4726 - val_accuracy: 0.6759\n",
      "Epoch 460/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5082 - accuracy: 0.8393 - val_loss: 2.8692 - val_accuracy: 0.6481\n",
      "Epoch 461/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5949 - accuracy: 0.8132 - val_loss: 2.6516 - val_accuracy: 0.6914\n",
      "Epoch 462/500\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.5240 - accuracy: 0.8225 - val_loss: 2.8863 - val_accuracy: 0.6852\n",
      "Epoch 463/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5353 - accuracy: 0.8240 - val_loss: 2.6029 - val_accuracy: 0.6914\n",
      "Epoch 464/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5129 - accuracy: 0.8281 - val_loss: 2.5653 - val_accuracy: 0.7253\n",
      "Epoch 465/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5227 - accuracy: 0.8378 - val_loss: 3.0954 - val_accuracy: 0.6481\n",
      "Epoch 466/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5628 - accuracy: 0.8266 - val_loss: 3.2330 - val_accuracy: 0.6296\n",
      "Epoch 467/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5279 - accuracy: 0.8315 - val_loss: 3.0882 - val_accuracy: 0.7006\n",
      "Epoch 468/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5366 - accuracy: 0.8389 - val_loss: 2.8858 - val_accuracy: 0.6944\n",
      "Epoch 469/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5410 - accuracy: 0.8262 - val_loss: 2.7091 - val_accuracy: 0.6728\n",
      "Epoch 470/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5857 - accuracy: 0.8165 - val_loss: 3.2064 - val_accuracy: 0.6481\n",
      "Epoch 471/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5787 - accuracy: 0.8184 - val_loss: 2.7937 - val_accuracy: 0.7068\n",
      "Epoch 472/500\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.5116 - accuracy: 0.8356 - val_loss: 3.0083 - val_accuracy: 0.6852\n",
      "Epoch 473/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5725 - accuracy: 0.8217 - val_loss: 2.6753 - val_accuracy: 0.7006\n",
      "Epoch 474/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5585 - accuracy: 0.8217 - val_loss: 2.5943 - val_accuracy: 0.6759\n",
      "Epoch 475/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5180 - accuracy: 0.8296 - val_loss: 2.5609 - val_accuracy: 0.6728\n",
      "Epoch 476/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5530 - accuracy: 0.8266 - val_loss: 2.4507 - val_accuracy: 0.7099\n",
      "Epoch 477/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5100 - accuracy: 0.8206 - val_loss: 2.4999 - val_accuracy: 0.7284\n",
      "Epoch 478/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5359 - accuracy: 0.8330 - val_loss: 2.4765 - val_accuracy: 0.7160\n",
      "Epoch 479/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5493 - accuracy: 0.8180 - val_loss: 2.6017 - val_accuracy: 0.7099\n",
      "Epoch 480/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5508 - accuracy: 0.8247 - val_loss: 2.5741 - val_accuracy: 0.7160\n",
      "Epoch 481/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5169 - accuracy: 0.8300 - val_loss: 2.7681 - val_accuracy: 0.7099\n",
      "Epoch 482/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.4805 - accuracy: 0.8371 - val_loss: 2.6092 - val_accuracy: 0.7191\n",
      "Epoch 483/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5279 - accuracy: 0.8288 - val_loss: 2.4070 - val_accuracy: 0.7222\n",
      "Epoch 484/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5347 - accuracy: 0.8296 - val_loss: 2.4643 - val_accuracy: 0.7130\n",
      "Epoch 485/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5396 - accuracy: 0.8281 - val_loss: 2.5725 - val_accuracy: 0.6698\n",
      "Epoch 486/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5826 - accuracy: 0.8232 - val_loss: 2.6556 - val_accuracy: 0.7006\n",
      "Epoch 487/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5832 - accuracy: 0.8169 - val_loss: 2.6489 - val_accuracy: 0.7160\n",
      "Epoch 488/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5566 - accuracy: 0.8221 - val_loss: 2.3367 - val_accuracy: 0.7346\n",
      "Epoch 489/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5347 - accuracy: 0.8397 - val_loss: 3.0821 - val_accuracy: 0.6296\n",
      "Epoch 490/500\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.5555 - accuracy: 0.8188 - val_loss: 2.6474 - val_accuracy: 0.6698\n",
      "Epoch 491/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5672 - accuracy: 0.8236 - val_loss: 2.4458 - val_accuracy: 0.7068\n",
      "Epoch 492/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5206 - accuracy: 0.8374 - val_loss: 2.4732 - val_accuracy: 0.7006\n",
      "Epoch 493/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5425 - accuracy: 0.8281 - val_loss: 2.7946 - val_accuracy: 0.6543\n",
      "Epoch 494/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5599 - accuracy: 0.8259 - val_loss: 2.2600 - val_accuracy: 0.7068\n",
      "Epoch 495/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5243 - accuracy: 0.8348 - val_loss: 2.2868 - val_accuracy: 0.7438\n",
      "Epoch 496/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5838 - accuracy: 0.8244 - val_loss: 2.6663 - val_accuracy: 0.6636\n",
      "Epoch 497/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5459 - accuracy: 0.8311 - val_loss: 2.3763 - val_accuracy: 0.7315\n",
      "Epoch 498/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5226 - accuracy: 0.8374 - val_loss: 2.3865 - val_accuracy: 0.7191\n",
      "Epoch 499/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5581 - accuracy: 0.8210 - val_loss: 2.6426 - val_accuracy: 0.6975\n",
      "Epoch 500/500\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.5411 - accuracy: 0.8322 - val_loss: 2.4813 - val_accuracy: 0.7099\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training the best model...\")\n",
    "model = tuner.hypermodel.build(bestHP)\n",
    "History = model.fit(x=Xtrain, y=Ytrain,validation_data= (Xval,Yval), batch_size=96,epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c9f07de3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T19:33:51.087478Z",
     "start_time": "2023-08-12T19:33:50.665242Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "res = best_model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "64a8859f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T10:09:00.162967Z",
     "start_time": "2023-08-14T10:09:00.082469Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9a5bae2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T19:34:18.367753Z",
     "start_time": "2023-08-12T19:34:14.265611Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristian/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kristian/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kristian/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71        11\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.75      0.40      0.52        15\n",
      "           3       1.00      0.14      0.25         7\n",
      "           4       0.43      1.00      0.60        15\n",
      "           5       0.45      0.62      0.53         8\n",
      "           6       0.33      0.20      0.25        10\n",
      "           7       0.75      0.25      0.38        12\n",
      "           8       0.83      0.38      0.53        13\n",
      "           9       0.50      0.08      0.14        12\n",
      "          10       1.00      0.71      0.83        14\n",
      "          11       0.67      0.40      0.50        10\n",
      "          12       0.53      0.67      0.59        12\n",
      "          13       0.00      0.00      0.00        10\n",
      "          14       0.50      0.55      0.52        11\n",
      "          15       0.00      0.00      0.00        10\n",
      "          16       1.00      0.17      0.29        12\n",
      "          17       0.52      0.93      0.67        14\n",
      "          18       0.37      0.58      0.45        12\n",
      "          19       0.67      0.22      0.33         9\n",
      "          20       1.00      0.54      0.70        13\n",
      "          21       0.75      0.46      0.57        13\n",
      "          22       0.47      0.64      0.54        11\n",
      "          23       1.00      0.57      0.73         7\n",
      "          24       0.39      0.58      0.47        12\n",
      "          25       1.00      0.29      0.44         7\n",
      "          26       0.90      0.75      0.82        12\n",
      "          27       0.33      0.08      0.13        12\n",
      "          28       0.42      0.67      0.52        12\n",
      "          29       0.00      0.00      0.00         7\n",
      "          30       1.00      0.25      0.40         8\n",
      "          31       0.26      0.62      0.37         8\n",
      "          32       0.00      0.00      0.00         8\n",
      "          33       1.00      0.67      0.80         6\n",
      "          34       0.25      0.14      0.18         7\n",
      "          35       0.56      0.71      0.63        14\n",
      "          36       0.00      0.00      0.00        14\n",
      "          37       0.33      0.57      0.42        14\n",
      "          38       0.00      0.00      0.00        11\n",
      "          39       0.80      0.73      0.76        11\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.19      1.00      0.32         7\n",
      "          42       0.19      0.80      0.31        10\n",
      "          43       0.15      0.92      0.26        12\n",
      "          44       0.67      0.50      0.57        12\n",
      "          45       0.67      0.22      0.33         9\n",
      "          46       0.33      0.20      0.25         5\n",
      "          47       0.42      0.50      0.45        10\n",
      "          48       0.31      0.36      0.33        11\n",
      "          49       1.00      0.15      0.27        13\n",
      "\n",
      "    accuracy                           0.43       534\n",
      "   macro avg       0.51      0.42      0.39       534\n",
      "weighted avg       0.52      0.43      0.41       534\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(np.argmax(Ytest, axis=1), np.argmax(res, axis=1))\n",
    "\n",
    "sns.heatmap(cm, annot = True)\n",
    "\n",
    "print(classification_report(np.argmax(Ytest, axis=1), np.argmax(res, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "89c89036",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T18:58:04.896951Z",
     "start_time": "2023-08-12T18:58:04.893558Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2917"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_class = np.argmax(predict, axis=1)\n",
    "predict_class = predict_class.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5643f5d8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Hyperparameter Tunning 2 1D CNN Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e251abae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T11:33:57.763888Z",
     "start_time": "2023-08-14T11:33:57.719662Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_198611/792044357.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import Hyperband\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SpatialDropout1D,\n",
    "from keras_tuner import HyperModel\n",
    "from kerastuner.tuners import Hyperband\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        act_function = hp.Choice('dense_activation',values=['selu','LeakyReLU'],default='selu')\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=hp.Choice('num_filters_1',values=[25,50, 100,150],default=50,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(filters=hp.Choice('num_filters_2',values=[25,50, 100,150],default=50,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "#        model.add(Conv1D(filters=hp.Choice('num_filters_3',values=[25,50, 100,150],default=50,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "#        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_1',min_value=0.0,max_value=0.7,default=0.25,step=0.05,)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=hp.Int('units',min_value=20,max_value=120,step=20,default=40),activation=act_function))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_2',min_value=0.0,max_value=0.7,default=0.25,step=0.05,)))\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(Lion(hp.Float('learning_rate',min_value=1e-5,max_value=1e-3,sampling='LOG',default=1e-5)),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "hypermodel = CNNHyperModel(input_shape=(130,126), num_classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "ae789de8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:25:18.214400Z",
     "start_time": "2023-08-14T14:22:32.914583Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from hyperband/test4/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "HYPERBAND_MAX_EPOCHS = 100\n",
    "#MAX_TRIALS = 20\n",
    "EXECUTION_PER_TRIAL = 2\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    max_epochs=HYPERBAND_MAX_EPOCHS,\n",
    "    objective='val_loss',\n",
    "    seed=10,\n",
    "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "    directory='/media/kristian/HDD/ASL_Citizen/Mediapipe/hyperband/',\n",
    "    project_name='test4',\n",
    "    overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "64785dca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:25:23.014293Z",
     "start_time": "2023-08-14T14:25:23.011314Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 7\n",
      "dense_activation (Choice)\n",
      "{'default': 'selu', 'conditions': [], 'values': ['selu', 'LeakyReLU'], 'ordered': False}\n",
      "num_filters_1 (Choice)\n",
      "{'default': 50, 'conditions': [], 'values': [25, 50, 100, 150], 'ordered': True}\n",
      "num_filters_2 (Choice)\n",
      "{'default': 50, 'conditions': [], 'values': [25, 50, 100, 150], 'ordered': True}\n",
      "dropout_1 (Float)\n",
      "{'default': 0.25, 'conditions': [], 'min_value': 0.0, 'max_value': 0.7, 'step': 0.05, 'sampling': 'linear'}\n",
      "units (Int)\n",
      "{'default': 40, 'conditions': [], 'min_value': 20, 'max_value': 120, 'step': 20, 'sampling': 'linear'}\n",
      "dropout_2 (Float)\n",
      "{'default': 0.25, 'conditions': [], 'min_value': 0.0, 'max_value': 0.7, 'step': 0.05, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.001, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "3ab409f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:25:33.083701Z",
     "start_time": "2023-08-14T14:25:33.081256Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\",patience=20,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32338686",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T18:23:58.497530Z",
     "start_time": "2023-08-13T15:49:42.509141Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 02m 53s]\n",
      "val_loss: 2.798992872238159\n",
      "\n",
      "Best val_loss So Far: 1.5037063360214233\n",
      "Total elapsed time: 02h 34m 13s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(Xtrain, Ytrain, epochs=1000, validation_data=(Xval,Yval),batch_size=96,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "72549502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:25:38.087318Z",
     "start_time": "2023-08-14T14:25:38.083271Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in hyperband/test4\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 0245 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 100\n",
      "num_filters_2: 25\n",
      "dropout_1: 0.65\n",
      "units: 40\n",
      "dropout_2: 0.4\n",
      "learning_rate: 0.00013960407115272237\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0242\n",
      "Score: 1.5037063360214233\n",
      "\n",
      "Trial 0208 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 50\n",
      "num_filters_2: 100\n",
      "dropout_1: 0.6000000000000001\n",
      "units: 60\n",
      "dropout_2: 0.6000000000000001\n",
      "learning_rate: 0.00022015333534136284\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0207\n",
      "Score: 2.004472494125366\n",
      "\n",
      "Trial 0233 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 25\n",
      "num_filters_2: 25\n",
      "dropout_1: 0.30000000000000004\n",
      "units: 80\n",
      "dropout_2: 0.65\n",
      "learning_rate: 0.00025224242614677007\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0216\n",
      "Score: 2.0138278007507324\n",
      "\n",
      "Trial 0207 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 50\n",
      "num_filters_2: 100\n",
      "dropout_1: 0.6000000000000001\n",
      "units: 60\n",
      "dropout_2: 0.6000000000000001\n",
      "learning_rate: 0.00022015333534136284\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0199\n",
      "Score: 2.0394604206085205\n",
      "\n",
      "Trial 0229 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 50\n",
      "num_filters_2: 50\n",
      "dropout_1: 0.55\n",
      "units: 80\n",
      "dropout_2: 0.1\n",
      "learning_rate: 0.00021979153094558063\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0213\n",
      "Score: 2.0706980228424072\n",
      "\n",
      "Trial 0235 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 50\n",
      "num_filters_2: 50\n",
      "dropout_1: 0.55\n",
      "units: 80\n",
      "dropout_2: 0.1\n",
      "learning_rate: 0.00021979153094558063\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0229\n",
      "Score: 2.1079723834991455\n",
      "\n",
      "Trial 0234 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 25\n",
      "num_filters_2: 25\n",
      "dropout_1: 0.30000000000000004\n",
      "units: 80\n",
      "dropout_2: 0.65\n",
      "learning_rate: 0.00025224242614677007\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0233\n",
      "Score: 2.117971181869507\n",
      "\n",
      "Trial 0242 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 100\n",
      "num_filters_2: 25\n",
      "dropout_1: 0.65\n",
      "units: 40\n",
      "dropout_2: 0.4\n",
      "learning_rate: 0.00013960407115272237\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 2.139823079109192\n",
      "\n",
      "Trial 0228 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 100\n",
      "num_filters_2: 25\n",
      "dropout_1: 0.1\n",
      "units: 40\n",
      "dropout_2: 0.6000000000000001\n",
      "learning_rate: 0.0005977428471215702\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0221\n",
      "Score: 2.1791250705718994\n",
      "\n",
      "Trial 0203 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 100\n",
      "num_filters_2: 50\n",
      "dropout_1: 0.4\n",
      "units: 100\n",
      "dropout_2: 0.4\n",
      "learning_rate: 0.0003956370567137553\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0191\n",
      "Score: 2.233685255050659\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "95dcbe01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:25:43.828821Z",
     "start_time": "2023-08-14T14:25:43.825826Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bestHP = tuner.get_best_hyperparameters(num_trials=2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "734f9c9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:27:22.594551Z",
     "start_time": "2023-08-14T14:25:59.426914Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the best model...\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 5.5308 - accuracy: 0.0243 - val_loss: 3.8263 - val_accuracy: 0.0833\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 4.3483 - accuracy: 0.0501 - val_loss: 3.5147 - val_accuracy: 0.1420\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 3.8559 - accuracy: 0.0968 - val_loss: 3.2292 - val_accuracy: 0.2006\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 3.4544 - accuracy: 0.1424 - val_loss: 3.0182 - val_accuracy: 0.2623\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 3.1560 - accuracy: 0.1865 - val_loss: 2.7759 - val_accuracy: 0.3519\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 2.9038 - accuracy: 0.2414 - val_loss: 2.5860 - val_accuracy: 0.3951\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 2.7335 - accuracy: 0.2844 - val_loss: 2.3896 - val_accuracy: 0.4506\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 2.4972 - accuracy: 0.3356 - val_loss: 2.2067 - val_accuracy: 0.5154\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 2.3514 - accuracy: 0.3692 - val_loss: 2.0840 - val_accuracy: 0.5093\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 2.1716 - accuracy: 0.4099 - val_loss: 1.9994 - val_accuracy: 0.5278\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 2.0520 - accuracy: 0.4368 - val_loss: 1.9309 - val_accuracy: 0.5093\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.9696 - accuracy: 0.4365 - val_loss: 1.8154 - val_accuracy: 0.5772\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.8699 - accuracy: 0.4742 - val_loss: 1.7206 - val_accuracy: 0.6204\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.7178 - accuracy: 0.5191 - val_loss: 1.6894 - val_accuracy: 0.6111\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 1.6474 - accuracy: 0.5299 - val_loss: 1.6038 - val_accuracy: 0.6111\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.5564 - accuracy: 0.5624 - val_loss: 1.6286 - val_accuracy: 0.6173\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.5348 - accuracy: 0.5583 - val_loss: 1.5651 - val_accuracy: 0.6420\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.4657 - accuracy: 0.5691 - val_loss: 1.4919 - val_accuracy: 0.6512\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.3881 - accuracy: 0.5886 - val_loss: 1.4436 - val_accuracy: 0.6574\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.2939 - accuracy: 0.6218 - val_loss: 1.4128 - val_accuracy: 0.6574\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.3096 - accuracy: 0.6061 - val_loss: 1.3903 - val_accuracy: 0.6759\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.2240 - accuracy: 0.6315 - val_loss: 1.4312 - val_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.1938 - accuracy: 0.6491 - val_loss: 1.3492 - val_accuracy: 0.6883\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.1892 - accuracy: 0.6573 - val_loss: 1.3428 - val_accuracy: 0.6852\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.1914 - accuracy: 0.6510 - val_loss: 1.3558 - val_accuracy: 0.6883\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 1.0852 - accuracy: 0.6771 - val_loss: 1.3170 - val_accuracy: 0.6759\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.0761 - accuracy: 0.6827 - val_loss: 1.2993 - val_accuracy: 0.6698\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.1031 - accuracy: 0.6726 - val_loss: 1.2659 - val_accuracy: 0.6883\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.0363 - accuracy: 0.6891 - val_loss: 1.3168 - val_accuracy: 0.6975\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.0423 - accuracy: 0.6820 - val_loss: 1.2879 - val_accuracy: 0.7037\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9447 - accuracy: 0.7164 - val_loss: 1.2738 - val_accuracy: 0.6790\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9920 - accuracy: 0.6992 - val_loss: 1.2634 - val_accuracy: 0.7068\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9398 - accuracy: 0.7130 - val_loss: 1.2426 - val_accuracy: 0.7130\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.9221 - accuracy: 0.7141 - val_loss: 1.3108 - val_accuracy: 0.7006\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.9227 - accuracy: 0.7119 - val_loss: 1.3133 - val_accuracy: 0.7191\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.9047 - accuracy: 0.7138 - val_loss: 1.2524 - val_accuracy: 0.7191\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.8569 - accuracy: 0.7343 - val_loss: 1.2189 - val_accuracy: 0.7284\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.8790 - accuracy: 0.7265 - val_loss: 1.2455 - val_accuracy: 0.7160\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.9084 - accuracy: 0.7175 - val_loss: 1.2738 - val_accuracy: 0.6914\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.8612 - accuracy: 0.7343 - val_loss: 1.2865 - val_accuracy: 0.6914\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.8354 - accuracy: 0.7422 - val_loss: 1.3090 - val_accuracy: 0.6975\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.8291 - accuracy: 0.7395 - val_loss: 1.2529 - val_accuracy: 0.7037\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.8845 - accuracy: 0.7205 - val_loss: 1.2737 - val_accuracy: 0.7315\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.8794 - accuracy: 0.7321 - val_loss: 1.2576 - val_accuracy: 0.7160\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.8333 - accuracy: 0.7347 - val_loss: 1.3692 - val_accuracy: 0.7068\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.8516 - accuracy: 0.7369 - val_loss: 1.2869 - val_accuracy: 0.7160\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7579 - accuracy: 0.7668 - val_loss: 1.3040 - val_accuracy: 0.6975\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7916 - accuracy: 0.7463 - val_loss: 1.3047 - val_accuracy: 0.7377\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7912 - accuracy: 0.7410 - val_loss: 1.3270 - val_accuracy: 0.6975\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7554 - accuracy: 0.7635 - val_loss: 1.2856 - val_accuracy: 0.7253\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7270 - accuracy: 0.7739 - val_loss: 1.3046 - val_accuracy: 0.7315\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7468 - accuracy: 0.7623 - val_loss: 1.2527 - val_accuracy: 0.7315\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7509 - accuracy: 0.7649 - val_loss: 1.3378 - val_accuracy: 0.6975\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7668 - accuracy: 0.7601 - val_loss: 1.2904 - val_accuracy: 0.7284\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7200 - accuracy: 0.7631 - val_loss: 1.2986 - val_accuracy: 0.7284\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7506 - accuracy: 0.7713 - val_loss: 1.3572 - val_accuracy: 0.7130\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7302 - accuracy: 0.7765 - val_loss: 1.3397 - val_accuracy: 0.7222\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7124 - accuracy: 0.7833 - val_loss: 1.2809 - val_accuracy: 0.7438\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7487 - accuracy: 0.7605 - val_loss: 1.3401 - val_accuracy: 0.7191\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7259 - accuracy: 0.7653 - val_loss: 1.3592 - val_accuracy: 0.7068\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.7231 - accuracy: 0.7582 - val_loss: 1.2955 - val_accuracy: 0.7160\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6610 - accuracy: 0.7844 - val_loss: 1.3583 - val_accuracy: 0.7222\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6895 - accuracy: 0.7732 - val_loss: 1.3789 - val_accuracy: 0.7068\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7115 - accuracy: 0.7743 - val_loss: 1.3309 - val_accuracy: 0.7130\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7138 - accuracy: 0.7769 - val_loss: 1.3012 - val_accuracy: 0.7253\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7251 - accuracy: 0.7724 - val_loss: 1.3281 - val_accuracy: 0.7438\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7084 - accuracy: 0.7791 - val_loss: 1.2873 - val_accuracy: 0.7531\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6870 - accuracy: 0.7821 - val_loss: 1.3533 - val_accuracy: 0.7253\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6952 - accuracy: 0.7780 - val_loss: 1.3476 - val_accuracy: 0.7099\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6647 - accuracy: 0.7851 - val_loss: 1.3293 - val_accuracy: 0.7469\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6477 - accuracy: 0.8019 - val_loss: 1.3193 - val_accuracy: 0.7099\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6680 - accuracy: 0.7844 - val_loss: 1.3278 - val_accuracy: 0.7377\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.7101 - accuracy: 0.7765 - val_loss: 1.3482 - val_accuracy: 0.7346\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.6933 - accuracy: 0.7747 - val_loss: 1.3412 - val_accuracy: 0.7346\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.6619 - accuracy: 0.7851 - val_loss: 1.3299 - val_accuracy: 0.7315\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.6275 - accuracy: 0.8004 - val_loss: 1.4076 - val_accuracy: 0.7253\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6573 - accuracy: 0.7889 - val_loss: 1.3853 - val_accuracy: 0.7130\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6475 - accuracy: 0.7904 - val_loss: 1.3553 - val_accuracy: 0.7253\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.6793 - accuracy: 0.7952 - val_loss: 1.3214 - val_accuracy: 0.7346\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.6890 - accuracy: 0.7788 - val_loss: 1.3086 - val_accuracy: 0.7346\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.6423 - accuracy: 0.7993 - val_loss: 1.3319 - val_accuracy: 0.7346\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6251 - accuracy: 0.8019 - val_loss: 1.3940 - val_accuracy: 0.7346\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6200 - accuracy: 0.8087 - val_loss: 1.3711 - val_accuracy: 0.7222\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6136 - accuracy: 0.8019 - val_loss: 1.4067 - val_accuracy: 0.7315\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.6480 - accuracy: 0.7907 - val_loss: 1.3689 - val_accuracy: 0.7562\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6323 - accuracy: 0.7907 - val_loss: 1.3716 - val_accuracy: 0.7623\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6027 - accuracy: 0.8090 - val_loss: 1.4070 - val_accuracy: 0.7407\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.6304 - accuracy: 0.7975 - val_loss: 1.4130 - val_accuracy: 0.7469\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6513 - accuracy: 0.7919 - val_loss: 1.3937 - val_accuracy: 0.7438\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6093 - accuracy: 0.8046 - val_loss: 1.4291 - val_accuracy: 0.7346\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6122 - accuracy: 0.8012 - val_loss: 1.3368 - val_accuracy: 0.7531\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6669 - accuracy: 0.7960 - val_loss: 1.3003 - val_accuracy: 0.7438\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6076 - accuracy: 0.8072 - val_loss: 1.2681 - val_accuracy: 0.7685\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.6378 - accuracy: 0.8012 - val_loss: 1.3163 - val_accuracy: 0.7377\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.6000 - accuracy: 0.8161 - val_loss: 1.3082 - val_accuracy: 0.7593\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6021 - accuracy: 0.8105 - val_loss: 1.3749 - val_accuracy: 0.7315\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6245 - accuracy: 0.7997 - val_loss: 1.4073 - val_accuracy: 0.7377\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.6359 - accuracy: 0.8012 - val_loss: 1.3963 - val_accuracy: 0.7377\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6335 - accuracy: 0.8098 - val_loss: 1.2968 - val_accuracy: 0.7407\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.6157 - accuracy: 0.8046 - val_loss: 1.3734 - val_accuracy: 0.7469\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training the best model...\")\n",
    "model = tuner.hypermodel.build(bestHP)\n",
    "History = model.fit(x=Xtrain, y=Ytrain,validation_data= (Xval,Yval), batch_size=96,epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9887c252",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T18:50:06.880241Z",
     "start_time": "2023-08-13T18:50:06.066233Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab61844f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T18:59:13.467930Z",
     "start_time": "2023-08-13T18:56:40.132852Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "28/28 [==============================] - 2s 17ms/step - loss: 1.1973 - accuracy: 0.6364 - val_loss: 1.6069 - val_accuracy: 0.6543\n",
      "Epoch 2/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1804 - accuracy: 0.6368 - val_loss: 1.6015 - val_accuracy: 0.6049\n",
      "Epoch 3/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1668 - accuracy: 0.6480 - val_loss: 1.6986 - val_accuracy: 0.6173\n",
      "Epoch 4/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.2008 - accuracy: 0.6177 - val_loss: 1.6607 - val_accuracy: 0.6111\n",
      "Epoch 5/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1745 - accuracy: 0.6319 - val_loss: 1.6212 - val_accuracy: 0.6173\n",
      "Epoch 6/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1680 - accuracy: 0.6383 - val_loss: 1.5716 - val_accuracy: 0.6204\n",
      "Epoch 7/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.1666 - accuracy: 0.6371 - val_loss: 1.4613 - val_accuracy: 0.6543\n",
      "Epoch 8/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1380 - accuracy: 0.6558 - val_loss: 1.5754 - val_accuracy: 0.6451\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1614 - accuracy: 0.6446 - val_loss: 1.4947 - val_accuracy: 0.6451\n",
      "Epoch 10/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1297 - accuracy: 0.6491 - val_loss: 1.5498 - val_accuracy: 0.6142\n",
      "Epoch 11/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1395 - accuracy: 0.6469 - val_loss: 1.4729 - val_accuracy: 0.6698\n",
      "Epoch 12/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1595 - accuracy: 0.6491 - val_loss: 1.5184 - val_accuracy: 0.6574\n",
      "Epoch 13/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1748 - accuracy: 0.6428 - val_loss: 1.4772 - val_accuracy: 0.6481\n",
      "Epoch 14/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1233 - accuracy: 0.6502 - val_loss: 1.6565 - val_accuracy: 0.6111\n",
      "Epoch 15/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1171 - accuracy: 0.6540 - val_loss: 1.7072 - val_accuracy: 0.6049\n",
      "Epoch 16/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1470 - accuracy: 0.6371 - val_loss: 1.6475 - val_accuracy: 0.6327\n",
      "Epoch 17/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1371 - accuracy: 0.6487 - val_loss: 1.5763 - val_accuracy: 0.6327\n",
      "Epoch 18/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.0981 - accuracy: 0.6633 - val_loss: 1.6119 - val_accuracy: 0.6173\n",
      "Epoch 19/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1175 - accuracy: 0.6566 - val_loss: 1.5882 - val_accuracy: 0.6296\n",
      "Epoch 20/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1283 - accuracy: 0.6596 - val_loss: 1.6541 - val_accuracy: 0.6235\n",
      "Epoch 21/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0980 - accuracy: 0.6495 - val_loss: 1.7295 - val_accuracy: 0.6173\n",
      "Epoch 22/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.0766 - accuracy: 0.6682 - val_loss: 1.4862 - val_accuracy: 0.6944\n",
      "Epoch 23/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0572 - accuracy: 0.6682 - val_loss: 1.6509 - val_accuracy: 0.6420\n",
      "Epoch 24/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0879 - accuracy: 0.6663 - val_loss: 1.5664 - val_accuracy: 0.6605\n",
      "Epoch 25/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0858 - accuracy: 0.6558 - val_loss: 1.6121 - val_accuracy: 0.6543\n",
      "Epoch 26/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1264 - accuracy: 0.6551 - val_loss: 1.5370 - val_accuracy: 0.6698\n",
      "Epoch 27/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.0429 - accuracy: 0.6723 - val_loss: 1.4700 - val_accuracy: 0.6975\n",
      "Epoch 28/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0560 - accuracy: 0.6760 - val_loss: 1.6535 - val_accuracy: 0.6543\n",
      "Epoch 29/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0706 - accuracy: 0.6887 - val_loss: 1.4512 - val_accuracy: 0.6821\n",
      "Epoch 30/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.1234 - accuracy: 0.6472 - val_loss: 1.5283 - val_accuracy: 0.6667\n",
      "Epoch 31/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0753 - accuracy: 0.6689 - val_loss: 1.4756 - val_accuracy: 0.6759\n",
      "Epoch 32/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0423 - accuracy: 0.6655 - val_loss: 1.5469 - val_accuracy: 0.6235\n",
      "Epoch 33/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0523 - accuracy: 0.6704 - val_loss: 1.5811 - val_accuracy: 0.6451\n",
      "Epoch 34/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0555 - accuracy: 0.6723 - val_loss: 1.8408 - val_accuracy: 0.5802\n",
      "Epoch 35/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0613 - accuracy: 0.6641 - val_loss: 1.6380 - val_accuracy: 0.6173\n",
      "Epoch 36/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0292 - accuracy: 0.6783 - val_loss: 1.7070 - val_accuracy: 0.6296\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0399 - accuracy: 0.6794 - val_loss: 1.7266 - val_accuracy: 0.6111\n",
      "Epoch 38/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0370 - accuracy: 0.6880 - val_loss: 1.4257 - val_accuracy: 0.7130\n",
      "Epoch 39/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0355 - accuracy: 0.6745 - val_loss: 1.7419 - val_accuracy: 0.6019\n",
      "Epoch 40/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0361 - accuracy: 0.6764 - val_loss: 1.6059 - val_accuracy: 0.6481\n",
      "Epoch 41/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0534 - accuracy: 0.6693 - val_loss: 1.5771 - val_accuracy: 0.6296\n",
      "Epoch 42/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0103 - accuracy: 0.6891 - val_loss: 1.7003 - val_accuracy: 0.6235\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.0206 - accuracy: 0.6783 - val_loss: 1.4951 - val_accuracy: 0.6852\n",
      "Epoch 44/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0303 - accuracy: 0.6794 - val_loss: 1.5262 - val_accuracy: 0.6574\n",
      "Epoch 45/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0310 - accuracy: 0.6854 - val_loss: 1.6403 - val_accuracy: 0.6265\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0467 - accuracy: 0.6641 - val_loss: 1.6153 - val_accuracy: 0.6698\n",
      "Epoch 47/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0346 - accuracy: 0.6715 - val_loss: 1.4386 - val_accuracy: 0.7068\n",
      "Epoch 48/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0118 - accuracy: 0.6846 - val_loss: 1.5094 - val_accuracy: 0.6605\n",
      "Epoch 49/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0367 - accuracy: 0.6753 - val_loss: 1.5639 - val_accuracy: 0.6451\n",
      "Epoch 50/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0370 - accuracy: 0.6648 - val_loss: 1.8370 - val_accuracy: 0.6080\n",
      "Epoch 51/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0028 - accuracy: 0.6876 - val_loss: 1.6423 - val_accuracy: 0.6111\n",
      "Epoch 52/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0228 - accuracy: 0.6850 - val_loss: 1.6612 - val_accuracy: 0.6389\n",
      "Epoch 53/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9821 - accuracy: 0.6861 - val_loss: 1.6447 - val_accuracy: 0.6543\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0039 - accuracy: 0.6842 - val_loss: 1.5994 - val_accuracy: 0.6481\n",
      "Epoch 55/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0004 - accuracy: 0.6906 - val_loss: 1.7531 - val_accuracy: 0.6389\n",
      "Epoch 56/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9893 - accuracy: 0.6988 - val_loss: 1.5389 - val_accuracy: 0.6728\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0027 - accuracy: 0.6887 - val_loss: 1.6061 - val_accuracy: 0.6605\n",
      "Epoch 58/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0032 - accuracy: 0.6854 - val_loss: 1.6338 - val_accuracy: 0.6574\n",
      "Epoch 59/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9836 - accuracy: 0.6880 - val_loss: 1.8506 - val_accuracy: 0.5679\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9857 - accuracy: 0.6887 - val_loss: 1.7372 - val_accuracy: 0.6019\n",
      "Epoch 61/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9697 - accuracy: 0.6928 - val_loss: 1.5793 - val_accuracy: 0.6574\n",
      "Epoch 62/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0118 - accuracy: 0.6783 - val_loss: 1.6169 - val_accuracy: 0.6358\n",
      "Epoch 63/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.9945 - accuracy: 0.6954 - val_loss: 1.4736 - val_accuracy: 0.6944\n",
      "Epoch 64/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9556 - accuracy: 0.7081 - val_loss: 1.5606 - val_accuracy: 0.6636\n",
      "Epoch 65/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0265 - accuracy: 0.6794 - val_loss: 1.7313 - val_accuracy: 0.6512\n",
      "Epoch 66/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0081 - accuracy: 0.6831 - val_loss: 1.4842 - val_accuracy: 0.6852\n",
      "Epoch 67/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0129 - accuracy: 0.6857 - val_loss: 1.5568 - val_accuracy: 0.6543\n",
      "Epoch 68/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0133 - accuracy: 0.6868 - val_loss: 1.6497 - val_accuracy: 0.6204\n",
      "Epoch 69/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0142 - accuracy: 0.6812 - val_loss: 1.6613 - val_accuracy: 0.6389\n",
      "Epoch 70/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0179 - accuracy: 0.6831 - val_loss: 1.5320 - val_accuracy: 0.6605\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9488 - accuracy: 0.7078 - val_loss: 1.5859 - val_accuracy: 0.6728\n",
      "Epoch 72/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9999 - accuracy: 0.6756 - val_loss: 1.4563 - val_accuracy: 0.6944\n",
      "Epoch 73/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0201 - accuracy: 0.6835 - val_loss: 1.4750 - val_accuracy: 0.6914\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9779 - accuracy: 0.6906 - val_loss: 1.7835 - val_accuracy: 0.5926\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9901 - accuracy: 0.6846 - val_loss: 1.5734 - val_accuracy: 0.6790\n",
      "Epoch 76/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0168 - accuracy: 0.6783 - val_loss: 1.5009 - val_accuracy: 0.6852\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9655 - accuracy: 0.7003 - val_loss: 1.4742 - val_accuracy: 0.6944\n",
      "Epoch 78/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9997 - accuracy: 0.6801 - val_loss: 1.5614 - val_accuracy: 0.6821\n",
      "Epoch 79/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9778 - accuracy: 0.6996 - val_loss: 1.8525 - val_accuracy: 0.5864\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0135 - accuracy: 0.6839 - val_loss: 1.6484 - val_accuracy: 0.6235\n",
      "Epoch 81/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9896 - accuracy: 0.6805 - val_loss: 1.6327 - val_accuracy: 0.6667\n",
      "Epoch 82/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9895 - accuracy: 0.6969 - val_loss: 1.4950 - val_accuracy: 0.6975\n",
      "Epoch 83/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9794 - accuracy: 0.6910 - val_loss: 1.6178 - val_accuracy: 0.6790\n",
      "Epoch 84/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9775 - accuracy: 0.6891 - val_loss: 1.6689 - val_accuracy: 0.6543\n",
      "Epoch 85/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0018 - accuracy: 0.6839 - val_loss: 1.8862 - val_accuracy: 0.5833\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9894 - accuracy: 0.6865 - val_loss: 1.4418 - val_accuracy: 0.7099\n",
      "Epoch 87/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9625 - accuracy: 0.6936 - val_loss: 1.4996 - val_accuracy: 0.6728\n",
      "Epoch 88/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9697 - accuracy: 0.7007 - val_loss: 1.4735 - val_accuracy: 0.7037\n",
      "Epoch 89/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9513 - accuracy: 0.7022 - val_loss: 1.5463 - val_accuracy: 0.6605\n",
      "Epoch 90/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9469 - accuracy: 0.7089 - val_loss: 1.6629 - val_accuracy: 0.6389\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9600 - accuracy: 0.6883 - val_loss: 1.7718 - val_accuracy: 0.6049\n",
      "Epoch 92/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.9312 - accuracy: 0.7055 - val_loss: 1.5438 - val_accuracy: 0.6883\n",
      "Epoch 93/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9646 - accuracy: 0.6996 - val_loss: 1.5140 - val_accuracy: 0.6667\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9451 - accuracy: 0.6984 - val_loss: 1.6365 - val_accuracy: 0.6728\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9437 - accuracy: 0.7059 - val_loss: 1.6012 - val_accuracy: 0.6883\n",
      "Epoch 96/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9467 - accuracy: 0.7063 - val_loss: 1.6805 - val_accuracy: 0.6204\n",
      "Epoch 97/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9153 - accuracy: 0.7085 - val_loss: 1.6671 - val_accuracy: 0.6636\n",
      "Epoch 98/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.9630 - accuracy: 0.7029 - val_loss: 1.5893 - val_accuracy: 0.6914\n",
      "Epoch 99/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9612 - accuracy: 0.7010 - val_loss: 1.5774 - val_accuracy: 0.6543\n",
      "Epoch 100/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9318 - accuracy: 0.6988 - val_loss: 1.6272 - val_accuracy: 0.6605\n",
      "Epoch 101/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9036 - accuracy: 0.7115 - val_loss: 1.5370 - val_accuracy: 0.6790\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9494 - accuracy: 0.7025 - val_loss: 1.5802 - val_accuracy: 0.6667\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9383 - accuracy: 0.7108 - val_loss: 1.7839 - val_accuracy: 0.6296\n",
      "Epoch 104/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.9347 - accuracy: 0.6925 - val_loss: 1.8336 - val_accuracy: 0.6019\n",
      "Epoch 105/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9288 - accuracy: 0.7126 - val_loss: 1.7996 - val_accuracy: 0.6173\n",
      "Epoch 106/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9033 - accuracy: 0.7134 - val_loss: 1.7183 - val_accuracy: 0.6327\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.9295 - accuracy: 0.7078 - val_loss: 1.7973 - val_accuracy: 0.6204\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9017 - accuracy: 0.7242 - val_loss: 1.8875 - val_accuracy: 0.6080\n",
      "Epoch 109/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9470 - accuracy: 0.7055 - val_loss: 1.6466 - val_accuracy: 0.6667\n",
      "Epoch 110/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.9084 - accuracy: 0.7059 - val_loss: 1.6918 - val_accuracy: 0.6605\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.9506 - accuracy: 0.7067 - val_loss: 1.5608 - val_accuracy: 0.6481\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9498 - accuracy: 0.6962 - val_loss: 1.5757 - val_accuracy: 0.6698\n",
      "Epoch 113/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9222 - accuracy: 0.7063 - val_loss: 1.8903 - val_accuracy: 0.6204\n",
      "Epoch 114/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9286 - accuracy: 0.7093 - val_loss: 1.5386 - val_accuracy: 0.6821\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8847 - accuracy: 0.7156 - val_loss: 1.7174 - val_accuracy: 0.6358\n",
      "Epoch 116/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9036 - accuracy: 0.7100 - val_loss: 1.6745 - val_accuracy: 0.6389\n",
      "Epoch 117/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9146 - accuracy: 0.7100 - val_loss: 1.6302 - val_accuracy: 0.6852\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8746 - accuracy: 0.7294 - val_loss: 1.4993 - val_accuracy: 0.6728\n",
      "Epoch 119/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8975 - accuracy: 0.7134 - val_loss: 1.5081 - val_accuracy: 0.6821\n",
      "Epoch 120/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9008 - accuracy: 0.7111 - val_loss: 1.6858 - val_accuracy: 0.6698\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9219 - accuracy: 0.7104 - val_loss: 1.8443 - val_accuracy: 0.6235\n",
      "Epoch 122/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9113 - accuracy: 0.7190 - val_loss: 1.9146 - val_accuracy: 0.6019\n",
      "Epoch 123/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8897 - accuracy: 0.7220 - val_loss: 1.5637 - val_accuracy: 0.6790\n",
      "Epoch 124/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8949 - accuracy: 0.7074 - val_loss: 1.6222 - val_accuracy: 0.6481\n",
      "Epoch 125/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9018 - accuracy: 0.7216 - val_loss: 1.7178 - val_accuracy: 0.6574\n",
      "Epoch 126/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9013 - accuracy: 0.7156 - val_loss: 1.5039 - val_accuracy: 0.6914\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9055 - accuracy: 0.7093 - val_loss: 1.4664 - val_accuracy: 0.6883\n",
      "Epoch 128/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8860 - accuracy: 0.7194 - val_loss: 1.4938 - val_accuracy: 0.6821\n",
      "Epoch 129/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8587 - accuracy: 0.7272 - val_loss: 1.7853 - val_accuracy: 0.6605\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.9232 - accuracy: 0.7055 - val_loss: 1.8025 - val_accuracy: 0.6296\n",
      "Epoch 131/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9010 - accuracy: 0.7078 - val_loss: 1.6178 - val_accuracy: 0.6543\n",
      "Epoch 132/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9080 - accuracy: 0.7115 - val_loss: 1.5236 - val_accuracy: 0.6790\n",
      "Epoch 133/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8790 - accuracy: 0.7257 - val_loss: 1.6146 - val_accuracy: 0.6728\n",
      "Epoch 134/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9038 - accuracy: 0.7179 - val_loss: 1.7931 - val_accuracy: 0.6512\n",
      "Epoch 135/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8542 - accuracy: 0.7365 - val_loss: 1.7716 - val_accuracy: 0.6451\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8585 - accuracy: 0.7231 - val_loss: 1.7546 - val_accuracy: 0.6481\n",
      "Epoch 137/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8695 - accuracy: 0.7253 - val_loss: 2.0575 - val_accuracy: 0.5988\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8450 - accuracy: 0.7321 - val_loss: 1.7202 - val_accuracy: 0.6420\n",
      "Epoch 139/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8466 - accuracy: 0.7309 - val_loss: 1.8394 - val_accuracy: 0.6296\n",
      "Epoch 140/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8835 - accuracy: 0.7156 - val_loss: 1.6770 - val_accuracy: 0.6698\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8694 - accuracy: 0.7272 - val_loss: 1.9358 - val_accuracy: 0.6049\n",
      "Epoch 142/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8708 - accuracy: 0.7209 - val_loss: 1.7198 - val_accuracy: 0.6574\n",
      "Epoch 143/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8616 - accuracy: 0.7242 - val_loss: 1.6012 - val_accuracy: 0.6667\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8705 - accuracy: 0.7223 - val_loss: 1.6829 - val_accuracy: 0.6636\n",
      "Epoch 145/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8580 - accuracy: 0.7332 - val_loss: 1.7916 - val_accuracy: 0.6173\n",
      "Epoch 146/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8250 - accuracy: 0.7309 - val_loss: 1.6543 - val_accuracy: 0.6790\n",
      "Epoch 147/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8309 - accuracy: 0.7291 - val_loss: 1.5514 - val_accuracy: 0.7006\n",
      "Epoch 148/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8535 - accuracy: 0.7160 - val_loss: 1.5995 - val_accuracy: 0.6975\n",
      "Epoch 149/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8999 - accuracy: 0.7201 - val_loss: 1.5412 - val_accuracy: 0.6914\n",
      "Epoch 150/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8612 - accuracy: 0.7197 - val_loss: 1.5506 - val_accuracy: 0.7068\n",
      "Epoch 151/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8857 - accuracy: 0.7089 - val_loss: 1.6447 - val_accuracy: 0.6728\n",
      "Epoch 152/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8768 - accuracy: 0.7149 - val_loss: 1.6279 - val_accuracy: 0.6821\n",
      "Epoch 153/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8231 - accuracy: 0.7358 - val_loss: 1.8229 - val_accuracy: 0.6451\n",
      "Epoch 154/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.8442 - accuracy: 0.7261 - val_loss: 2.0596 - val_accuracy: 0.6204\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8412 - accuracy: 0.7294 - val_loss: 1.6133 - val_accuracy: 0.6728\n",
      "Epoch 156/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8201 - accuracy: 0.7384 - val_loss: 1.5977 - val_accuracy: 0.6481\n",
      "Epoch 157/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8307 - accuracy: 0.7388 - val_loss: 1.6422 - val_accuracy: 0.6821\n",
      "Epoch 158/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8630 - accuracy: 0.7246 - val_loss: 1.6996 - val_accuracy: 0.6605\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8394 - accuracy: 0.7302 - val_loss: 1.5821 - val_accuracy: 0.6821\n",
      "Epoch 160/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8580 - accuracy: 0.7194 - val_loss: 1.7028 - val_accuracy: 0.6636\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8946 - accuracy: 0.7268 - val_loss: 1.5065 - val_accuracy: 0.7068\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8220 - accuracy: 0.7422 - val_loss: 1.7243 - val_accuracy: 0.6574\n",
      "Epoch 163/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8434 - accuracy: 0.7309 - val_loss: 1.8014 - val_accuracy: 0.6389\n",
      "Epoch 164/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8349 - accuracy: 0.7336 - val_loss: 1.7565 - val_accuracy: 0.6728\n",
      "Epoch 165/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8397 - accuracy: 0.7283 - val_loss: 1.5655 - val_accuracy: 0.6790\n",
      "Epoch 166/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8558 - accuracy: 0.7231 - val_loss: 1.6199 - val_accuracy: 0.6914\n",
      "Epoch 167/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8250 - accuracy: 0.7365 - val_loss: 1.9190 - val_accuracy: 0.6111\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8042 - accuracy: 0.7414 - val_loss: 1.6281 - val_accuracy: 0.6698\n",
      "Epoch 169/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8515 - accuracy: 0.7362 - val_loss: 1.6672 - val_accuracy: 0.6852\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8048 - accuracy: 0.7410 - val_loss: 1.5576 - val_accuracy: 0.6944\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8072 - accuracy: 0.7351 - val_loss: 1.8501 - val_accuracy: 0.6327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8254 - accuracy: 0.7298 - val_loss: 1.6094 - val_accuracy: 0.6821\n",
      "Epoch 173/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8408 - accuracy: 0.7351 - val_loss: 2.1210 - val_accuracy: 0.5617\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8103 - accuracy: 0.7354 - val_loss: 1.6483 - val_accuracy: 0.7037\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8149 - accuracy: 0.7365 - val_loss: 1.8927 - val_accuracy: 0.6420\n",
      "Epoch 176/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.7995 - accuracy: 0.7384 - val_loss: 1.7119 - val_accuracy: 0.6420\n",
      "Epoch 177/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8509 - accuracy: 0.7328 - val_loss: 1.5842 - val_accuracy: 0.6698\n",
      "Epoch 178/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8482 - accuracy: 0.7283 - val_loss: 1.8628 - val_accuracy: 0.6420\n",
      "Epoch 179/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8491 - accuracy: 0.7231 - val_loss: 1.5269 - val_accuracy: 0.6944\n",
      "Epoch 180/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8512 - accuracy: 0.7257 - val_loss: 1.6518 - val_accuracy: 0.6728\n",
      "Epoch 181/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.8514 - accuracy: 0.7403 - val_loss: 1.8081 - val_accuracy: 0.6420\n",
      "Epoch 182/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.7921 - accuracy: 0.7395 - val_loss: 1.6407 - val_accuracy: 0.6975\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8287 - accuracy: 0.7373 - val_loss: 1.7130 - val_accuracy: 0.6636\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8225 - accuracy: 0.7362 - val_loss: 1.5016 - val_accuracy: 0.6883\n",
      "Epoch 185/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8004 - accuracy: 0.7362 - val_loss: 1.5030 - val_accuracy: 0.7068\n",
      "Epoch 186/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.7984 - accuracy: 0.7466 - val_loss: 1.6900 - val_accuracy: 0.6512\n",
      "Epoch 187/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7937 - accuracy: 0.7324 - val_loss: 1.9915 - val_accuracy: 0.6265\n",
      "Epoch 188/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7979 - accuracy: 0.7410 - val_loss: 1.7144 - val_accuracy: 0.6451\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7887 - accuracy: 0.7466 - val_loss: 1.5767 - val_accuracy: 0.6914\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8108 - accuracy: 0.7448 - val_loss: 1.6708 - val_accuracy: 0.6728\n",
      "Epoch 191/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7794 - accuracy: 0.7507 - val_loss: 2.0337 - val_accuracy: 0.6173\n",
      "Epoch 192/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8114 - accuracy: 0.7384 - val_loss: 1.9101 - val_accuracy: 0.6265\n",
      "Epoch 193/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8022 - accuracy: 0.7481 - val_loss: 1.9089 - val_accuracy: 0.6296\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8227 - accuracy: 0.7309 - val_loss: 1.5746 - val_accuracy: 0.6759\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8192 - accuracy: 0.7373 - val_loss: 1.4319 - val_accuracy: 0.7284\n",
      "Epoch 196/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7985 - accuracy: 0.7463 - val_loss: 1.7085 - val_accuracy: 0.6728\n",
      "Epoch 197/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8023 - accuracy: 0.7410 - val_loss: 1.7163 - val_accuracy: 0.6605\n",
      "Epoch 198/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.7627 - accuracy: 0.7504 - val_loss: 1.6899 - val_accuracy: 0.6698\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.7996 - accuracy: 0.7511 - val_loss: 1.5679 - val_accuracy: 0.6975\n",
      "Epoch 200/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7645 - accuracy: 0.7403 - val_loss: 1.7388 - val_accuracy: 0.6728\n",
      "Epoch 201/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7958 - accuracy: 0.7414 - val_loss: 1.6220 - val_accuracy: 0.6944\n",
      "Epoch 202/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7752 - accuracy: 0.7481 - val_loss: 1.5973 - val_accuracy: 0.7160\n",
      "Epoch 203/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7632 - accuracy: 0.7556 - val_loss: 1.6518 - val_accuracy: 0.6852\n",
      "Epoch 204/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8219 - accuracy: 0.7336 - val_loss: 1.6468 - val_accuracy: 0.6883\n",
      "Epoch 205/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7913 - accuracy: 0.7410 - val_loss: 1.9883 - val_accuracy: 0.6173\n",
      "Epoch 206/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8181 - accuracy: 0.7496 - val_loss: 1.6531 - val_accuracy: 0.6728\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7675 - accuracy: 0.7526 - val_loss: 1.6748 - val_accuracy: 0.6821\n",
      "Epoch 208/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7704 - accuracy: 0.7459 - val_loss: 1.7112 - val_accuracy: 0.6821\n",
      "Epoch 209/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7734 - accuracy: 0.7515 - val_loss: 1.5836 - val_accuracy: 0.7006\n",
      "Epoch 210/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7652 - accuracy: 0.7616 - val_loss: 1.6943 - val_accuracy: 0.6821\n",
      "Epoch 211/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8093 - accuracy: 0.7321 - val_loss: 1.8540 - val_accuracy: 0.6389\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8207 - accuracy: 0.7324 - val_loss: 1.7298 - val_accuracy: 0.6759\n",
      "Epoch 213/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.7946 - accuracy: 0.7500 - val_loss: 1.8271 - val_accuracy: 0.6636\n",
      "Epoch 214/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7680 - accuracy: 0.7489 - val_loss: 1.7790 - val_accuracy: 0.6605\n",
      "Epoch 215/500\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8116 - accuracy: 0.7336 - val_loss: 1.9800 - val_accuracy: 0.6389\n",
      "Epoch 216/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8095 - accuracy: 0.7444 - val_loss: 1.8880 - val_accuracy: 0.6235\n",
      "Epoch 217/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7822 - accuracy: 0.7552 - val_loss: 1.8533 - val_accuracy: 0.6481\n",
      "Epoch 218/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7640 - accuracy: 0.7478 - val_loss: 1.6872 - val_accuracy: 0.7037\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.7856 - accuracy: 0.7526 - val_loss: 1.8425 - val_accuracy: 0.6574\n",
      "Epoch 220/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7151 - accuracy: 0.7631 - val_loss: 1.6492 - val_accuracy: 0.7099\n",
      "Epoch 221/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7655 - accuracy: 0.7567 - val_loss: 1.6868 - val_accuracy: 0.6759\n",
      "Epoch 222/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7702 - accuracy: 0.7470 - val_loss: 1.6773 - val_accuracy: 0.6975\n",
      "Epoch 223/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8377 - accuracy: 0.7194 - val_loss: 1.8371 - val_accuracy: 0.6698\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7791 - accuracy: 0.7507 - val_loss: 1.9605 - val_accuracy: 0.6265\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7424 - accuracy: 0.7560 - val_loss: 1.9437 - val_accuracy: 0.6420\n",
      "Epoch 226/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7519 - accuracy: 0.7668 - val_loss: 1.8785 - val_accuracy: 0.6451\n",
      "Epoch 227/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7575 - accuracy: 0.7489 - val_loss: 2.0847 - val_accuracy: 0.6235\n",
      "Epoch 228/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8007 - accuracy: 0.7463 - val_loss: 1.7705 - val_accuracy: 0.6759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7591 - accuracy: 0.7410 - val_loss: 1.7798 - val_accuracy: 0.6636\n",
      "Epoch 230/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7688 - accuracy: 0.7451 - val_loss: 1.8049 - val_accuracy: 0.6543\n",
      "Epoch 231/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7679 - accuracy: 0.7608 - val_loss: 1.6894 - val_accuracy: 0.6852\n",
      "Epoch 232/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7392 - accuracy: 0.7653 - val_loss: 1.7807 - val_accuracy: 0.6605\n",
      "Epoch 233/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7773 - accuracy: 0.7515 - val_loss: 1.7914 - val_accuracy: 0.6636\n",
      "Epoch 234/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7373 - accuracy: 0.7597 - val_loss: 1.9289 - val_accuracy: 0.6327\n",
      "Epoch 235/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7769 - accuracy: 0.7560 - val_loss: 2.0037 - val_accuracy: 0.6512\n",
      "Epoch 236/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.7834 - accuracy: 0.7403 - val_loss: 1.6694 - val_accuracy: 0.7037\n",
      "Epoch 237/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.7930 - accuracy: 0.7377 - val_loss: 1.8669 - val_accuracy: 0.6512\n",
      "Epoch 238/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7760 - accuracy: 0.7481 - val_loss: 1.7536 - val_accuracy: 0.6636\n",
      "Epoch 239/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7418 - accuracy: 0.7605 - val_loss: 1.7452 - val_accuracy: 0.6790\n",
      "Epoch 240/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7554 - accuracy: 0.7597 - val_loss: 1.8631 - val_accuracy: 0.6389\n",
      "Epoch 241/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7823 - accuracy: 0.7466 - val_loss: 2.0493 - val_accuracy: 0.6111\n",
      "Epoch 242/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7364 - accuracy: 0.7560 - val_loss: 2.1672 - val_accuracy: 0.5895\n",
      "Epoch 243/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7406 - accuracy: 0.7571 - val_loss: 1.6837 - val_accuracy: 0.6821\n",
      "Epoch 244/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8057 - accuracy: 0.7440 - val_loss: 1.9039 - val_accuracy: 0.6358\n",
      "Epoch 245/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.7568 - accuracy: 0.7578 - val_loss: 1.5314 - val_accuracy: 0.6914\n",
      "Epoch 246/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7675 - accuracy: 0.7474 - val_loss: 1.4432 - val_accuracy: 0.7191\n",
      "Epoch 247/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7380 - accuracy: 0.7586 - val_loss: 1.6904 - val_accuracy: 0.6728\n",
      "Epoch 248/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7321 - accuracy: 0.7560 - val_loss: 1.4995 - val_accuracy: 0.7099\n",
      "Epoch 249/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7336 - accuracy: 0.7661 - val_loss: 1.6402 - val_accuracy: 0.6852\n",
      "Epoch 250/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7670 - accuracy: 0.7571 - val_loss: 1.9537 - val_accuracy: 0.6358\n",
      "Epoch 251/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7527 - accuracy: 0.7522 - val_loss: 1.9691 - val_accuracy: 0.6327\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7363 - accuracy: 0.7515 - val_loss: 2.0185 - val_accuracy: 0.6235\n",
      "Epoch 253/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7510 - accuracy: 0.7597 - val_loss: 1.8392 - val_accuracy: 0.6667\n",
      "Epoch 254/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7134 - accuracy: 0.7687 - val_loss: 1.6789 - val_accuracy: 0.6728\n",
      "Epoch 255/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7434 - accuracy: 0.7668 - val_loss: 1.5259 - val_accuracy: 0.6944\n",
      "Epoch 256/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7693 - accuracy: 0.7530 - val_loss: 1.9572 - val_accuracy: 0.6420\n",
      "Epoch 257/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7467 - accuracy: 0.7586 - val_loss: 1.7301 - val_accuracy: 0.6512\n",
      "Epoch 258/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7484 - accuracy: 0.7623 - val_loss: 1.7556 - val_accuracy: 0.6574\n",
      "Epoch 259/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7488 - accuracy: 0.7582 - val_loss: 1.7968 - val_accuracy: 0.6481\n",
      "Epoch 260/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7643 - accuracy: 0.7478 - val_loss: 1.7682 - val_accuracy: 0.6667\n",
      "Epoch 261/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7554 - accuracy: 0.7552 - val_loss: 1.8881 - val_accuracy: 0.6420\n",
      "Epoch 262/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7433 - accuracy: 0.7668 - val_loss: 1.7443 - val_accuracy: 0.6728\n",
      "Epoch 263/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7415 - accuracy: 0.7478 - val_loss: 1.9232 - val_accuracy: 0.6296\n",
      "Epoch 264/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7508 - accuracy: 0.7522 - val_loss: 2.0222 - val_accuracy: 0.6173\n",
      "Epoch 265/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7362 - accuracy: 0.7526 - val_loss: 1.9739 - val_accuracy: 0.6235\n",
      "Epoch 266/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7589 - accuracy: 0.7593 - val_loss: 1.9141 - val_accuracy: 0.6605\n",
      "Epoch 267/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6972 - accuracy: 0.7810 - val_loss: 1.8312 - val_accuracy: 0.6389\n",
      "Epoch 268/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7194 - accuracy: 0.7616 - val_loss: 1.9054 - val_accuracy: 0.6451\n",
      "Epoch 269/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7380 - accuracy: 0.7627 - val_loss: 1.5822 - val_accuracy: 0.7006\n",
      "Epoch 270/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7142 - accuracy: 0.7638 - val_loss: 2.0901 - val_accuracy: 0.6451\n",
      "Epoch 271/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7329 - accuracy: 0.7672 - val_loss: 1.8971 - val_accuracy: 0.6698\n",
      "Epoch 272/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7425 - accuracy: 0.7567 - val_loss: 1.6173 - val_accuracy: 0.7006\n",
      "Epoch 273/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7263 - accuracy: 0.7743 - val_loss: 2.3051 - val_accuracy: 0.5988\n",
      "Epoch 274/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7301 - accuracy: 0.7646 - val_loss: 1.8946 - val_accuracy: 0.6358\n",
      "Epoch 275/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7204 - accuracy: 0.7679 - val_loss: 2.0201 - val_accuracy: 0.6173\n",
      "Epoch 276/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7046 - accuracy: 0.7803 - val_loss: 1.7836 - val_accuracy: 0.6698\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7176 - accuracy: 0.7743 - val_loss: 1.9364 - val_accuracy: 0.6327\n",
      "Epoch 278/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7363 - accuracy: 0.7668 - val_loss: 1.9574 - val_accuracy: 0.6420\n",
      "Epoch 279/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.7371 - accuracy: 0.7605 - val_loss: 2.0293 - val_accuracy: 0.6204\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7139 - accuracy: 0.7754 - val_loss: 1.9305 - val_accuracy: 0.6420\n",
      "Epoch 281/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7180 - accuracy: 0.7702 - val_loss: 1.9289 - val_accuracy: 0.6605\n",
      "Epoch 282/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7132 - accuracy: 0.7672 - val_loss: 1.9756 - val_accuracy: 0.6543\n",
      "Epoch 283/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7333 - accuracy: 0.7635 - val_loss: 2.0304 - val_accuracy: 0.6265\n",
      "Epoch 284/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7380 - accuracy: 0.7627 - val_loss: 1.7239 - val_accuracy: 0.6728\n",
      "Epoch 285/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7330 - accuracy: 0.7758 - val_loss: 1.7151 - val_accuracy: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7167 - accuracy: 0.7713 - val_loss: 1.9682 - val_accuracy: 0.6451\n",
      "Epoch 287/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7190 - accuracy: 0.7664 - val_loss: 1.9762 - val_accuracy: 0.6451\n",
      "Epoch 288/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7686 - accuracy: 0.7500 - val_loss: 1.9480 - val_accuracy: 0.6605\n",
      "Epoch 289/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7175 - accuracy: 0.7672 - val_loss: 1.9774 - val_accuracy: 0.6389\n",
      "Epoch 290/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7338 - accuracy: 0.7564 - val_loss: 1.7772 - val_accuracy: 0.6451\n",
      "Epoch 291/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7107 - accuracy: 0.7679 - val_loss: 1.6474 - val_accuracy: 0.6914\n",
      "Epoch 292/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7212 - accuracy: 0.7575 - val_loss: 1.7297 - val_accuracy: 0.6821\n",
      "Epoch 293/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7350 - accuracy: 0.7627 - val_loss: 1.8289 - val_accuracy: 0.6543\n",
      "Epoch 294/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6976 - accuracy: 0.7709 - val_loss: 1.7734 - val_accuracy: 0.6698\n",
      "Epoch 295/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7129 - accuracy: 0.7691 - val_loss: 2.0313 - val_accuracy: 0.6481\n",
      "Epoch 296/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7311 - accuracy: 0.7623 - val_loss: 1.7072 - val_accuracy: 0.6944\n",
      "Epoch 297/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7376 - accuracy: 0.7672 - val_loss: 3.0277 - val_accuracy: 0.5123\n",
      "Epoch 298/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6880 - accuracy: 0.7706 - val_loss: 2.1721 - val_accuracy: 0.6173\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7175 - accuracy: 0.7754 - val_loss: 1.7190 - val_accuracy: 0.6543\n",
      "Epoch 300/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7308 - accuracy: 0.7612 - val_loss: 2.1760 - val_accuracy: 0.6080\n",
      "Epoch 301/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7227 - accuracy: 0.7735 - val_loss: 1.8385 - val_accuracy: 0.6698\n",
      "Epoch 302/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6944 - accuracy: 0.7679 - val_loss: 1.8779 - val_accuracy: 0.6543\n",
      "Epoch 303/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7025 - accuracy: 0.7642 - val_loss: 1.8547 - val_accuracy: 0.6512\n",
      "Epoch 304/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7122 - accuracy: 0.7649 - val_loss: 1.7408 - val_accuracy: 0.6852\n",
      "Epoch 305/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7465 - accuracy: 0.7567 - val_loss: 2.2885 - val_accuracy: 0.5957\n",
      "Epoch 306/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7171 - accuracy: 0.7683 - val_loss: 2.3881 - val_accuracy: 0.5926\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7207 - accuracy: 0.7593 - val_loss: 2.0167 - val_accuracy: 0.6204\n",
      "Epoch 308/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7130 - accuracy: 0.7545 - val_loss: 1.8139 - val_accuracy: 0.6667\n",
      "Epoch 309/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6689 - accuracy: 0.7799 - val_loss: 2.0238 - val_accuracy: 0.6204\n",
      "Epoch 310/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7165 - accuracy: 0.7679 - val_loss: 1.8916 - val_accuracy: 0.6481\n",
      "Epoch 311/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7203 - accuracy: 0.7635 - val_loss: 1.8047 - val_accuracy: 0.6790\n",
      "Epoch 312/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6896 - accuracy: 0.7706 - val_loss: 1.8387 - val_accuracy: 0.6667\n",
      "Epoch 313/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7095 - accuracy: 0.7732 - val_loss: 2.1341 - val_accuracy: 0.5957\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7212 - accuracy: 0.7706 - val_loss: 1.8390 - val_accuracy: 0.6358\n",
      "Epoch 315/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6953 - accuracy: 0.7743 - val_loss: 1.6918 - val_accuracy: 0.6667\n",
      "Epoch 316/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7221 - accuracy: 0.7694 - val_loss: 1.8253 - val_accuracy: 0.6852\n",
      "Epoch 317/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.7111 - accuracy: 0.7679 - val_loss: 1.6983 - val_accuracy: 0.6605\n",
      "Epoch 318/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7181 - accuracy: 0.7635 - val_loss: 1.7526 - val_accuracy: 0.6296\n",
      "Epoch 319/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7269 - accuracy: 0.7575 - val_loss: 1.9561 - val_accuracy: 0.6265\n",
      "Epoch 320/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6819 - accuracy: 0.7806 - val_loss: 1.8187 - val_accuracy: 0.6512\n",
      "Epoch 321/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7021 - accuracy: 0.7754 - val_loss: 2.0701 - val_accuracy: 0.6204\n",
      "Epoch 322/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7128 - accuracy: 0.7635 - val_loss: 1.9359 - val_accuracy: 0.6296\n",
      "Epoch 323/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7010 - accuracy: 0.7687 - val_loss: 1.6888 - val_accuracy: 0.6852\n",
      "Epoch 324/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6880 - accuracy: 0.7653 - val_loss: 2.0692 - val_accuracy: 0.6111\n",
      "Epoch 325/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7061 - accuracy: 0.7679 - val_loss: 1.8049 - val_accuracy: 0.6605\n",
      "Epoch 326/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7291 - accuracy: 0.7642 - val_loss: 1.8306 - val_accuracy: 0.6481\n",
      "Epoch 327/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7074 - accuracy: 0.7724 - val_loss: 1.7940 - val_accuracy: 0.6852\n",
      "Epoch 328/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7082 - accuracy: 0.7773 - val_loss: 2.2551 - val_accuracy: 0.5864\n",
      "Epoch 329/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6484 - accuracy: 0.7803 - val_loss: 1.9227 - val_accuracy: 0.6420\n",
      "Epoch 330/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6704 - accuracy: 0.7896 - val_loss: 2.1186 - val_accuracy: 0.6204\n",
      "Epoch 331/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6839 - accuracy: 0.7743 - val_loss: 1.9804 - val_accuracy: 0.6389\n",
      "Epoch 332/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7025 - accuracy: 0.7747 - val_loss: 1.8179 - val_accuracy: 0.6543\n",
      "Epoch 333/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7064 - accuracy: 0.7713 - val_loss: 2.0755 - val_accuracy: 0.6296\n",
      "Epoch 334/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6752 - accuracy: 0.7821 - val_loss: 1.8815 - val_accuracy: 0.6574\n",
      "Epoch 335/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7160 - accuracy: 0.7601 - val_loss: 2.3922 - val_accuracy: 0.5926\n",
      "Epoch 336/500\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.7145 - accuracy: 0.7724 - val_loss: 1.8392 - val_accuracy: 0.6451\n",
      "Epoch 337/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7320 - accuracy: 0.7593 - val_loss: 2.0407 - val_accuracy: 0.6358\n",
      "Epoch 338/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6920 - accuracy: 0.7743 - val_loss: 1.9211 - val_accuracy: 0.6451\n",
      "Epoch 339/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7145 - accuracy: 0.7691 - val_loss: 1.7995 - val_accuracy: 0.6574\n",
      "Epoch 340/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6775 - accuracy: 0.7855 - val_loss: 1.7999 - val_accuracy: 0.6543\n",
      "Epoch 341/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6840 - accuracy: 0.7728 - val_loss: 1.7132 - val_accuracy: 0.6698\n",
      "Epoch 342/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6783 - accuracy: 0.7818 - val_loss: 2.3942 - val_accuracy: 0.5741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6997 - accuracy: 0.7720 - val_loss: 2.1009 - val_accuracy: 0.6080\n",
      "Epoch 344/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6925 - accuracy: 0.7724 - val_loss: 1.6792 - val_accuracy: 0.7006\n",
      "Epoch 345/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6749 - accuracy: 0.7806 - val_loss: 2.0945 - val_accuracy: 0.6265\n",
      "Epoch 346/500\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6950 - accuracy: 0.7750 - val_loss: 2.5844 - val_accuracy: 0.5710\n",
      "Epoch 347/500\n",
      "13/28 [============>.................] - ETA: 0s - loss: 0.6542 - accuracy: 0.7949"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m History \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mXval\u001b[49m\u001b[43m,\u001b[49m\u001b[43mYval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1748\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1746\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1747\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1748\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/tf_utils.py:694\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/nest.py:624\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    540\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 624\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1054\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \n\u001b[1;32m    959\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1054\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/tf_utils.py:687\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 687\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1141\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m \n\u001b[1;32m   1120\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1107\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1106\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1108\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "History = best_model.fit(x=Xtrain, y=Ytrain,validation_data= (Xval,Yval), batch_size=96,epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "3fdbaafb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:27:59.809096Z",
     "start_time": "2023-08-14T14:27:59.635107Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "c795d93f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:28:06.075651Z",
     "start_time": "2023-08-14T14:28:05.961543Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 1.3734 - accuracy: 0.7469\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(Xval, Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "63633d4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:28:08.943425Z",
     "start_time": "2023-08-14T14:28:08.940984Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "9ef86c0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:28:24.856584Z",
     "start_time": "2023-08-14T14:28:19.982076Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.38      0.46         8\n",
      "           1       0.86      1.00      0.92         6\n",
      "           2       0.70      0.70      0.70        10\n",
      "           3       1.00      0.70      0.82        10\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       0.88      0.88      0.88         8\n",
      "           6       0.33      0.50      0.40         6\n",
      "           7       0.80      1.00      0.89         8\n",
      "           8       0.67      0.67      0.67         6\n",
      "           9       0.43      1.00      0.60         6\n",
      "          10       0.67      1.00      0.80         4\n",
      "          11       0.83      0.83      0.83         6\n",
      "          12       0.67      0.67      0.67         6\n",
      "          13       0.57      0.50      0.53         8\n",
      "          14       0.40      0.33      0.36         6\n",
      "          15       0.62      0.62      0.62         8\n",
      "          16       1.00      1.00      1.00         6\n",
      "          17       1.00      0.88      0.93         8\n",
      "          18       0.75      0.75      0.75         4\n",
      "          19       0.86      1.00      0.92         6\n",
      "          20       0.86      1.00      0.92         6\n",
      "          21       1.00      0.88      0.93         8\n",
      "          22       0.80      1.00      0.89         4\n",
      "          23       0.33      0.50      0.40         4\n",
      "          24       0.71      0.83      0.77         6\n",
      "          25       0.80      1.00      0.89         8\n",
      "          26       0.75      0.75      0.75         8\n",
      "          27       0.50      0.17      0.25         6\n",
      "          28       0.75      0.75      0.75         4\n",
      "          29       0.67      0.50      0.57         4\n",
      "          30       0.67      0.50      0.57         4\n",
      "          31       0.83      0.62      0.71         8\n",
      "          32       1.00      0.50      0.67         8\n",
      "          33       1.00      1.00      1.00         4\n",
      "          34       0.75      1.00      0.86         6\n",
      "          35       0.67      0.50      0.57         4\n",
      "          36       0.67      0.25      0.36         8\n",
      "          37       0.71      0.62      0.67         8\n",
      "          38       0.57      1.00      0.73         8\n",
      "          39       1.00      0.75      0.86         8\n",
      "          40       0.75      1.00      0.86         6\n",
      "          41       0.50      0.50      0.50         4\n",
      "          42       0.86      1.00      0.92         6\n",
      "          43       1.00      1.00      1.00         8\n",
      "          44       0.89      0.80      0.84        10\n",
      "          45       1.00      0.17      0.29         6\n",
      "          46       0.50      0.50      0.50         4\n",
      "          47       0.67      1.00      0.80         4\n",
      "          48       1.00      0.88      0.93         8\n",
      "          49       0.82      0.90      0.86        10\n",
      "\n",
      "    accuracy                           0.75       324\n",
      "   macro avg       0.75      0.75      0.73       324\n",
      "weighted avg       0.77      0.75      0.74       324\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(np.argmax(Yval, axis=1), np.argmax(res, axis=1))\n",
    "\n",
    "sns.heatmap(cm, annot = True)\n",
    "\n",
    "print(classification_report(np.argmax(Yval, axis=1), np.argmax(res, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "52d2cf4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:28:27.562843Z",
     "start_time": "2023-08-14T14:28:27.558952Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(res[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "afb93049",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:28:28.977981Z",
     "start_time": "2023-08-14T14:28:28.973766Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Yval[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "53c6e20e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:28:31.137431Z",
     "start_time": "2023-08-14T14:28:31.133499Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  8, 23,  0,  1,  1,  1, 38,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
       "        4,  4,  5,  2,  5,  5,  5,  6, 38,  7,  7,  7,  7,  8,  8,  8,  9,\n",
       "        9,  9, 10, 10, 11, 11, 49, 12, 12, 37, 14, 25, 13, 13, 14, 22, 37,\n",
       "        9, 15, 24, 15, 16, 16, 16, 17, 17, 17, 17, 18, 18, 19, 19, 19, 20,\n",
       "       20, 20, 29, 21, 21, 21, 22, 22, 23, 42, 24, 23, 24, 25, 25, 25, 25,\n",
       "       26,  0, 26, 26, 18, 10, 25, 28, 28, 29, 26, 31, 30, 31,  6, 31, 31,\n",
       "       47, 32, 32, 36, 33, 33, 34, 34, 34, 35, 28, 40, 15, 15,  7, 37, 37,\n",
       "        9, 37, 38, 38, 38, 38, 46, 39, 39, 39, 40, 40, 40, 44, 41, 42, 42,\n",
       "       42, 43, 43, 43, 43, 44, 44, 44, 38, 44, 10, 23, 45, 46,  9, 47, 47,\n",
       "       48, 48, 48, 48, 11, 49, 49, 49, 49,  9,  9,  9,  0,  1,  1,  1, 38,\n",
       "       12,  2,  2,  2,  6,  3,  3,  3,  8,  4,  4,  5,  5,  5,  5, 14,  6,\n",
       "        6,  7,  7,  7,  7, 38,  8, 38,  9,  9,  9, 10, 10, 11, 11, 11, 12,\n",
       "       12,  7,  6, 14, 13, 13,  6,  6, 14, 15, 15, 24, 15, 16, 16, 16, 17,\n",
       "       17, 35, 17, 41, 18, 19, 19, 19, 20, 20, 20, 21, 21, 21, 21, 22, 22,\n",
       "       23, 12, 24, 24, 24, 25, 25, 25, 25, 26,  0, 26, 26, 30, 41, 27, 34,\n",
       "       28, 29, 26,  1, 30, 31, 13, 13, 31, 49, 32, 32,  6, 33, 33, 34, 34,\n",
       "       34, 35, 47, 40, 36, 19, 36, 34, 37,  9, 37, 38, 38, 38, 38, 46, 39,\n",
       "       39, 39, 40, 40, 40, 15, 41, 42, 42, 42, 43, 43, 43, 43, 44, 44, 44,\n",
       "       20, 44, 13, 23,  2, 46,  9, 47, 47, 48, 27, 48, 48, 49, 49, 49, 49,\n",
       "       49])"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(res, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "4d117387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:28:32.217926Z",
     "start_time": "2023-08-14T14:28:32.213177Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  1,  1,  1,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,\n",
       "        4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,  7,  7,  8,  8,  8,  9,\n",
       "        9,  9, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14,\n",
       "       15, 15, 15, 15, 16, 16, 16, 17, 17, 17, 17, 18, 18, 19, 19, 19, 20,\n",
       "       20, 20, 21, 21, 21, 21, 22, 22, 23, 23, 24, 24, 24, 25, 25, 25, 25,\n",
       "       26, 26, 26, 26, 27, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 31, 31,\n",
       "       32, 32, 32, 32, 33, 33, 34, 34, 34, 35, 35, 36, 36, 36, 36, 37, 37,\n",
       "       37, 37, 38, 38, 38, 38, 39, 39, 39, 39, 40, 40, 40, 41, 41, 42, 42,\n",
       "       42, 43, 43, 43, 43, 44, 44, 44, 44, 44, 45, 45, 45, 46, 46, 47, 47,\n",
       "       48, 48, 48, 48, 49, 49, 49, 49, 49,  0,  0,  0,  0,  1,  1,  1,  2,\n",
       "        2,  2,  2,  2,  3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,\n",
       "        6,  7,  7,  7,  7,  8,  8,  8,  9,  9,  9, 10, 10, 11, 11, 11, 12,\n",
       "       12, 12, 13, 13, 13, 13, 14, 14, 14, 15, 15, 15, 15, 16, 16, 16, 17,\n",
       "       17, 17, 17, 18, 18, 19, 19, 19, 20, 20, 20, 21, 21, 21, 21, 22, 22,\n",
       "       23, 23, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 27, 27, 27, 28,\n",
       "       28, 29, 29, 30, 30, 31, 31, 31, 31, 32, 32, 32, 32, 33, 33, 34, 34,\n",
       "       34, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 38, 38, 38, 38, 39, 39,\n",
       "       39, 39, 40, 40, 40, 41, 41, 42, 42, 42, 43, 43, 43, 43, 44, 44, 44,\n",
       "       44, 44, 45, 45, 45, 46, 46, 47, 47, 48, 48, 48, 48, 49, 49, 49, 49,\n",
       "       49])"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Yval, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e1678d90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:52:28.213111Z",
     "start_time": "2023-08-13T21:52:28.193798Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list.count() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[214], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: list.count() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58f045",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3bc3f2d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:34:11.070933Z",
     "start_time": "2023-08-13T21:34:11.056659Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[202], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f253263d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:02:12.012032Z",
     "start_time": "2023-08-13T21:02:12.008092Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.61430512, 0.        , 0.        ,\n",
       "       0.39596278, 0.        , 0.        , 0.40874202, 0.        ,\n",
       "       0.        , 0.40810024, 0.        , 0.        , 0.48266869,\n",
       "       0.        , 0.        , 0.65779321, 0.        , 0.        ,\n",
       "       0.81176704, 0.        , 0.        , 0.92339662, 0.        ,\n",
       "       0.        , 0.96071672, 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       0.70816574, 0.        , 0.        , 0.30657587, 0.        ,\n",
       "       0.        , 0.52645834, 0.        , 0.        , 0.65912126,\n",
       "       0.        , 0.        , 0.74968314, 0.        , 0.        ,\n",
       "       0.76095988, 0.        , 0.        , 0.86712809, 0.        ,\n",
       "       0.        , 0.91103094, 0.        , 0.        , 0.92972564,\n",
       "       0.        , 0.        , 0.99377522, 0.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "92e6e2e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T20:07:08.096049Z",
     "start_time": "2023-08-13T20:07:08.091263Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d2e91403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T20:40:08.843345Z",
     "start_time": "2023-08-13T20:40:08.839714Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "287a2639",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T20:42:19.568634Z",
     "start_time": "2023-08-13T20:42:19.564395Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8890ac8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T20:52:21.940891Z",
     "start_time": "2023-08-13T20:51:48.463452Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000 3.898800849914551\n",
      "0001 3.803058624267578\n",
      "0002 3.886780858039856\n",
      "0003 3.5405542850494385\n",
      "0004 3.8846980333328247\n",
      "0005 3.9728771448135376\n",
      "0006 3.5900771617889404\n",
      "0007 3.9532002210617065\n",
      "0008 3.938177227973938\n",
      "0009 4.048365831375122\n",
      "0010 3.615102171897888\n",
      "0011 3.7522424459457397\n",
      "0012 3.909103274345398\n",
      "0013 3.9027684926986694\n",
      "0014 3.885507822036743\n",
      "0015 3.9257211685180664\n",
      "0016 3.282256007194519\n",
      "0017 3.7758527994155884\n",
      "0018 3.873215436935425\n",
      "0019 3.8949038982391357\n",
      "0020 3.8801382780075073\n",
      "0021 3.788564443588257\n",
      "0022 3.5741392374038696\n",
      "0023 3.3994975090026855\n",
      "0024 3.911440849304199\n",
      "0025 3.7547767162323\n",
      "0026 4.029992580413818\n",
      "0027 3.9448060989379883\n",
      "0028 3.910792350769043\n",
      "0029 3.740312933921814\n",
      "0030 3.8987677097320557\n",
      "0031 3.4418601989746094\n",
      "0032 3.28007972240448\n",
      "0033 3.9038991928100586\n",
      "0034 3.888121247291565\n",
      "0035 3.936005473136902\n",
      "0036 3.3792749643325806\n",
      "0037 3.713937997817993\n",
      "0038 3.5628620386123657\n",
      "0039 3.688674569129944\n",
      "0040 3.908714771270752\n",
      "0041 3.925951600074768\n",
      "0042 3.9032832384109497\n",
      "0043 3.8355159759521484\n",
      "0044 3.861657977104187\n",
      "0045 3.5904723405838013\n",
      "0046 3.9303979873657227\n",
      "0047 3.4963732957839966\n",
      "0048 3.408271312713623\n",
      "0049 4.104234457015991\n",
      "0050 3.908795952796936\n",
      "0051 3.979867696762085\n",
      "0052 3.5365536212921143\n",
      "0053 3.777398943901062\n",
      "0054 3.255426287651062\n",
      "0055 4.000001668930054\n",
      "0056 3.769771933555603\n",
      "0057 3.6735295057296753\n",
      "0058 3.9292482137680054\n",
      "0059 3.833427667617798\n",
      "0060 3.8524972200393677\n",
      "0061 3.7670044898986816\n",
      "0062 3.983374238014221\n",
      "0063 3.686607241630554\n",
      "0064 4.000898838043213\n",
      "0065 3.5330151319503784\n",
      "0066 3.72915518283844\n",
      "0067 3.9197007417678833\n",
      "0068 3.7158780097961426\n",
      "0069 3.922991156578064\n",
      "0070 3.54120135307312\n",
      "0071 3.9837945699691772\n",
      "0072 3.5175141096115112\n",
      "0073 3.4284658432006836\n",
      "0074 3.8905351161956787\n",
      "0075 3.911569356918335\n",
      "0076 3.8076270818710327\n",
      "0077 3.90852952003479\n",
      "0078 3.5595375299453735\n",
      "0079 3.843134880065918\n",
      "0080 3.5238864421844482\n",
      "0081 3.7321274280548096\n",
      "0082 3.9117802381515503\n",
      "0083 3.9110502004623413\n",
      "0084 3.900148868560791\n",
      "0085 3.743301033973694\n",
      "0086 3.8975151777267456\n",
      "0087 3.5991064310073853\n",
      "0088 3.8415225744247437\n",
      "0089 3.68539559841156\n",
      "0090 3.674814820289612\n",
      "0091 3.8092721700668335\n",
      "0092 3.9205145835876465\n",
      "0093 3.9077967405319214\n",
      "0094 3.880114436149597\n",
      "0095 3.8321073055267334\n",
      "0096 3.5588834285736084\n",
      "0097 3.900855541229248\n",
      "0098 2.8569464683532715\n",
      "0099 3.1912224292755127\n",
      "0100 3.1881227493286133\n",
      "0101 3.288637399673462\n",
      "0102 3.1372952461242676\n",
      "0103 3.1087543964385986\n",
      "0104 2.8974013328552246\n",
      "0105 3.218998670578003\n",
      "0106 3.186781167984009\n",
      "0107 3.430274486541748\n",
      "0108 3.2336692810058594\n",
      "0109 3.5120043754577637\n",
      "0110 3.3972270488739014\n",
      "0111 3.2348146438598633\n",
      "0112 3.1258881092071533\n",
      "0113 3.1192407608032227\n",
      "0114 3.1357274055480957\n",
      "0115 3.2806396484375\n",
      "0116 3.333399534225464\n",
      "0117 3.3196377754211426\n",
      "0118 3.1955487728118896\n",
      "0119 3.2669906616210938\n",
      "0120 3.1917834281921387\n",
      "0121 3.3143913745880127\n",
      "0122 3.391062021255493\n",
      "0123 3.361448049545288\n",
      "0124 3.2364819049835205\n",
      "0125 3.2788054943084717\n",
      "0126 3.4161739349365234\n",
      "0127 3.2763559818267822\n",
      "0128 3.444265842437744\n",
      "0129 3.3691511154174805\n",
      "0130 3.309950828552246\n",
      "0131 3.1365013122558594\n",
      "0132 3.087808132171631\n",
      "0133 2.5123331546783447\n",
      "0134 3.0719993114471436\n",
      "0135 2.9415979385375977\n",
      "0136 2.8667595386505127\n",
      "0137 2.957545042037964\n",
      "0138 2.709430456161499\n",
      "0139 2.9632041454315186\n",
      "0140 3.014355182647705\n",
      "0141 2.470214366912842\n",
      "0142 2.4964020252227783\n",
      "0143 3.0600056648254395\n",
      "0144 2.773334264755249\n",
      "0145 2.9169540405273438\n",
      "0146 2.8618593215942383\n",
      "0147 2.9135241508483887\n",
      "0148 3.588689684867859\n",
      "0149 3.7039328813552856\n",
      "0150 3.9387197494506836\n",
      "0151 3.8391830921173096\n",
      "0152 3.8894927501678467\n",
      "0153 3.9134968519210815\n",
      "0154 3.8752583265304565\n",
      "0155 3.104026675224304\n",
      "0156 3.9047592878341675\n",
      "0157 4.1123340129852295\n",
      "0158 3.999816656112671\n",
      "0159 3.63451611995697\n",
      "0160 3.252768039703369\n",
      "0161 3.1612491607666016\n",
      "0162 3.5475558042526245\n",
      "0163 3.935612916946411\n",
      "0164 3.739456534385681\n",
      "0165 3.780824065208435\n",
      "0166 3.876420497894287\n",
      "0167 3.6253161430358887\n",
      "0168 3.2914928197860718\n",
      "0169 3.9188530445098877\n",
      "0170 3.7967156171798706\n",
      "0171 3.291629195213318\n",
      "0172 3.8366137742996216\n",
      "0173 4.001960754394531\n",
      "0174 2.942251443862915\n",
      "0175 3.3356679677963257\n",
      "0176 3.7813282012939453\n",
      "0177 3.860199213027954\n",
      "0178 3.395293712615967\n",
      "0179 3.6541738510131836\n",
      "0180 3.8217577934265137\n",
      "0181 3.8576570749282837\n",
      "0182 3.9012110233306885\n",
      "0183 3.8539047241210938\n",
      "0184 3.9040106534957886\n",
      "0185 3.5292296409606934\n",
      "0186 3.5329442024230957\n",
      "0187 3.889161705970764\n",
      "0188 3.688228487968445\n",
      "0189 2.8183741569519043\n",
      "0190 2.812584400177002\n",
      "0191 2.3165905475616455\n",
      "0192 2.8675289154052734\n",
      "0193 2.756605625152588\n",
      "0194 2.7546451091766357\n",
      "0195 3.459845542907715\n",
      "0196 2.7441654205322266\n",
      "0197 3.0567331314086914\n",
      "0198 2.950937271118164\n",
      "0199 2.783646821975708\n",
      "0200 3.1197123527526855\n",
      "0201 2.927121877670288\n",
      "0202 3.0597503185272217\n",
      "0203 2.233685255050659\n",
      "0204 2.6235384941101074\n",
      "0205 2.753307580947876\n",
      "0206 2.9370813369750977\n",
      "0207 2.0394604206085205\n",
      "0208 2.004472494125366\n",
      "0209 2.3843977451324463\n",
      "0210 2.499351978302002\n",
      "0211 2.9396978616714478\n",
      "0212 2.982459545135498\n",
      "0213 2.4946035146713257\n",
      "0214 3.3048324584960938\n",
      "0215 2.988304376602173\n",
      "0216 2.907829999923706\n",
      "0217 3.5671898126602173\n",
      "0218 2.7507866621017456\n",
      "0219 2.6968823671340942\n",
      "0220 3.868654727935791\n",
      "0221 2.4029946327209473\n",
      "0222 3.6933382749557495\n",
      "0223 3.0044811964035034\n",
      "0224 3.858461022377014\n",
      "0225 3.0490232706069946\n",
      "0226 3.3284432888031006\n",
      "0227 3.7886992692947388\n",
      "0228 2.1791250705718994\n",
      "0229 2.0706980228424072\n",
      "0230 2.369703769683838\n",
      "0231 2.537485122680664\n",
      "0232 2.779223680496216\n",
      "0233 2.0138278007507324\n",
      "0234 2.117971181869507\n",
      "0235 2.1079723834991455\n",
      "0236 3.518277406692505\n",
      "0237 2.9867398738861084\n",
      "0238 2.771961212158203\n",
      "0239 3.305688738822937\n",
      "0240 2.676287293434143\n",
      "0241 3.5114505290985107\n",
      "0242 2.139823079109192\n",
      "0243 3.5153714418411255\n",
      "0244 2.9670761823654175\n",
      "0245 1.5037063360214233\n",
      "0246 2.6093223094940186\n",
      "0247 2.729426622390747\n",
      "0248 2.755583882331848\n",
      "0249 2.623753547668457\n",
      "0250 2.3441174030303955\n",
      "0251 2.96156907081604\n",
      "0252 2.691678285598755\n",
      "0253 2.798992872238159\n",
      "Trial 0245 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 100\n",
      "num_filters_2: 25\n",
      "dropout_1: 0.65\n",
      "units: 40\n",
      "dropout_2: 0.4\n",
      "learning_rate: 0.00013960407115272237\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0242\n",
      "Score: 1.5037063360214233\n",
      "Trial 0208 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 50\n",
      "num_filters_2: 100\n",
      "dropout_1: 0.6000000000000001\n",
      "units: 60\n",
      "dropout_2: 0.6000000000000001\n",
      "learning_rate: 0.00022015333534136284\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0207\n",
      "Score: 2.004472494125366\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "Trial 0233 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 25\n",
      "num_filters_2: 25\n",
      "dropout_1: 0.30000000000000004\n",
      "units: 80\n",
      "dropout_2: 0.65\n",
      "learning_rate: 0.00025224242614677007\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0216\n",
      "Score: 2.0138278007507324\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "Trial 0207 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 50\n",
      "num_filters_2: 100\n",
      "dropout_1: 0.6000000000000001\n",
      "units: 60\n",
      "dropout_2: 0.6000000000000001\n",
      "learning_rate: 0.00022015333534136284\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0199\n",
      "Score: 2.0394604206085205\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "Trial 0229 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 50\n",
      "num_filters_2: 50\n",
      "dropout_1: 0.55\n",
      "units: 80\n",
      "dropout_2: 0.1\n",
      "learning_rate: 0.00021979153094558063\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0213\n",
      "Score: 2.0706980228424072\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    }
   ],
   "source": [
    "trials = tuner.oracle.trials\n",
    "\n",
    "# Print out the ID and the score of all trials\n",
    "for trial_id, trial in trials.items():\n",
    "    print(trial_id, trial.score)\n",
    "\n",
    "# Return best 5 trials\n",
    "best_trials = tuner.oracle.get_best_trials(num_trials=5)\n",
    "for trial in best_trials:\n",
    "    trial.summary()\n",
    "    model2 = tuner.load_model(trial)\n",
    "    # Do some stuff to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b822aa9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T10:26:53.274329Z",
     "start_time": "2023-08-14T10:26:53.021857Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 2.0496 - accuracy: 0.6358\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = reconstructed_model.evaluate(Xval, Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d0a00990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T20:53:35.014218Z",
     "start_time": "2023-08-13T20:53:34.828192Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 2.0496 - accuracy: 0.6358\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = best_model.evaluate(Xval, Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "1605e522",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:29:04.023181Z",
     "start_time": "2023-08-14T14:29:04.003458Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[513], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(model\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel 1 accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history['accuracy'])\n",
    "plt.plot(model.history['val_accuracy'])\n",
    "plt.title('Model 1 accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(best_model.history['loss'])\n",
    "plt.plot(best_model.history['val_loss'])\n",
    "plt.title('Model 1 loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "22a7d5eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T07:52:12.250694Z",
     "start_time": "2023-08-14T07:52:03.609007Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/assets\n"
     ]
    }
   ],
   "source": [
    "best_model.save(\"best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "783da957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T10:11:40.191333Z",
     "start_time": "2023-08-14T10:11:32.118214Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reconstructed_model = tf.keras.models.load_model(\"best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9c011d4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T07:54:11.302867Z",
     "start_time": "2023-08-14T07:54:11.289539Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[240], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreconstructed_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'History' object is not callable"
     ]
    }
   ],
   "source": [
    "reconstructed_model.history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e48e53e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:23:10.009167Z",
     "start_time": "2023-08-13T21:23:09.821397Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887f0c96",
   "metadata": {},
   "source": [
    "## Realtime Code Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9d0db29b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T10:38:54.462368Z",
     "start_time": "2023-08-14T10:38:39.922369Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 30, 4)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "18\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "5\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "46\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "46\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "46\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "46\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "46\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "12\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "12\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "12\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "12\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "42\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "path = '/home/kristian/ASL_Citizen/videos/0525121513125173-DARK.mp4'\n",
    "cap = cv2.VideoCapture(path)\n",
    "#cap = cv2.VideoCapture(0)\n",
    "print(frames_from_file(path))\n",
    "\n",
    "sequence = [np.zeros(126)] * 130  # Initialize with 130 zero-filled sequences\n",
    "predictions = []\n",
    "\n",
    "with mp_holistic.Holistic(static_image_mode=False,\n",
    "                          model_complexity=1) as holistic:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "            \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(frame_rgb)\n",
    "        # Left hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "\n",
    "        # Right Hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "                # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence.pop(0)  # Remove the oldest element\n",
    "        \n",
    "        if len(sequence) == 130:\n",
    "            res = reconstructed_model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(np.argmax(res))\n",
    "            predictions.append(np.argmax(res))\n",
    "            \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f6823b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T20:18:08.869606Z",
     "start_time": "2023-08-23T20:17:56.440809Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "26\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "26\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "26\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "26\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "26\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "26\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "26\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "26\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "#path = valdf.Path[9]\n",
    "#path = '/home/kristian/ASL_Citizen/videos/00930662603221255-WHAT FOR.mp4'\n",
    "path = '/home/kristian/WLASL/videos_organized/basketball/05243.mp4'\n",
    "#path = 0\n",
    "cap = cv2.VideoCapture(path)\n",
    "#cap = cv2.VideoCapture(0)\n",
    "#print(frames_from_file(path))\n",
    "\n",
    "sequence = [np.zeros(126)] * 130  # Initialize with 130 zero-filled sequences\n",
    "predictions = []\n",
    "threshold = 0.8\n",
    "\n",
    "with mp_holistic.Holistic(static_image_mode=False,\n",
    "                          model_complexity=1) as holistic:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "            \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(frame_rgb)\n",
    "        # Left hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "\n",
    "        # Right Hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "                # 2. Prediction logic\n",
    "            \n",
    "            # Open the video file\n",
    "        # Initialize an empty list to store the keypoints for each frame\n",
    "        keypoints = []\n",
    "        sequence.append(extract_keypoints(results))\n",
    "        sequence.pop(0)  # Remove the oldest element\n",
    "        sequence = np.array(sequence)\n",
    "     #   sequence = sequence.reshape(1, -1)\n",
    "     #   sequence=scaler.transform(sequence).reshape(130, 126)\n",
    "        sequence = sequence.tolist()\n",
    "        if len(sequence) == 130:\n",
    "            \n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            if res[np.argmax(res)] > threshold:\n",
    "                print(np.argmax(res))\n",
    "                predictions.append(np.argmax(res))\n",
    "            \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6f4bf89d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:25:25.370634Z",
     "start_time": "2023-08-23T22:24:06.379896Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "FOREIGNER\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "FOREIGNER\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "AXE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "FOREIGNER\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "FLOAT\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "FLOAT\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "FLOAT\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "FLOAT\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "FLOAT\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "FLOAT\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "DARK\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "MECHANIC\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ELEVATOR\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "FOREIGNER\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "DOWNSIZE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "FOREIGNER\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "FOREIGNER\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "FOREIGNER\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "FOREIGNER\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "FOREIGNER\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "FOREIGNER\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "DECIDE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "DECIDE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "DECIDE\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "DECIDE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "DECIDE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "DECIDE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "DECIDE\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "DECIDE\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "DECIDE\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "DECIDE\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "DECIDE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "DECIDE\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "DECIDE\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "BASKETBALL\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "BASKETBALL\n"
     ]
    }
   ],
   "source": [
    "#path = valdf.Path[9]\n",
    "#path = '/home/kristian/ASL_Citizen/videos/9161417844146778-WHAT FOR.mp4'\n",
    "#path = '/home/kristian/WLASL/videos_organized/dark/65440.mp4'\n",
    "path = 0\n",
    "cap = cv2.VideoCapture(path)\n",
    "#cap = cv2.VideoCapture(0)\n",
    "#print(frames_from_file(path))\n",
    "\n",
    "sequence = [np.zeros(126)] * 130  # Initialize with 130 zero-filled sequences\n",
    "predictions = []\n",
    "threshold = 0.9\n",
    "\n",
    "with mp_holistic.Holistic(static_image_mode=False,\n",
    "                          model_complexity=1) as holistic:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "            \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(frame_rgb)\n",
    "        # Left hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "\n",
    "        # Right Hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "                # 2. Prediction logic\n",
    "            \n",
    "            # Open the video file\n",
    "        # Initialize an empty list to store the keypoints for each frame\n",
    "        keypoints = []\n",
    "        sequence = np.array(sequence)\n",
    "        sequence = sequence.reshape(1, -1)\n",
    "        sequence = scaler.inverse_transform(sequence).reshape(130, 126)\n",
    "        sequence = sequence.tolist()\n",
    "        sequence.append(extract_keypoints(results))\n",
    "        sequence.pop(0)  # Remove the oldest element\n",
    "        sequence = np.array(sequence)\n",
    "        sequence = sequence.reshape(1, -1)\n",
    "        sequence=scaler.transform(sequence).reshape(130, 126)\n",
    "        sequence = sequence.tolist()\n",
    "        if len(sequence) == 130:\n",
    "            \n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            if res[np.argmax(res)] > threshold:\n",
    "                print(inv_label_map[np.argmax(res)])\n",
    "                predictions.append(np.argmax(res))\n",
    "                frame = cv2.putText(frame,inv_label_map[np.argmax(res)],(10,30),cv2.FONT_HERSHEY_SIMPLEX,1.0,(0, 255, 0), 2)\n",
    "#        frame = cv2.flip(frame, 1)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822e443f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "974ce379",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T08:23:41.927235Z",
     "start_time": "2023-08-23T08:23:41.854302Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m sequence \u001b[38;5;241m=\u001b[39m sequence\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m sequence\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m----> 4\u001b[0m sequence\u001b[38;5;241m=\u001b[39m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m130\u001b[39m, \u001b[38;5;241m126\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:992\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    989\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    991\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m--> 992\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "#sequence = np.array(sequence)\n",
    "sequence = sequence.reshape(1, -1)\n",
    "sequence.shape\n",
    "sequence=scaler.transform(sequence).reshape(130, 126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "77062f00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T08:23:45.646146Z",
     "start_time": "2023-08-23T08:23:45.642488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.17129192e+049, -3.04913669e+046,  1.22797842e+299, ...,\n",
       "         0.00000000e+000,  0.00000000e+000,  0.00000000e+000]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3496d54c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T07:55:35.384109Z",
     "start_time": "2023-08-23T07:55:35.380185Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9a2a7230",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T11:13:06.487350Z",
     "start_time": "2023-08-14T11:13:06.482750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157    file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...\n",
       "158    file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...\n",
       "159    file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...\n",
       "160    file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...\n",
       "161    file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...\n",
       "Name: Path, dtype: object"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf.Path.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "09c8f032",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:16:10.736569Z",
     "start_time": "2023-08-14T14:16:10.732233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.13346792e+049, -3.22915747e+046,  2.01043630e+293, ...,\n",
       "         0.00000000e+000,  0.00000000e+000,  0.00000000e+000]])"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "801f1ee6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T13:24:09.315061Z",
     "start_time": "2023-08-14T13:24:09.308143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.80275307, -0.76500565,  0.15641896, ..., -0.79544123,\n",
       "        -0.6547425 ,  0.61363025],\n",
       "       [-0.80275307, -0.76500565,  0.15641896, ..., -0.79544123,\n",
       "        -0.6547425 ,  0.61363025],\n",
       "       [-0.80275307, -0.76500565,  0.15641896, ..., -0.79544123,\n",
       "        -0.6547425 ,  0.61363025],\n",
       "       ...,\n",
       "       [-0.80275307, -0.76500565,  0.15641896, ..., -0.79544123,\n",
       "        -0.6547425 ,  0.61363025],\n",
       "       [-0.80275307, -0.76500565,  0.15641896, ..., -0.79544123,\n",
       "        -0.6547425 ,  0.61363025],\n",
       "       [-0.80275307, -0.76500565,  0.15641896, ..., -0.79544123,\n",
       "        -0.6547425 ,  0.61363025]])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform(sequence).reshape(130, 126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "c1b7f043",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T12:22:10.730307Z",
     "start_time": "2023-08-14T12:22:10.645703Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_28 (Conv1D)          (None, 129, 100)          25300     \n",
      "                                                                 \n",
      " max_pooling1d_28 (MaxPooli  (None, 64, 100)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_29 (Conv1D)          (None, 63, 25)            5025      \n",
      "                                                                 \n",
      " max_pooling1d_29 (MaxPooli  (None, 31, 25)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 31, 25)            0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 775)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 40)                31040     \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 40)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 50)                2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63415 (247.71 KB)\n",
      "Trainable params: 63415 (247.71 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "act_function = 'selu'\n",
    "model = Sequential(name='sequential')\n",
    "model.add(Conv1D(filters=100,kernel_size=2,activation=act_function,input_shape=(130,126)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=25,kernel_size=2,activation=act_function))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "#        model.add(Conv1D(filters=hp.Choice('num_filters_3',values=[25,50, 100,150],default=50,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "#        model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(.65))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=40,activation=act_function))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "\n",
    "model.compile(Lion(learning_rate=0.00013960407115272237),\n",
    "           loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d325028c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T12:20:40.968833Z",
     "start_time": "2023-08-14T12:20:40.966122Z"
    }
   },
   "outputs": [],
   "source": [
    "def reset_random_seeds():\n",
    "   os.environ['PYTHONHASHSEED']=str(2)\n",
    "   tf.random.set_seed(2)\n",
    "   np.random.seed(2)\n",
    "  # random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "366d0700",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T12:22:15.683212Z",
     "start_time": "2023-08-14T12:22:15.676375Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "15f34bec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T12:20:41.620164Z",
     "start_time": "2023-08-14T12:20:41.614782Z"
    }
   },
   "outputs": [],
   "source": [
    "reset_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "0d1b7352",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T12:22:22.246702Z",
     "start_time": "2023-08-14T12:22:17.433760Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 4.6835 - accuracy: 0.0217 - val_loss: 3.9621 - val_accuracy: 0.0247\n",
      "Epoch 2/5\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 4.1676 - accuracy: 0.0262 - val_loss: 3.9453 - val_accuracy: 0.0185\n",
      "Epoch 3/5\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 4.0481 - accuracy: 0.0258 - val_loss: 3.8856 - val_accuracy: 0.0309\n",
      "Epoch 4/5\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 3.9564 - accuracy: 0.0321 - val_loss: 3.8553 - val_accuracy: 0.0309\n",
      "Epoch 5/5\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 3.8901 - accuracy: 0.0362 - val_loss: 3.8133 - val_accuracy: 0.0679\n"
     ]
    }
   ],
   "source": [
    "History = model.fit(x=Xtrain, y=Ytrain,validation_data= (Xval,Yval), batch_size=96,epochs=5, verbose=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "64b81eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T12:22:03.993402Z",
     "start_time": "2023-08-14T12:22:03.876552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 3.7301 - accuracy: 0.0710\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(Xval, Yval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646d1ed3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Test 2 1D CNN Layers + 3 GRU Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "7bcc6c17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T23:03:36.191782Z",
     "start_time": "2023-08-18T23:03:35.294778Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_68 (Conv1D)          (None, 127, 150)          75750     \n",
      "                                                                 \n",
      " max_pooling1d_68 (MaxPoolin  (None, 31, 150)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_69 (Conv1D)          (None, 28, 100)           60100     \n",
      "                                                                 \n",
      " max_pooling1d_69 (MaxPoolin  (None, 7, 100)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " gru_102 (GRU)               (None, 7, 150)            113400    \n",
      "                                                                 \n",
      " gru_103 (GRU)               (None, 7, 200)            211200    \n",
      "                                                                 \n",
      " gru_104 (GRU)               (None, 100)               90600     \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " flatten_34 (Flatten)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 80)                8080      \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 50)                4050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 563,180\n",
      "Trainable params: 563,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "act_function = 'selu'\n",
    "model = Sequential(name='sequential')\n",
    "model.add(Conv1D(filters=150,kernel_size=4,activation=act_function,input_shape=(130,126)))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Conv1D(filters=100,kernel_size=4,activation=act_function))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(GRU(150,return_sequences=True))\n",
    "model.add(GRU(200,return_sequences=True))\n",
    "model.add(GRU(100))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=80,activation=act_function))\n",
    "model.add(Dropout(.65))\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "\n",
    "model.compile(tf.optimizers.experimental.Nadam(learning_rate=0.0002),\n",
    "           loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d0a94dfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T23:05:21.763920Z",
     "start_time": "2023-08-18T23:03:37.190588Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "26/26 [==============================] - 14s 93ms/step - loss: 3.9566 - accuracy: 0.0203 - val_loss: 3.8417 - val_accuracy: 0.0261\n",
      "Epoch 2/300\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.8492 - accuracy: 0.0461 - val_loss: 3.7791 - val_accuracy: 0.0373\n",
      "Epoch 3/300\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.7827 - accuracy: 0.0577 - val_loss: 3.6928 - val_accuracy: 0.0560\n",
      "Epoch 4/300\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 3.7025 - accuracy: 0.0768 - val_loss: 3.6296 - val_accuracy: 0.0821\n",
      "Epoch 5/300\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.6247 - accuracy: 0.0918 - val_loss: 3.5040 - val_accuracy: 0.1157\n",
      "Epoch 6/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.5450 - accuracy: 0.1188 - val_loss: 3.4345 - val_accuracy: 0.1269\n",
      "Epoch 7/300\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.4724 - accuracy: 0.1250 - val_loss: 3.3438 - val_accuracy: 0.1493\n",
      "Epoch 8/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.3645 - accuracy: 0.1449 - val_loss: 3.2274 - val_accuracy: 0.1343\n",
      "Epoch 9/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.3102 - accuracy: 0.1545 - val_loss: 3.1717 - val_accuracy: 0.1455\n",
      "Epoch 10/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.2169 - accuracy: 0.1640 - val_loss: 3.0527 - val_accuracy: 0.1604\n",
      "Epoch 11/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 3.1476 - accuracy: 0.1848 - val_loss: 2.9855 - val_accuracy: 0.1866\n",
      "Epoch 12/300\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 3.0554 - accuracy: 0.2002 - val_loss: 2.8950 - val_accuracy: 0.2239\n",
      "Epoch 13/300\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 2.9741 - accuracy: 0.2193 - val_loss: 2.7806 - val_accuracy: 0.2500\n",
      "Epoch 14/300\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 2.9061 - accuracy: 0.2222 - val_loss: 2.7522 - val_accuracy: 0.2425\n",
      "Epoch 15/300\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 2.8556 - accuracy: 0.2425 - val_loss: 2.6508 - val_accuracy: 0.2388\n",
      "Epoch 16/300\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 2.8040 - accuracy: 0.2471 - val_loss: 2.5614 - val_accuracy: 0.3022\n",
      "Epoch 17/300\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 2.7318 - accuracy: 0.2533 - val_loss: 2.4840 - val_accuracy: 0.3246\n",
      "Epoch 18/300\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 2.6649 - accuracy: 0.2824 - val_loss: 2.4613 - val_accuracy: 0.3433\n",
      "Epoch 19/300\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 2.5898 - accuracy: 0.3015 - val_loss: 2.4013 - val_accuracy: 0.3433\n",
      "Epoch 20/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 2.5090 - accuracy: 0.3185 - val_loss: 2.3894 - val_accuracy: 0.3657\n",
      "Epoch 21/300\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 2.4573 - accuracy: 0.3260 - val_loss: 2.3327 - val_accuracy: 0.3582\n",
      "Epoch 22/300\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 2.3909 - accuracy: 0.3418 - val_loss: 2.2367 - val_accuracy: 0.3731\n",
      "Epoch 23/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 2.3307 - accuracy: 0.3642 - val_loss: 2.1555 - val_accuracy: 0.4179\n",
      "Epoch 24/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 2.2734 - accuracy: 0.3708 - val_loss: 2.1065 - val_accuracy: 0.4291\n",
      "Epoch 25/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 2.2067 - accuracy: 0.3833 - val_loss: 2.0630 - val_accuracy: 0.4366\n",
      "Epoch 26/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 2.1560 - accuracy: 0.3978 - val_loss: 2.0626 - val_accuracy: 0.4590\n",
      "Epoch 27/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 2.0775 - accuracy: 0.4252 - val_loss: 2.0461 - val_accuracy: 0.4254\n",
      "Epoch 28/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 2.0791 - accuracy: 0.4165 - val_loss: 1.9275 - val_accuracy: 0.4963\n",
      "Epoch 29/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.9768 - accuracy: 0.4481 - val_loss: 1.8239 - val_accuracy: 0.5037\n",
      "Epoch 30/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.9966 - accuracy: 0.4473 - val_loss: 1.8078 - val_accuracy: 0.5037\n",
      "Epoch 31/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.9059 - accuracy: 0.4626 - val_loss: 1.9094 - val_accuracy: 0.4813\n",
      "Epoch 32/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.9306 - accuracy: 0.4576 - val_loss: 1.8022 - val_accuracy: 0.4888\n",
      "Epoch 33/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.7977 - accuracy: 0.4805 - val_loss: 1.7507 - val_accuracy: 0.5373\n",
      "Epoch 34/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.7382 - accuracy: 0.4983 - val_loss: 1.7924 - val_accuracy: 0.5149\n",
      "Epoch 35/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.7502 - accuracy: 0.4963 - val_loss: 1.7450 - val_accuracy: 0.5448\n",
      "Epoch 36/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.6901 - accuracy: 0.5083 - val_loss: 1.6711 - val_accuracy: 0.5187\n",
      "Epoch 37/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.6163 - accuracy: 0.5365 - val_loss: 1.6697 - val_accuracy: 0.5709\n",
      "Epoch 38/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.5886 - accuracy: 0.5527 - val_loss: 1.5711 - val_accuracy: 0.5784\n",
      "Epoch 39/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.5090 - accuracy: 0.5743 - val_loss: 1.5478 - val_accuracy: 0.5858\n",
      "Epoch 40/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.4928 - accuracy: 0.5594 - val_loss: 1.5375 - val_accuracy: 0.5672\n",
      "Epoch 41/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.4472 - accuracy: 0.5793 - val_loss: 1.6146 - val_accuracy: 0.5299\n",
      "Epoch 42/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.4298 - accuracy: 0.5914 - val_loss: 1.4627 - val_accuracy: 0.6045\n",
      "Epoch 43/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.4044 - accuracy: 0.5885 - val_loss: 1.4576 - val_accuracy: 0.6119\n",
      "Epoch 44/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.3507 - accuracy: 0.6055 - val_loss: 1.4886 - val_accuracy: 0.5560\n",
      "Epoch 45/300\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 1.3228 - accuracy: 0.6113 - val_loss: 1.4245 - val_accuracy: 0.6157\n",
      "Epoch 46/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.3058 - accuracy: 0.6188 - val_loss: 1.4654 - val_accuracy: 0.5858\n",
      "Epoch 47/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.2323 - accuracy: 0.6474 - val_loss: 1.3989 - val_accuracy: 0.6157\n",
      "Epoch 48/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 1.1909 - accuracy: 0.6566 - val_loss: 1.4508 - val_accuracy: 0.5597\n",
      "Epoch 49/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.1458 - accuracy: 0.6736 - val_loss: 1.4363 - val_accuracy: 0.5896\n",
      "Epoch 50/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.2042 - accuracy: 0.6453 - val_loss: 1.4063 - val_accuracy: 0.6269\n",
      "Epoch 51/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.1237 - accuracy: 0.6836 - val_loss: 1.3621 - val_accuracy: 0.6157\n",
      "Epoch 52/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.0948 - accuracy: 0.6806 - val_loss: 1.3268 - val_accuracy: 0.6604\n",
      "Epoch 53/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.0901 - accuracy: 0.6898 - val_loss: 1.3445 - val_accuracy: 0.6157\n",
      "Epoch 54/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.0317 - accuracy: 0.7027 - val_loss: 1.2750 - val_accuracy: 0.6604\n",
      "Epoch 55/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 1.0234 - accuracy: 0.6919 - val_loss: 1.3348 - val_accuracy: 0.6530\n",
      "Epoch 56/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.9834 - accuracy: 0.7122 - val_loss: 1.4362 - val_accuracy: 0.5858\n",
      "Epoch 57/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.0060 - accuracy: 0.7114 - val_loss: 1.3261 - val_accuracy: 0.6343\n",
      "Epoch 58/300\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.9164 - accuracy: 0.7317 - val_loss: 1.4695 - val_accuracy: 0.5784\n",
      "Epoch 59/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.0211 - accuracy: 0.6985 - val_loss: 1.3322 - val_accuracy: 0.6269\n",
      "Epoch 60/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.8701 - accuracy: 0.7471 - val_loss: 1.3143 - val_accuracy: 0.6418\n",
      "Epoch 61/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.8640 - accuracy: 0.7438 - val_loss: 1.2905 - val_accuracy: 0.6306\n",
      "Epoch 62/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.8291 - accuracy: 0.7587 - val_loss: 1.2541 - val_accuracy: 0.6343\n",
      "Epoch 63/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.8035 - accuracy: 0.7616 - val_loss: 1.3047 - val_accuracy: 0.6530\n",
      "Epoch 64/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.7615 - accuracy: 0.7762 - val_loss: 1.2145 - val_accuracy: 0.6679\n",
      "Epoch 65/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.7367 - accuracy: 0.7811 - val_loss: 1.1632 - val_accuracy: 0.6828\n",
      "Epoch 66/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.7237 - accuracy: 0.7845 - val_loss: 1.2347 - val_accuracy: 0.6455\n",
      "Epoch 67/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6978 - accuracy: 0.8027 - val_loss: 1.2911 - val_accuracy: 0.6567\n",
      "Epoch 68/300\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.7324 - accuracy: 0.7853 - val_loss: 1.2509 - val_accuracy: 0.6828\n",
      "Epoch 69/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.7285 - accuracy: 0.7861 - val_loss: 1.1964 - val_accuracy: 0.6828\n",
      "Epoch 70/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6811 - accuracy: 0.7928 - val_loss: 1.2925 - val_accuracy: 0.6716\n",
      "Epoch 71/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6561 - accuracy: 0.7998 - val_loss: 1.1524 - val_accuracy: 0.7015\n",
      "Epoch 72/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6391 - accuracy: 0.8148 - val_loss: 1.2341 - val_accuracy: 0.6604\n",
      "Epoch 73/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6225 - accuracy: 0.8144 - val_loss: 1.1907 - val_accuracy: 0.6866\n",
      "Epoch 74/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.6343 - accuracy: 0.8194 - val_loss: 1.1436 - val_accuracy: 0.6866\n",
      "Epoch 75/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.5787 - accuracy: 0.8293 - val_loss: 1.2021 - val_accuracy: 0.6754\n",
      "Epoch 76/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.5697 - accuracy: 0.8306 - val_loss: 1.1572 - val_accuracy: 0.6866\n",
      "Epoch 77/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.5704 - accuracy: 0.8360 - val_loss: 1.1298 - val_accuracy: 0.7015\n",
      "Epoch 78/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.5346 - accuracy: 0.8455 - val_loss: 1.1836 - val_accuracy: 0.6866\n",
      "Epoch 79/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.5044 - accuracy: 0.8559 - val_loss: 1.2127 - val_accuracy: 0.6604\n",
      "Epoch 80/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.4764 - accuracy: 0.8700 - val_loss: 1.1670 - val_accuracy: 0.6866\n",
      "Epoch 81/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.4827 - accuracy: 0.8704 - val_loss: 1.2215 - val_accuracy: 0.6716\n",
      "Epoch 82/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.4803 - accuracy: 0.8605 - val_loss: 1.1348 - val_accuracy: 0.6940\n",
      "Epoch 83/300\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.4770 - accuracy: 0.8679 - val_loss: 1.2223 - val_accuracy: 0.6716\n",
      "Epoch 84/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.4773 - accuracy: 0.8534 - val_loss: 1.1570 - val_accuracy: 0.7015\n",
      "Epoch 85/300\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.4597 - accuracy: 0.8746 - val_loss: 1.1506 - val_accuracy: 0.6754\n",
      "Epoch 86/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.4474 - accuracy: 0.8713 - val_loss: 1.1866 - val_accuracy: 0.6679\n",
      "Epoch 87/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.4357 - accuracy: 0.8800 - val_loss: 1.1822 - val_accuracy: 0.6978\n",
      "Epoch 88/300\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.4411 - accuracy: 0.8708 - val_loss: 1.1403 - val_accuracy: 0.7015\n",
      "Epoch 89/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.4146 - accuracy: 0.8850 - val_loss: 1.2324 - val_accuracy: 0.6866\n",
      "Epoch 90/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.4023 - accuracy: 0.8858 - val_loss: 1.2020 - val_accuracy: 0.6866\n",
      "Epoch 91/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3746 - accuracy: 0.8983 - val_loss: 1.2814 - val_accuracy: 0.6604\n",
      "Epoch 92/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.4005 - accuracy: 0.8916 - val_loss: 1.2207 - val_accuracy: 0.6978\n",
      "Epoch 93/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.3515 - accuracy: 0.9032 - val_loss: 1.1304 - val_accuracy: 0.7127\n",
      "Epoch 94/300\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.3772 - accuracy: 0.8953 - val_loss: 1.3141 - val_accuracy: 0.6791\n",
      "Epoch 95/300\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3716 - accuracy: 0.8900 - val_loss: 1.1742 - val_accuracy: 0.7127\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[253], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m History \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/engine/training.py:1624\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1620\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1621\u001b[0m     }\n\u001b[1;32m   1622\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[0;32m-> 1624\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1625\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/callbacks.py:448\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    446\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_logs(logs)\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 448\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/callbacks.py:1092\u001b[0m, in \u001b[0;36mProgbarLogger.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_epoch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1092\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_finalize_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._finalize_progbar\u001b[0;34m(self, logs, counter)\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m counter \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget\n\u001b[0;32m-> 1169\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/utils/generic_utils.py:1051\u001b[0m, in \u001b[0;36mProgbar.update\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m   1048\u001b[0m         info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1050\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m info\n\u001b[0;32m-> 1051\u001b[0m     \u001b[43mio_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_break\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/utils/io_utils.py:80\u001b[0m, in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(message)\n\u001b[0;32m---> 80\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(message)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/ipykernel/iostream.py:564\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(evt\u001b[38;5;241m.\u001b[39mset)\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mevt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush_timeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    565\u001b[0m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOStream.flush timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39m__stderr__)\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "History = model.fit(x=Xtrain, y=Ytrain,validation_split=.1, batch_size=96,epochs=300, verbose=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "45155f23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T22:29:46.342884Z",
     "start_time": "2023-08-18T22:29:46.110755Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 0.9502 - accuracy: 0.8025\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(Xval, Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c18adb29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T22:29:50.401089Z",
     "start_time": "2023-08-18T22:29:50.398665Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "6bdf749d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T22:43:42.198074Z",
     "start_time": "2023-08-18T22:43:37.538206Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 10ms/step\n",
      "11/11 [==============================] - 0s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93         8\n",
      "           1       0.80      0.67      0.73         6\n",
      "           2       1.00      1.00      1.00        10\n",
      "           3       0.83      0.50      0.62        10\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       0.78      0.88      0.82         8\n",
      "           6       0.43      1.00      0.60         6\n",
      "           7       0.73      1.00      0.84         8\n",
      "           8       0.80      0.67      0.73         6\n",
      "           9       0.62      0.83      0.71         6\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       0.62      0.83      0.71         6\n",
      "          12       0.75      1.00      0.86         6\n",
      "          13       1.00      0.62      0.77         8\n",
      "          14       0.67      0.67      0.67         6\n",
      "          15       1.00      0.62      0.77         8\n",
      "          16       1.00      0.83      0.91         6\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       0.60      0.75      0.67         4\n",
      "          19       1.00      1.00      1.00         6\n",
      "          20       0.80      0.67      0.73         6\n",
      "          21       0.67      1.00      0.80         8\n",
      "          22       0.80      1.00      0.89         4\n",
      "          23       0.17      0.25      0.20         4\n",
      "          24       0.80      0.67      0.73         6\n",
      "          25       1.00      0.88      0.93         8\n",
      "          26       0.80      1.00      0.89         8\n",
      "          27       1.00      0.83      0.91         6\n",
      "          28       1.00      0.75      0.86         4\n",
      "          29       1.00      0.50      0.67         4\n",
      "          30       0.67      0.50      0.57         4\n",
      "          31       0.71      0.62      0.67         8\n",
      "          32       0.80      0.50      0.62         8\n",
      "          33       0.67      1.00      0.80         4\n",
      "          34       1.00      1.00      1.00         6\n",
      "          35       1.00      1.00      1.00         4\n",
      "          36       0.88      0.88      0.88         8\n",
      "          37       0.75      0.75      0.75         8\n",
      "          38       0.89      1.00      0.94         8\n",
      "          39       0.78      0.88      0.82         8\n",
      "          40       0.86      1.00      0.92         6\n",
      "          41       1.00      0.50      0.67         4\n",
      "          42       0.67      1.00      0.80         6\n",
      "          43       1.00      1.00      1.00         8\n",
      "          44       0.88      0.70      0.78        10\n",
      "          45       0.00      0.00      0.00         6\n",
      "          46       1.00      0.25      0.40         4\n",
      "          47       0.80      1.00      0.89         4\n",
      "          48       0.88      0.88      0.88         8\n",
      "          49       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.80       324\n",
      "   macro avg       0.82      0.79      0.78       324\n",
      "weighted avg       0.82      0.80      0.80       324\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(np.argmax(Yval, axis=1), np.argmax(model.predict(Xval), axis=1))\n",
    "\n",
    "sns.heatmap(cm, annot = True)\n",
    "\n",
    "print(classification_report(np.argmax(Yval, axis=1), np.argmax(model.predict(Xval), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "afbb6f8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T22:42:48.259795Z",
     "start_time": "2023-08-18T22:42:48.054303Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0, 23,  0,  0, 39,  1,  1,  2,  2,  2,  2,  2,  6,  3,  3,  3,  3,\n",
       "        4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,  7,  7,  8,  8, 33,  9,\n",
       "        9,  9, 10, 10, 11, 11, 11, 12, 12, 12,  8, 13, 31, 13, 45, 37, 14,\n",
       "       23, 15, 21, 15, 16, 16, 16, 17, 17, 17, 17,  5, 18, 19, 19, 19, 20,\n",
       "        7, 20, 21, 21, 21, 21, 22, 22, 24, 12, 24, 42, 24, 25, 25,  7, 25,\n",
       "       26, 26, 26, 26, 27, 27, 27, 28, 28, 29, 26, 21, 30, 31, 48, 31, 31,\n",
       "       11, 32, 32,  3, 33, 33, 34, 34, 34, 35, 35, 36, 45, 36, 36, 37, 14,\n",
       "       37, 37, 38, 38, 38, 38, 39, 39,  1, 39, 40, 40, 40, 18, 41, 42, 42,\n",
       "       42, 43, 43, 43, 43, 23, 44, 44, 40, 44,  6, 23,  6, 14,  9, 47, 47,\n",
       "       48, 48, 48, 48, 49, 49, 49, 49, 49,  0,  0,  0,  0, 39,  1,  1,  2,\n",
       "        2,  2,  2,  2,  6,  3,  6, 38,  6,  4,  4,  5,  5, 11,  5,  6,  6,\n",
       "        6,  7,  7,  7,  7,  8,  8, 33,  9, 42,  9, 10, 10, 11, 11, 49, 12,\n",
       "       12, 12, 13, 13, 13, 31, 14, 14, 14, 15, 15, 37, 15, 16, 16, 32, 17,\n",
       "       17, 17, 17, 18, 18, 19, 19, 19, 20, 21, 20, 21, 21, 21, 21, 22, 22,\n",
       "       23, 12, 24, 42, 24, 25, 25, 25, 25, 26, 26, 26, 26, 30, 27, 27,  5,\n",
       "       28, 29, 26, 20, 30,  7, 22, 31, 31, 11, 32, 32,  6, 33, 33, 34, 34,\n",
       "       34, 35, 35, 36, 36, 36, 36, 37, 37,  9, 37, 38, 38, 38, 38, 39, 39,\n",
       "       39, 39, 40, 40, 40, 44, 41, 42, 42, 42, 43, 43, 43, 43, 44, 44, 44,\n",
       "       21, 44, 36, 23,  9, 46, 18, 47, 47, 48,  6, 48, 48, 49, 49, 47, 49,\n",
       "       49])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(Xval), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "03930813",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T22:42:16.854733Z",
     "start_time": "2023-08-18T22:42:16.850578Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  1,  1,  1,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,\n",
       "        4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,  7,  7,  8,  8,  8,  9,\n",
       "        9,  9, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14,\n",
       "       15, 15, 15, 15, 16, 16, 16, 17, 17, 17, 17, 18, 18, 19, 19, 19, 20,\n",
       "       20, 20, 21, 21, 21, 21, 22, 22, 23, 23, 24, 24, 24, 25, 25, 25, 25,\n",
       "       26, 26, 26, 26, 27, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 31, 31,\n",
       "       32, 32, 32, 32, 33, 33, 34, 34, 34, 35, 35, 36, 36, 36, 36, 37, 37,\n",
       "       37, 37, 38, 38, 38, 38, 39, 39, 39, 39, 40, 40, 40, 41, 41, 42, 42,\n",
       "       42, 43, 43, 43, 43, 44, 44, 44, 44, 44, 45, 45, 45, 46, 46, 47, 47,\n",
       "       48, 48, 48, 48, 49, 49, 49, 49, 49,  0,  0,  0,  0,  1,  1,  1,  2,\n",
       "        2,  2,  2,  2,  3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,\n",
       "        6,  7,  7,  7,  7,  8,  8,  8,  9,  9,  9, 10, 10, 11, 11, 11, 12,\n",
       "       12, 12, 13, 13, 13, 13, 14, 14, 14, 15, 15, 15, 15, 16, 16, 16, 17,\n",
       "       17, 17, 17, 18, 18, 19, 19, 19, 20, 20, 20, 21, 21, 21, 21, 22, 22,\n",
       "       23, 23, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 27, 27, 27, 28,\n",
       "       28, 29, 29, 30, 30, 31, 31, 31, 31, 32, 32, 32, 32, 33, 33, 34, 34,\n",
       "       34, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 38, 38, 38, 38, 39, 39,\n",
       "       39, 39, 40, 40, 40, 41, 41, 42, 42, 42, 43, 43, 43, 43, 44, 44, 44,\n",
       "       44, 44, 45, 45, 45, 46, 46, 47, 47, 48, 48, 48, 48, 49, 49, 49, 49,\n",
       "       49])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Yval, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952060fd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Hyperparameter Tunning 2 1D CNN Layers + 3 GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f604cb0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T23:11:32.612163Z",
     "start_time": "2023-08-18T23:11:32.184012Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_362142/1222377179.py:2: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import Hyperband\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import HyperModel\n",
    "from kerastuner.tuners import Hyperband\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c4097b77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T05:52:09.651732Z",
     "start_time": "2023-08-19T05:52:09.642633Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SpatialDropout1D, GRU\n",
    "from keras_tuner import HyperModel\n",
    "from kerastuner.tuners import Hyperband\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        act_function = hp.Choice('dense_activation',values=['selu','LeakyReLU','gelu','elu'],default='selu')\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=hp.Choice('num_filters_1',values=[25,50,75, 100,150],default=150,),kernel_size=hp.Choice('kernel_1',values=[2,3,4,5],default=3,),activation=act_function,input_shape=self.input_shape))\n",
    "        model.add(MaxPooling1D(pool_size=hp.Choice('pool_1',values=[2,3,4,5],default=3,)))\n",
    "        model.add(Conv1D(filters=hp.Choice('num_filters_2',values=[25,50,75, 100,150],default=150,),kernel_size=hp.Choice('kernel_2',values=[2,3,4,5],default=3,),activation=act_function))\n",
    "        model.add(MaxPooling1D(pool_size=hp.Choice('pool_2',values=[2,3,4,5],default=3,)))\n",
    "#        model.add(Conv1D(filters=hp.Choice('num_filters_3',values=[25,50, 100,150],default=50,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "#        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(GRU(units=hp.Int('units_1',min_value=50,max_value=200,step=50,default=200),return_sequences=True))\n",
    "        model.add(GRU(units=hp.Int('units_2',min_value=50,max_value=200,step=50,default=150),return_sequences=True))\n",
    "        model.add(GRU(units=hp.Int('units_3',min_value=50,max_value=200,step=50,default=100),return_sequences=True))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_1',min_value=0.0,max_value=0.7,default=0.65,step=0.05,)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=hp.Int('units_4',min_value=20,max_value=120,step=20,default=40),activation=act_function))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_2',min_value=0.0,max_value=0.7,default=0.0,step=0.05,)))\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(tf.optimizers.experimental.Nadam(hp.Float('learning_rate',min_value=1e-7,max_value=1e-4,sampling='LOG',default=0.00002)),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "hypermodel = CNNHyperModel(input_shape=(130,126), num_classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e255405c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T05:52:17.416122Z",
     "start_time": "2023-08-19T05:52:16.799194Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "HYPERBAND_MAX_EPOCHS = 300\n",
    "#MAX_TRIALS = 20\n",
    "EXECUTION_PER_TRIAL = 2\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    max_epochs=HYPERBAND_MAX_EPOCHS,\n",
    "    objective='val_loss',\n",
    "    seed=10,\n",
    "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "    directory='/media/kristian/HDD/ASL_Citizen/Mediapipe/hyperband/',\n",
    "    project_name='2CNN-3GRU',\n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b3a38f0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T05:52:20.068211Z",
     "start_time": "2023-08-19T05:52:20.064604Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 14\n",
      "dense_activation (Choice)\n",
      "{'default': 'selu', 'conditions': [], 'values': ['selu', 'LeakyReLU', 'gelu', 'elu'], 'ordered': False}\n",
      "num_filters_1 (Choice)\n",
      "{'default': 150, 'conditions': [], 'values': [25, 50, 75, 100, 150], 'ordered': True}\n",
      "kernel_1 (Choice)\n",
      "{'default': 3, 'conditions': [], 'values': [2, 3, 4, 5], 'ordered': True}\n",
      "pool_1 (Choice)\n",
      "{'default': 3, 'conditions': [], 'values': [2, 3, 4, 5], 'ordered': True}\n",
      "num_filters_2 (Choice)\n",
      "{'default': 150, 'conditions': [], 'values': [25, 50, 75, 100, 150], 'ordered': True}\n",
      "kernel_2 (Choice)\n",
      "{'default': 3, 'conditions': [], 'values': [2, 3, 4, 5], 'ordered': True}\n",
      "pool_2 (Choice)\n",
      "{'default': 3, 'conditions': [], 'values': [2, 3, 4, 5], 'ordered': True}\n",
      "units_1 (Int)\n",
      "{'default': 200, 'conditions': [], 'min_value': 50, 'max_value': 200, 'step': 50, 'sampling': 'linear'}\n",
      "units_2 (Int)\n",
      "{'default': 150, 'conditions': [], 'min_value': 50, 'max_value': 200, 'step': 50, 'sampling': 'linear'}\n",
      "units_3 (Int)\n",
      "{'default': 100, 'conditions': [], 'min_value': 50, 'max_value': 200, 'step': 50, 'sampling': 'linear'}\n",
      "dropout_1 (Float)\n",
      "{'default': 0.65, 'conditions': [], 'min_value': 0.0, 'max_value': 0.7, 'step': 0.05, 'sampling': 'linear'}\n",
      "units_4 (Int)\n",
      "{'default': 40, 'conditions': [], 'min_value': 20, 'max_value': 120, 'step': 20, 'sampling': 'linear'}\n",
      "dropout_2 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.7, 'step': 0.05, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 2e-05, 'conditions': [], 'min_value': 1e-07, 'max_value': 0.0001, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "80a11182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T05:52:29.678992Z",
     "start_time": "2023-08-19T05:52:29.676257Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\",patience=30,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "338a1f9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T05:52:30.921380Z",
     "start_time": "2023-08-19T05:52:30.919104Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8510ca00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T16:19:40.897421Z",
     "start_time": "2023-08-19T05:52:32.234676Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 725 Complete [00h 16m 39s]\n",
      "val_loss: 3.8870142698287964\n",
      "\n",
      "Best val_loss So Far: 1.0019769072532654\n",
      "Total elapsed time: 10h 27m 09s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(Xtrain, Ytrain, epochs=1000, validation_data=(Xval,Yval),batch_size=96,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "efac4a43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T16:38:42.439247Z",
     "start_time": "2023-08-19T16:38:37.762173Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4f5488a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T16:39:00.284509Z",
     "start_time": "2023-08-19T16:39:00.277484Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in /media/kristian/HDD/ASL_Citizen/Mediapipe/hyperband/2CNN-3GRU\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 0423 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 75\n",
      "kernel_1: 4\n",
      "pool_1: 4\n",
      "num_filters_2: 100\n",
      "kernel_2: 2\n",
      "pool_2: 2\n",
      "units_1: 50\n",
      "units_2: 100\n",
      "units_3: 50\n",
      "dropout_1: 0.0\n",
      "units_4: 100\n",
      "dropout_2: 0.45\n",
      "learning_rate: 9.32064685337975e-05\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 5\n",
      "tuner/round: 4\n",
      "tuner/trial_id: 0414\n",
      "Score: 1.0019769072532654\n",
      "\n",
      "Trial 0426 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 75\n",
      "kernel_1: 4\n",
      "pool_1: 4\n",
      "num_filters_2: 100\n",
      "kernel_2: 2\n",
      "pool_2: 2\n",
      "units_1: 50\n",
      "units_2: 100\n",
      "units_3: 50\n",
      "dropout_1: 0.0\n",
      "units_4: 100\n",
      "dropout_2: 0.45\n",
      "learning_rate: 9.32064685337975e-05\n",
      "tuner/epochs: 300\n",
      "tuner/initial_epoch: 100\n",
      "tuner/bracket: 5\n",
      "tuner/round: 5\n",
      "tuner/trial_id: 0423\n",
      "Score: 1.0033312439918518\n",
      "\n",
      "Trial 0670 summary\n",
      "Hyperparameters:\n",
      "dense_activation: LeakyReLU\n",
      "num_filters_1: 100\n",
      "kernel_1: 3\n",
      "pool_1: 3\n",
      "num_filters_2: 150\n",
      "kernel_2: 5\n",
      "pool_2: 2\n",
      "units_1: 100\n",
      "units_2: 50\n",
      "units_3: 50\n",
      "dropout_1: 0.05\n",
      "units_4: 80\n",
      "dropout_2: 0.65\n",
      "learning_rate: 8.01039750969662e-05\n",
      "tuner/epochs: 300\n",
      "tuner/initial_epoch: 100\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0666\n",
      "Score: 1.0286853909492493\n",
      "\n",
      "Trial 0599 summary\n",
      "Hyperparameters:\n",
      "dense_activation: elu\n",
      "num_filters_1: 150\n",
      "kernel_1: 2\n",
      "pool_1: 3\n",
      "num_filters_2: 100\n",
      "kernel_2: 2\n",
      "pool_2: 5\n",
      "units_1: 100\n",
      "units_2: 200\n",
      "units_3: 200\n",
      "dropout_1: 0.45\n",
      "units_4: 120\n",
      "dropout_2: 0.45\n",
      "learning_rate: 5.696733365822847e-05\n",
      "tuner/epochs: 300\n",
      "tuner/initial_epoch: 100\n",
      "tuner/bracket: 4\n",
      "tuner/round: 4\n",
      "tuner/trial_id: 0595\n",
      "Score: 1.0638198256492615\n",
      "\n",
      "Trial 0598 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 100\n",
      "kernel_1: 2\n",
      "pool_1: 2\n",
      "num_filters_2: 75\n",
      "kernel_2: 3\n",
      "pool_2: 5\n",
      "units_1: 100\n",
      "units_2: 150\n",
      "units_3: 150\n",
      "dropout_1: 0.05\n",
      "units_4: 60\n",
      "dropout_2: 0.30000000000000004\n",
      "learning_rate: 6.58719081561856e-05\n",
      "tuner/epochs: 300\n",
      "tuner/initial_epoch: 100\n",
      "tuner/bracket: 4\n",
      "tuner/round: 4\n",
      "tuner/trial_id: 0593\n",
      "Score: 1.1076378226280212\n",
      "\n",
      "Trial 0593 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 100\n",
      "kernel_1: 2\n",
      "pool_1: 2\n",
      "num_filters_2: 75\n",
      "kernel_2: 3\n",
      "pool_2: 5\n",
      "units_1: 100\n",
      "units_2: 150\n",
      "units_3: 150\n",
      "dropout_1: 0.05\n",
      "units_4: 60\n",
      "dropout_2: 0.30000000000000004\n",
      "learning_rate: 6.58719081561856e-05\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 4\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0580\n",
      "Score: 1.1089742183685303\n",
      "\n",
      "Trial 0666 summary\n",
      "Hyperparameters:\n",
      "dense_activation: LeakyReLU\n",
      "num_filters_1: 100\n",
      "kernel_1: 3\n",
      "pool_1: 3\n",
      "num_filters_2: 150\n",
      "kernel_2: 5\n",
      "pool_2: 2\n",
      "units_1: 100\n",
      "units_2: 50\n",
      "units_3: 50\n",
      "dropout_1: 0.05\n",
      "units_4: 80\n",
      "dropout_2: 0.65\n",
      "learning_rate: 8.01039750969662e-05\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0651\n",
      "Score: 1.1181127429008484\n",
      "\n",
      "Trial 0595 summary\n",
      "Hyperparameters:\n",
      "dense_activation: elu\n",
      "num_filters_1: 150\n",
      "kernel_1: 2\n",
      "pool_1: 3\n",
      "num_filters_2: 100\n",
      "kernel_2: 2\n",
      "pool_2: 5\n",
      "units_1: 100\n",
      "units_2: 200\n",
      "units_3: 200\n",
      "dropout_1: 0.45\n",
      "units_4: 120\n",
      "dropout_2: 0.45\n",
      "learning_rate: 5.696733365822847e-05\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 4\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0583\n",
      "Score: 1.123171091079712\n",
      "\n",
      "Trial 0596 summary\n",
      "Hyperparameters:\n",
      "dense_activation: elu\n",
      "num_filters_1: 150\n",
      "kernel_1: 2\n",
      "pool_1: 2\n",
      "num_filters_2: 100\n",
      "kernel_2: 5\n",
      "pool_2: 3\n",
      "units_1: 200\n",
      "units_2: 100\n",
      "units_3: 150\n",
      "dropout_1: 0.5\n",
      "units_4: 120\n",
      "dropout_2: 0.45\n",
      "learning_rate: 3.094308681066267e-05\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 4\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0584\n",
      "Score: 1.1272169351577759\n",
      "\n",
      "Trial 0715 summary\n",
      "Hyperparameters:\n",
      "dense_activation: gelu\n",
      "num_filters_1: 25\n",
      "kernel_1: 2\n",
      "pool_1: 4\n",
      "num_filters_2: 50\n",
      "kernel_2: 2\n",
      "pool_2: 2\n",
      "units_1: 200\n",
      "units_2: 150\n",
      "units_3: 200\n",
      "dropout_1: 0.0\n",
      "units_4: 120\n",
      "dropout_2: 0.65\n",
      "learning_rate: 3.0034861977052257e-05\n",
      "tuner/epochs: 300\n",
      "tuner/initial_epoch: 100\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0704\n",
      "Score: 1.13815438747406\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fb231c90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T16:39:11.727478Z",
     "start_time": "2023-08-19T16:39:09.847740Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 10ms/step - loss: 1.0014 - accuracy: 0.7623\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = best_model.evaluate(Xval, Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30ad169b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T05:35:57.698222Z",
     "start_time": "2023-08-15T05:35:56.464419Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04cd60e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T05:36:04.791290Z",
     "start_time": "2023-08-15T05:35:59.339639Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 9ms/step\n",
      "11/11 [==============================] - 0s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88         8\n",
      "           1       0.80      0.67      0.73         6\n",
      "           2       0.91      1.00      0.95        10\n",
      "           3       0.88      0.70      0.78        10\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       0.67      1.00      0.80         8\n",
      "           6       0.45      0.83      0.59         6\n",
      "           7       1.00      0.88      0.93         8\n",
      "           8       1.00      0.33      0.50         6\n",
      "           9       1.00      0.83      0.91         6\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       0.83      0.83      0.83         6\n",
      "          12       0.80      0.67      0.73         6\n",
      "          13       1.00      0.75      0.86         8\n",
      "          14       0.55      1.00      0.71         6\n",
      "          15       0.86      0.75      0.80         8\n",
      "          16       0.86      1.00      0.92         6\n",
      "          17       1.00      0.88      0.93         8\n",
      "          18       0.75      0.75      0.75         4\n",
      "          19       1.00      1.00      1.00         6\n",
      "          20       1.00      1.00      1.00         6\n",
      "          21       0.73      1.00      0.84         8\n",
      "          22       0.67      1.00      0.80         4\n",
      "          23       1.00      0.25      0.40         4\n",
      "          24       0.80      0.67      0.73         6\n",
      "          25       0.89      1.00      0.94         8\n",
      "          26       0.80      1.00      0.89         8\n",
      "          27       1.00      0.83      0.91         6\n",
      "          28       0.67      0.50      0.57         4\n",
      "          29       1.00      0.50      0.67         4\n",
      "          30       0.50      0.50      0.50         4\n",
      "          31       1.00      0.75      0.86         8\n",
      "          32       0.83      0.62      0.71         8\n",
      "          33       1.00      1.00      1.00         4\n",
      "          34       0.86      1.00      0.92         6\n",
      "          35       1.00      1.00      1.00         4\n",
      "          36       1.00      0.75      0.86         8\n",
      "          37       0.80      1.00      0.89         8\n",
      "          38       0.78      0.88      0.82         8\n",
      "          39       0.80      1.00      0.89         8\n",
      "          40       0.75      1.00      0.86         6\n",
      "          41       1.00      0.75      0.86         4\n",
      "          42       0.67      1.00      0.80         6\n",
      "          43       0.73      1.00      0.84         8\n",
      "          44       1.00      0.80      0.89        10\n",
      "          45       1.00      0.33      0.50         6\n",
      "          46       0.75      0.75      0.75         4\n",
      "          47       0.75      0.75      0.75         4\n",
      "          48       1.00      0.62      0.77         8\n",
      "          49       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.83       324\n",
      "   macro avg       0.86      0.82      0.82       324\n",
      "weighted avg       0.87      0.83      0.83       324\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(np.argmax(Yval, axis=1), np.argmax(best_model.predict(Xval), axis=1))\n",
    "\n",
    "sns.heatmap(cm, annot = True)\n",
    "\n",
    "print(classification_report(np.argmax(Yval, axis=1), np.argmax(best_model.predict(Xval), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d69868d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T05:36:22.506144Z",
     "start_time": "2023-08-15T05:36:22.295116Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0, 37,  0,  0, 39,  1,  1,  2,  2,  2,  2,  2,  6,  3,  3,  3, 32,\n",
       "        4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,  7,  7, 25,  8,  0,  9,\n",
       "        9,  9, 10, 10, 11, 11, 11, 12, 12, 43, 21, 13, 13, 13, 14, 14, 14,\n",
       "       15, 15, 14, 15, 16, 16, 16, 17, 17, 17, 17, 46, 18, 19, 19, 19, 20,\n",
       "       20, 20, 21, 21, 21, 21, 22, 22, 24, 42, 24, 42, 24, 25, 25, 25, 25,\n",
       "       26, 26, 26, 26, 27, 27, 27,  5, 28, 29, 26, 21, 30, 31,  6, 31, 31,\n",
       "       47, 32, 32, 32, 33, 33, 34, 34, 34, 35, 35, 36, 36, 36, 36, 37, 37,\n",
       "       37, 37, 38, 38, 38, 38, 39, 39, 39, 39, 40, 40, 40, 18, 41, 42, 42,\n",
       "       42, 43, 43, 43, 43, 44, 44, 44, 40, 44, 45, 15,  6, 14, 46, 47, 47,\n",
       "       22, 48,  6, 48, 49, 49, 49, 49, 49,  0,  0,  0,  0, 39,  1,  1,  2,\n",
       "        2,  2,  2,  2,  6,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  5,  6,\n",
       "        6, 21,  7,  7,  7, 38,  8, 38,  9, 12,  9, 10, 10, 11, 11,  5, 12,\n",
       "       12, 43, 13, 37, 13, 13, 14, 14, 14, 15, 15, 14, 15, 16, 16, 16, 17,\n",
       "       17, 43, 17, 18, 18, 19, 19, 19, 20, 20, 20, 21, 21, 21, 21, 22, 22,\n",
       "       23, 42, 24,  2, 24, 25, 25, 25, 25, 26, 26, 26, 26, 30, 27, 27,  5,\n",
       "       28, 29, 26,  1, 30, 14, 31, 31, 31, 11, 32, 32,  6, 33, 33, 34, 34,\n",
       "       34, 35, 35, 36, 30, 28, 36, 37, 37, 37, 37,  3, 38, 38, 38, 39, 39,\n",
       "       39, 39, 40, 40, 40, 41, 41, 42, 42, 42, 43, 43, 43, 43, 44, 44, 44,\n",
       "       40, 44, 45, 34, 14, 46, 46, 16, 47, 22, 48, 48, 48, 49, 49, 49, 49,\n",
       "       49])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(best_model.predict(Xval), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee6e9bdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T05:36:28.414493Z",
     "start_time": "2023-08-15T05:36:28.409588Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  1,  1,  1,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,\n",
       "        4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,  7,  7,  8,  8,  8,  9,\n",
       "        9,  9, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14,\n",
       "       15, 15, 15, 15, 16, 16, 16, 17, 17, 17, 17, 18, 18, 19, 19, 19, 20,\n",
       "       20, 20, 21, 21, 21, 21, 22, 22, 23, 23, 24, 24, 24, 25, 25, 25, 25,\n",
       "       26, 26, 26, 26, 27, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 31, 31,\n",
       "       32, 32, 32, 32, 33, 33, 34, 34, 34, 35, 35, 36, 36, 36, 36, 37, 37,\n",
       "       37, 37, 38, 38, 38, 38, 39, 39, 39, 39, 40, 40, 40, 41, 41, 42, 42,\n",
       "       42, 43, 43, 43, 43, 44, 44, 44, 44, 44, 45, 45, 45, 46, 46, 47, 47,\n",
       "       48, 48, 48, 48, 49, 49, 49, 49, 49,  0,  0,  0,  0,  1,  1,  1,  2,\n",
       "        2,  2,  2,  2,  3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,\n",
       "        6,  7,  7,  7,  7,  8,  8,  8,  9,  9,  9, 10, 10, 11, 11, 11, 12,\n",
       "       12, 12, 13, 13, 13, 13, 14, 14, 14, 15, 15, 15, 15, 16, 16, 16, 17,\n",
       "       17, 17, 17, 18, 18, 19, 19, 19, 20, 20, 20, 21, 21, 21, 21, 22, 22,\n",
       "       23, 23, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 27, 27, 27, 28,\n",
       "       28, 29, 29, 30, 30, 31, 31, 31, 31, 32, 32, 32, 32, 33, 33, 34, 34,\n",
       "       34, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 38, 38, 38, 38, 39, 39,\n",
       "       39, 39, 40, 40, 40, 41, 41, 42, 42, 42, 43, 43, 43, 43, 44, 44, 44,\n",
       "       44, 44, 45, 45, 45, 46, 46, 47, 47, 48, 48, 48, 48, 49, 49, 49, 49,\n",
       "       49])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Yval, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec8676",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Hyperparameter Tuning 3 GRU Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca639343",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T05:48:35.792709Z",
     "start_time": "2023-08-15T05:48:35.758361Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64262/3598984445.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import Hyperband\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SpatialDropout1D, GRU\n",
    "from keras_tuner import HyperModel\n",
    "from kerastuner.tuners import Hyperband\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        act_function = hp.Choice('dense_activation',values=['selu','LeakyReLU','elu','gelu'],default='selu')\n",
    "        model = Sequential()\n",
    "#        model.add(Conv1D(filters=hp.Choice('num_filters_1',values=[25,50, 100,150],default=100,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "#        model.add(MaxPooling1D(pool_size=2))\n",
    "#        model.add(Conv1D(filters=hp.Choice('num_filters_2',values=[25,50, 100,150],default=25,),kernel_size=2,activation=act_function))\n",
    "#        model.add(MaxPooling1D(pool_size=2))\n",
    "#        model.add(Conv1D(filters=hp.Choice('num_filters_3',values=[25,50, 100,150],default=50,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "#        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(GRU(units=hp.Int('units_1',min_value=1,max_value=200,step=50,default=200),return_sequences=True, input_shape=self.input_shape))\n",
    "        model.add(GRU(units=hp.Int('units_2',min_value=1,max_value=200,step=50,default=150),return_sequences=True))\n",
    "        model.add(GRU(units=hp.Int('units_3',min_value=1,max_value=200,step=50,default=100),return_sequences=False))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_1',min_value=0.0,max_value=0.7,default=0.65,step=0.05,)))\n",
    " #       model.add(Flatten())\n",
    "        model.add(Dense(units=hp.Int('units_4',min_value=20,max_value=120,step=20,default=40),activation=act_function))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_2',min_value=0.0,max_value=0.7,default=0.0,step=0.05,)))\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(Adam(hp.Float('learning_rate',min_value=1e-5,max_value=1e-3,sampling='LOG',default=0.00013960407115272237)),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "hypermodel = CNNHyperModel(input_shape=(130,126), num_classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e8048f0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T05:49:28.490201Z",
     "start_time": "2023-08-15T05:49:27.721969Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 06:49:27.726689: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-15 06:49:27.787802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1739 MB memory:  -> device: 0, name: NVIDIA GeForce MX250, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "HYPERBAND_MAX_EPOCHS = 100\n",
    "#MAX_TRIALS = 20\n",
    "EXECUTION_PER_TRIAL = 2\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    max_epochs=HYPERBAND_MAX_EPOCHS,\n",
    "    objective='val_loss',\n",
    "    seed=10,\n",
    "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "    directory='/media/kristian/HDD/ASL_Citizen/Mediapipe/hyperband/',\n",
    "    project_name='GRU',\n",
    "    overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "edecf3ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T05:49:38.186028Z",
     "start_time": "2023-08-15T05:49:38.182620Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 8\n",
      "dense_activation (Choice)\n",
      "{'default': 'selu', 'conditions': [], 'values': ['selu', 'LeakyReLU', 'elu', 'gelu'], 'ordered': False}\n",
      "units_1 (Int)\n",
      "{'default': 200, 'conditions': [], 'min_value': 1, 'max_value': 200, 'step': 50, 'sampling': 'linear'}\n",
      "units_2 (Int)\n",
      "{'default': 150, 'conditions': [], 'min_value': 1, 'max_value': 200, 'step': 50, 'sampling': 'linear'}\n",
      "units_3 (Int)\n",
      "{'default': 100, 'conditions': [], 'min_value': 1, 'max_value': 200, 'step': 50, 'sampling': 'linear'}\n",
      "dropout_1 (Float)\n",
      "{'default': 0.65, 'conditions': [], 'min_value': 0.0, 'max_value': 0.7, 'step': 0.05, 'sampling': 'linear'}\n",
      "units_4 (Int)\n",
      "{'default': 40, 'conditions': [], 'min_value': 20, 'max_value': 120, 'step': 20, 'sampling': 'linear'}\n",
      "dropout_2 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.7, 'step': 0.05, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 0.00013960407115272237, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.001, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a3fc9013",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T05:49:40.838931Z",
     "start_time": "2023-08-15T05:49:40.836650Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\",patience=20,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "72697b07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T05:49:42.463740Z",
     "start_time": "2023-08-15T05:49:42.461175Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a250d990",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-15T05:49:44.279Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 160 Complete [00h 00m 45s]\n",
      "val_loss: 3.910211682319641\n",
      "\n",
      "Best val_loss So Far: 1.9025814533233643\n",
      "Total elapsed time: 01h 57m 10s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(Xtrain, Ytrain, validation_data=(Xval,Yval),batch_size=96,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "fe461ff4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:15:09.397018Z",
     "start_time": "2023-08-14T14:15:09.089297Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0, 44,  0,  0, 39,  1,  1,  2,  2,  2,  2,  2,  6,  3,  3,  3,  3,\n",
       "        4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,  7,  7,  8,  8, 33,  9,\n",
       "       42, 45, 10, 10, 11, 11, 11, 12, 12, 42, 31, 13, 13, 13, 45,  6, 14,\n",
       "       15, 15, 37, 15, 16, 16, 16, 17, 17, 17, 17, 45, 18, 19, 19, 19, 20,\n",
       "       20, 20, 21, 21, 21, 21, 22, 22, 24, 42, 24, 18, 24, 25, 25, 25, 25,\n",
       "       26, 26, 26, 26, 27, 27, 27, 28, 28, 29, 26, 41, 30, 31, 48, 31, 31,\n",
       "       11, 32, 49, 32, 33, 33, 34, 34, 34, 35, 35, 36, 28, 15, 36, 37, 21,\n",
       "       37, 37, 38, 38, 38, 38, 39, 39, 39, 39, 40, 40, 40, 18, 41, 42, 42,\n",
       "       42, 43, 43, 43, 43, 44, 44, 44, 40, 44,  6, 34, 45,  5, 18, 47, 47,\n",
       "       22, 48,  3, 48, 49, 49, 11, 49, 49,  0,  2,  0,  0,  1,  1,  1,  2,\n",
       "        2,  2,  2,  2,  3,  3,  6,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,\n",
       "        6,  7,  7,  7,  7,  8,  8,  0,  9, 18, 42, 10, 10, 11, 11, 11, 12,\n",
       "       12, 42, 14,  9, 31, 13, 14,  6, 14, 15, 15, 22, 15, 16, 16, 16, 17,\n",
       "       17, 17, 17, 28, 18, 19, 19, 19, 20, 20, 20, 21, 21, 21, 21, 22, 22,\n",
       "       23, 42, 24, 12, 13, 25,  0, 25,  5, 26, 26, 26, 26,  2, 27, 27,  5,\n",
       "       28, 29, 26, 18, 30, 14, 22, 31, 31, 11, 32, 32,  6, 33, 33, 34, 34,\n",
       "       23, 35, 35, 15, 30, 15, 36, 37, 14, 37, 37, 38, 38, 38, 38, 39, 39,\n",
       "       39, 39, 40, 40, 40, 18, 41, 42, 12, 42, 43, 43, 43, 43, 44, 44, 44,\n",
       "       30, 44, 26, 23, 45, 46,  9, 47, 47, 48, 48,  3, 48, 49, 49, 47, 49,\n",
       "       49])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(best_model.predict(Xval), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "0560f331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:15:10.036321Z",
     "start_time": "2023-08-14T14:15:10.032139Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  1,  1,  1,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,\n",
       "        4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,  7,  7,  8,  8,  8,  9,\n",
       "        9,  9, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14,\n",
       "       15, 15, 15, 15, 16, 16, 16, 17, 17, 17, 17, 18, 18, 19, 19, 19, 20,\n",
       "       20, 20, 21, 21, 21, 21, 22, 22, 23, 23, 24, 24, 24, 25, 25, 25, 25,\n",
       "       26, 26, 26, 26, 27, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 31, 31,\n",
       "       32, 32, 32, 32, 33, 33, 34, 34, 34, 35, 35, 36, 36, 36, 36, 37, 37,\n",
       "       37, 37, 38, 38, 38, 38, 39, 39, 39, 39, 40, 40, 40, 41, 41, 42, 42,\n",
       "       42, 43, 43, 43, 43, 44, 44, 44, 44, 44, 45, 45, 45, 46, 46, 47, 47,\n",
       "       48, 48, 48, 48, 49, 49, 49, 49, 49,  0,  0,  0,  0,  1,  1,  1,  2,\n",
       "        2,  2,  2,  2,  3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,\n",
       "        6,  7,  7,  7,  7,  8,  8,  8,  9,  9,  9, 10, 10, 11, 11, 11, 12,\n",
       "       12, 12, 13, 13, 13, 13, 14, 14, 14, 15, 15, 15, 15, 16, 16, 16, 17,\n",
       "       17, 17, 17, 18, 18, 19, 19, 19, 20, 20, 20, 21, 21, 21, 21, 22, 22,\n",
       "       23, 23, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 27, 27, 27, 28,\n",
       "       28, 29, 29, 30, 30, 31, 31, 31, 31, 32, 32, 32, 32, 33, 33, 34, 34,\n",
       "       34, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 38, 38, 38, 38, 39, 39,\n",
       "       39, 39, 40, 40, 40, 41, 41, 42, 42, 42, 43, 43, 43, 43, 44, 44, 44,\n",
       "       44, 44, 45, 45, 45, 46, 46, 47, 47, 48, 48, 48, 48, 49, 49, 49, 49,\n",
       "       49])"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Yval, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e9715",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Hyperparameter Tuning 3 LSTM Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09356bdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T05:48:35.792709Z",
     "start_time": "2023-08-15T05:48:35.758361Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64262/3598984445.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import Hyperband\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SpatialDropout1D, GRU\n",
    "from keras_tuner import HyperModel\n",
    "from kerastuner.tuners import Hyperband\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        act_function = hp.Choice('dense_activation',values=['selu','LeakyReLU','elu','gelu'],default='selu')\n",
    "        model = Sequential()\n",
    "#        model.add(Conv1D(filters=hp.Choice('num_filters_1',values=[25,50, 100,150],default=100,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "#        model.add(MaxPooling1D(pool_size=2))\n",
    "#        model.add(Conv1D(filters=hp.Choice('num_filters_2',values=[25,50, 100,150],default=25,),kernel_size=2,activation=act_function))\n",
    "#        model.add(MaxPooling1D(pool_size=2))\n",
    "#        model.add(Conv1D(filters=hp.Choice('num_filters_3',values=[25,50, 100,150],default=50,),kernel_size=2,activation=act_function,input_shape=self.input_shape))\n",
    "#        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(LSTM(units=hp.Int('units_1',min_value=1,max_value=200,step=50,default=200),return_sequences=True, input_shape=self.input_shape))\n",
    "        model.add(LSTM(units=hp.Int('units_2',min_value=1,max_value=200,step=50,default=150),return_sequences=True))\n",
    "        model.add(LSTM(units=hp.Int('units_3',min_value=1,max_value=200,step=50,default=100),return_sequences=False))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_1',min_value=0.0,max_value=0.7,default=0.65,step=0.05,)))\n",
    " #       model.add(Flatten())\n",
    "        model.add(Dense(units=hp.Int('units_4',min_value=20,max_value=120,step=20,default=40),activation=act_function))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_2',min_value=0.0,max_value=0.7,default=0.0,step=0.05,)))\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(Adam(hp.Float('learning_rate',min_value=1e-5,max_value=1e-3,sampling='LOG',default=0.00013960407115272237)),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "hypermodel = CNNHyperModel(input_shape=(130,126), num_classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b2cfed9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T05:49:28.490201Z",
     "start_time": "2023-08-15T05:49:27.721969Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 06:49:27.726689: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-15 06:49:27.787802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1739 MB memory:  -> device: 0, name: NVIDIA GeForce MX250, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "HYPERBAND_MAX_EPOCHS = 100\n",
    "#MAX_TRIALS = 20\n",
    "EXECUTION_PER_TRIAL = 2\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    max_epochs=HYPERBAND_MAX_EPOCHS,\n",
    "    objective='val_loss',\n",
    "    seed=10,\n",
    "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "    directory='/media/kristian/HDD/ASL_Citizen/Mediapipe/hyperband/',\n",
    "    project_name='GRU',\n",
    "    overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc5579a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T05:49:38.186028Z",
     "start_time": "2023-08-15T05:49:38.182620Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 8\n",
      "dense_activation (Choice)\n",
      "{'default': 'selu', 'conditions': [], 'values': ['selu', 'LeakyReLU', 'elu', 'gelu'], 'ordered': False}\n",
      "units_1 (Int)\n",
      "{'default': 200, 'conditions': [], 'min_value': 1, 'max_value': 200, 'step': 50, 'sampling': 'linear'}\n",
      "units_2 (Int)\n",
      "{'default': 150, 'conditions': [], 'min_value': 1, 'max_value': 200, 'step': 50, 'sampling': 'linear'}\n",
      "units_3 (Int)\n",
      "{'default': 100, 'conditions': [], 'min_value': 1, 'max_value': 200, 'step': 50, 'sampling': 'linear'}\n",
      "dropout_1 (Float)\n",
      "{'default': 0.65, 'conditions': [], 'min_value': 0.0, 'max_value': 0.7, 'step': 0.05, 'sampling': 'linear'}\n",
      "units_4 (Int)\n",
      "{'default': 40, 'conditions': [], 'min_value': 20, 'max_value': 120, 'step': 20, 'sampling': 'linear'}\n",
      "dropout_2 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.7, 'step': 0.05, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 0.00013960407115272237, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.001, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a5ebee0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T05:49:40.838931Z",
     "start_time": "2023-08-15T05:49:40.836650Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\",patience=20,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c68c725d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T05:49:42.463740Z",
     "start_time": "2023-08-15T05:49:42.461175Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bddfcf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-15T05:49:44.279Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 160 Complete [00h 00m 45s]\n",
      "val_loss: 3.910211682319641\n",
      "\n",
      "Best val_loss So Far: 1.9025814533233643\n",
      "Total elapsed time: 01h 57m 10s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(Xtrain, Ytrain, validation_data=(Xval,Yval),batch_size=96,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "019f724f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:15:09.397018Z",
     "start_time": "2023-08-14T14:15:09.089297Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0, 44,  0,  0, 39,  1,  1,  2,  2,  2,  2,  2,  6,  3,  3,  3,  3,\n",
       "        4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,  7,  7,  8,  8, 33,  9,\n",
       "       42, 45, 10, 10, 11, 11, 11, 12, 12, 42, 31, 13, 13, 13, 45,  6, 14,\n",
       "       15, 15, 37, 15, 16, 16, 16, 17, 17, 17, 17, 45, 18, 19, 19, 19, 20,\n",
       "       20, 20, 21, 21, 21, 21, 22, 22, 24, 42, 24, 18, 24, 25, 25, 25, 25,\n",
       "       26, 26, 26, 26, 27, 27, 27, 28, 28, 29, 26, 41, 30, 31, 48, 31, 31,\n",
       "       11, 32, 49, 32, 33, 33, 34, 34, 34, 35, 35, 36, 28, 15, 36, 37, 21,\n",
       "       37, 37, 38, 38, 38, 38, 39, 39, 39, 39, 40, 40, 40, 18, 41, 42, 42,\n",
       "       42, 43, 43, 43, 43, 44, 44, 44, 40, 44,  6, 34, 45,  5, 18, 47, 47,\n",
       "       22, 48,  3, 48, 49, 49, 11, 49, 49,  0,  2,  0,  0,  1,  1,  1,  2,\n",
       "        2,  2,  2,  2,  3,  3,  6,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,\n",
       "        6,  7,  7,  7,  7,  8,  8,  0,  9, 18, 42, 10, 10, 11, 11, 11, 12,\n",
       "       12, 42, 14,  9, 31, 13, 14,  6, 14, 15, 15, 22, 15, 16, 16, 16, 17,\n",
       "       17, 17, 17, 28, 18, 19, 19, 19, 20, 20, 20, 21, 21, 21, 21, 22, 22,\n",
       "       23, 42, 24, 12, 13, 25,  0, 25,  5, 26, 26, 26, 26,  2, 27, 27,  5,\n",
       "       28, 29, 26, 18, 30, 14, 22, 31, 31, 11, 32, 32,  6, 33, 33, 34, 34,\n",
       "       23, 35, 35, 15, 30, 15, 36, 37, 14, 37, 37, 38, 38, 38, 38, 39, 39,\n",
       "       39, 39, 40, 40, 40, 18, 41, 42, 12, 42, 43, 43, 43, 43, 44, 44, 44,\n",
       "       30, 44, 26, 23, 45, 46,  9, 47, 47, 48, 48,  3, 48, 49, 49, 47, 49,\n",
       "       49])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(best_model.predict(Xval), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "aac3957e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:15:10.036321Z",
     "start_time": "2023-08-14T14:15:10.032139Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  1,  1,  1,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,\n",
       "        4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,  7,  7,  8,  8,  8,  9,\n",
       "        9,  9, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14,\n",
       "       15, 15, 15, 15, 16, 16, 16, 17, 17, 17, 17, 18, 18, 19, 19, 19, 20,\n",
       "       20, 20, 21, 21, 21, 21, 22, 22, 23, 23, 24, 24, 24, 25, 25, 25, 25,\n",
       "       26, 26, 26, 26, 27, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 31, 31,\n",
       "       32, 32, 32, 32, 33, 33, 34, 34, 34, 35, 35, 36, 36, 36, 36, 37, 37,\n",
       "       37, 37, 38, 38, 38, 38, 39, 39, 39, 39, 40, 40, 40, 41, 41, 42, 42,\n",
       "       42, 43, 43, 43, 43, 44, 44, 44, 44, 44, 45, 45, 45, 46, 46, 47, 47,\n",
       "       48, 48, 48, 48, 49, 49, 49, 49, 49,  0,  0,  0,  0,  1,  1,  1,  2,\n",
       "        2,  2,  2,  2,  3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,\n",
       "        6,  7,  7,  7,  7,  8,  8,  8,  9,  9,  9, 10, 10, 11, 11, 11, 12,\n",
       "       12, 12, 13, 13, 13, 13, 14, 14, 14, 15, 15, 15, 15, 16, 16, 16, 17,\n",
       "       17, 17, 17, 18, 18, 19, 19, 19, 20, 20, 20, 21, 21, 21, 21, 22, 22,\n",
       "       23, 23, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 27, 27, 27, 28,\n",
       "       28, 29, 29, 30, 30, 31, 31, 31, 31, 32, 32, 32, 32, 33, 33, 34, 34,\n",
       "       34, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 38, 38, 38, 38, 39, 39,\n",
       "       39, 39, 40, 40, 40, 41, 41, 42, 42, 42, 43, 43, 43, 43, 44, 44, 44,\n",
       "       44, 44, 45, 45, 45, 46, 46, 47, 47, 48, 48, 48, 48, 49, 49, 49, 49,\n",
       "       49])"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Yval, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262ab4c9",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning 4 1D CNN Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7ab158e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:40:02.614759Z",
     "start_time": "2023-08-23T22:40:01.660272Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8299/1222377179.py:2: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import Hyperband\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import HyperModel\n",
    "from kerastuner.tuners import Hyperband\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a7b1759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:40:06.498091Z",
     "start_time": "2023-08-23T22:40:05.672351Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristian/miniconda3/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SpatialDropout1D, GRU\n",
    "import keras_tuner\n",
    "from keras_tuner import HyperModel\n",
    "from kerastuner.tuners import Hyperband\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        act_function = hp.Choice('dense_activation',values=['selu','LeakyReLU','gelu','elu'],default='elu')\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=hp.Choice('num_filters_1',values=[100,125,150,200],default=150,),kernel_size=hp.Choice('kernel_1',values=[2,3,4,5],default=2,),activation=act_function,input_shape=self.input_shape))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(filters=hp.Choice('num_filters_2',values=[100,125,150,200],default=150,),kernel_size=hp.Choice('kernel_2',values=[2,3,4,5],default=2,),activation=act_function))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(filters=hp.Choice('num_filters_3',values=[100,125,150,200],default=150,),kernel_size=hp.Choice('kernel_3',values=[2,3,4,5],default=2,),activation=act_function))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "#        model.add(Conv1D(filters=hp.Choice('num_filters_4',values=[50,100,150,200],default=150,),kernel_size=hp.Choice('kernel_4',values=[2,3,4,5],default=2,),activation=act_function))\n",
    "#        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_1',min_value=0.5,max_value=0.9,default=0.8,step=0.05,)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=hp.Int('units_5',min_value=70,max_value=120,step=10,default=80),activation=act_function))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_2',min_value=0.5,max_value=0.9,default=0.8,step=0.05,)))\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(tf.optimizers.experimental.Nadam(hp.Float('learning_rate',min_value=1e-4,max_value=1e-2,sampling='LOG',default=.0008273819395816823)),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=[tfa.metrics.F1Score(num_classes=50, average='macro')]\n",
    "        )\n",
    "        return model\n",
    "\n",
    "hypermodel = CNNHyperModel(input_shape=(130,126), num_classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "734971ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:41:31.333118Z",
     "start_time": "2023-08-23T22:41:31.242666Z"
    }
   },
   "outputs": [],
   "source": [
    "HYPERBAND_MAX_EPOCHS = 300\n",
    "#MAX_TRIALS = 20\n",
    "EXECUTION_PER_TRIAL = 2\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    max_epochs=HYPERBAND_MAX_EPOCHS,\n",
    "    objective=keras_tuner.Objective(\"val_f1_score\", direction=\"max\"),\n",
    "    seed=10,\n",
    "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "    directory='/media/kristian/HDD/ASL_Citizen/Mediapipe/hyperband/',\n",
    "    project_name='3_1D_CNN_2',\n",
    "    overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "414194f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:41:44.199605Z",
     "start_time": "2023-08-23T22:41:44.196356Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 11\n",
      "dense_activation (Choice)\n",
      "{'default': 'elu', 'conditions': [], 'values': ['selu', 'LeakyReLU', 'gelu', 'elu'], 'ordered': False}\n",
      "num_filters_1 (Choice)\n",
      "{'default': 150, 'conditions': [], 'values': [100, 125, 150, 200], 'ordered': True}\n",
      "kernel_1 (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3, 4, 5], 'ordered': True}\n",
      "num_filters_2 (Choice)\n",
      "{'default': 150, 'conditions': [], 'values': [100, 125, 150, 200], 'ordered': True}\n",
      "kernel_2 (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3, 4, 5], 'ordered': True}\n",
      "num_filters_3 (Choice)\n",
      "{'default': 150, 'conditions': [], 'values': [100, 125, 150, 200], 'ordered': True}\n",
      "kernel_3 (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3, 4, 5], 'ordered': True}\n",
      "dropout_1 (Float)\n",
      "{'default': 0.8, 'conditions': [], 'min_value': 0.5, 'max_value': 0.9, 'step': 0.05, 'sampling': 'linear'}\n",
      "units_5 (Int)\n",
      "{'default': 80, 'conditions': [], 'min_value': 70, 'max_value': 120, 'step': 10, 'sampling': 'linear'}\n",
      "dropout_2 (Float)\n",
      "{'default': 0.8, 'conditions': [], 'min_value': 0.5, 'max_value': 0.9, 'step': 0.05, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0008273819395816823, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44aa794a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:41:51.333671Z",
     "start_time": "2023-08-23T22:41:51.331135Z"
    }
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_f1_score\",patience=30,restore_best_weights=True,mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5be7b3b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:42:05.721079Z",
     "start_time": "2023-08-23T22:42:05.718374Z"
    }
   },
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76168bd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-23T22:42:13.905Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 Complete [00h 00m 11s]\n",
      "val_f1_score: 0.04849547706544399\n",
      "\n",
      "Best val_f1_score So Far: 0.127159271389246\n",
      "Total elapsed time: 00h 01m 41s\n",
      "\n",
      "Search: Running Trial #9\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "LeakyReLU         |selu              |dense_activation\n",
      "125               |150               |num_filters_1\n",
      "2                 |4                 |kernel_1\n",
      "150               |150               |num_filters_2\n",
      "2                 |3                 |kernel_2\n",
      "200               |150               |num_filters_3\n",
      "5                 |4                 |kernel_3\n",
      "0.85              |0.55              |dropout_1\n",
      "110               |90                |units_5\n",
      "0.6               |0.65              |dropout_2\n",
      "0.00018241        |0.0019004         |learning_rate\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "5                 |5                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 23:43:57.504375: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.56GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - ETA: 0s - loss: 3.9681 - f1_score: 0.0180"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 23:44:00.229789: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.49GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 59ms/step - loss: 3.9681 - f1_score: 0.0180 - val_loss: 3.9055 - val_f1_score: 0.0058\n",
      "Epoch 2/2\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 3.9103 - f1_score: 0.0148 - val_loss: 3.8981 - val_f1_score: 0.0145\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "tuner.search(Xtrain, Ytrain, epochs=1000, validation_data=(Xval,Yval),batch_size=96,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "be52c5de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T21:47:20.300685Z",
     "start_time": "2023-08-23T21:47:19.296417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._u_product\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.0\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._u_product\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.0\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._u_product\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.0\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "514d158c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T19:14:54.469714Z",
     "start_time": "2023-08-23T19:14:54.464915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in /media/kristian/HDD/ASL_Citizen/Mediapipe/hyperband/4_1D_CNN_2\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_f1_score\", direction=\"max\")\n",
      "\n",
      "Trial 0599 summary\n",
      "Hyperparameters:\n",
      "dense_activation: gelu\n",
      "num_filters_1: 200\n",
      "kernel_1: 2\n",
      "num_filters_2: 200\n",
      "kernel_2: 4\n",
      "num_filters_3: 150\n",
      "kernel_3: 5\n",
      "dropout_1: 0.5\n",
      "units_5: 100\n",
      "dropout_2: 0.7\n",
      "learning_rate: 0.0015664483309874415\n",
      "tuner/epochs: 300\n",
      "tuner/initial_epoch: 100\n",
      "tuner/bracket: 4\n",
      "tuner/round: 4\n",
      "tuner/trial_id: 0593\n",
      "Score: 0.8009045422077179\n",
      "\n",
      "Trial 0714 summary\n",
      "Hyperparameters:\n",
      "dense_activation: elu\n",
      "num_filters_1: 150\n",
      "kernel_1: 5\n",
      "num_filters_2: 125\n",
      "kernel_2: 5\n",
      "num_filters_3: 200\n",
      "kernel_3: 3\n",
      "dropout_1: 0.75\n",
      "units_5: 120\n",
      "dropout_2: 0.65\n",
      "learning_rate: 0.000332180455993387\n",
      "tuner/epochs: 300\n",
      "tuner/initial_epoch: 100\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0703\n",
      "Score: 0.798288881778717\n",
      "\n",
      "Trial 0718 summary\n",
      "Hyperparameters:\n",
      "dense_activation: elu\n",
      "num_filters_1: 200\n",
      "kernel_1: 5\n",
      "num_filters_2: 100\n",
      "kernel_2: 3\n",
      "num_filters_3: 100\n",
      "kernel_3: 2\n",
      "dropout_1: 0.8500000000000001\n",
      "units_5: 120\n",
      "dropout_2: 0.6\n",
      "learning_rate: 0.00027660256617556995\n",
      "tuner/epochs: 300\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.7960334718227386\n",
      "\n",
      "Trial 0715 summary\n",
      "Hyperparameters:\n",
      "dense_activation: elu\n",
      "num_filters_1: 150\n",
      "kernel_1: 2\n",
      "num_filters_2: 150\n",
      "kernel_2: 2\n",
      "num_filters_3: 100\n",
      "kernel_3: 2\n",
      "dropout_1: 0.75\n",
      "units_5: 90\n",
      "dropout_2: 0.5\n",
      "learning_rate: 0.001201687537647584\n",
      "tuner/epochs: 300\n",
      "tuner/initial_epoch: 100\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0708\n",
      "Score: 0.7958742082118988\n",
      "\n",
      "Trial 0700 summary\n",
      "Hyperparameters:\n",
      "dense_activation: gelu\n",
      "num_filters_1: 100\n",
      "kernel_1: 5\n",
      "num_filters_2: 100\n",
      "kernel_2: 3\n",
      "num_filters_3: 150\n",
      "kernel_3: 2\n",
      "dropout_1: 0.75\n",
      "units_5: 110\n",
      "dropout_2: 0.5\n",
      "learning_rate: 0.0018151801415464167\n",
      "tuner/epochs: 300\n",
      "tuner/initial_epoch: 100\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0693\n",
      "Score: 0.7905385792255402\n",
      "\n",
      "Trial 0722 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 200\n",
      "kernel_1: 5\n",
      "num_filters_2: 200\n",
      "kernel_2: 3\n",
      "num_filters_3: 150\n",
      "kernel_3: 4\n",
      "dropout_1: 0.65\n",
      "units_5: 100\n",
      "dropout_2: 0.6\n",
      "learning_rate: 0.00011654631348796121\n",
      "tuner/epochs: 300\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.788326621055603\n",
      "\n",
      "Trial 0719 summary\n",
      "Hyperparameters:\n",
      "dense_activation: elu\n",
      "num_filters_1: 125\n",
      "kernel_1: 3\n",
      "num_filters_2: 100\n",
      "kernel_2: 3\n",
      "num_filters_3: 200\n",
      "kernel_3: 2\n",
      "dropout_1: 0.75\n",
      "units_5: 110\n",
      "dropout_2: 0.8\n",
      "learning_rate: 0.0010499262063009608\n",
      "tuner/epochs: 300\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.7869904637336731\n",
      "\n",
      "Trial 0717 summary\n",
      "Hyperparameters:\n",
      "dense_activation: selu\n",
      "num_filters_1: 200\n",
      "kernel_1: 4\n",
      "num_filters_2: 100\n",
      "kernel_2: 5\n",
      "num_filters_3: 125\n",
      "kernel_3: 3\n",
      "dropout_1: 0.8500000000000001\n",
      "units_5: 120\n",
      "dropout_2: 0.65\n",
      "learning_rate: 0.00017971302135677287\n",
      "tuner/epochs: 300\n",
      "tuner/initial_epoch: 100\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0709\n",
      "Score: 0.7858077585697174\n",
      "\n",
      "Trial 0671 summary\n",
      "Hyperparameters:\n",
      "dense_activation: gelu\n",
      "num_filters_1: 100\n",
      "kernel_1: 2\n",
      "num_filters_2: 150\n",
      "kernel_2: 5\n",
      "num_filters_3: 125\n",
      "kernel_3: 2\n",
      "dropout_1: 0.65\n",
      "units_5: 100\n",
      "dropout_2: 0.75\n",
      "learning_rate: 0.002047306960005961\n",
      "tuner/epochs: 300\n",
      "tuner/initial_epoch: 100\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0665\n",
      "Score: 0.7839965522289276\n",
      "\n",
      "Trial 0693 summary\n",
      "Hyperparameters:\n",
      "dense_activation: gelu\n",
      "num_filters_1: 100\n",
      "kernel_1: 5\n",
      "num_filters_2: 100\n",
      "kernel_2: 3\n",
      "num_filters_3: 150\n",
      "kernel_3: 2\n",
      "dropout_1: 0.75\n",
      "units_5: 110\n",
      "dropout_2: 0.5\n",
      "learning_rate: 0.0018151801415464167\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0682\n",
      "Score: 0.7839264273643494\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ba701ab7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T21:47:38.271964Z",
     "start_time": "2023-08-23T21:47:33.944016Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 22:47:35.152206: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 27ms/step - loss: 1.1782 - f1_score: 0.8031\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = best_model.evaluate(Xval, Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "02bcc338",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:03:17.509552Z",
     "start_time": "2023-08-23T22:03:16.145161Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "91aa9e5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:22:54.133309Z",
     "start_time": "2023-08-23T22:22:53.860984Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80         8\n",
      "           1       0.75      1.00      0.86         6\n",
      "           2       0.83      1.00      0.91        10\n",
      "           3       0.88      0.70      0.78        10\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      1.00      1.00         8\n",
      "           6       0.55      1.00      0.71         6\n",
      "           7       0.80      1.00      0.89         8\n",
      "           8       1.00      0.50      0.67         6\n",
      "           9       0.71      0.83      0.77         6\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       0.86      1.00      0.92         6\n",
      "          12       1.00      0.67      0.80         6\n",
      "          13       0.86      0.75      0.80         8\n",
      "          14       0.67      0.67      0.67         6\n",
      "          15       0.75      0.75      0.75         8\n",
      "          16       1.00      1.00      1.00         6\n",
      "          17       1.00      0.75      0.86         8\n",
      "          18       0.75      0.75      0.75         4\n",
      "          19       1.00      1.00      1.00         6\n",
      "          20       1.00      1.00      1.00         6\n",
      "          21       1.00      1.00      1.00         8\n",
      "          22       0.80      1.00      0.89         4\n",
      "          23       0.50      0.50      0.50         4\n",
      "          24       0.83      0.83      0.83         6\n",
      "          25       1.00      1.00      1.00         8\n",
      "          26       1.00      1.00      1.00         8\n",
      "          27       1.00      0.83      0.91         6\n",
      "          28       1.00      0.50      0.67         4\n",
      "          29       1.00      0.50      0.67         4\n",
      "          30       0.33      0.50      0.40         4\n",
      "          31       1.00      0.62      0.77         8\n",
      "          32       1.00      0.50      0.67         8\n",
      "          33       0.67      1.00      0.80         4\n",
      "          34       0.67      1.00      0.80         6\n",
      "          35       1.00      1.00      1.00         4\n",
      "          36       0.83      0.62      0.71         8\n",
      "          37       0.62      0.62      0.62         8\n",
      "          38       0.88      0.88      0.88         8\n",
      "          39       0.78      0.88      0.82         8\n",
      "          40       0.86      1.00      0.92         6\n",
      "          41       1.00      0.75      0.86         4\n",
      "          42       0.67      1.00      0.80         6\n",
      "          43       0.73      1.00      0.84         8\n",
      "          44       1.00      0.80      0.89        10\n",
      "          45       1.00      0.50      0.67         6\n",
      "          46       1.00      1.00      1.00         4\n",
      "          47       0.67      1.00      0.80         4\n",
      "          48       1.00      1.00      1.00         8\n",
      "          49       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.84       324\n",
      "   macro avg       0.86      0.84      0.83       324\n",
      "weighted avg       0.87      0.84      0.84       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#cm = confusion_matrix(np.argmax(Yval, axis=1), np.argmax(model.predict(Xval), axis=1))\n",
    "\n",
    "#sns.heatmap(cm, annot = True)\n",
    "\n",
    "print(classification_report(np.argmax(Yval, axis=1), np.argmax(reconstructed_model.predict(Xval), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9e90f051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T19:46:56.067674Z",
     "start_time": "2023-08-23T19:46:55.877821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0, 37,  0,  0,  1,  1,  1,  2,  2,  2,  2,  2,  6,  3,  3,  3,  6,\n",
       "        4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,  7,  7,  8,  8, 17,  9,\n",
       "        9,  9, 10, 10, 11, 11, 11, 12, 12, 35, 14, 37, 31, 13, 45, 37, 14,\n",
       "       15, 15, 24, 15, 16, 16, 16, 17, 17, 17, 17, 46, 18, 19, 19, 19, 20,\n",
       "       20, 20, 21, 21, 21, 21, 22, 22, 23, 42, 24, 42, 24, 25, 25, 25, 25,\n",
       "       26, 26, 26, 26, 27, 27, 27, 28, 28, 29, 26,  1, 30, 31,  6, 31, 31,\n",
       "       47, 32, 32,  6, 33, 33, 34, 34, 23, 35, 35, 36, 28, 34, 36, 37, 37,\n",
       "        9, 37, 38, 38, 38, 38, 39, 39, 39, 39, 40, 40, 40, 41, 41, 42, 42,\n",
       "       42, 43, 43, 43, 43, 41, 44, 44, 44, 44,  6, 37,  6,  5, 42, 47, 47,\n",
       "       48, 48, 48, 48, 49, 49, 49, 49, 49,  0, 37,  0,  0, 39,  1,  1,  2,\n",
       "        2,  2,  2,  2,  6,  3,  3,  3,  6,  4,  4,  5,  5,  5,  5,  6,  6,\n",
       "        6,  7,  7,  7,  7, 38,  8, 17,  9, 46,  9, 10, 10, 11, 11, 11, 12,\n",
       "       12, 24, 13, 14, 13, 13, 14, 14, 14, 15, 15, 24, 15, 16, 16, 16, 17,\n",
       "       17, 17, 17, 18, 18, 19, 19, 19, 20, 20, 20, 21, 21, 21, 21, 22, 22,\n",
       "       23, 42, 24, 42, 24, 25, 25, 25, 11, 26, 26, 26, 26, 18, 27, 27, 34,\n",
       "       28, 29, 26,  1, 30, 31,  6, 21, 31, 46, 32, 32,  6, 33, 33, 34, 34,\n",
       "       34, 35, 35, 36, 44, 28, 36, 37, 37,  9, 37, 38, 38, 38, 38, 39, 39,\n",
       "       39, 39, 40, 40, 40, 23, 41, 42, 42, 42, 43, 43, 43, 43, 44, 44, 44,\n",
       "       40, 44, 45, 37, 45,  5, 34, 47, 47, 48, 48, 48, 48, 49, 49, 11, 49,\n",
       "       49])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(best_model.predict(Xval), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "63e684f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T19:46:59.388709Z",
     "start_time": "2023-08-23T19:46:59.384531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  1,  1,  1,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,\n",
       "        4,  4,  5,  5,  5,  5,  6,  6,  6,  7,  7,  7,  7,  8,  8,  8,  9,\n",
       "        9,  9, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14,\n",
       "       15, 15, 15, 15, 16, 16, 16, 17, 17, 17, 17, 18, 18, 19, 19, 19, 20,\n",
       "       20, 20, 21, 21, 21, 21, 22, 22, 23, 23, 24, 24, 24, 25, 25, 25, 25,\n",
       "       26, 26, 26, 26, 27, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 31, 31,\n",
       "       32, 32, 32, 32, 33, 33, 34, 34, 34, 35, 35, 36, 36, 36, 36, 37, 37,\n",
       "       37, 37, 38, 38, 38, 38, 39, 39, 39, 39, 40, 40, 40, 41, 41, 42, 42,\n",
       "       42, 43, 43, 43, 43, 44, 44, 44, 44, 44, 45, 45, 45, 46, 46, 47, 47,\n",
       "       48, 48, 48, 48, 49, 49, 49, 49, 49,  0,  0,  0,  0,  1,  1,  1,  2,\n",
       "        2,  2,  2,  2,  3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,\n",
       "        6,  7,  7,  7,  7,  8,  8,  8,  9,  9,  9, 10, 10, 11, 11, 11, 12,\n",
       "       12, 12, 13, 13, 13, 13, 14, 14, 14, 15, 15, 15, 15, 16, 16, 16, 17,\n",
       "       17, 17, 17, 18, 18, 19, 19, 19, 20, 20, 20, 21, 21, 21, 21, 22, 22,\n",
       "       23, 23, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 27, 27, 27, 28,\n",
       "       28, 29, 29, 30, 30, 31, 31, 31, 31, 32, 32, 32, 32, 33, 33, 34, 34,\n",
       "       34, 35, 35, 36, 36, 36, 36, 37, 37, 37, 37, 38, 38, 38, 38, 39, 39,\n",
       "       39, 39, 40, 40, 40, 41, 41, 42, 42, 42, 43, 43, 43, 43, 44, 44, 44,\n",
       "       44, 44, 45, 45, 45, 46, 46, 47, 47, 48, 48, 48, 48, 49, 49, 49, 49,\n",
       "       49])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Yval, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "aeca798d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T21:47:52.118851Z",
     "start_time": "2023-08-23T21:47:52.116041Z"
    }
   },
   "outputs": [],
   "source": [
    "#bestHP = tuner.get_best_hyperparameters(num_trials=5)[2]\n",
    "bestHP = tuner.get_best_hyperparameters(num_trials=5)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ebd69a87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:07:37.038598Z",
     "start_time": "2023-08-23T22:07:37.035646Z"
    }
   },
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='best_model/',\n",
    "    monitor='val_f1_score',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7e50e52a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:22:02.519552Z",
     "start_time": "2023-08-23T22:07:43.985906Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the best model...\n",
      "Epoch 1/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 4.1188 - f1_score: 0.0196"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 10s 287ms/step - loss: 4.1166 - f1_score: 0.0193 - val_loss: 3.9013 - val_f1_score: 0.0586\n",
      "Epoch 2/500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 4.0031 - f1_score: 0.0192 - val_loss: 3.8677 - val_f1_score: 0.0301\n",
      "Epoch 3/500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 3.9711 - f1_score: 0.0286 - val_loss: 3.8331 - val_f1_score: 0.0476\n",
      "Epoch 4/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 3.9119 - f1_score: 0.0353 - val_loss: 3.7936 - val_f1_score: 0.0433\n",
      "Epoch 5/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 3.8669 - f1_score: 0.0414"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 168ms/step - loss: 3.8702 - f1_score: 0.0418 - val_loss: 3.7464 - val_f1_score: 0.0740\n",
      "Epoch 6/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 3.8443 - f1_score: 0.0484"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 199ms/step - loss: 3.8466 - f1_score: 0.0479 - val_loss: 3.6856 - val_f1_score: 0.0762\n",
      "Epoch 7/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 3.7926 - f1_score: 0.0501 - val_loss: 3.6147 - val_f1_score: 0.0754\n",
      "Epoch 8/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 3.7113 - f1_score: 0.0574 - val_loss: 3.5455 - val_f1_score: 0.0596\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 3.6512 - f1_score: 0.0664 - val_loss: 3.4618 - val_f1_score: 0.0617\n",
      "Epoch 10/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 3.5877 - f1_score: 0.0832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 180ms/step - loss: 3.5890 - f1_score: 0.0816 - val_loss: 3.3892 - val_f1_score: 0.0820\n",
      "Epoch 11/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 3.5328 - f1_score: 0.0866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 4s 154ms/step - loss: 3.5253 - f1_score: 0.0888 - val_loss: 3.3011 - val_f1_score: 0.0899\n",
      "Epoch 12/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 3.4711 - f1_score: 0.1027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 4s 159ms/step - loss: 3.4656 - f1_score: 0.1030 - val_loss: 3.2443 - val_f1_score: 0.1141\n",
      "Epoch 13/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 3.3926 - f1_score: 0.1122"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 22s 828ms/step - loss: 3.3923 - f1_score: 0.1121 - val_loss: 3.1629 - val_f1_score: 0.1478\n",
      "Epoch 14/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 3.3236 - f1_score: 0.1194"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 4s 161ms/step - loss: 3.3274 - f1_score: 0.1182 - val_loss: 3.0865 - val_f1_score: 0.1636\n",
      "Epoch 15/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 3.2564 - f1_score: 0.1186"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 4s 159ms/step - loss: 3.2503 - f1_score: 0.1197 - val_loss: 2.9978 - val_f1_score: 0.1893\n",
      "Epoch 16/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 3.2265 - f1_score: 0.1295"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 168ms/step - loss: 3.2240 - f1_score: 0.1300 - val_loss: 2.9305 - val_f1_score: 0.2015\n",
      "Epoch 17/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 3.1844 - f1_score: 0.1439"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 185ms/step - loss: 3.1799 - f1_score: 0.1448 - val_loss: 2.8763 - val_f1_score: 0.2061\n",
      "Epoch 18/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 3.0765 - f1_score: 0.1627"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 179ms/step - loss: 3.0811 - f1_score: 0.1620 - val_loss: 2.7879 - val_f1_score: 0.2598\n",
      "Epoch 19/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 3.0063 - f1_score: 0.1840"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 195ms/step - loss: 3.0017 - f1_score: 0.1847 - val_loss: 2.7149 - val_f1_score: 0.3069\n",
      "Epoch 20/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.9614 - f1_score: 0.1685"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 4s 164ms/step - loss: 2.9572 - f1_score: 0.1702 - val_loss: 2.6359 - val_f1_score: 0.3396\n",
      "Epoch 21/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.8919 - f1_score: 0.1925"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 4s 157ms/step - loss: 2.8868 - f1_score: 0.1937 - val_loss: 2.5444 - val_f1_score: 0.3752\n",
      "Epoch 22/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.8297 - f1_score: 0.2073"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 4s 163ms/step - loss: 2.8233 - f1_score: 0.2109 - val_loss: 2.5032 - val_f1_score: 0.3790\n",
      "Epoch 23/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.7471 - f1_score: 0.2272"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 169ms/step - loss: 2.7553 - f1_score: 0.2263 - val_loss: 2.4529 - val_f1_score: 0.4081\n",
      "Epoch 24/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.7794 - f1_score: 0.2154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 170ms/step - loss: 2.7768 - f1_score: 0.2153 - val_loss: 2.3774 - val_f1_score: 0.4089\n",
      "Epoch 25/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.6633 - f1_score: 0.2610"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 179ms/step - loss: 2.6671 - f1_score: 0.2600 - val_loss: 2.2874 - val_f1_score: 0.4326\n",
      "Epoch 26/500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 2.6094 - f1_score: 0.2660 - val_loss: 2.2260 - val_f1_score: 0.4220\n",
      "Epoch 27/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.5880 - f1_score: 0.2671"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 185ms/step - loss: 2.5810 - f1_score: 0.2679 - val_loss: 2.1859 - val_f1_score: 0.4556\n",
      "Epoch 28/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 2.4999 - f1_score: 0.2798 - val_loss: 2.1423 - val_f1_score: 0.4490\n",
      "Epoch 29/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.4425 - f1_score: 0.2923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 183ms/step - loss: 2.4409 - f1_score: 0.2926 - val_loss: 2.0501 - val_f1_score: 0.4880\n",
      "Epoch 30/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.4343 - f1_score: 0.2812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 185ms/step - loss: 2.4273 - f1_score: 0.2839 - val_loss: 2.0313 - val_f1_score: 0.4885\n",
      "Epoch 31/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.3761 - f1_score: 0.3112"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 4s 164ms/step - loss: 2.3782 - f1_score: 0.3104 - val_loss: 1.9683 - val_f1_score: 0.5188\n",
      "Epoch 32/500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 2.2965 - f1_score: 0.3224 - val_loss: 1.9154 - val_f1_score: 0.5019\n",
      "Epoch 33/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 2.3094 - f1_score: 0.3341 - val_loss: 1.9231 - val_f1_score: 0.5114\n",
      "Epoch 34/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.2552 - f1_score: 0.3305"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 199ms/step - loss: 2.2539 - f1_score: 0.3296 - val_loss: 1.8274 - val_f1_score: 0.5402\n",
      "Epoch 35/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.1729 - f1_score: 0.3703"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 4s 160ms/step - loss: 2.1721 - f1_score: 0.3695 - val_loss: 1.8348 - val_f1_score: 0.5460\n",
      "Epoch 36/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.1606 - f1_score: 0.3602"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 173ms/step - loss: 2.1621 - f1_score: 0.3617 - val_loss: 1.7827 - val_f1_score: 0.5589\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 2.0885 - f1_score: 0.3810 - val_loss: 1.7940 - val_f1_score: 0.5421\n",
      "Epoch 38/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.0864 - f1_score: 0.3853"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 32s 1s/step - loss: 2.0799 - f1_score: 0.3871 - val_loss: 1.6919 - val_f1_score: 0.5654\n",
      "Epoch 39/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 2.0246 - f1_score: 0.3976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 184ms/step - loss: 2.0215 - f1_score: 0.3969 - val_loss: 1.6841 - val_f1_score: 0.5797\n",
      "Epoch 40/500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 2.0117 - f1_score: 0.3959 - val_loss: 1.6439 - val_f1_score: 0.5622\n",
      "Epoch 41/500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 2.0091 - f1_score: 0.4077 - val_loss: 1.6561 - val_f1_score: 0.5699\n",
      "Epoch 42/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.9993 - f1_score: 0.4098"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 189ms/step - loss: 1.9985 - f1_score: 0.4081 - val_loss: 1.6006 - val_f1_score: 0.5816\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 1.8981 - f1_score: 0.4374 - val_loss: 1.6074 - val_f1_score: 0.5761\n",
      "Epoch 44/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.9202 - f1_score: 0.4419"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 190ms/step - loss: 1.9218 - f1_score: 0.4429 - val_loss: 1.5717 - val_f1_score: 0.6066\n",
      "Epoch 45/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.9216 - f1_score: 0.4317"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 4s 153ms/step - loss: 1.9269 - f1_score: 0.4329 - val_loss: 1.5538 - val_f1_score: 0.6077\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 1.8949 - f1_score: 0.4439 - val_loss: 1.5215 - val_f1_score: 0.6037\n",
      "Epoch 47/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.8518 - f1_score: 0.4584"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 4s 157ms/step - loss: 1.8485 - f1_score: 0.4594 - val_loss: 1.4850 - val_f1_score: 0.6335\n",
      "Epoch 48/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.8109 - f1_score: 0.4652"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 171ms/step - loss: 1.8191 - f1_score: 0.4612 - val_loss: 1.4896 - val_f1_score: 0.6372\n",
      "Epoch 49/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.8581 - f1_score: 0.4543"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 196ms/step - loss: 1.8510 - f1_score: 0.4532 - val_loss: 1.4752 - val_f1_score: 0.6372\n",
      "Epoch 50/500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 1.7873 - f1_score: 0.4624 - val_loss: 1.4511 - val_f1_score: 0.6284\n",
      "Epoch 51/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.7872 - f1_score: 0.4684 - val_loss: 1.4553 - val_f1_score: 0.6181\n",
      "Epoch 52/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.7610 - f1_score: 0.4716 - val_loss: 1.4317 - val_f1_score: 0.6116\n",
      "Epoch 53/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.7280 - f1_score: 0.4727 - val_loss: 1.4882 - val_f1_score: 0.6279\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.7237 - f1_score: 0.4780 - val_loss: 1.4520 - val_f1_score: 0.6258\n",
      "Epoch 55/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.7186 - f1_score: 0.4932 - val_loss: 1.3936 - val_f1_score: 0.6112\n",
      "Epoch 56/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.6785 - f1_score: 0.5201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 180ms/step - loss: 1.6794 - f1_score: 0.5187 - val_loss: 1.3727 - val_f1_score: 0.6547\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.6852 - f1_score: 0.5029 - val_loss: 1.3411 - val_f1_score: 0.6501\n",
      "Epoch 58/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.6300 - f1_score: 0.5172"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 187ms/step - loss: 1.6365 - f1_score: 0.5146 - val_loss: 1.3697 - val_f1_score: 0.6668\n",
      "Epoch 59/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.6248 - f1_score: 0.5090 - val_loss: 1.3478 - val_f1_score: 0.6471\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.6485 - f1_score: 0.4977 - val_loss: 1.3412 - val_f1_score: 0.6485\n",
      "Epoch 61/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.6041 - f1_score: 0.5280 - val_loss: 1.3348 - val_f1_score: 0.6321\n",
      "Epoch 62/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.5782 - f1_score: 0.5249 - val_loss: 1.2991 - val_f1_score: 0.6568\n",
      "Epoch 63/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.5941 - f1_score: 0.5209 - val_loss: 1.3133 - val_f1_score: 0.6509\n",
      "Epoch 64/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.4947 - f1_score: 0.5459"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 198ms/step - loss: 1.4974 - f1_score: 0.5476 - val_loss: 1.3162 - val_f1_score: 0.6700\n",
      "Epoch 65/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.5895 - f1_score: 0.5190 - val_loss: 1.2892 - val_f1_score: 0.6586\n",
      "Epoch 66/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.5348 - f1_score: 0.5457"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 175ms/step - loss: 1.5326 - f1_score: 0.5470 - val_loss: 1.2835 - val_f1_score: 0.6740\n",
      "Epoch 67/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.5699 - f1_score: 0.5304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 173ms/step - loss: 1.5621 - f1_score: 0.5341 - val_loss: 1.2566 - val_f1_score: 0.6796\n",
      "Epoch 68/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.4917 - f1_score: 0.5568"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 201ms/step - loss: 1.4945 - f1_score: 0.5570 - val_loss: 1.2534 - val_f1_score: 0.6851\n",
      "Epoch 69/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.4831 - f1_score: 0.5572 - val_loss: 1.2858 - val_f1_score: 0.6565\n",
      "Epoch 70/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.4904 - f1_score: 0.5540 - val_loss: 1.2446 - val_f1_score: 0.6831\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.4274 - f1_score: 0.5801 - val_loss: 1.2598 - val_f1_score: 0.6701\n",
      "Epoch 72/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.4776 - f1_score: 0.5614"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 193ms/step - loss: 1.4822 - f1_score: 0.5601 - val_loss: 1.2088 - val_f1_score: 0.6855\n",
      "Epoch 73/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.3840 - f1_score: 0.5871"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 170ms/step - loss: 1.3842 - f1_score: 0.5878 - val_loss: 1.2044 - val_f1_score: 0.6963\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.4235 - f1_score: 0.5776 - val_loss: 1.2119 - val_f1_score: 0.6796\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.4081 - f1_score: 0.5618 - val_loss: 1.1845 - val_f1_score: 0.6850\n",
      "Epoch 76/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.4107 - f1_score: 0.5723"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 18s 684ms/step - loss: 1.4098 - f1_score: 0.5721 - val_loss: 1.1772 - val_f1_score: 0.7065\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.3912 - f1_score: 0.5765 - val_loss: 1.1959 - val_f1_score: 0.7043\n",
      "Epoch 78/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.4102 - f1_score: 0.5722"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 172ms/step - loss: 1.4025 - f1_score: 0.5729 - val_loss: 1.1871 - val_f1_score: 0.7198\n",
      "Epoch 79/500\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 1.3849 - f1_score: 0.5754 - val_loss: 1.1865 - val_f1_score: 0.7087\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.3697 - f1_score: 0.5968 - val_loss: 1.2492 - val_f1_score: 0.6728\n",
      "Epoch 81/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.3495 - f1_score: 0.5848 - val_loss: 1.1951 - val_f1_score: 0.7101\n",
      "Epoch 82/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.3765 - f1_score: 0.5922 - val_loss: 1.1733 - val_f1_score: 0.6752\n",
      "Epoch 83/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.3146 - f1_score: 0.5928 - val_loss: 1.1945 - val_f1_score: 0.7113\n",
      "Epoch 84/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.3319 - f1_score: 0.5908 - val_loss: 1.2064 - val_f1_score: 0.6784\n",
      "Epoch 85/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.3211 - f1_score: 0.5931"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 194ms/step - loss: 1.3184 - f1_score: 0.5939 - val_loss: 1.1552 - val_f1_score: 0.7200\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.2832 - f1_score: 0.5994 - val_loss: 1.1668 - val_f1_score: 0.7049\n",
      "Epoch 87/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.3068 - f1_score: 0.5991 - val_loss: 1.1313 - val_f1_score: 0.7102\n",
      "Epoch 88/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.2915 - f1_score: 0.6111 - val_loss: 1.1660 - val_f1_score: 0.6998\n",
      "Epoch 89/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.2398 - f1_score: 0.6261 - val_loss: 1.1204 - val_f1_score: 0.6991\n",
      "Epoch 90/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.2772 - f1_score: 0.6156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 191ms/step - loss: 1.2754 - f1_score: 0.6140 - val_loss: 1.1133 - val_f1_score: 0.7366\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.2887 - f1_score: 0.6096 - val_loss: 1.1120 - val_f1_score: 0.7163\n",
      "Epoch 92/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.2685 - f1_score: 0.6110 - val_loss: 1.1612 - val_f1_score: 0.7006\n",
      "Epoch 93/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.2880 - f1_score: 0.5972 - val_loss: 1.1012 - val_f1_score: 0.7358\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.2593 - f1_score: 0.6217 - val_loss: 1.1730 - val_f1_score: 0.6889\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.2095 - f1_score: 0.6382 - val_loss: 1.1669 - val_f1_score: 0.6987\n",
      "Epoch 96/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.1988 - f1_score: 0.6477 - val_loss: 1.1257 - val_f1_score: 0.7177\n",
      "Epoch 97/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.2279 - f1_score: 0.6227 - val_loss: 1.1200 - val_f1_score: 0.7281\n",
      "Epoch 98/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.2085 - f1_score: 0.6146 - val_loss: 1.1504 - val_f1_score: 0.7208\n",
      "Epoch 99/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.1846 - f1_score: 0.6420 - val_loss: 1.1351 - val_f1_score: 0.7358\n",
      "Epoch 100/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.2112 - f1_score: 0.6235 - val_loss: 1.1602 - val_f1_score: 0.7005\n",
      "Epoch 101/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.1688 - f1_score: 0.6388 - val_loss: 1.1293 - val_f1_score: 0.7140\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.1612 - f1_score: 0.6530 - val_loss: 1.1283 - val_f1_score: 0.7208\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.1773 - f1_score: 0.6391 - val_loss: 1.1056 - val_f1_score: 0.7162\n",
      "Epoch 104/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.1082 - f1_score: 0.6677 - val_loss: 1.1046 - val_f1_score: 0.7206\n",
      "Epoch 105/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1566 - f1_score: 0.6402"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 13s 481ms/step - loss: 1.1562 - f1_score: 0.6415 - val_loss: 1.0578 - val_f1_score: 0.7456\n",
      "Epoch 106/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.1450 - f1_score: 0.6424 - val_loss: 1.1065 - val_f1_score: 0.7211\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.1332 - f1_score: 0.6523 - val_loss: 1.1214 - val_f1_score: 0.7207\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.1434 - f1_score: 0.6428 - val_loss: 1.0687 - val_f1_score: 0.7416\n",
      "Epoch 109/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.1114 - f1_score: 0.6582 - val_loss: 1.0970 - val_f1_score: 0.7289\n",
      "Epoch 110/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.1282 - f1_score: 0.6550 - val_loss: 1.1297 - val_f1_score: 0.7320\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.1352 - f1_score: 0.6575 - val_loss: 1.0955 - val_f1_score: 0.7451\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.0830 - f1_score: 0.6594 - val_loss: 1.1448 - val_f1_score: 0.7200\n",
      "Epoch 113/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1096 - f1_score: 0.6572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 197ms/step - loss: 1.1090 - f1_score: 0.6580 - val_loss: 1.0580 - val_f1_score: 0.7492\n",
      "Epoch 114/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1260 - f1_score: 0.6476"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 183ms/step - loss: 1.1331 - f1_score: 0.6471 - val_loss: 1.1136 - val_f1_score: 0.7498\n",
      "Epoch 115/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.1259 - f1_score: 0.6489"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 175ms/step - loss: 1.1305 - f1_score: 0.6456 - val_loss: 1.0833 - val_f1_score: 0.7619\n",
      "Epoch 116/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.1133 - f1_score: 0.6536 - val_loss: 1.0820 - val_f1_score: 0.7401\n",
      "Epoch 117/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.0876 - f1_score: 0.6643 - val_loss: 1.0816 - val_f1_score: 0.7298\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.0569 - f1_score: 0.6706 - val_loss: 1.0845 - val_f1_score: 0.7307\n",
      "Epoch 119/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.0794 - f1_score: 0.6616 - val_loss: 1.1633 - val_f1_score: 0.7235\n",
      "Epoch 120/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.0131 - f1_score: 0.6940 - val_loss: 1.1617 - val_f1_score: 0.7127\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.0575 - f1_score: 0.6805 - val_loss: 1.0899 - val_f1_score: 0.7326\n",
      "Epoch 122/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.0519 - f1_score: 0.6744 - val_loss: 1.1084 - val_f1_score: 0.7381\n",
      "Epoch 123/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.0333 - f1_score: 0.6825 - val_loss: 1.0892 - val_f1_score: 0.7521\n",
      "Epoch 124/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0986 - f1_score: 0.6587"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 6s 219ms/step - loss: 1.0923 - f1_score: 0.6632 - val_loss: 1.0606 - val_f1_score: 0.7699\n",
      "Epoch 125/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.0282 - f1_score: 0.6779 - val_loss: 1.1188 - val_f1_score: 0.7323\n",
      "Epoch 126/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.0236 - f1_score: 0.6783 - val_loss: 1.1237 - val_f1_score: 0.7378\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.9983 - f1_score: 0.6860 - val_loss: 1.0703 - val_f1_score: 0.7384\n",
      "Epoch 128/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.0280 - f1_score: 0.6871 - val_loss: 1.0725 - val_f1_score: 0.7635\n",
      "Epoch 129/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.0355 - f1_score: 0.6845 - val_loss: 1.0767 - val_f1_score: 0.7266\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.9943 - f1_score: 0.6893 - val_loss: 1.1004 - val_f1_score: 0.7419\n",
      "Epoch 131/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.0350 - f1_score: 0.6740 - val_loss: 1.1311 - val_f1_score: 0.7347\n",
      "Epoch 132/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.9988 - f1_score: 0.6983 - val_loss: 1.0725 - val_f1_score: 0.7612\n",
      "Epoch 133/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.9594 - f1_score: 0.6984 - val_loss: 1.1158 - val_f1_score: 0.7363\n",
      "Epoch 134/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.0003 - f1_score: 0.6863 - val_loss: 1.0647 - val_f1_score: 0.7447\n",
      "Epoch 135/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.9356 - f1_score: 0.7048 - val_loss: 1.0652 - val_f1_score: 0.7553\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.9699 - f1_score: 0.6976 - val_loss: 1.0417 - val_f1_score: 0.7455\n",
      "Epoch 137/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.9770 - f1_score: 0.6950 - val_loss: 1.0388 - val_f1_score: 0.7473\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.9323 - f1_score: 0.7149 - val_loss: 1.0842 - val_f1_score: 0.7526\n",
      "Epoch 139/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.9787 - f1_score: 0.7066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 8s 301ms/step - loss: 0.9731 - f1_score: 0.7080 - val_loss: 1.0512 - val_f1_score: 0.7725\n",
      "Epoch 140/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.9244 - f1_score: 0.7180 - val_loss: 1.0861 - val_f1_score: 0.7495\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.9461 - f1_score: 0.7028 - val_loss: 1.0336 - val_f1_score: 0.7546\n",
      "Epoch 142/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.9462 - f1_score: 0.7186 - val_loss: 1.0767 - val_f1_score: 0.7631\n",
      "Epoch 143/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.9186 - f1_score: 0.7029 - val_loss: 1.0172 - val_f1_score: 0.7575\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.9011 - f1_score: 0.7236 - val_loss: 1.1005 - val_f1_score: 0.7515\n",
      "Epoch 145/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.9454 - f1_score: 0.7008 - val_loss: 1.0543 - val_f1_score: 0.7713\n",
      "Epoch 146/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.9031 - f1_score: 0.7102 - val_loss: 1.0987 - val_f1_score: 0.7433\n",
      "Epoch 147/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8893 - f1_score: 0.7331"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 174ms/step - loss: 0.8976 - f1_score: 0.7314 - val_loss: 1.0378 - val_f1_score: 0.7771\n",
      "Epoch 148/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.9224 - f1_score: 0.7226 - val_loss: 1.0543 - val_f1_score: 0.7494\n",
      "Epoch 149/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.9055 - f1_score: 0.7056 - val_loss: 1.0816 - val_f1_score: 0.7550\n",
      "Epoch 150/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.8996 - f1_score: 0.7249 - val_loss: 1.0899 - val_f1_score: 0.7722\n",
      "Epoch 151/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.8991 - f1_score: 0.7220 - val_loss: 1.0320 - val_f1_score: 0.7680\n",
      "Epoch 152/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.8619 - f1_score: 0.7229 - val_loss: 1.1108 - val_f1_score: 0.7521\n",
      "Epoch 153/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8484 - f1_score: 0.7261"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 177ms/step - loss: 0.8466 - f1_score: 0.7265 - val_loss: 1.0338 - val_f1_score: 0.7774\n",
      "Epoch 154/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.8789 - f1_score: 0.7204 - val_loss: 1.0709 - val_f1_score: 0.7640\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.8647 - f1_score: 0.7234 - val_loss: 1.0442 - val_f1_score: 0.7620\n",
      "Epoch 156/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.8731 - f1_score: 0.7213 - val_loss: 1.0359 - val_f1_score: 0.7660\n",
      "Epoch 157/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.8416 - f1_score: 0.7250 - val_loss: 1.0830 - val_f1_score: 0.7621\n",
      "Epoch 158/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.8846 - f1_score: 0.7270 - val_loss: 1.2240 - val_f1_score: 0.7300\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.9052 - f1_score: 0.7219 - val_loss: 1.0510 - val_f1_score: 0.7499\n",
      "Epoch 160/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8432 - f1_score: 0.7383"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 202ms/step - loss: 0.8411 - f1_score: 0.7389 - val_loss: 1.0603 - val_f1_score: 0.7835\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.8524 - f1_score: 0.7312 - val_loss: 1.0585 - val_f1_score: 0.7558\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.8548 - f1_score: 0.7354 - val_loss: 1.0931 - val_f1_score: 0.7547\n",
      "Epoch 163/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.8689 - f1_score: 0.7074 - val_loss: 1.1267 - val_f1_score: 0.7310\n",
      "Epoch 164/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.8401 - f1_score: 0.7270 - val_loss: 1.0260 - val_f1_score: 0.7750\n",
      "Epoch 165/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.7963 - f1_score: 0.7417 - val_loss: 1.0656 - val_f1_score: 0.7742\n",
      "Epoch 166/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.8542 - f1_score: 0.7303 - val_loss: 1.0502 - val_f1_score: 0.7808\n",
      "Epoch 167/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.8015 - f1_score: 0.7454 - val_loss: 1.0313 - val_f1_score: 0.7730\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.8628 - f1_score: 0.7251 - val_loss: 1.0294 - val_f1_score: 0.7680\n",
      "Epoch 169/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.8000 - f1_score: 0.7431 - val_loss: 1.0826 - val_f1_score: 0.7650\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.8459 - f1_score: 0.7318 - val_loss: 1.0447 - val_f1_score: 0.7788\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.7748 - f1_score: 0.7487 - val_loss: 1.0097 - val_f1_score: 0.7791\n",
      "Epoch 172/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7959 - f1_score: 0.7444 - val_loss: 1.0806 - val_f1_score: 0.7633\n",
      "Epoch 173/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.7687 - f1_score: 0.7501"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 21s 795ms/step - loss: 0.7596 - f1_score: 0.7528 - val_loss: 1.0368 - val_f1_score: 0.7972\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.8087 - f1_score: 0.7396 - val_loss: 1.0296 - val_f1_score: 0.7874\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.8325 - f1_score: 0.7339 - val_loss: 1.0375 - val_f1_score: 0.7857\n",
      "Epoch 176/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.7836 - f1_score: 0.7441 - val_loss: 1.0855 - val_f1_score: 0.7690\n",
      "Epoch 177/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.7883 - f1_score: 0.7387 - val_loss: 1.0206 - val_f1_score: 0.7836\n",
      "Epoch 178/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.7750 - f1_score: 0.7548 - val_loss: 1.0370 - val_f1_score: 0.7709\n",
      "Epoch 179/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7635 - f1_score: 0.7462 - val_loss: 1.0671 - val_f1_score: 0.7704\n",
      "Epoch 180/500\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.7623 - f1_score: 0.7578 - val_loss: 1.0664 - val_f1_score: 0.7404\n",
      "Epoch 181/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7657 - f1_score: 0.7547 - val_loss: 1.0631 - val_f1_score: 0.7589\n",
      "Epoch 182/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7526 - f1_score: 0.7593 - val_loss: 1.1133 - val_f1_score: 0.7556\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.7926 - f1_score: 0.7456 - val_loss: 1.0642 - val_f1_score: 0.7739\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7780 - f1_score: 0.7563 - val_loss: 1.0515 - val_f1_score: 0.7707\n",
      "Epoch 185/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7776 - f1_score: 0.7567 - val_loss: 1.0907 - val_f1_score: 0.7684\n",
      "Epoch 186/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7918 - f1_score: 0.7444 - val_loss: 1.0897 - val_f1_score: 0.7666\n",
      "Epoch 187/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7172 - f1_score: 0.7691 - val_loss: 1.0464 - val_f1_score: 0.7823\n",
      "Epoch 188/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7864 - f1_score: 0.7430 - val_loss: 1.0003 - val_f1_score: 0.7889\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7638 - f1_score: 0.7606 - val_loss: 1.0349 - val_f1_score: 0.7683\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7492 - f1_score: 0.7532 - val_loss: 1.0294 - val_f1_score: 0.7955\n",
      "Epoch 191/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7585 - f1_score: 0.7620 - val_loss: 1.0228 - val_f1_score: 0.7821\n",
      "Epoch 192/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7662 - f1_score: 0.7492 - val_loss: 1.0638 - val_f1_score: 0.7686\n",
      "Epoch 193/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7286 - f1_score: 0.7588 - val_loss: 1.0450 - val_f1_score: 0.7953\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7662 - f1_score: 0.7579 - val_loss: 1.0515 - val_f1_score: 0.7808\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7386 - f1_score: 0.7603 - val_loss: 1.0628 - val_f1_score: 0.7934\n",
      "Epoch 196/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7380 - f1_score: 0.7633 - val_loss: 1.0689 - val_f1_score: 0.7536\n",
      "Epoch 197/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.6996 - f1_score: 0.7752 - val_loss: 1.0839 - val_f1_score: 0.7792\n",
      "Epoch 198/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7279 - f1_score: 0.7583 - val_loss: 1.0783 - val_f1_score: 0.7738\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7441 - f1_score: 0.7588 - val_loss: 1.0303 - val_f1_score: 0.7773\n",
      "Epoch 200/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7266 - f1_score: 0.7622 - val_loss: 1.0931 - val_f1_score: 0.7696\n",
      "Epoch 201/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7239 - f1_score: 0.7716 - val_loss: 1.0261 - val_f1_score: 0.7901\n",
      "Epoch 202/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7399 - f1_score: 0.7622 - val_loss: 1.0548 - val_f1_score: 0.7793\n",
      "Epoch 203/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.7099 - f1_score: 0.7700 - val_loss: 1.0676 - val_f1_score: 0.7622\n",
      "Epoch 204/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7173 - f1_score: 0.7691 - val_loss: 1.0287 - val_f1_score: 0.7777\n",
      "Epoch 205/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.7036 - f1_score: 0.7755 - val_loss: 1.0336 - val_f1_score: 0.7918\n",
      "Epoch 206/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.7122 - f1_score: 0.7665 - val_loss: 1.0891 - val_f1_score: 0.7743\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6927 - f1_score: 0.7671 - val_loss: 0.9727 - val_f1_score: 0.7951\n",
      "Epoch 208/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6902 - f1_score: 0.7883 - val_loss: 1.0321 - val_f1_score: 0.7707\n",
      "Epoch 209/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.6748 - f1_score: 0.7839 - val_loss: 1.0771 - val_f1_score: 0.7805\n",
      "Epoch 210/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.6751 - f1_score: 0.7861 - val_loss: 1.0982 - val_f1_score: 0.7805\n",
      "Epoch 211/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6628 - f1_score: 0.7860 - val_loss: 1.0837 - val_f1_score: 0.7576\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.7350 - f1_score: 0.7674 - val_loss: 1.0747 - val_f1_score: 0.7799\n",
      "Epoch 213/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6816 - f1_score: 0.7875 - val_loss: 1.0913 - val_f1_score: 0.7838\n",
      "Epoch 214/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6860 - f1_score: 0.7731 - val_loss: 1.0992 - val_f1_score: 0.7680\n",
      "Epoch 215/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6889 - f1_score: 0.7675 - val_loss: 1.0606 - val_f1_score: 0.7838\n",
      "Epoch 216/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6584 - f1_score: 0.7856 - val_loss: 1.0528 - val_f1_score: 0.7742\n",
      "Epoch 217/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6724 - f1_score: 0.7851 - val_loss: 1.0464 - val_f1_score: 0.7771\n",
      "Epoch 218/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.6852 - f1_score: 0.7731 - val_loss: 1.1006 - val_f1_score: 0.7824\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6606 - f1_score: 0.7842 - val_loss: 1.0852 - val_f1_score: 0.7688\n",
      "Epoch 220/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6886 - f1_score: 0.7799 - val_loss: 1.0701 - val_f1_score: 0.7602\n",
      "Epoch 221/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6508 - f1_score: 0.7923 - val_loss: 1.0722 - val_f1_score: 0.7849\n",
      "Epoch 222/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6705 - f1_score: 0.7876 - val_loss: 1.0755 - val_f1_score: 0.7745\n",
      "Epoch 223/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6545 - f1_score: 0.7892 - val_loss: 1.0402 - val_f1_score: 0.7854\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6845 - f1_score: 0.7691 - val_loss: 1.0839 - val_f1_score: 0.7637\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.6316 - f1_score: 0.8038 - val_loss: 1.1127 - val_f1_score: 0.7654\n",
      "Epoch 226/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6428 - f1_score: 0.7952 - val_loss: 1.0513 - val_f1_score: 0.7728\n",
      "Epoch 227/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6560 - f1_score: 0.7772 - val_loss: 1.0895 - val_f1_score: 0.7909\n",
      "Epoch 228/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6426 - f1_score: 0.8000 - val_loss: 1.0307 - val_f1_score: 0.7963\n",
      "Epoch 229/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6567 - f1_score: 0.7839 - val_loss: 1.1751 - val_f1_score: 0.7596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6703 - f1_score: 0.7816 - val_loss: 1.0351 - val_f1_score: 0.7892\n",
      "Epoch 231/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6238 - f1_score: 0.7989 - val_loss: 1.0918 - val_f1_score: 0.7759\n",
      "Epoch 232/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6181 - f1_score: 0.8025 - val_loss: 1.0412 - val_f1_score: 0.7881\n",
      "Epoch 233/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.6043 - f1_score: 0.8104 - val_loss: 1.0879 - val_f1_score: 0.7735\n",
      "Epoch 234/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6577 - f1_score: 0.7875 - val_loss: 1.0951 - val_f1_score: 0.7764\n",
      "Epoch 235/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6204 - f1_score: 0.7995 - val_loss: 1.1822 - val_f1_score: 0.7634\n",
      "Epoch 236/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.6321 - f1_score: 0.7913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 7s 258ms/step - loss: 0.6307 - f1_score: 0.7915 - val_loss: 1.0759 - val_f1_score: 0.8052\n",
      "Epoch 237/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.6295 - f1_score: 0.8063 - val_loss: 1.0682 - val_f1_score: 0.7875\n",
      "Epoch 238/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6130 - f1_score: 0.7959 - val_loss: 1.1468 - val_f1_score: 0.7399\n",
      "Epoch 239/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6113 - f1_score: 0.8026 - val_loss: 1.0720 - val_f1_score: 0.7771\n",
      "Epoch 240/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.6356 - f1_score: 0.7882 - val_loss: 1.0866 - val_f1_score: 0.7703\n",
      "Epoch 241/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6489 - f1_score: 0.7884 - val_loss: 1.0713 - val_f1_score: 0.7749\n",
      "Epoch 242/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.6352 - f1_score: 0.7978 - val_loss: 1.0257 - val_f1_score: 0.7951\n",
      "Epoch 243/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5721 - f1_score: 0.8138 - val_loss: 1.0323 - val_f1_score: 0.8010\n",
      "Epoch 244/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5924 - f1_score: 0.8081 - val_loss: 1.1030 - val_f1_score: 0.7791\n",
      "Epoch 245/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5884 - f1_score: 0.8030 - val_loss: 1.1091 - val_f1_score: 0.7790\n",
      "Epoch 246/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6052 - f1_score: 0.7993 - val_loss: 1.0786 - val_f1_score: 0.7666\n",
      "Epoch 247/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6041 - f1_score: 0.8071 - val_loss: 1.0768 - val_f1_score: 0.7731\n",
      "Epoch 248/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6138 - f1_score: 0.7976 - val_loss: 1.0273 - val_f1_score: 0.8011\n",
      "Epoch 249/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6105 - f1_score: 0.8001 - val_loss: 1.0743 - val_f1_score: 0.7829\n",
      "Epoch 250/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5916 - f1_score: 0.8103 - val_loss: 1.0830 - val_f1_score: 0.7911\n",
      "Epoch 251/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5735 - f1_score: 0.8064 - val_loss: 1.0834 - val_f1_score: 0.7950\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5813 - f1_score: 0.7948 - val_loss: 1.1618 - val_f1_score: 0.7687\n",
      "Epoch 253/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6092 - f1_score: 0.7981 - val_loss: 1.0739 - val_f1_score: 0.7848\n",
      "Epoch 254/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6326 - f1_score: 0.8022 - val_loss: 1.1647 - val_f1_score: 0.7636\n",
      "Epoch 255/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6066 - f1_score: 0.8082 - val_loss: 1.0894 - val_f1_score: 0.7805\n",
      "Epoch 256/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5746 - f1_score: 0.8189 - val_loss: 1.0634 - val_f1_score: 0.7861\n",
      "Epoch 257/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.6075 - f1_score: 0.8049 - val_loss: 1.0602 - val_f1_score: 0.7999\n",
      "Epoch 258/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5746 - f1_score: 0.8135 - val_loss: 1.0642 - val_f1_score: 0.7986\n",
      "Epoch 259/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5881 - f1_score: 0.8029 - val_loss: 1.1513 - val_f1_score: 0.7693\n",
      "Epoch 260/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5578 - f1_score: 0.8151 - val_loss: 1.0735 - val_f1_score: 0.7859\n",
      "Epoch 261/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5872 - f1_score: 0.8089 - val_loss: 1.0276 - val_f1_score: 0.7925\n",
      "Epoch 262/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5664 - f1_score: 0.8170 - val_loss: 1.0848 - val_f1_score: 0.7783\n",
      "Epoch 263/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5937 - f1_score: 0.8159 - val_loss: 1.0734 - val_f1_score: 0.8031\n",
      "Epoch 264/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.6131 - f1_score: 0.7966 - val_loss: 1.1044 - val_f1_score: 0.7758\n",
      "Epoch 265/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5761 - f1_score: 0.8096 - val_loss: 1.0547 - val_f1_score: 0.7883\n",
      "Epoch 266/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5615 - f1_score: 0.8107 - val_loss: 1.0626 - val_f1_score: 0.7854\n",
      "Epoch 267/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5865 - f1_score: 0.8101 - val_loss: 1.0445 - val_f1_score: 0.7874\n",
      "Epoch 268/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5697 - f1_score: 0.8073 - val_loss: 1.0515 - val_f1_score: 0.7747\n",
      "Epoch 269/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5233 - f1_score: 0.8241 - val_loss: 1.1306 - val_f1_score: 0.7587\n",
      "Epoch 270/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5272 - f1_score: 0.8244 - val_loss: 1.1866 - val_f1_score: 0.7726\n",
      "Epoch 271/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5400 - f1_score: 0.8146 - val_loss: 1.0629 - val_f1_score: 0.7977\n",
      "Epoch 272/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5612 - f1_score: 0.8269 - val_loss: 1.0708 - val_f1_score: 0.7933\n",
      "Epoch 273/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5757 - f1_score: 0.8141 - val_loss: 1.0901 - val_f1_score: 0.7792\n",
      "Epoch 274/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5490 - f1_score: 0.8213 - val_loss: 1.1135 - val_f1_score: 0.7806\n",
      "Epoch 275/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5744 - f1_score: 0.8081 - val_loss: 1.1098 - val_f1_score: 0.7670\n",
      "Epoch 276/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5680 - f1_score: 0.8110 - val_loss: 1.1220 - val_f1_score: 0.7752\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5561 - f1_score: 0.8237 - val_loss: 1.0317 - val_f1_score: 0.7890\n",
      "Epoch 278/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5670 - f1_score: 0.8238 - val_loss: 1.0417 - val_f1_score: 0.8022\n",
      "Epoch 279/500\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.5313 - f1_score: 0.8262 - val_loss: 1.0251 - val_f1_score: 0.8020\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5523 - f1_score: 0.8187 - val_loss: 1.1473 - val_f1_score: 0.7924\n",
      "Epoch 281/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5186 - f1_score: 0.8321 - val_loss: 1.1344 - val_f1_score: 0.7867\n",
      "Epoch 282/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5448 - f1_score: 0.8253 - val_loss: 1.0724 - val_f1_score: 0.7872\n",
      "Epoch 283/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.5344 - f1_score: 0.8261"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 6s 219ms/step - loss: 0.5302 - f1_score: 0.8272 - val_loss: 1.0956 - val_f1_score: 0.8189\n",
      "Epoch 284/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5397 - f1_score: 0.8247 - val_loss: 1.1059 - val_f1_score: 0.7794\n",
      "Epoch 285/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5488 - f1_score: 0.8257 - val_loss: 1.1269 - val_f1_score: 0.7952\n",
      "Epoch 286/500\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.5515 - f1_score: 0.8180 - val_loss: 1.1288 - val_f1_score: 0.7588\n",
      "Epoch 287/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5237 - f1_score: 0.8267 - val_loss: 1.0727 - val_f1_score: 0.7919\n",
      "Epoch 288/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5010 - f1_score: 0.8287 - val_loss: 1.0870 - val_f1_score: 0.8003\n",
      "Epoch 289/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5495 - f1_score: 0.8162 - val_loss: 1.1286 - val_f1_score: 0.7688\n",
      "Epoch 290/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5119 - f1_score: 0.8382 - val_loss: 1.1144 - val_f1_score: 0.7857\n",
      "Epoch 291/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5319 - f1_score: 0.8215 - val_loss: 1.0468 - val_f1_score: 0.8034\n",
      "Epoch 292/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5126 - f1_score: 0.8352 - val_loss: 1.0886 - val_f1_score: 0.7945\n",
      "Epoch 293/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5440 - f1_score: 0.8260 - val_loss: 1.0666 - val_f1_score: 0.7936\n",
      "Epoch 294/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5161 - f1_score: 0.8270 - val_loss: 1.0157 - val_f1_score: 0.8089\n",
      "Epoch 295/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5198 - f1_score: 0.8264 - val_loss: 1.0849 - val_f1_score: 0.7894\n",
      "Epoch 296/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5566 - f1_score: 0.8160 - val_loss: 1.1631 - val_f1_score: 0.7676\n",
      "Epoch 297/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4996 - f1_score: 0.8385 - val_loss: 1.1065 - val_f1_score: 0.7860\n",
      "Epoch 298/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5150 - f1_score: 0.8306 - val_loss: 1.1889 - val_f1_score: 0.7629\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5303 - f1_score: 0.8267 - val_loss: 1.0657 - val_f1_score: 0.7731\n",
      "Epoch 300/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5349 - f1_score: 0.8170 - val_loss: 1.1493 - val_f1_score: 0.7741\n",
      "Epoch 301/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5291 - f1_score: 0.8251 - val_loss: 1.0700 - val_f1_score: 0.7966\n",
      "Epoch 302/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.5049 - f1_score: 0.8270 - val_loss: 1.1268 - val_f1_score: 0.7859\n",
      "Epoch 303/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5304 - f1_score: 0.8248 - val_loss: 1.1775 - val_f1_score: 0.7844\n",
      "Epoch 304/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5100 - f1_score: 0.8404 - val_loss: 1.1300 - val_f1_score: 0.7881\n",
      "Epoch 305/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5107 - f1_score: 0.8326 - val_loss: 1.0882 - val_f1_score: 0.8103\n",
      "Epoch 306/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5002 - f1_score: 0.8403 - val_loss: 1.1159 - val_f1_score: 0.7800\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4845 - f1_score: 0.8499 - val_loss: 1.0888 - val_f1_score: 0.7879\n",
      "Epoch 308/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4989 - f1_score: 0.8363 - val_loss: 1.0898 - val_f1_score: 0.7996\n",
      "Epoch 309/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4798 - f1_score: 0.8541 - val_loss: 1.0772 - val_f1_score: 0.7831\n",
      "Epoch 310/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5251 - f1_score: 0.8305 - val_loss: 1.0628 - val_f1_score: 0.8035\n",
      "Epoch 311/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5299 - f1_score: 0.8222 - val_loss: 1.0827 - val_f1_score: 0.7897\n",
      "Epoch 312/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4958 - f1_score: 0.8276 - val_loss: 1.1112 - val_f1_score: 0.8058\n",
      "Epoch 313/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.5024 - f1_score: 0.8251 - val_loss: 1.0926 - val_f1_score: 0.7893\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4605 - f1_score: 0.8501 - val_loss: 1.1388 - val_f1_score: 0.7942\n",
      "Epoch 315/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4848 - f1_score: 0.8377 - val_loss: 1.1394 - val_f1_score: 0.7715\n",
      "Epoch 316/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4963 - f1_score: 0.8328 - val_loss: 1.0899 - val_f1_score: 0.8023\n",
      "Epoch 317/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4997 - f1_score: 0.8280 - val_loss: 1.0904 - val_f1_score: 0.7810\n",
      "Epoch 318/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4986 - f1_score: 0.8334 - val_loss: 1.1121 - val_f1_score: 0.7864\n",
      "Epoch 319/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4967 - f1_score: 0.8407 - val_loss: 1.1072 - val_f1_score: 0.7942\n",
      "Epoch 320/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4937 - f1_score: 0.8348 - val_loss: 1.1429 - val_f1_score: 0.7918\n",
      "Epoch 321/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4730 - f1_score: 0.8380 - val_loss: 1.1176 - val_f1_score: 0.7797\n",
      "Epoch 322/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4692 - f1_score: 0.8409 - val_loss: 1.1441 - val_f1_score: 0.8006\n",
      "Epoch 323/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4901 - f1_score: 0.8419 - val_loss: 1.1509 - val_f1_score: 0.7883\n",
      "Epoch 324/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4832 - f1_score: 0.8471 - val_loss: 1.0860 - val_f1_score: 0.8023\n",
      "Epoch 325/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4656 - f1_score: 0.8501 - val_loss: 1.1591 - val_f1_score: 0.7798\n",
      "Epoch 326/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4827 - f1_score: 0.8433 - val_loss: 1.1502 - val_f1_score: 0.8058\n",
      "Epoch 327/500\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.4963 - f1_score: 0.8436 - val_loss: 1.1506 - val_f1_score: 0.7750\n",
      "Epoch 328/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4917 - f1_score: 0.8383 - val_loss: 1.1532 - val_f1_score: 0.7845\n",
      "Epoch 329/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4643 - f1_score: 0.8432 - val_loss: 1.1510 - val_f1_score: 0.7780\n",
      "Epoch 330/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4631 - f1_score: 0.8487 - val_loss: 1.0993 - val_f1_score: 0.7976\n",
      "Epoch 331/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4310 - f1_score: 0.8605 - val_loss: 1.1518 - val_f1_score: 0.7779\n",
      "Epoch 332/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4803 - f1_score: 0.8453 - val_loss: 1.0963 - val_f1_score: 0.7893\n",
      "Epoch 333/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4662 - f1_score: 0.8456 - val_loss: 1.0940 - val_f1_score: 0.7919\n",
      "Epoch 334/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4654 - f1_score: 0.8516 - val_loss: 1.1885 - val_f1_score: 0.7744\n",
      "Epoch 335/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4677 - f1_score: 0.8534 - val_loss: 1.0860 - val_f1_score: 0.7942\n",
      "Epoch 336/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4889 - f1_score: 0.8394 - val_loss: 1.1883 - val_f1_score: 0.7739\n",
      "Epoch 337/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4660 - f1_score: 0.8473 - val_loss: 1.0949 - val_f1_score: 0.7920\n",
      "Epoch 338/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4556 - f1_score: 0.8452 - val_loss: 1.1636 - val_f1_score: 0.7939\n",
      "Epoch 339/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4594 - f1_score: 0.8425 - val_loss: 1.0720 - val_f1_score: 0.8168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4772 - f1_score: 0.8464 - val_loss: 1.1731 - val_f1_score: 0.7913\n",
      "Epoch 341/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4930 - f1_score: 0.8340 - val_loss: 1.1502 - val_f1_score: 0.7790\n",
      "Epoch 342/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4712 - f1_score: 0.8450 - val_loss: 1.1391 - val_f1_score: 0.7911\n",
      "Epoch 343/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4627 - f1_score: 0.8445 - val_loss: 1.0965 - val_f1_score: 0.8066\n",
      "Epoch 344/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4718 - f1_score: 0.8379 - val_loss: 1.1706 - val_f1_score: 0.7789\n",
      "Epoch 345/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4504 - f1_score: 0.8464 - val_loss: 1.1470 - val_f1_score: 0.7946\n",
      "Epoch 346/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4629 - f1_score: 0.8471 - val_loss: 1.1563 - val_f1_score: 0.8016\n",
      "Epoch 347/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4221 - f1_score: 0.8639 - val_loss: 1.1391 - val_f1_score: 0.7822\n",
      "Epoch 348/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4582 - f1_score: 0.8496 - val_loss: 1.1120 - val_f1_score: 0.8016\n",
      "Epoch 349/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4488 - f1_score: 0.8508 - val_loss: 1.0938 - val_f1_score: 0.7925\n",
      "Epoch 350/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4360 - f1_score: 0.8637 - val_loss: 1.1710 - val_f1_score: 0.7979\n",
      "Epoch 351/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4611 - f1_score: 0.8381 - val_loss: 1.1586 - val_f1_score: 0.8007\n",
      "Epoch 352/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4370 - f1_score: 0.8535 - val_loss: 1.0885 - val_f1_score: 0.7922\n",
      "Epoch 353/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4594 - f1_score: 0.8571 - val_loss: 1.1461 - val_f1_score: 0.7733\n",
      "Epoch 354/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4406 - f1_score: 0.8562 - val_loss: 1.1406 - val_f1_score: 0.7848\n",
      "Epoch 355/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4100 - f1_score: 0.8690 - val_loss: 1.1540 - val_f1_score: 0.7888\n",
      "Epoch 356/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4495 - f1_score: 0.8467 - val_loss: 1.1048 - val_f1_score: 0.8046\n",
      "Epoch 357/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4455 - f1_score: 0.8647 - val_loss: 1.1144 - val_f1_score: 0.7872\n",
      "Epoch 358/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4219 - f1_score: 0.8605 - val_loss: 1.1322 - val_f1_score: 0.7775\n",
      "Epoch 359/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4458 - f1_score: 0.8562 - val_loss: 1.0981 - val_f1_score: 0.8083\n",
      "Epoch 360/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4438 - f1_score: 0.8555 - val_loss: 1.1860 - val_f1_score: 0.7725\n",
      "Epoch 361/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4111 - f1_score: 0.8678 - val_loss: 1.1730 - val_f1_score: 0.7966\n",
      "Epoch 362/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4121 - f1_score: 0.8586 - val_loss: 1.1580 - val_f1_score: 0.7794\n",
      "Epoch 363/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4659 - f1_score: 0.8424 - val_loss: 1.2031 - val_f1_score: 0.7795\n",
      "Epoch 364/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4316 - f1_score: 0.8589 - val_loss: 1.1090 - val_f1_score: 0.8144\n",
      "Epoch 365/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4378 - f1_score: 0.8593 - val_loss: 1.1102 - val_f1_score: 0.8013\n",
      "Epoch 366/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4636 - f1_score: 0.8432 - val_loss: 1.1082 - val_f1_score: 0.7920\n",
      "Epoch 367/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4378 - f1_score: 0.8567 - val_loss: 1.1815 - val_f1_score: 0.7801\n",
      "Epoch 368/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4218 - f1_score: 0.8597 - val_loss: 1.1649 - val_f1_score: 0.7918\n",
      "Epoch 369/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4617 - f1_score: 0.8499 - val_loss: 1.0978 - val_f1_score: 0.7870\n",
      "Epoch 370/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4171 - f1_score: 0.8602 - val_loss: 1.1098 - val_f1_score: 0.8071\n",
      "Epoch 371/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4430 - f1_score: 0.8504 - val_loss: 1.2481 - val_f1_score: 0.7861\n",
      "Epoch 372/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4373 - f1_score: 0.8432 - val_loss: 1.2006 - val_f1_score: 0.7941\n",
      "Epoch 373/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4209 - f1_score: 0.8564 - val_loss: 1.2062 - val_f1_score: 0.7798\n",
      "Epoch 374/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4325 - f1_score: 0.8548 - val_loss: 1.1051 - val_f1_score: 0.8037\n",
      "Epoch 375/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3999 - f1_score: 0.8636 - val_loss: 1.1082 - val_f1_score: 0.7804\n",
      "Epoch 376/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4232 - f1_score: 0.8618 - val_loss: 1.1607 - val_f1_score: 0.8018\n",
      "Epoch 377/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4174 - f1_score: 0.8636 - val_loss: 1.1290 - val_f1_score: 0.7825\n",
      "Epoch 378/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4186 - f1_score: 0.8641 - val_loss: 1.1315 - val_f1_score: 0.8082\n",
      "Epoch 379/500\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.4313 - f1_score: 0.8562 - val_loss: 1.2054 - val_f1_score: 0.7909\n",
      "Epoch 380/500\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.4114 - f1_score: 0.8649 - val_loss: 1.1282 - val_f1_score: 0.8105\n",
      "Epoch 381/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4368 - f1_score: 0.8527 - val_loss: 1.1491 - val_f1_score: 0.8036\n",
      "Epoch 382/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4091 - f1_score: 0.8595 - val_loss: 1.1262 - val_f1_score: 0.8168\n",
      "Epoch 383/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4091 - f1_score: 0.8606 - val_loss: 1.1992 - val_f1_score: 0.7943\n",
      "Epoch 384/500\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.3975 - f1_score: 0.8706 - val_loss: 1.1525 - val_f1_score: 0.8086\n",
      "Epoch 385/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4207 - f1_score: 0.8550 - val_loss: 1.1586 - val_f1_score: 0.7858\n",
      "Epoch 386/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3905 - f1_score: 0.8809 - val_loss: 1.1439 - val_f1_score: 0.7939\n",
      "Epoch 387/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4075 - f1_score: 0.8647 - val_loss: 1.1638 - val_f1_score: 0.7852\n",
      "Epoch 388/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3861 - f1_score: 0.8723 - val_loss: 1.2504 - val_f1_score: 0.7696\n",
      "Epoch 389/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.4011 - f1_score: 0.8668"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 7s 269ms/step - loss: 0.3973 - f1_score: 0.8686 - val_loss: 1.1294 - val_f1_score: 0.8279\n",
      "Epoch 390/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.3877 - f1_score: 0.8760 - val_loss: 1.1907 - val_f1_score: 0.7930\n",
      "Epoch 391/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4166 - f1_score: 0.8563 - val_loss: 1.1640 - val_f1_score: 0.7872\n",
      "Epoch 392/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4390 - f1_score: 0.8557 - val_loss: 1.2190 - val_f1_score: 0.7870\n",
      "Epoch 393/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4313 - f1_score: 0.8580 - val_loss: 1.1436 - val_f1_score: 0.8006\n",
      "Epoch 394/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4105 - f1_score: 0.8573 - val_loss: 1.1365 - val_f1_score: 0.8116\n",
      "Epoch 395/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4178 - f1_score: 0.8675 - val_loss: 1.1244 - val_f1_score: 0.7930\n",
      "Epoch 396/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4152 - f1_score: 0.8658 - val_loss: 1.2075 - val_f1_score: 0.8208\n",
      "Epoch 397/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3820 - f1_score: 0.8765 - val_loss: 1.1979 - val_f1_score: 0.7865\n",
      "Epoch 398/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.3922 - f1_score: 0.8708 - val_loss: 1.1651 - val_f1_score: 0.8016\n",
      "Epoch 399/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3996 - f1_score: 0.8698 - val_loss: 1.1569 - val_f1_score: 0.8102\n",
      "Epoch 400/500\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.3819 - f1_score: 0.8704 - val_loss: 1.1235 - val_f1_score: 0.7872\n",
      "Epoch 401/500\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.3987 - f1_score: 0.8650 - val_loss: 1.1431 - val_f1_score: 0.7976\n",
      "Epoch 402/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.3827 - f1_score: 0.8638 - val_loss: 1.1915 - val_f1_score: 0.7706\n",
      "Epoch 403/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3888 - f1_score: 0.8707 - val_loss: 1.1031 - val_f1_score: 0.8013\n",
      "Epoch 404/500\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.3906 - f1_score: 0.8763 - val_loss: 1.2048 - val_f1_score: 0.7906\n",
      "Epoch 405/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3911 - f1_score: 0.8693 - val_loss: 1.1337 - val_f1_score: 0.8041\n",
      "Epoch 406/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3836 - f1_score: 0.8727 - val_loss: 1.1359 - val_f1_score: 0.7930\n",
      "Epoch 407/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3675 - f1_score: 0.8793 - val_loss: 1.2091 - val_f1_score: 0.7991\n",
      "Epoch 408/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3723 - f1_score: 0.8789 - val_loss: 1.2582 - val_f1_score: 0.7840\n",
      "Epoch 409/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4000 - f1_score: 0.8759 - val_loss: 1.1630 - val_f1_score: 0.8111\n",
      "Epoch 410/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3930 - f1_score: 0.8775 - val_loss: 1.1547 - val_f1_score: 0.8033\n",
      "Epoch 411/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3848 - f1_score: 0.8740 - val_loss: 1.1790 - val_f1_score: 0.8067\n",
      "Epoch 412/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3931 - f1_score: 0.8777 - val_loss: 1.1998 - val_f1_score: 0.7836\n",
      "Epoch 413/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3688 - f1_score: 0.8824 - val_loss: 1.1380 - val_f1_score: 0.8162\n",
      "Epoch 414/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.3773 - f1_score: 0.8798 - val_loss: 1.2572 - val_f1_score: 0.7901\n",
      "Epoch 415/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3749 - f1_score: 0.8766 - val_loss: 1.1490 - val_f1_score: 0.8038\n",
      "Epoch 416/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3690 - f1_score: 0.8797 - val_loss: 1.2012 - val_f1_score: 0.8095\n",
      "Epoch 417/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4083 - f1_score: 0.8643 - val_loss: 1.1449 - val_f1_score: 0.7966\n",
      "Epoch 418/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3797 - f1_score: 0.8690 - val_loss: 1.1684 - val_f1_score: 0.7918\n",
      "Epoch 419/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4187 - f1_score: 0.8661 - val_loss: 1.1674 - val_f1_score: 0.7987\n",
      "Epoch 420/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4234 - f1_score: 0.8560 - val_loss: 1.1051 - val_f1_score: 0.8092\n",
      "Epoch 421/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3872 - f1_score: 0.8739 - val_loss: 1.2033 - val_f1_score: 0.7854\n",
      "Epoch 422/500\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.3845 - f1_score: 0.8700 - val_loss: 1.1622 - val_f1_score: 0.7974\n",
      "Epoch 423/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3740 - f1_score: 0.8749 - val_loss: 1.1445 - val_f1_score: 0.8150\n",
      "Epoch 424/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3762 - f1_score: 0.8715 - val_loss: 1.1687 - val_f1_score: 0.7952\n",
      "Epoch 425/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3849 - f1_score: 0.8737 - val_loss: 1.1136 - val_f1_score: 0.8024\n",
      "Epoch 426/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3866 - f1_score: 0.8753 - val_loss: 1.2106 - val_f1_score: 0.8031\n",
      "Epoch 427/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3677 - f1_score: 0.8692 - val_loss: 1.2104 - val_f1_score: 0.7946\n",
      "Epoch 428/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3894 - f1_score: 0.8730 - val_loss: 1.1602 - val_f1_score: 0.7997\n",
      "Epoch 429/500\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.3825 - f1_score: 0.8757 - val_loss: 1.2044 - val_f1_score: 0.7942\n",
      "Epoch 430/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3946 - f1_score: 0.8686 - val_loss: 1.1294 - val_f1_score: 0.7896\n",
      "Epoch 431/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3690 - f1_score: 0.8808 - val_loss: 1.1660 - val_f1_score: 0.8075\n",
      "Epoch 432/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3622 - f1_score: 0.8842 - val_loss: 1.1522 - val_f1_score: 0.8090\n",
      "Epoch 433/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3528 - f1_score: 0.8851 - val_loss: 1.2146 - val_f1_score: 0.7971\n",
      "Epoch 434/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3590 - f1_score: 0.8738 - val_loss: 1.1653 - val_f1_score: 0.7897\n",
      "Epoch 435/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3568 - f1_score: 0.8830 - val_loss: 1.1796 - val_f1_score: 0.7917\n",
      "Epoch 436/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3812 - f1_score: 0.8743 - val_loss: 1.1875 - val_f1_score: 0.7870\n",
      "Epoch 437/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3680 - f1_score: 0.8732 - val_loss: 1.1805 - val_f1_score: 0.8026\n",
      "Epoch 438/500\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.3627 - f1_score: 0.8818 - val_loss: 1.1802 - val_f1_score: 0.8050\n",
      "Epoch 439/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3685 - f1_score: 0.8732 - val_loss: 1.1526 - val_f1_score: 0.7928\n",
      "Epoch 440/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3540 - f1_score: 0.8859 - val_loss: 1.1324 - val_f1_score: 0.7963\n",
      "Epoch 441/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3832 - f1_score: 0.8651 - val_loss: 1.2522 - val_f1_score: 0.7719\n",
      "Epoch 442/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3869 - f1_score: 0.8694 - val_loss: 1.2593 - val_f1_score: 0.7957\n",
      "Epoch 443/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3846 - f1_score: 0.8720 - val_loss: 1.1229 - val_f1_score: 0.8145\n",
      "Epoch 444/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3628 - f1_score: 0.8798 - val_loss: 1.2116 - val_f1_score: 0.7784\n",
      "Epoch 445/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3064 - f1_score: 0.8934 - val_loss: 1.1827 - val_f1_score: 0.8044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3692 - f1_score: 0.8756 - val_loss: 1.1889 - val_f1_score: 0.7993\n",
      "Epoch 447/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3520 - f1_score: 0.8854 - val_loss: 1.1936 - val_f1_score: 0.8071\n",
      "Epoch 448/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3801 - f1_score: 0.8690 - val_loss: 1.1629 - val_f1_score: 0.7935\n",
      "Epoch 449/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3548 - f1_score: 0.8883 - val_loss: 1.1535 - val_f1_score: 0.8051\n",
      "Epoch 450/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3657 - f1_score: 0.8765 - val_loss: 1.1642 - val_f1_score: 0.8027\n",
      "Epoch 451/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3748 - f1_score: 0.8721 - val_loss: 1.2139 - val_f1_score: 0.7788\n",
      "Epoch 452/500\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3423 - f1_score: 0.8842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 6s 234ms/step - loss: 0.3432 - f1_score: 0.8833 - val_loss: 1.1148 - val_f1_score: 0.8328\n",
      "Epoch 453/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.3340 - f1_score: 0.8858 - val_loss: 1.1574 - val_f1_score: 0.8104\n",
      "Epoch 454/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.3633 - f1_score: 0.8759 - val_loss: 1.1273 - val_f1_score: 0.8036\n",
      "Epoch 455/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.3699 - f1_score: 0.8795 - val_loss: 1.1508 - val_f1_score: 0.8008\n",
      "Epoch 456/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.3310 - f1_score: 0.8913 - val_loss: 1.2252 - val_f1_score: 0.7843\n",
      "Epoch 457/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.3284 - f1_score: 0.8858 - val_loss: 1.1786 - val_f1_score: 0.7964\n",
      "Epoch 458/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.3535 - f1_score: 0.8823 - val_loss: 1.1576 - val_f1_score: 0.8230\n",
      "Epoch 459/500\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.3152 - f1_score: 0.8888 - val_loss: 1.1906 - val_f1_score: 0.8013\n",
      "Epoch 460/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3585 - f1_score: 0.8838 - val_loss: 1.2440 - val_f1_score: 0.8018\n",
      "Epoch 461/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3230 - f1_score: 0.9004 - val_loss: 1.1859 - val_f1_score: 0.8089\n",
      "Epoch 462/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3132 - f1_score: 0.8974 - val_loss: 1.1778 - val_f1_score: 0.8163\n",
      "Epoch 463/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3313 - f1_score: 0.8864 - val_loss: 1.1676 - val_f1_score: 0.8027\n",
      "Epoch 464/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3423 - f1_score: 0.8857 - val_loss: 1.2535 - val_f1_score: 0.7939\n",
      "Epoch 465/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3511 - f1_score: 0.8886 - val_loss: 1.2028 - val_f1_score: 0.7921\n",
      "Epoch 466/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3469 - f1_score: 0.8778 - val_loss: 1.1264 - val_f1_score: 0.8072\n",
      "Epoch 467/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3246 - f1_score: 0.8952 - val_loss: 1.3632 - val_f1_score: 0.7768\n",
      "Epoch 468/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3674 - f1_score: 0.8772 - val_loss: 1.1759 - val_f1_score: 0.7823\n",
      "Epoch 469/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3322 - f1_score: 0.8815 - val_loss: 1.2897 - val_f1_score: 0.7899\n",
      "Epoch 470/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3308 - f1_score: 0.8902 - val_loss: 1.1780 - val_f1_score: 0.8134\n",
      "Epoch 471/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3281 - f1_score: 0.8937 - val_loss: 1.2653 - val_f1_score: 0.7903\n",
      "Epoch 472/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.2975 - f1_score: 0.8989 - val_loss: 1.1993 - val_f1_score: 0.8104\n",
      "Epoch 473/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3491 - f1_score: 0.8863 - val_loss: 1.1551 - val_f1_score: 0.7927\n",
      "Epoch 474/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3206 - f1_score: 0.8843 - val_loss: 1.2167 - val_f1_score: 0.7917\n",
      "Epoch 475/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3455 - f1_score: 0.8832 - val_loss: 1.1501 - val_f1_score: 0.8178\n",
      "Epoch 476/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3267 - f1_score: 0.8960 - val_loss: 1.1696 - val_f1_score: 0.8023\n",
      "Epoch 477/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3092 - f1_score: 0.8959 - val_loss: 1.2586 - val_f1_score: 0.7852\n",
      "Epoch 478/500\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.3430 - f1_score: 0.8940 - val_loss: 1.2921 - val_f1_score: 0.7848\n",
      "Epoch 479/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3584 - f1_score: 0.8746 - val_loss: 1.2364 - val_f1_score: 0.8095\n",
      "Epoch 480/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3388 - f1_score: 0.8850 - val_loss: 1.1673 - val_f1_score: 0.8012\n",
      "Epoch 481/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3272 - f1_score: 0.8897 - val_loss: 1.1814 - val_f1_score: 0.8021\n",
      "Epoch 482/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3298 - f1_score: 0.8913 - val_loss: 1.1983 - val_f1_score: 0.7887\n",
      "Epoch 483/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3467 - f1_score: 0.8858 - val_loss: 1.1823 - val_f1_score: 0.8145\n",
      "Epoch 484/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3303 - f1_score: 0.8898 - val_loss: 1.1966 - val_f1_score: 0.7983\n",
      "Epoch 485/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3309 - f1_score: 0.8928 - val_loss: 1.1967 - val_f1_score: 0.7885\n",
      "Epoch 486/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3542 - f1_score: 0.8838 - val_loss: 1.2302 - val_f1_score: 0.7916\n",
      "Epoch 487/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3518 - f1_score: 0.8785 - val_loss: 1.3072 - val_f1_score: 0.7876\n",
      "Epoch 488/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3618 - f1_score: 0.8806 - val_loss: 1.2435 - val_f1_score: 0.8206\n",
      "Epoch 489/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.2950 - f1_score: 0.9001 - val_loss: 1.1869 - val_f1_score: 0.8187\n",
      "Epoch 490/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3004 - f1_score: 0.8960 - val_loss: 1.3223 - val_f1_score: 0.7801\n",
      "Epoch 491/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3212 - f1_score: 0.8901 - val_loss: 1.1672 - val_f1_score: 0.8126\n",
      "Epoch 492/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3172 - f1_score: 0.8966 - val_loss: 1.2253 - val_f1_score: 0.7844\n",
      "Epoch 493/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3250 - f1_score: 0.8935 - val_loss: 1.1650 - val_f1_score: 0.8067\n",
      "Epoch 494/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3290 - f1_score: 0.8925 - val_loss: 1.2443 - val_f1_score: 0.8042\n",
      "Epoch 495/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3085 - f1_score: 0.8980 - val_loss: 1.2456 - val_f1_score: 0.7976\n",
      "Epoch 496/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3220 - f1_score: 0.8868 - val_loss: 1.2573 - val_f1_score: 0.7776\n",
      "Epoch 497/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3244 - f1_score: 0.8933 - val_loss: 1.2334 - val_f1_score: 0.8014\n",
      "Epoch 498/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3342 - f1_score: 0.8881 - val_loss: 1.2559 - val_f1_score: 0.8072\n",
      "Epoch 499/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3469 - f1_score: 0.8820 - val_loss: 1.2378 - val_f1_score: 0.8091\n",
      "Epoch 500/500\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.3092 - f1_score: 0.8923 - val_loss: 1.2028 - val_f1_score: 0.8039\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training the best model...\")\n",
    "model = tuner.hypermodel.build(bestHP)\n",
    "History = model.fit(x=Xtrain, y=Ytrain,validation_data= (Xval,Yval), batch_size=96,epochs=500, verbose=1,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d7b21c30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T07:33:07.620253Z",
     "start_time": "2023-08-23T07:33:07.617267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cd23e571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T07:36:30.331312Z",
     "start_time": "2023-08-23T07:36:30.322448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fdf05a4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:29:05.677929Z",
     "start_time": "2023-08-23T22:29:04.398531Z"
    }
   },
   "outputs": [],
   "source": [
    "reconstructed_model = tf.keras.models.load_model(\"best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "593d23fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:23:24.002568Z",
     "start_time": "2023-08-23T22:23:23.573387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 6ms/step - loss: 1.1148 - f1_score: 0.8328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.114823818206787, 0.8327561020851135]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_model.evaluate(Xval,Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80d2a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "401.844px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
