{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "957d823f",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab7927e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:06:22.214447Z",
     "start_time": "2023-08-13T22:06:22.211370Z"
    }
   },
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from operator import add\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fefa485b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:30.023563Z",
     "start_time": "2023-08-13T21:58:30.020857Z"
    }
   },
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05d07926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:42.822165Z",
     "start_time": "2023-08-13T21:58:36.830409Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(static_image_mode=False,\n",
    "                          model_complexity=1) as holistic:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "            \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(frame_rgb)\n",
    "        # Left hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "\n",
    "        # Right Hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3884fb03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:48.033707Z",
     "start_time": "2023-08-13T21:58:48.029854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mediapipe.python.solution_base.SolutionOutputs"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "439656a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:48.941786Z",
     "start_time": "2023-08-13T21:58:48.746156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.pose_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5879199",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:49.991379Z",
     "start_time": "2023-08-13T21:58:49.451815Z"
    }
   },
   "outputs": [],
   "source": [
    "pose = []\n",
    "for res in results.pose_landmarks.landmark:\n",
    "    test = np.array([res.x, res.y, res.z, res.visibility])\n",
    "    pose.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85938609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:51.598576Z",
     "start_time": "2023-08-13T21:58:51.593929Z"
    }
   },
   "outputs": [],
   "source": [
    "pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)\n",
    "lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d61e74ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:59:15.408957Z",
     "start_time": "2023-08-13T21:59:15.404471Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "#    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "#    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7a805c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:59:16.153518Z",
     "start_time": "2023-08-13T21:59:16.150961Z"
    }
   },
   "outputs": [],
   "source": [
    "result_test = extract_keypoints(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96d95912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:59:16.876312Z",
     "start_time": "2023-08-13T21:59:16.872421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8fb31b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:59:23.539935Z",
     "start_time": "2023-08-13T21:59:23.536626Z"
    }
   },
   "outputs": [],
   "source": [
    "def signvideodataframe(filepath):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # Define the path to the videos directory\n",
    "    path = 'file:///media/kristian/HDD/ASL_Citizen/ASL_Citizen/videos/'\n",
    "\n",
    "    # Create a 'Path' column by concatenating the path with 'Video file' column\n",
    "    df['Path'] = path + df['Video file']\n",
    "    \n",
    "#    df['Gloss'] = df['Gloss'].str.replace('\\d+', '',regex=True)\n",
    "\n",
    "    # Calculate the frequency of each gloss and create a 'frequency' column\n",
    "    df['Frequency'] = df['Gloss'].map(df['Gloss'].value_counts())\n",
    "\n",
    "    # Sort the DataFrame by the 'Gloss' column\n",
    "    df = df.sort_values(by='Gloss')\n",
    "\n",
    "    # Reset the index of the DataFrame\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1877e8ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:59:25.802882Z",
     "start_time": "2023-08-13T21:59:25.800013Z"
    }
   },
   "outputs": [],
   "source": [
    "def frames_from_file(filepath):\n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "    frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    length = round(frames / fps)\n",
    "    return frames, fps, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c90d3d92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T05:37:39.381439Z",
     "start_time": "2023-08-09T05:37:38.922996Z"
    }
   },
   "outputs": [],
   "source": [
    "traindf = signvideodataframe('file:///media/kristian/HDD/ASL_Citizen/ASL_Citizen/splits/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea9e1a27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T05:37:41.879254Z",
     "start_time": "2023-08-09T05:37:41.867326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P31</td>\n",
       "      <td>3827306090663467-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P37</td>\n",
       "      <td>16792698524451422-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P11</td>\n",
       "      <td>6868778695018762-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P11</td>\n",
       "      <td>6870709051348651-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P50</td>\n",
       "      <td>0719792557216079-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                      Video file    Gloss ASL-LEX Code  \\\n",
       "0            P31   3827306090663467-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "1            P37  16792698524451422-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "2            P11   6868778695018762-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "3            P11   6870709051348651-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "4            P50   0719792557216079-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "\n",
       "                                                Path  Frequency  \n",
       "0  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "1  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "2  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "3  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "4  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bdd5fc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T05:37:45.667677Z",
     "start_time": "2023-08-09T05:37:45.659354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40149</th>\n",
       "      <td>P37</td>\n",
       "      <td>9716493262876276-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40150</th>\n",
       "      <td>P31</td>\n",
       "      <td>7550572181460327-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40151</th>\n",
       "      <td>P46</td>\n",
       "      <td>47985881750082227-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40152</th>\n",
       "      <td>P50</td>\n",
       "      <td>04671245574824856-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40153</th>\n",
       "      <td>P51</td>\n",
       "      <td>19959052532136146-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant ID                      Video file    Gloss ASL-LEX Code  \\\n",
       "40149            P37   9716493262876276-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "40150            P31   7550572181460327-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "40151            P46  47985881750082227-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "40152            P50  04671245574824856-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "40153            P51  19959052532136146-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "\n",
       "                                                    Path  Frequency  \n",
       "40149  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "40150  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "40151  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "40152  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  \n",
       "40153  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         15  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "095e54bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T05:38:09.247703Z",
     "start_time": "2023-08-09T05:38:09.243106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///media/kristian/HDD/ASL_Citizen/ASL_Citizen/videos/3827306090663467-1 DOLLAR.mp4'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf['Path'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d581c72d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T05:38:17.483406Z",
     "start_time": "2023-08-09T05:38:13.260607Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(traindf['Path'][0])\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(static_image_mode=False,\n",
    "                          model_complexity=2) as holistic:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(frame_rgb)\n",
    "        # Right Hand\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "\n",
    "        # Posture\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e7c3bde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T05:38:19.782612Z",
     "start_time": "2023-08-09T05:38:19.772402Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27666</th>\n",
       "      <td>P33</td>\n",
       "      <td>38253788313087966-RACE.mp4</td>\n",
       "      <td>RACE</td>\n",
       "      <td>F_02_075</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28666</th>\n",
       "      <td>P37</td>\n",
       "      <td>8020060049631272-RIGHT 2.mp4</td>\n",
       "      <td>RIGHT2</td>\n",
       "      <td>C_01_070</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9271</th>\n",
       "      <td>P40</td>\n",
       "      <td>5336635865778496-DICE.mp4</td>\n",
       "      <td>DICE</td>\n",
       "      <td>D_02_036</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30435</th>\n",
       "      <td>P16</td>\n",
       "      <td>08013205314920557-SHAME ON_YOU.mp4</td>\n",
       "      <td>SHAMEONYOU</td>\n",
       "      <td>H_01_066</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20590</th>\n",
       "      <td>P7</td>\n",
       "      <td>34292735943128716-LOCKER.mp4</td>\n",
       "      <td>LOCKER</td>\n",
       "      <td>K_01_126</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30006</th>\n",
       "      <td>P43</td>\n",
       "      <td>17195855615886702-SCULPT.mp4</td>\n",
       "      <td>SCULPT</td>\n",
       "      <td>J_01_028</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34604</th>\n",
       "      <td>P3</td>\n",
       "      <td>17146468242733048-SWEET.mp4</td>\n",
       "      <td>SWEET</td>\n",
       "      <td>J_03_029</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39486</th>\n",
       "      <td>P40</td>\n",
       "      <td>7278194454734639-WOMAN 2.mp4</td>\n",
       "      <td>WOMAN2</td>\n",
       "      <td>K_01_101</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28099</th>\n",
       "      <td>P40</td>\n",
       "      <td>45570209958510843-REGISTER.mp4</td>\n",
       "      <td>REGISTER</td>\n",
       "      <td>F_01_021</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26878</th>\n",
       "      <td>P27</td>\n",
       "      <td>9525196309623671-PREFER.mp4</td>\n",
       "      <td>PREFER</td>\n",
       "      <td>B_01_078</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10901</th>\n",
       "      <td>P46</td>\n",
       "      <td>8152747504583406-EASEL.mp4</td>\n",
       "      <td>EASEL</td>\n",
       "      <td>F_01_044</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>P52</td>\n",
       "      <td>4451521527224398-seedBANDAGE.mp4</td>\n",
       "      <td>BANDAGE</td>\n",
       "      <td>F_03_020</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11762</th>\n",
       "      <td>P52</td>\n",
       "      <td>7299627327879386-seedERUPT 2.mp4</td>\n",
       "      <td>ERUPT2</td>\n",
       "      <td>K_01_119</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29180</th>\n",
       "      <td>P14</td>\n",
       "      <td>41300781278902954-RUN 2.mp4</td>\n",
       "      <td>RUN2</td>\n",
       "      <td>J_01_100</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30305</th>\n",
       "      <td>P52</td>\n",
       "      <td>4530632655496043-seedSERVE 2.mp4</td>\n",
       "      <td>SERVE2</td>\n",
       "      <td>K_02_061</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36643</th>\n",
       "      <td>P52</td>\n",
       "      <td>923366471300946-seedTRANSLATE.mp4</td>\n",
       "      <td>TRANSLATE</td>\n",
       "      <td>D_01_080</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8628</th>\n",
       "      <td>P30</td>\n",
       "      <td>6849916550986419-DAY.mp4</td>\n",
       "      <td>DAY</td>\n",
       "      <td>C_01_044</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18512</th>\n",
       "      <td>P33</td>\n",
       "      <td>011754574039328336-ISLAND.mp4</td>\n",
       "      <td>ISLAND</td>\n",
       "      <td>A_01_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32124</th>\n",
       "      <td>P31</td>\n",
       "      <td>9604527458122922-SNOWMAN.mp4</td>\n",
       "      <td>SNOWMAN</td>\n",
       "      <td>G_03_073</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38249</th>\n",
       "      <td>P33</td>\n",
       "      <td>39269779031539565-WANT 2.mp4</td>\n",
       "      <td>WANT1</td>\n",
       "      <td>E_01_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant ID                          Video file       Gloss  \\\n",
       "27666            P33          38253788313087966-RACE.mp4        RACE   \n",
       "28666            P37        8020060049631272-RIGHT 2.mp4      RIGHT2   \n",
       "9271             P40           5336635865778496-DICE.mp4        DICE   \n",
       "30435            P16  08013205314920557-SHAME ON_YOU.mp4  SHAMEONYOU   \n",
       "20590             P7        34292735943128716-LOCKER.mp4      LOCKER   \n",
       "30006            P43        17195855615886702-SCULPT.mp4      SCULPT   \n",
       "34604             P3         17146468242733048-SWEET.mp4       SWEET   \n",
       "39486            P40        7278194454734639-WOMAN 2.mp4      WOMAN2   \n",
       "28099            P40      45570209958510843-REGISTER.mp4    REGISTER   \n",
       "26878            P27         9525196309623671-PREFER.mp4      PREFER   \n",
       "10901            P46          8152747504583406-EASEL.mp4       EASEL   \n",
       "2070             P52    4451521527224398-seedBANDAGE.mp4     BANDAGE   \n",
       "11762            P52    7299627327879386-seedERUPT 2.mp4      ERUPT2   \n",
       "29180            P14         41300781278902954-RUN 2.mp4        RUN2   \n",
       "30305            P52    4530632655496043-seedSERVE 2.mp4      SERVE2   \n",
       "36643            P52   923366471300946-seedTRANSLATE.mp4   TRANSLATE   \n",
       "8628             P30            6849916550986419-DAY.mp4         DAY   \n",
       "18512            P33       011754574039328336-ISLAND.mp4      ISLAND   \n",
       "32124            P31        9604527458122922-SNOWMAN.mp4     SNOWMAN   \n",
       "38249            P33        39269779031539565-WANT 2.mp4       WANT1   \n",
       "\n",
       "      ASL-LEX Code                                               Path  \\\n",
       "27666     F_02_075  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "28666     C_01_070  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "9271      D_02_036  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "30435     H_01_066  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "20590     K_01_126  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "30006     J_01_028  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "34604     J_03_029  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "39486     K_01_101  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "28099     F_01_021  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "26878     B_01_078  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "10901     F_01_044  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "2070      F_03_020  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "11762     K_01_119  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "29180     J_01_100  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "30305     K_02_061  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "36643     D_01_080  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "8628      C_01_044  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "18512     A_01_025  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "32124     G_03_073  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "38249     E_01_025  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...   \n",
       "\n",
       "       Frequency  \n",
       "27666         13  \n",
       "28666         14  \n",
       "9271          15  \n",
       "30435         14  \n",
       "20590         13  \n",
       "30006         15  \n",
       "34604         15  \n",
       "39486         14  \n",
       "28099         15  \n",
       "26878         15  \n",
       "10901         15  \n",
       "2070          17  \n",
       "11762         17  \n",
       "29180         16  \n",
       "30305         16  \n",
       "36643         15  \n",
       "8628          16  \n",
       "18512         14  \n",
       "32124         14  \n",
       "38249         16  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf42e5e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T05:39:03.731426Z",
     "start_time": "2023-08-09T05:39:03.298904Z"
    }
   },
   "outputs": [],
   "source": [
    "valdf = signvideodataframe('file:///media/kristian/HDD/ASL_Citizen/ASL_Citizen/splits/val.csv') \n",
    "testdf = signvideodataframe('file:///media/kristian/HDD/ASL_Citizen/ASL_Citizen/splits/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4da1ef21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T05:42:53.084714Z",
     "start_time": "2023-08-09T05:42:53.075586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P26</td>\n",
       "      <td>22595012150860327-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P39</td>\n",
       "      <td>7421622940519235-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P21</td>\n",
       "      <td>686738356933241-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P12</td>\n",
       "      <td>9219095671540121-5 DOLLARS.mp4</td>\n",
       "      <td>5DOLLARS</td>\n",
       "      <td>B_01_062</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P21</td>\n",
       "      <td>1448188216215387-5 DOLLARS.mp4</td>\n",
       "      <td>5DOLLARS</td>\n",
       "      <td>B_01_062</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                      Video file     Gloss ASL-LEX Code  \\\n",
       "0            P26  22595012150860327-1 DOLLAR.mp4   1DOLLAR     C_02_025   \n",
       "1            P39   7421622940519235-1 DOLLAR.mp4   1DOLLAR     C_02_025   \n",
       "2            P21    686738356933241-1 DOLLAR.mp4   1DOLLAR     C_02_025   \n",
       "3            P12  9219095671540121-5 DOLLARS.mp4  5DOLLARS     B_01_062   \n",
       "4            P21  1448188216215387-5 DOLLARS.mp4  5DOLLARS     B_01_062   \n",
       "\n",
       "                                                Path  Frequency  \n",
       "0  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          3  \n",
       "1  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          3  \n",
       "2  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          3  \n",
       "3  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4  \n",
       "4  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...          4  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5eced7b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T05:42:54.332165Z",
     "start_time": "2023-08-09T05:42:54.324836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P18</td>\n",
       "      <td>23521769221811684-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P42</td>\n",
       "      <td>023931338852502426-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P49</td>\n",
       "      <td>4893817008748198-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P17</td>\n",
       "      <td>13991818149960333-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P49</td>\n",
       "      <td>34625615110480457-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                       Video file    Gloss ASL-LEX Code  \\\n",
       "0            P18   23521769221811684-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "1            P42  023931338852502426-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "2            P49    4893817008748198-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "3            P17   13991818149960333-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "4            P49   34625615110480457-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "\n",
       "                                                Path  Frequency  \n",
       "0  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  \n",
       "1  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  \n",
       "2  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  \n",
       "3  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  \n",
       "4  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee2b1972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T05:47:17.464282Z",
     "start_time": "2023-08-09T05:47:17.456421Z"
    }
   },
   "outputs": [],
   "source": [
    "traindf = pd.concat([traindf,valdf,testdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "22d0c6e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T05:47:20.573374Z",
     "start_time": "2023-08-09T05:47:20.563672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32936</th>\n",
       "      <td>P18</td>\n",
       "      <td>4320702510886756-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32937</th>\n",
       "      <td>P9</td>\n",
       "      <td>7676354653247301-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32938</th>\n",
       "      <td>P47</td>\n",
       "      <td>5386272465310649-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32939</th>\n",
       "      <td>P18</td>\n",
       "      <td>738440364224181-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32940</th>\n",
       "      <td>P17</td>\n",
       "      <td>9953298353288469-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant ID                     Video file    Gloss ASL-LEX Code  \\\n",
       "32936            P18  4320702510886756-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "32937             P9  7676354653247301-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "32938            P47  5386272465310649-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "32939            P18   738440364224181-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "32940            P17  9953298353288469-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "\n",
       "                                                    Path  Frequency  \n",
       "32936  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  \n",
       "32937  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  \n",
       "32938  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  \n",
       "32939  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  \n",
       "32940  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         13  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c5569cb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T05:47:23.367846Z",
     "start_time": "2023-08-09T05:47:23.290492Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the frequency of each gloss and create a 'frequency' column\n",
    "traindf['Frequency'] = traindf['Gloss'].map(traindf['Gloss'].value_counts())\n",
    "\n",
    "# Sort the DataFrame by the 'Gloss' column\n",
    "traindf = traindf.sort_values(by='Gloss')\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "traindf = traindf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2f76fea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T05:47:24.449973Z",
     "start_time": "2023-08-09T05:47:24.442985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P31</td>\n",
       "      <td>3827306090663467-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P21</td>\n",
       "      <td>686738356933241-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P18</td>\n",
       "      <td>23521769221811684-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P42</td>\n",
       "      <td>023931338852502426-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P49</td>\n",
       "      <td>4893817008748198-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                       Video file    Gloss ASL-LEX Code  \\\n",
       "0            P31    3827306090663467-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "1            P21     686738356933241-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "2            P18   23521769221811684-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "3            P42  023931338852502426-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "4            P49    4893817008748198-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "\n",
       "                                                Path  Frequency  \n",
       "0  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         31  \n",
       "1  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         31  \n",
       "2  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         31  \n",
       "3  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         31  \n",
       "4  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         31  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eeb05886",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T05:47:26.066392Z",
     "start_time": "2023-08-09T05:47:26.059798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83394</th>\n",
       "      <td>P40</td>\n",
       "      <td>29614325657927165-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83395</th>\n",
       "      <td>P33</td>\n",
       "      <td>38572260119226276-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83396</th>\n",
       "      <td>P16</td>\n",
       "      <td>29179019672445805-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83397</th>\n",
       "      <td>P26</td>\n",
       "      <td>19366754134806952-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83398</th>\n",
       "      <td>P17</td>\n",
       "      <td>9953298353288469-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant ID                      Video file    Gloss ASL-LEX Code  \\\n",
       "83394            P40  29614325657927165-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "83395            P33  38572260119226276-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "83396            P16  29179019672445805-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "83397            P26  19366754134806952-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "83398            P17   9953298353288469-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "\n",
       "                                                    Path  Frequency  \n",
       "83394  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         32  \n",
       "83395  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         32  \n",
       "83396  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         32  \n",
       "83397  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         32  \n",
       "83398  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         32  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4ac6a6ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T05:47:30.534349Z",
     "start_time": "2023-08-09T05:47:30.525546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>83399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.635631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Frequency\n",
       "count  83399.000000\n",
       "mean      30.635631\n",
       "std        1.741494\n",
       "min       21.000000\n",
       "25%       30.000000\n",
       "50%       31.000000\n",
       "75%       31.000000\n",
       "max       45.000000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a839c01d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T06:43:37.611622Z",
     "start_time": "2023-08-09T05:52:20.303802Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 83399/83399 [51:17<00:00, 27.10it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "traindf[['Frames', 'FPS', 'Length']] = traindf['Path'].progress_apply(lambda x: pd.Series(frames_from_file(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9f9e1d83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T06:46:48.719205Z",
     "start_time": "2023-08-09T06:46:48.140766Z"
    }
   },
   "outputs": [],
   "source": [
    "#traindf.to_csv('//home/kristian/ASL_Citizen/splits/all_videos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc51db42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:10.208086Z",
     "start_time": "2023-08-13T22:00:09.149413Z"
    }
   },
   "outputs": [],
   "source": [
    "traindf=pd.read_csv('//home/kristian/ASL_Citizen/splits/all_videos.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd24afff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:13.486774Z",
     "start_time": "2023-08-13T22:00:13.202135Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83394</th>\n",
       "      <td>P40</td>\n",
       "      <td>29614325657927165-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>32</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83395</th>\n",
       "      <td>P33</td>\n",
       "      <td>38572260119226276-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>32</td>\n",
       "      <td>131</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83396</th>\n",
       "      <td>P16</td>\n",
       "      <td>29179019672445805-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>32</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83397</th>\n",
       "      <td>P26</td>\n",
       "      <td>19366754134806952-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83398</th>\n",
       "      <td>P17</td>\n",
       "      <td>9953298353288469-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant ID                      Video file    Gloss ASL-LEX Code  \\\n",
       "83394            P40  29614325657927165-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "83395            P33  38572260119226276-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "83396            P16  29179019672445805-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "83397            P26  19366754134806952-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "83398            P17   9953298353288469-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "\n",
       "                                                    Path  Frequency  Frames  \\\n",
       "83394  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         32     103   \n",
       "83395  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         32     131   \n",
       "83396  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         32      57   \n",
       "83397  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         32      53   \n",
       "83398  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         32      50   \n",
       "\n",
       "       FPS  Length  \n",
       "83394   30       3  \n",
       "83395   29       5  \n",
       "83396   30       2  \n",
       "83397   30       2  \n",
       "83398   30       2  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f6e2bc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:14.642776Z",
     "start_time": "2023-08-13T22:00:14.620932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>83399.000000</td>\n",
       "      <td>83399.000000</td>\n",
       "      <td>83399.000000</td>\n",
       "      <td>83399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.635631</td>\n",
       "      <td>82.755585</td>\n",
       "      <td>29.146357</td>\n",
       "      <td>2.849231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741494</td>\n",
       "      <td>37.687446</td>\n",
       "      <td>2.767382</td>\n",
       "      <td>1.268591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>680.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Frequency        Frames           FPS        Length\n",
       "count  83399.000000  83399.000000  83399.000000  83399.000000\n",
       "mean      30.635631     82.755585     29.146357      2.849231\n",
       "std        1.741494     37.687446      2.767382      1.268591\n",
       "min       21.000000      3.000000     11.000000      0.000000\n",
       "25%       30.000000     58.000000     29.000000      2.000000\n",
       "50%       31.000000     75.000000     30.000000      3.000000\n",
       "75%       31.000000     96.000000     30.000000      3.000000\n",
       "max       45.000000    680.000000    120.000000     23.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "980e9aca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:17.025337Z",
     "start_time": "2023-08-13T22:00:17.015987Z"
    }
   },
   "outputs": [],
   "source": [
    "traindf2 = traindf[(traindf['Length'] > 0) & (traindf['FPS'] > 28) &(traindf['Frames'] < 61) ]\n",
    "traindf2 = traindf2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3da8550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:17.674550Z",
     "start_time": "2023-08-13T22:00:17.664912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P21</td>\n",
       "      <td>686738356933241-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P42</td>\n",
       "      <td>023931338852502426-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>31</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P17</td>\n",
       "      <td>13991818149960333-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>31</td>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P6</td>\n",
       "      <td>641444141964802-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>31</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P22</td>\n",
       "      <td>86640342214128-1 DOLLAR.mp4</td>\n",
       "      <td>1DOLLAR</td>\n",
       "      <td>C_02_025</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant ID                       Video file    Gloss ASL-LEX Code  \\\n",
       "0            P21     686738356933241-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "1            P42  023931338852502426-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "2            P17   13991818149960333-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "3             P6     641444141964802-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "4            P22      86640342214128-1 DOLLAR.mp4  1DOLLAR     C_02_025   \n",
       "\n",
       "                                                Path  Frequency  Frames  FPS  \\\n",
       "0  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         31      57   29   \n",
       "1  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         31      45   30   \n",
       "2  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         31      56   30   \n",
       "3  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         31      49   29   \n",
       "4  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         31      50   29   \n",
       "\n",
       "   Length  \n",
       "0       2  \n",
       "1       2  \n",
       "2       2  \n",
       "3       2  \n",
       "4       2  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98e78fd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:18.292461Z",
     "start_time": "2023-08-13T22:00:18.285128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21320</th>\n",
       "      <td>P27</td>\n",
       "      <td>2780771420581618-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>32</td>\n",
       "      <td>47</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21321</th>\n",
       "      <td>P11</td>\n",
       "      <td>6893191909065832-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21322</th>\n",
       "      <td>P16</td>\n",
       "      <td>29179019672445805-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>32</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21323</th>\n",
       "      <td>P26</td>\n",
       "      <td>19366754134806952-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21324</th>\n",
       "      <td>P17</td>\n",
       "      <td>9953298353288469-ZOOM OFF.mp4</td>\n",
       "      <td>ZOOMOFF</td>\n",
       "      <td>D_01_057</td>\n",
       "      <td>file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant ID                      Video file    Gloss ASL-LEX Code  \\\n",
       "21320            P27   2780771420581618-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "21321            P11   6893191909065832-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "21322            P16  29179019672445805-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "21323            P26  19366754134806952-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "21324            P17   9953298353288469-ZOOM OFF.mp4  ZOOMOFF     D_01_057   \n",
       "\n",
       "                                                    Path  Frequency  Frames  \\\n",
       "21320  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         32      47   \n",
       "21321  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         32      50   \n",
       "21322  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         32      57   \n",
       "21323  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         32      53   \n",
       "21324  file:///media/kristian/HDD/ASL_Citizen/ASL_Cit...         32      50   \n",
       "\n",
       "       FPS  Length  \n",
       "21320   30       2  \n",
       "21321   29       2  \n",
       "21322   30       2  \n",
       "21323   30       2  \n",
       "21324   30       2  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1d6fcb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:19.404345Z",
     "start_time": "2023-08-13T22:00:18.819544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21325.000000</td>\n",
       "      <td>21325.000000</td>\n",
       "      <td>21325.000000</td>\n",
       "      <td>21325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.703400</td>\n",
       "      <td>50.040469</td>\n",
       "      <td>29.689004</td>\n",
       "      <td>1.795545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.747375</td>\n",
       "      <td>7.409050</td>\n",
       "      <td>0.525716</td>\n",
       "      <td>0.403312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Frequency        Frames           FPS        Length\n",
       "count  21325.000000  21325.000000  21325.000000  21325.000000\n",
       "mean      30.703400     50.040469     29.689004      1.795545\n",
       "std        1.747375      7.409050      0.525716      0.403312\n",
       "min       21.000000     16.000000     29.000000      1.000000\n",
       "25%       30.000000     46.000000     29.000000      2.000000\n",
       "50%       31.000000     51.000000     30.000000      2.000000\n",
       "75%       31.000000     56.000000     30.000000      2.000000\n",
       "max       45.000000     60.000000     60.000000      2.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93e87d0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:20.581913Z",
     "start_time": "2023-08-13T22:00:20.510301Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the frequency of each gloss and create a 'frequency' column\n",
    "traindf2['Frequency'] = traindf2['Gloss'].map(traindf2['Gloss'].value_counts())\n",
    "\n",
    "    # Sort the DataFrame by the 'Gloss' column\n",
    "traindf2 = traindf2.sort_values(by='Gloss')\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "traindf2 = traindf2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5033c536",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:22.827330Z",
     "start_time": "2023-08-13T22:00:22.045096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21325.000000</td>\n",
       "      <td>21325.000000</td>\n",
       "      <td>21325.000000</td>\n",
       "      <td>21325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.043236</td>\n",
       "      <td>50.040469</td>\n",
       "      <td>29.689004</td>\n",
       "      <td>1.795545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.965475</td>\n",
       "      <td>7.409050</td>\n",
       "      <td>0.525716</td>\n",
       "      <td>0.403312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Frequency        Frames           FPS        Length\n",
       "count  21325.000000  21325.000000  21325.000000  21325.000000\n",
       "mean       9.043236     50.040469     29.689004      1.795545\n",
       "std        2.965475      7.409050      0.525716      0.403312\n",
       "min        1.000000     16.000000     29.000000      1.000000\n",
       "25%        7.000000     46.000000     29.000000      2.000000\n",
       "50%        9.000000     51.000000     30.000000      2.000000\n",
       "75%       11.000000     56.000000     30.000000      2.000000\n",
       "max       19.000000     60.000000     60.000000      2.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e520be93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:23.446231Z",
     "start_time": "2023-08-13T22:00:23.441354Z"
    }
   },
   "outputs": [],
   "source": [
    "traindf2 = traindf2[(traindf2['Frequency'] > 14) ]\n",
    "    # Sort the DataFrame by the 'Gloss' column\n",
    "traindf2 = traindf2.sort_values(by='Gloss')\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "traindf2 = traindf2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e2c901a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:24.047932Z",
     "start_time": "2023-08-13T22:00:24.033108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>920.000000</td>\n",
       "      <td>920.000000</td>\n",
       "      <td>920.000000</td>\n",
       "      <td>920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.641304</td>\n",
       "      <td>48.479348</td>\n",
       "      <td>29.695652</td>\n",
       "      <td>1.716304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.904366</td>\n",
       "      <td>8.424123</td>\n",
       "      <td>0.498946</td>\n",
       "      <td>0.451036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Frequency      Frames         FPS      Length\n",
       "count  920.000000  920.000000  920.000000  920.000000\n",
       "mean    15.641304   48.479348   29.695652    1.716304\n",
       "std      0.904366    8.424123    0.498946    0.451036\n",
       "min     15.000000   16.000000   29.000000    1.000000\n",
       "25%     15.000000   44.000000   29.000000    1.000000\n",
       "50%     15.000000   50.000000   30.000000    2.000000\n",
       "75%     16.000000   55.000000   30.000000    2.000000\n",
       "max     19.000000   60.000000   31.000000    2.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90a5583a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:25.656255Z",
     "start_time": "2023-08-13T22:00:25.654393Z"
    }
   },
   "outputs": [],
   "source": [
    "#traindf['Gloss'] = traindf['Gloss'].str.replace('\\d+', '',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17318e0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:26.360326Z",
     "start_time": "2023-08-13T22:00:26.275559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf2['Gloss'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e7f4f27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:27.097920Z",
     "start_time": "2023-08-13T22:00:27.094035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AND', 'ASK', 'BEST', 'BETTER', 'BLOND', 'BOLT', 'CANDY2', 'CLICK',\n",
       "       'COME', 'DEAF1', 'DENTIST2', 'DOG1', 'EAST', 'EAT1', 'ELEVEN',\n",
       "       'FAKE', 'FIND', 'FINE1', 'FOND', 'FOUR', 'GALLAUDET', 'GAY',\n",
       "       'GIVE', 'GOTCHA', 'GREEN', 'HANDSOME3', 'HONEY1', 'HOT', 'HOW2',\n",
       "       'HURDLE/TRIP1', 'LIGHTER', 'LOOKAT', 'LUCKY', 'NINE', 'NORTH',\n",
       "       'NOTCARE', 'OFF', 'OK', 'PATIENT2', 'PINK', 'REALLY', 'RECENT1',\n",
       "       'SEEM', 'SELECT', 'SEND', 'SHORTDISTANCE', 'SIX', 'SPITOUT',\n",
       "       'STRAIGHT', 'STRANGE', 'TAKE', 'TAKEPILL', 'THINK', 'THIRD1',\n",
       "       'TINY', 'TWINS1', 'UNDERSTAND', 'WINK', 'WISH'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = traindf2['Gloss'].unique()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6afdda5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:27.806019Z",
     "start_time": "2023-08-13T22:00:27.802128Z"
    }
   },
   "outputs": [],
   "source": [
    "traindf2['Gloss'] = traindf2['Gloss'].str.replace('\\d+', '',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "327c7f6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:29.297261Z",
     "start_time": "2023-08-13T22:00:29.292969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AND', 'ASK', 'BEST', 'BETTER', 'BLOND', 'BOLT', 'CANDY', 'CLICK',\n",
       "       'COME', 'DEAF', 'DENTIST', 'DOG', 'EAST', 'EAT', 'ELEVEN', 'FAKE',\n",
       "       'FIND', 'FINE', 'FOND', 'FOUR', 'GALLAUDET', 'GAY', 'GIVE',\n",
       "       'GOTCHA', 'GREEN', 'HANDSOME', 'HONEY', 'HOT', 'HOW',\n",
       "       'HURDLE/TRIP', 'LIGHTER', 'LOOKAT', 'LUCKY', 'NINE', 'NORTH',\n",
       "       'NOTCARE', 'OFF', 'OK', 'PATIENT', 'PINK', 'REALLY', 'RECENT',\n",
       "       'SEEM', 'SELECT', 'SEND', 'SHORTDISTANCE', 'SIX', 'SPITOUT',\n",
       "       'STRAIGHT', 'STRANGE', 'TAKE', 'TAKEPILL', 'THINK', 'THIRD',\n",
       "       'TINY', 'TWINS', 'UNDERSTAND', 'WINK', 'WISH'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = traindf2['Gloss'].unique()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e358e38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:00:30.132183Z",
     "start_time": "2023-08-13T22:00:30.129750Z"
    }
   },
   "outputs": [],
   "source": [
    "traindf=traindf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad70c4fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:01:16.397692Z",
     "start_time": "2023-08-13T22:01:11.501131Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(traindf.Path[1])\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(static_image_mode=False,\n",
    "                          model_complexity=2) as holistic:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(frame_rgb)\n",
    "\n",
    "        # Mano izquieda (azul)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "\n",
    "        # Mano derecha (verde)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 0),\n",
    "                                   thickness=2,\n",
    "                                   circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(0, 92, 230), thickness=2))\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b4860ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:01:31.486806Z",
     "start_time": "2023-08-13T22:01:31.481961Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to extract keypoints from a single video file\n",
    "def extract_keypoints_from_file(filepath):\n",
    "    # Initialize a MediaPipe Holistic model\n",
    "    holistic = mp.solutions.holistic.Holistic(static_image_mode=False,\n",
    "                                              model_complexity=1,\n",
    "                                              min_detection_confidence=0.5,\n",
    "                                              min_tracking_confidence=0.5)\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "\n",
    "    # Initialize an empty list to store the keypoints for each frame\n",
    "    keypoints = []\n",
    "\n",
    "    # Loop through the frames of the video\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB color space\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Use the Holistic model to detect landmarks for the face, pose, and hands\n",
    "        results = holistic.process(frame)\n",
    "\n",
    "        # Extract the keypoints from the results object and append them to the keypoints list\n",
    "        keypoints.append(extract_keypoints(results))\n",
    "\n",
    "    # Release the video capture object and the Holistic model\n",
    "    cap.release()\n",
    "    holistic.close()\n",
    "\n",
    "    return np.array(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5bf16986",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:01:59.849924Z",
     "start_time": "2023-08-13T22:01:59.845415Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to extract keypoints from a single video file\n",
    "def extract_keypoints_from_file_flip(filepath):\n",
    "    # Initialize a MediaPipe Holistic model\n",
    "    holistic = mp.solutions.holistic.Holistic(static_image_mode=False,\n",
    "                                              model_complexity=1,\n",
    "                                              min_detection_confidence=0.5,\n",
    "                                              min_tracking_confidence=0.5)\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "\n",
    "    # Initialize an empty list to store the keypoints for each frame\n",
    "    keypoints = []\n",
    "\n",
    "    # Loop through the frames of the video\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB color space\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        # Use the Holistic model to detect landmarks for the face, pose, and hands\n",
    "        results = holistic.process(frame)\n",
    "\n",
    "        # Extract the keypoints from the results object and append them to the keypoints list\n",
    "        keypoints.append(extract_keypoints(results))\n",
    "\n",
    "    # Release the video capture object and the Holistic model\n",
    "    cap.release()\n",
    "    holistic.close()\n",
    "\n",
    "    return np.array(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77cbe2fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:01:08.393837Z",
     "start_time": "2023-08-13T22:01:08.387425Z"
    }
   },
   "outputs": [],
   "source": [
    "traindf['Path'] = traindf['Path'].str.replace('file:///media/kristian/HDD/ASL_Citizen/ASL_Citizen/', 'file:///home/kristian/ASL_Citizen/',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49e95ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:02:05.827245Z",
     "start_time": "2023-08-13T22:02:03.070862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 126)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_keypoints_from_file(traindf.Path[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d2a0a7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:02:08.863316Z",
     "start_time": "2023-08-13T22:02:08.859748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(traindf.Path[0])\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print( length )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b48bfa39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:02:13.830006Z",
     "start_time": "2023-08-13T22:02:11.702369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(extract_keypoints_from_file(traindf.Path[643]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "de2754c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T07:05:46.123747Z",
     "start_time": "2023-08-09T07:05:19.015852Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '6843816941433676-HURDLE-TRIP.mp4' copied.\n",
      "File '5270060903242877-DENTIST 2.mp4' copied.\n",
      "File '09014404715027236-WINK.mp4' copied.\n",
      "File '34178569625029054-TWINS.mp4' copied.\n",
      "File '18352529322609779-BEST.mp4' copied.\n",
      "File '8421220383934189-HOT.mp4' copied.\n",
      "File '8138364046329691-FOUR.mp4' copied.\n",
      "File '5141622294161379-FOUR.mp4' copied.\n",
      "File '22096800930230853-TAKE PILL.mp4' copied.\n",
      "File '4524158338314277-EAT.mp4' copied.\n",
      "File '45242458406215746-TAKE PILL.mp4' copied.\n",
      "File '10685950953531731-THIRD.mp4' copied.\n",
      "File '5745729001649573-OK.mp4' copied.\n",
      "File '5747517326015636-SELECT.mp4' copied.\n",
      "File '5575086704295376-CLICK.mp4' copied.\n",
      "File '10254755835642815-LUCKY.mp4' copied.\n",
      "File '5976950094284144-ASK.mp4' copied.\n",
      "File '42041801095735476-CANDY 2.mp4' copied.\n",
      "File '9331308031305054-CANDY 2.mp4' copied.\n",
      "File '4728590611874972-STRAIGHT.mp4' copied.\n",
      "File '5308291392983451-RECENT.mp4' copied.\n",
      "File '5309189359554582-HANDSOME 4.mp4' copied.\n",
      "File '1340015962713661-PINK.mp4' copied.\n",
      "File '5419108965116659-SHORT DISTANCE.mp4' copied.\n",
      "File '2279754462685024-SIX.mp4' copied.\n",
      "File '48582056242680793-HOW 2.mp4' copied.\n",
      "File '2704231887257391-HANDSOME 4.mp4' copied.\n",
      "File '2705349961309489-HURDLE-TRIP.mp4' copied.\n",
      "File '09611862624996848-SELECT.mp4' copied.\n",
      "File '9946830406807634-LUCKY.mp4' copied.\n",
      "File '9692657925833326-BETTER.mp4' copied.\n",
      "File '9692739680851399-PINK.mp4' copied.\n",
      "File '28272341017628855-BEST.mp4' copied.\n",
      "File '34581625896023915-COME.mp4' copied.\n",
      "File '5617280048659572-TAKE.mp4' copied.\n",
      "File '6006244554232261-NOT CARE.mp4' copied.\n",
      "File '4958280251317906-THINK.mp4' copied.\n",
      "File '25496283976425316-NOT CARE.mp4' copied.\n",
      "File '94332660312706-LOOK AT.mp4' copied.\n",
      "File '7781130034647721-SEND.mp4' copied.\n",
      "File '7856261530418045-SPIT OUT.mp4' copied.\n",
      "File '456076593467327-TINY.mp4' copied.\n",
      "File '6638613473402202-SEND.mp4' copied.\n",
      "File '826349513489413-COME.mp4' copied.\n",
      "File '5035137053083618-REALLY.mp4' copied.\n",
      "File '5035301373430681-EAT.mp4' copied.\n",
      "File '7474978008576432-TAKE PILL.mp4' copied.\n",
      "File '011246893774733424-TAKE.mp4' copied.\n",
      "File '7366917583319141-NINE.mp4' copied.\n",
      "File '1889882232546276-SHORT DISTANCE.mp4' copied.\n",
      "File '18914159249366724-DENTIST 2.mp4' copied.\n",
      "File '9174915733024191-GIVE.mp4' copied.\n",
      "File '9174976347516473-HOT.mp4' copied.\n",
      "File '39114000127985404-LOOK AT.mp4' copied.\n",
      "File '24203446191959643-NORTH.mp4' copied.\n",
      "File '2374155228317818-UNDERSTAND.mp4' copied.\n",
      "File '3537345851274545-COME.mp4' copied.\n",
      "File '3481637699143123-FIND.mp4' copied.\n",
      "File '8842998926765759-OFF.mp4' copied.\n",
      "File '01782931113550945-GOTCHA.mp4' copied.\n",
      "File '01784133236524288-OFF.mp4' copied.\n",
      "File '017934102607076285-GOTCHA.mp4' copied.\n",
      "File '3640824865298957-FOND.mp4' copied.\n",
      "File '7928879615693063-NOT CARE.mp4' copied.\n",
      "File '31724875643038497-HOW 2.mp4' copied.\n",
      "File '31730779368330464-TWINS.mp4' copied.\n",
      "File '046585146920706366-SIX.mp4' copied.\n",
      "File '25892481995213434-FOUR.mp4' copied.\n",
      "File '09372722526789401-TAKE.mp4' copied.\n",
      "File '05497869473628603-SELECT.mp4' copied.\n",
      "File '6336502024840074-GALLAUDET.mp4' copied.\n",
      "File '2629108059091052-ASK.mp4' copied.\n",
      "File '2629996520868716-GREEN.mp4' copied.\n",
      "File '23072373122450074-ELEVEN.mp4' copied.\n",
      "File '30953548448841706-DOG.mp4' copied.\n",
      "File '5009552564671704-CLICK.mp4' copied.\n",
      "File '46070187737730706-LIGHTER.mp4' copied.\n",
      "File '2901349503607584-BEST.mp4' copied.\n",
      "File '4746424730119678-DENTIST 2.mp4' copied.\n",
      "File '6235551137186706-BEST.mp4' copied.\n",
      "File '5899516180769444-FIND.mp4' copied.\n",
      "File '1674169211464116-HOW 2.mp4' copied.\n",
      "File '6821952562062066-TINY.mp4' copied.\n",
      "File '733923878962389-OFF.mp4' copied.\n",
      "File '1201537952691305-GOTCHA.mp4' copied.\n",
      "File '6903327734198565-LIGHTER.mp4' copied.\n",
      "File '1948108624588607-STRAIGHT.mp4' copied.\n",
      "File '3959694435516088-BEST.mp4' copied.\n",
      "File '19914703219633179-NOT CARE.mp4' copied.\n",
      "File '3741021155965083-AND.mp4' copied.\n",
      "File '40201308141070924-SPIT OUT.mp4' copied.\n",
      "File '12834201117290944-SIX.mp4' copied.\n",
      "File '46766274714290734-AND.mp4' copied.\n",
      "File '0756193896626629-GIVE.mp4' copied.\n",
      "File '2987380177072183-CANDY 2.mp4' copied.\n",
      "File '6727498378915875-DOG.mp4' copied.\n",
      "File '3869920875559121-SEEM.mp4' copied.\n",
      "File '3878260902223658-EAT.mp4' copied.\n",
      "File '512545662660741-BETTER.mp4' copied.\n",
      "File '512720877958327-WISH.mp4' copied.\n",
      "File '38959203938228004-TAKE PILL.mp4' copied.\n",
      "File '2257554613984365-NOT CARE.mp4' copied.\n",
      "File '627110026160292-HURDLE-TRIP.mp4' copied.\n",
      "File '9506704114850111-AND.mp4' copied.\n",
      "File '8057822437653506-TAKE PILL.mp4' copied.\n",
      "File '8315652353125724-EAST.mp4' copied.\n",
      "File '41409287699545816-BETTER.mp4' copied.\n",
      "File '45198637421522947-PINK.mp4' copied.\n",
      "File '8415288068843434-TAKE PILL.mp4' copied.\n",
      "File '33226505202024437-LIGHTER.mp4' copied.\n",
      "File '33243997680017356-DEAF.mp4' copied.\n",
      "File '1023816440677392-CLICK.mp4' copied.\n",
      "File '48758779214214476-STRANGE.mp4' copied.\n",
      "File '5082090494759806-TAKE PILL.mp4' copied.\n",
      "File '010356460960846414-GALLAUDET.mp4' copied.\n",
      "File '41699711447604804-NINE.mp4' copied.\n",
      "File '7234825506474691-LOOK AT.mp4' copied.\n",
      "File '528036690043189-GALLAUDET.mp4' copied.\n",
      "File '5281867130394469-NORTH.mp4' copied.\n",
      "File '5282378888311965-REALLY.mp4' copied.\n",
      "File '6968328028731545-TAKE.mp4' copied.\n",
      "File '16363179028002817-STRAIGHT.mp4' copied.\n",
      "File '9834164697641237-FAKE.mp4' copied.\n",
      "File '41048138699229675-DEAF.mp4' copied.\n",
      "File '9224013521423862-CANDY 2.mp4' copied.\n",
      "File '29587887363119436-TWINS.mp4' copied.\n",
      "File '6071326240783663-NOT CARE.mp4' copied.\n",
      "File '9992150959204005-RECENT.mp4' copied.\n",
      "File '06478294841003218-CLICK.mp4' copied.\n",
      "File '6306796203116509-ELEVEN.mp4' copied.\n",
      "File '2736869319842712-THINK.mp4' copied.\n",
      "File '27380760480335975-REALLY.mp4' copied.\n",
      "File '5817524945804566-FINE.mp4' copied.\n",
      "File '6324827452673183-RECENT.mp4' copied.\n",
      "File '660552812870673-FAKE.mp4' copied.\n",
      "File '6605969835390502-UNDERSTAND.mp4' copied.\n",
      "File '2762792243529284-HURDLE-TRIP.mp4' copied.\n",
      "File '43783660351930753-GOTCHA.mp4' copied.\n",
      "File '3712777130687983-THIRD.mp4' copied.\n",
      "File '7288759577617836-BOLT.mp4' copied.\n",
      "File '8088386464060653-GALLAUDET.mp4' copied.\n",
      "File '4812862159396367-ELEVEN.mp4' copied.\n",
      "File '8694420078662353-GOTCHA.mp4' copied.\n",
      "File '7639333888976483-FAKE.mp4' copied.\n",
      "File '17379769097110098-OK.mp4' copied.\n",
      "File '0479894483394554-DENTIST 2.mp4' copied.\n",
      "File '3183841529608291-TWINS.mp4' copied.\n",
      "File '3184640409002879-LIGHTER.mp4' copied.\n",
      "File '3108578299019191-PATIENT 2.mp4' copied.\n",
      "File '9058680059708657-WISH.mp4' copied.\n",
      "File '7991797671026146-CLICK.mp4' copied.\n",
      "File '8901031558158694-BLOND.mp4' copied.\n",
      "File '5788566001263671-GAY.mp4' copied.\n",
      "File '08871611654188283-SPIT OUT.mp4' copied.\n",
      "File '5187180924403598-ASK.mp4' copied.\n",
      "File '5224335234214932-SPIT OUT.mp4' copied.\n",
      "File '7841237666552301-AND.mp4' copied.\n",
      "File '6763157955886321-ASK.mp4' copied.\n",
      "File '09734878070308994-PINK.mp4' copied.\n",
      "File '5564819669362191-OFF.mp4' copied.\n",
      "File '6785114540405601-OK.mp4' copied.\n",
      "File '8742773141210243-DOG.mp4' copied.\n",
      "File '7373321930232359-LUCKY.mp4' copied.\n",
      "File '7373916094367448-CANDY 2.mp4' copied.\n",
      "File '9759813192587696-OK.mp4' copied.\n",
      "File '4633651967646373-SIX.mp4' copied.\n",
      "File '20489516363250782-NINE.mp4' copied.\n",
      "File '1462093595285281-FOND.mp4' copied.\n",
      "File '5986296474103647-WISH.mp4' copied.\n",
      "File '830413196012378-CLICK.mp4' copied.\n",
      "File '0165763043403353-COME.mp4' copied.\n",
      "File '19234689203810262-REALLY.mp4' copied.\n",
      "File '8797772478617758-GALLAUDET.mp4' copied.\n",
      "File '4841422916010285-BOLT.mp4' copied.\n",
      "File '05212260739583496-CANDY 2.mp4' copied.\n",
      "File '13328137713527943-GALLAUDET.mp4' copied.\n",
      "File '9083197141290018-FIND.mp4' copied.\n",
      "File '30387105972416184-SIX.mp4' copied.\n",
      "File '3732678629647439-AND.mp4' copied.\n",
      "File '13884914336494525-EAT.mp4' copied.\n",
      "File '924430669747311-WINK.mp4' copied.\n",
      "File '1605799239700627-DOG.mp4' copied.\n",
      "File '333133781342801-SPIT OUT.mp4' copied.\n",
      "File '2295384916053822-ASK.mp4' copied.\n",
      "File '24298622199216324-GIVE.mp4' copied.\n",
      "File '33642481024757687-STRAIGHT.mp4' copied.\n",
      "File '33787009673404844-BOLT.mp4' copied.\n",
      "File '5694623090054023-BOLT.mp4' copied.\n",
      "File '9809527206380761-BLOND.mp4' copied.\n",
      "File '10624966994296114-LIGHTER.mp4' copied.\n",
      "File '10652117554281637-GREEN.mp4' copied.\n",
      "File '3827741794247175-FINE.mp4' copied.\n",
      "File '8849383543656688-DEAF.mp4' copied.\n",
      "File '6740483377677127-GAY.mp4' copied.\n",
      "File '8812089061724724-SHORT DISTANCE.mp4' copied.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '2980712905804166-SELECT.mp4' copied.\n",
      "File '4788883809061111-THIRD.mp4' copied.\n",
      "File '6698348047100313-NORTH.mp4' copied.\n",
      "File '300554219176699-SEND.mp4' copied.\n",
      "File '5607838772101854-TWINS.mp4' copied.\n",
      "File '30539347753669954-GREEN.mp4' copied.\n",
      "File '5739215722518052-EAT.mp4' copied.\n",
      "File '14269575017191238-EAST.mp4' copied.\n",
      "File '8864496316656505-LIGHTER.mp4' copied.\n",
      "File '2495443890240825-GIVE.mp4' copied.\n",
      "File '756000062080056-GOTCHA.mp4' copied.\n",
      "File '7560560007286001-FOND.mp4' copied.\n",
      "File '7613143471093098-LIGHTER.mp4' copied.\n",
      "File '8569232579936605-THINK.mp4' copied.\n",
      "File '8569393046306124-CLICK.mp4' copied.\n",
      "File '07478302952605298-GAY.mp4' copied.\n",
      "File '8193368982950104-HOW 2.mp4' copied.\n",
      "File '8193754472141177-HONEY 1.mp4' copied.\n",
      "File '43107482372128714-REALLY.mp4' copied.\n",
      "File '6951725928781516-WISH.mp4' copied.\n",
      "File '006951411960890663-FINE.mp4' copied.\n",
      "File '919443966194881-EAST.mp4' copied.\n",
      "File '8440442611677397-FOUR.mp4' copied.\n",
      "File '5370118594616453-STRANGE.mp4' copied.\n",
      "File '8622441304805439-DEAF.mp4' copied.\n",
      "File '4915547930463213-OK.mp4' copied.\n",
      "File '7615518031882893-SEND.mp4' copied.\n",
      "File '04738273535882853-PINK.mp4' copied.\n",
      "File '8530024596631476-DENTIST 2.mp4' copied.\n",
      "File '8531403867752749-HANDSOME 4.mp4' copied.\n",
      "File '5014452686517441-WINK.mp4' copied.\n",
      "File '26718272677630317-NINE.mp4' copied.\n",
      "File '32024426702539666-SEND.mp4' copied.\n",
      "File '43251349327036803-SEND.mp4' copied.\n",
      "File '5318993732416839-DENTIST 2.mp4' copied.\n",
      "File '5942406195471865-EAST.mp4' copied.\n",
      "File '8353535122796334-CLICK.mp4' copied.\n",
      "File '9181458820457007-GAY.mp4' copied.\n",
      "File '48027094398019576-NORTH.mp4' copied.\n",
      "File '08197479357139326-PATIENT 2.mp4' copied.\n",
      "File '717226063042893-HURDLE-TRIP.mp4' copied.\n",
      "File '7131247482749883-TINY.mp4' copied.\n",
      "File '40156343723600907-UNDERSTAND.mp4' copied.\n",
      "File '4919776718698967-BETTER.mp4' copied.\n",
      "File '22042907092518438-FOND.mp4' copied.\n",
      "File '5276371337374621-GREEN.mp4' copied.\n",
      "File '0392835216734122-EAT.mp4' copied.\n",
      "File '985530753720834-GALLAUDET.mp4' copied.\n",
      "File '4455329487942934-HOT.mp4' copied.\n",
      "File '21796610333568833-SEEM.mp4' copied.\n",
      "File '29262412490880063-REALLY.mp4' copied.\n",
      "File '7760730226100536-LOOK AT.mp4' copied.\n",
      "File '9915177398162693-WISH.mp4' copied.\n",
      "File '9916743393596088-NOT CARE.mp4' copied.\n",
      "File '6958606143165649-TWINS.mp4' copied.\n",
      "File '4569712020319967-ELEVEN.mp4' copied.\n",
      "File '7219677772800852-THINK.mp4' copied.\n",
      "File '20685819276671857-BETTER.mp4' copied.\n",
      "File '8083384619681451-AND.mp4' copied.\n",
      "File '7634160961141707-COME.mp4' copied.\n",
      "File '29669279681518446-OK.mp4' copied.\n",
      "File '9618610602589022-UNDERSTAND.mp4' copied.\n",
      "File '11576233542635928-PINK.mp4' copied.\n",
      "File '5342802354346374-THINK.mp4' copied.\n",
      "File '9591609839614859-GALLAUDET.mp4' copied.\n",
      "File '2711614041567312-HANDSOME 4.mp4' copied.\n",
      "File '966402251864271-FAKE.mp4' copied.\n",
      "File '06170286063004182-THINK.mp4' copied.\n",
      "File '4602884180405882-GOTCHA.mp4' copied.\n",
      "File '7032362464915427-HURDLE-TRIP.mp4' copied.\n",
      "File '5794264707227115-CANDY 2.mp4' copied.\n",
      "File '34339348264869574-NINE.mp4' copied.\n",
      "File '27542820590351824-LUCKY.mp4' copied.\n",
      "File '9824120994807248-SEND.mp4' copied.\n",
      "File '9824579558010589-PINK.mp4' copied.\n",
      "File '5922606506694628-EAST.mp4' copied.\n",
      "File '5922800667315855-TAKE PILL.mp4' copied.\n",
      "File '10176087308204429-OFF.mp4' copied.\n",
      "File '734952989425808-DENTIST 2.mp4' copied.\n",
      "File '6908254835180958-TAKE.mp4' copied.\n",
      "File '48942739522180756-BETTER.mp4' copied.\n",
      "File '24155402085043542-BLOND.mp4' copied.\n",
      "File '5579456931257181-DOG.mp4' copied.\n",
      "File '8550662259271349-SPIT OUT.mp4' copied.\n",
      "File '7262581620088506-WISH.mp4' copied.\n",
      "File '8736458919974166-NOT CARE.mp4' copied.\n",
      "File '5457070151349404-WINK.mp4' copied.\n",
      "File '8934738525444881-LUCKY.mp4' copied.\n",
      "File '13752916440820018-SPIT OUT.mp4' copied.\n",
      "File '6494254793022431-HURDLE-TRIP.mp4' copied.\n",
      "File '7835153573711628-TINY.mp4' copied.\n",
      "File '03458515864070444-LOOK AT.mp4' copied.\n",
      "File '6931344932376056-ELEVEN.mp4' copied.\n",
      "File '3446645273513582-WISH.mp4' copied.\n",
      "File '8981918903910342-THINK.mp4' copied.\n",
      "File '3947368501065438-FINE.mp4' copied.\n",
      "File '1363777633602654-PATIENT 2.mp4' copied.\n",
      "File '49026310798660444-STRAIGHT.mp4' copied.\n",
      "File '6228389502484397-LIGHTER.mp4' copied.\n",
      "File '41461171624603455-EAT.mp4' copied.\n",
      "File '30604009790499287-SEEM.mp4' copied.\n",
      "File '5610159237699726-BEST.mp4' copied.\n",
      "File '41100355307213277-LUCKY.mp4' copied.\n",
      "File '4110410447080084-GAY.mp4' copied.\n",
      "File '6175480178461072-BETTER.mp4' copied.\n",
      "File '8699676621201298-OK.mp4' copied.\n",
      "File '41933820635700836-NOT CARE.mp4' copied.\n",
      "File '4193407831348237-PINK.mp4' copied.\n",
      "File '21216630436083284-FOUR.mp4' copied.\n",
      "File '687175058377234-TWINS.mp4' copied.\n",
      "File '7809584186980043-FIND.mp4' copied.\n",
      "File '5194547684631492-ELEVEN.mp4' copied.\n",
      "File '2691373142288416-BEST.mp4' copied.\n",
      "File '5356144703822832-HOW 2.mp4' copied.\n",
      "File '3841139490634713-PATIENT 2.mp4' copied.\n",
      "File '7298858007459978-STRANGE.mp4' copied.\n",
      "File '6191415507296982-UNDERSTAND.mp4' copied.\n",
      "File '5711747304509649-WISH.mp4' copied.\n",
      "File '9766513994870278-DOG.mp4' copied.\n",
      "File '07182185627902293-HONEY 1.mp4' copied.\n",
      "File '0720243684183901-OFF.mp4' copied.\n",
      "File '08954780499652149-TAKE PILL.mp4' copied.\n",
      "File '020001513874339905-HURDLE-TRIP.mp4' copied.\n",
      "File '32790323343367267-NORTH.mp4' copied.\n",
      "File '7327271470470507-EAT.mp4' copied.\n",
      "File '13553502839177423-SEND.mp4' copied.\n",
      "File '004276593413738317-GIVE.mp4' copied.\n",
      "File '0043140725862644835-HANDSOME 4.mp4' copied.\n",
      "File '3197529115324771-RECENT.mp4' copied.\n",
      "File '3198558371793543-BOLT.mp4' copied.\n",
      "File '07633291774567197-THIRD.mp4' copied.\n",
      "File '8391242573055968-GAY.mp4' copied.\n",
      "File '9144635138919697-HANDSOME 4.mp4' copied.\n",
      "File '8799499585540838-GIVE.mp4' copied.\n",
      "File '2732757606315379-TINY.mp4' copied.\n",
      "File '4050475261656792-FOND.mp4' copied.\n",
      "File '7394498504673854-BLOND.mp4' copied.\n",
      "File '7602780259740458-GIVE.mp4' copied.\n",
      "File '39081440676355306-COME.mp4' copied.\n",
      "File '39549485976085896-GIVE.mp4' copied.\n",
      "File '5851595172841455-CANDY 2.mp4' copied.\n",
      "File '5338341147221657-THINK.mp4' copied.\n",
      "File '14738255377419196-NOT CARE.mp4' copied.\n",
      "File '5672396093022622-EAT.mp4' copied.\n",
      "File '5673334075856531-GOTCHA.mp4' copied.\n",
      "File '7998905824707223-BETTER.mp4' copied.\n",
      "File '8410803588889355-THINK.mp4' copied.\n",
      "File '829860840395733-CLICK.mp4' copied.\n",
      "File '7592666596709279-GALLAUDET.mp4' copied.\n",
      "File '5681068854345341-NOT CARE.mp4' copied.\n",
      "File '5297200205393633-BLOND.mp4' copied.\n",
      "File '2862298227001887-STRANGE.mp4' copied.\n",
      "File '8792085229711837-SEEM.mp4' copied.\n",
      "File '7081997886148117-FINE.mp4' copied.\n",
      "File '22760199152360472-ELEVEN.mp4' copied.\n",
      "File '20458224320425433-HURDLE-TRIP.mp4' copied.\n",
      "File '6805373308766427-FOUR.mp4' copied.\n",
      "File '19373340311088127-LUCKY.mp4' copied.\n",
      "File '4589443576656864-EAT.mp4' copied.\n",
      "File '4233172454307945-TWINS.mp4' copied.\n",
      "File '9217947486683848-FAKE.mp4' copied.\n",
      "File '6898724827814644-DEAF.mp4' copied.\n",
      "File '1254039379272358-NORTH.mp4' copied.\n",
      "File '5421259944819825-SEEM.mp4' copied.\n",
      "File '6610091794646322-AND.mp4' copied.\n",
      "File '30148795754394175-EAT.mp4' copied.\n",
      "File '3521127235382102-BEST.mp4' copied.\n",
      "File '5602506471677693-COME.mp4' copied.\n",
      "File '5267042103505968-WINK.mp4' copied.\n",
      "File '038892973193729974-SEEM.mp4' copied.\n",
      "File '32881676555256245-SEND.mp4' copied.\n",
      "File '1484186619960186-FIND.mp4' copied.\n",
      "File '9574383234121289-RECENT.mp4' copied.\n",
      "File '43215532284999125-RECENT.mp4' copied.\n",
      "File '3511414357256921-THIRD.mp4' copied.\n",
      "File '22877680820569246-AND.mp4' copied.\n",
      "File '2149343960761707-DEAF.mp4' copied.\n",
      "File '6630994156987291-SEND.mp4' copied.\n",
      "File '9521376433888893-TINY.mp4' copied.\n",
      "File '8676304528363552-SIX.mp4' copied.\n",
      "File '8676867126730325-OFF.mp4' copied.\n",
      "File '8021279567515738-NORTH.mp4' copied.\n",
      "File '5494204143000812-FINE.mp4' copied.\n",
      "File '3870800609348781-TAKE PILL.mp4' copied.\n",
      "File '12221538032492663-GALLAUDET.mp4' copied.\n",
      "File '9061445516781446-SPIT OUT.mp4' copied.\n",
      "File '6256202413444414-SHORT DISTANCE.mp4' copied.\n",
      "File '45576193792893016-FAKE.mp4' copied.\n",
      "File '6211759212759429-AND.mp4' copied.\n",
      "File '8594640554882966-EAST.mp4' copied.\n",
      "File '2943130704557879-SIX.mp4' copied.\n",
      "File '19866027442823042-FINE.mp4' copied.\n",
      "File '9941614592907033-DOG.mp4' copied.\n",
      "File '9942639780287319-TWINS.mp4' copied.\n",
      "File '10703906146469544-TINY.mp4' copied.\n",
      "File '33524184538444524-SHORT DISTANCE.mp4' copied.\n",
      "File '6424637597161564-UNDERSTAND.mp4' copied.\n",
      "File '6425491441035218-AND.mp4' copied.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '9742883685495938-DEAF.mp4' copied.\n",
      "File '03845734114791988-BLOND.mp4' copied.\n",
      "File '4611032306786558-TWINS.mp4' copied.\n",
      "File '0020382808137153763-ELEVEN.mp4' copied.\n",
      "File '5170125336404756-COME.mp4' copied.\n",
      "File '03150905619350208-SELECT.mp4' copied.\n",
      "File '8122344601646359-LOOK AT.mp4' copied.\n",
      "File '8123288036507608-GAY.mp4' copied.\n",
      "File '10827398525400311-OFF.mp4' copied.\n",
      "File '5650868043704504-NINE.mp4' copied.\n",
      "File '8003732238675179-DEAF.mp4' copied.\n",
      "File '3981207314157731-AND.mp4' copied.\n",
      "File '08478560862167717-RECENT.mp4' copied.\n",
      "File '08497040540501066-SHORT DISTANCE.mp4' copied.\n",
      "File '043016679537065894-FOND.mp4' copied.\n",
      "File '4239903470632247-BOLT.mp4' copied.\n",
      "File '4487899898775074-LIGHTER.mp4' copied.\n",
      "File '6504234134902995-UNDERSTAND.mp4' copied.\n",
      "File '6156241027736771-RECENT.mp4' copied.\n",
      "File '42978197247437233-OFF.mp4' copied.\n",
      "File '8285963105812504-TAKE.mp4' copied.\n",
      "File '19543181290734046-CANDY 2.mp4' copied.\n",
      "File '2850100795370789-SIX.mp4' copied.\n",
      "File '9705021362579873-SPIT OUT.mp4' copied.\n",
      "File '10309126133056656-CLICK.mp4' copied.\n",
      "File '21948712174714302-DENTIST 2.mp4' copied.\n",
      "File '32530125966400014-SPIT OUT.mp4' copied.\n",
      "File '9259361312554082-STRANGE.mp4' copied.\n",
      "File '8521113894614278-GREEN.mp4' copied.\n",
      "File '18563266850591176-FOUR.mp4' copied.\n",
      "File '38331150548668425-CLICK.mp4' copied.\n",
      "File '9956058333717619-BLOND.mp4' copied.\n",
      "File '6139486577479072-AND.mp4' copied.\n",
      "File '6810397598953175-UNDERSTAND.mp4' copied.\n",
      "File '74247500952737-THIRD.mp4' copied.\n",
      "File '11871822001327859-WINK.mp4' copied.\n",
      "File '11885714152536164-EAST.mp4' copied.\n",
      "File '47327228222097584-BEST.mp4' copied.\n",
      "File '9858541230690814-PATIENT 2.mp4' copied.\n",
      "File '9858835848653265-FOND.mp4' copied.\n",
      "File '30338660692795494-FIND.mp4' copied.\n",
      "File '3657919944116619-RECENT.mp4' copied.\n",
      "File '788070944871925-HONEY 1.mp4' copied.\n",
      "File '005082179049994862-DOG.mp4' copied.\n",
      "File '23819147505993477-HOT.mp4' copied.\n",
      "File '1384893971212695-DEAF.mp4' copied.\n",
      "File '48525668766928076-NOT CARE.mp4' copied.\n",
      "File '5209269291515621-TAKE PILL.mp4' copied.\n",
      "File '3648442229599922-EAST.mp4' copied.\n",
      "File '7764581525163443-COME.mp4' copied.\n",
      "File '7370287966523523-HOT.mp4' copied.\n",
      "File '7371501507543785-DEAF.mp4' copied.\n",
      "File '7414475346730574-ASK.mp4' copied.\n",
      "File '7060265642402466-HOT.mp4' copied.\n",
      "File '2999107393441156-UNDERSTAND.mp4' copied.\n",
      "File '47205067019014724-HONEY 1.mp4' copied.\n",
      "File '7982233541490578-DENTIST 2.mp4' copied.\n",
      "File '014645203437414933-SHORT DISTANCE.mp4' copied.\n",
      "File '01470147349708184-SELECT.mp4' copied.\n",
      "File '7257805929367986-HOW 2.mp4' copied.\n",
      "File '9546916100759397-FOND.mp4' copied.\n",
      "File '4677802327393048-STRAIGHT.mp4' copied.\n",
      "File '4678281351844287-GAY.mp4' copied.\n",
      "File '23314151865153954-BETTER.mp4' copied.\n",
      "File '07081296954484628-SELECT.mp4' copied.\n",
      "File '36886184032889124-WINK.mp4' copied.\n",
      "File '3731859935641946-DENTIST 2.mp4' copied.\n",
      "File '06948950711239643-BEST.mp4' copied.\n",
      "File '8868059708540206-FAKE.mp4' copied.\n",
      "File '8929802071572237-GOTCHA.mp4' copied.\n",
      "File '8930667013805091-PINK.mp4' copied.\n",
      "File '7639942388226042-SEND.mp4' copied.\n",
      "File '7640667133656183-EAT.mp4' copied.\n",
      "File '18697877522861095-GREEN.mp4' copied.\n",
      "File '3815358216512903-WISH.mp4' copied.\n",
      "File '38153931915395023-BEST.mp4' copied.\n",
      "File '8562967503282453-TAKE.mp4' copied.\n",
      "File '0728901198375902-DENTIST 2.mp4' copied.\n",
      "File '42561609545136014-COME.mp4' copied.\n",
      "File '7335136138160512-GREEN.mp4' copied.\n",
      "File '6817762104884393-GREEN.mp4' copied.\n",
      "File '43379976436209144-FOUR.mp4' copied.\n",
      "File '13003746154241558-RECENT.mp4' copied.\n",
      "File '14498064704076463-OK.mp4' copied.\n",
      "File '3743799252551465-LUCKY.mp4' copied.\n",
      "File '8705859461648942-CLICK.mp4' copied.\n",
      "File '8806219174411618-WISH.mp4' copied.\n",
      "File '9240653301016948-CANDY 2.mp4' copied.\n",
      "File '9240929402876865-THIRD.mp4' copied.\n",
      "File '1926863549690485-GOTCHA.mp4' copied.\n",
      "File '8561176854571788-GAY.mp4' copied.\n",
      "File '5327888311124136-SHORT DISTANCE.mp4' copied.\n",
      "File '36211305458217447-BOLT.mp4' copied.\n",
      "File '6127967104764245-TAKE.mp4' copied.\n",
      "File '6128713139601467-ELEVEN.mp4' copied.\n",
      "File '9098726585421435-HOT.mp4' copied.\n",
      "File '9099130845645638-NOT CARE.mp4' copied.\n",
      "File '9099190157347956-STRAIGHT.mp4' copied.\n",
      "File '05630831773925915-BETTER.mp4' copied.\n",
      "File '24667604787836295-BLOND.mp4' copied.\n",
      "File '8955427311799309-REALLY.mp4' copied.\n",
      "File '15015471275920045-LUCKY.mp4' copied.\n",
      "File '8076163112657544-RECENT.mp4' copied.\n",
      "File '8826053491989787-NORTH.mp4' copied.\n",
      "File '5749208785683302-PINK.mp4' copied.\n",
      "File '575097801448069-SPIT OUT.mp4' copied.\n",
      "File '25950066981856557-CANDY 2.mp4' copied.\n",
      "File '9952746480983969-FIND.mp4' copied.\n",
      "File '7305424734559558-OK.mp4' copied.\n",
      "File '49242292546263156-BLOND.mp4' copied.\n",
      "File '8466065127842359-GALLAUDET.mp4' copied.\n",
      "File '9833342420720304-DEAF.mp4' copied.\n",
      "File '20889177562039807-HONEY 1.mp4' copied.\n",
      "File '7530496807705915-GIVE.mp4' copied.\n",
      "File '5833316008663412-REALLY.mp4' copied.\n",
      "File '4589398793876327-DEAF.mp4' copied.\n",
      "File '7182286410314891-RECENT.mp4' copied.\n",
      "File '7184251334812357-FOUR.mp4' copied.\n",
      "File '516307168172641-BETTER.mp4' copied.\n",
      "File '17156030645430365-FINE.mp4' copied.\n",
      "File '17172246079778142-FOUR.mp4' copied.\n",
      "File '2518011428400748-FINE.mp4' copied.\n",
      "File '5432804607364146-TAKE.mp4' copied.\n",
      "File '6301823315233508-HURDLE-TRIP.mp4' copied.\n",
      "File '5966497138153777-DEAF.mp4' copied.\n",
      "File '23706248733890045-ELEVEN.mp4' copied.\n",
      "File '7868445027066324-NINE.mp4' copied.\n",
      "File '4212999001602742-DOG.mp4' copied.\n",
      "File '8895105417637403-HOT.mp4' copied.\n",
      "File '9673285376166738-FAKE.mp4' copied.\n",
      "File '7823989202968566-TAKE PILL.mp4' copied.\n",
      "File '35349299710246207-STRANGE.mp4' copied.\n",
      "File '5178237631667904-GIVE.mp4' copied.\n",
      "File '17698818900198532-GIVE.mp4' copied.\n",
      "File '01699135237473781-THIRD.mp4' copied.\n",
      "File '6956239348425071-HOT.mp4' copied.\n",
      "File '7757635921191464-LOOK AT.mp4' copied.\n",
      "File '5658128989956679-WINK.mp4' copied.\n",
      "File '5658200184939948-DOG.mp4' copied.\n",
      "File '5658430416463056-HOW 2.mp4' copied.\n",
      "File '5658492471028722-SHORT DISTANCE.mp4' copied.\n",
      "File '5041030132527928-GOTCHA.mp4' copied.\n",
      "File '5470805439006985-DOG.mp4' copied.\n",
      "File '6879543266745689-EAST.mp4' copied.\n",
      "File '4835177397341548-GAY.mp4' copied.\n",
      "File '9360554484216261-SEND.mp4' copied.\n",
      "File '9360836400573538-SPIT OUT.mp4' copied.\n",
      "File '7717990545744957-THIRD.mp4' copied.\n",
      "File '6600524013477269-FIND.mp4' copied.\n",
      "File '7744826220635872-GIVE.mp4' copied.\n",
      "File '26616905656998036-FOUR.mp4' copied.\n",
      "File '06585822033156608-PATIENT 2.mp4' copied.\n",
      "File '0034638402574485028-SIX.mp4' copied.\n",
      "File '45417678103253367-HURDLE-TRIP.mp4' copied.\n",
      "File '4263603161819096-GREEN.mp4' copied.\n",
      "File '068296817498531-DEAF.mp4' copied.\n",
      "File '8060467891808021-STRAIGHT.mp4' copied.\n",
      "File '8267242257825924-EAT.mp4' copied.\n",
      "File '20301717388699103-THIRD.mp4' copied.\n",
      "File '17896699590362863-BLOND.mp4' copied.\n",
      "File '17899783963668914-TINY.mp4' copied.\n",
      "File '45279632751864196-SHORT DISTANCE.mp4' copied.\n",
      "File '1215533110994591-REALLY.mp4' copied.\n",
      "File '34451768752795986-TAKE PILL.mp4' copied.\n",
      "File '0007846701446196924-FAKE.mp4' copied.\n",
      "File '07764420978703401-HOT.mp4' copied.\n",
      "File '10140039043648663-RECENT.mp4' copied.\n",
      "File '31053045338678675-HONEY 1.mp4' copied.\n",
      "File '31069390622290594-RECENT.mp4' copied.\n",
      "File '38398644014722616-RECENT.mp4' copied.\n",
      "File '9104214105287733-TINY.mp4' copied.\n",
      "File '8080847093282741-OFF.mp4' copied.\n",
      "File '8082621375412273-SPIT OUT.mp4' copied.\n",
      "File '944678883177948-OFF.mp4' copied.\n",
      "File '086306935430017-SHORT DISTANCE.mp4' copied.\n",
      "File '9121749563331172-FOUR.mp4' copied.\n",
      "File '6748698769153474-HOW 2.mp4' copied.\n",
      "File '40194722932206095-WISH.mp4' copied.\n",
      "File '8255103409999225-GIVE.mp4' copied.\n",
      "File '9020730301433966-REALLY.mp4' copied.\n",
      "File '9022466165242344-FAKE.mp4' copied.\n",
      "File '1329928844357422-LUCKY.mp4' copied.\n",
      "File '8050232599036251-HONEY 1.mp4' copied.\n",
      "File '7631730254707754-TWINS.mp4' copied.\n",
      "File '6475568833259684-HONEY 1.mp4' copied.\n",
      "File '5414347966687401-GIVE.mp4' copied.\n",
      "File '5414581968670888-TWINS.mp4' copied.\n",
      "File '059950723125824945-LIGHTER.mp4' copied.\n",
      "File '09033463994461477-PATIENT 2.mp4' copied.\n",
      "File '7964322222241194-FOUR.mp4' copied.\n",
      "File '777804314039809-OK.mp4' copied.\n",
      "File '7778190480343923-LIGHTER.mp4' copied.\n",
      "File '28307245649361-FOND.mp4' copied.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '43905250683951924-STRANGE.mp4' copied.\n",
      "File '4576928379969838-EAST.mp4' copied.\n",
      "File '2490150449515618-ASK.mp4' copied.\n",
      "File '24921588003043138-BLOND.mp4' copied.\n",
      "File '19022708495593288-SEEM.mp4' copied.\n",
      "File '26319942987799516-BOLT.mp4' copied.\n",
      "File '10888540499689392-HANDSOME 4.mp4' copied.\n",
      "File '2274427695208907-LOOK AT.mp4' copied.\n",
      "File '2274519559281516-HOW 2.mp4' copied.\n",
      "File '8308912697239315-GIVE.mp4' copied.\n",
      "File '830943775589045-LOOK AT.mp4' copied.\n",
      "File '44964320032500793-WINK.mp4' copied.\n",
      "File '09953186633346167-OFF.mp4' copied.\n",
      "File '5268295753822807-STRANGE.mp4' copied.\n",
      "File '3821027760511011-SEEM.mp4' copied.\n",
      "File '20179596706480196-GAY.mp4' copied.\n",
      "File '4626224421615077-CANDY 2.mp4' copied.\n",
      "File '6491857817064066-PATIENT 2.mp4' copied.\n",
      "File '15587296563996822-GREEN.mp4' copied.\n",
      "File '9071310344664434-NORTH.mp4' copied.\n",
      "File '4550932054745036-PINK.mp4' copied.\n",
      "File '7660361464563388-GREEN.mp4' copied.\n",
      "File '2792895407119611-GREEN.mp4' copied.\n",
      "File '27946341175774014-RECENT.mp4' copied.\n",
      "File '2795008669013317-OK.mp4' copied.\n",
      "File '2690912082374577-FINE.mp4' copied.\n",
      "File '23481071177880364-FINE.mp4' copied.\n",
      "File '02514324335585849-HURDLE-TRIP.mp4' copied.\n",
      "File '5847293981432022-EAT.mp4' copied.\n",
      "File '03422390176190171-NORTH.mp4' copied.\n",
      "File '6406218170023705-THIRD.mp4' copied.\n",
      "File '4582628988743378-OK.mp4' copied.\n",
      "File '13683219097979515-EAST.mp4' copied.\n",
      "File '7246685614311985-WINK.mp4' copied.\n",
      "File '8436011453987953-EAST.mp4' copied.\n",
      "File '3142437678976202-HONEY 1.mp4' copied.\n",
      "File '7251085041046568-FOND.mp4' copied.\n",
      "File '8282095946241186-FAKE.mp4' copied.\n",
      "File '40550375821025386-UNDERSTAND.mp4' copied.\n",
      "File '011504158671063802-TAKE.mp4' copied.\n",
      "File '6309235179847048-DENTIST 2.mp4' copied.\n",
      "File '22275662087526515-LIGHTER.mp4' copied.\n",
      "File '31962282125568064-THINK.mp4' copied.\n",
      "File '5774324878258876-COME.mp4' copied.\n",
      "File '9998021350618418-SEEM.mp4' copied.\n",
      "File '3134692539495285-FAKE.mp4' copied.\n",
      "File '9619244676788752-WINK.mp4' copied.\n",
      "File '4615702025129498-THIRD.mp4' copied.\n",
      "File '004531118475225915-CLICK.mp4' copied.\n",
      "File '9015399008682803-THIRD.mp4' copied.\n",
      "File '1954835499063905-HANDSOME 4.mp4' copied.\n",
      "File '8852468091800154-FIND.mp4' copied.\n",
      "File '7724834869128405-FOND.mp4' copied.\n",
      "File '9523366394400623-STRANGE.mp4' copied.\n",
      "File '7156815666797753-SIX.mp4' copied.\n",
      "File '667162712047487-STRANGE.mp4' copied.\n",
      "File '7973536758685695-CANDY 2.mp4' copied.\n",
      "File '42013306604485967-SELECT.mp4' copied.\n",
      "File '42020105529707497-FOND.mp4' copied.\n",
      "File '5278240556504277-FOUR.mp4' copied.\n",
      "File '37942641665406507-SEEM.mp4' copied.\n",
      "File '5393407731733888-FINE.mp4' copied.\n",
      "File '36442823102165467-REALLY.mp4' copied.\n",
      "File '3217067801194846-AND.mp4' copied.\n",
      "File '5221737173718242-BLOND.mp4' copied.\n",
      "File '7839604835224319-FINE.mp4' copied.\n",
      "File '45715306705675407-STRANGE.mp4' copied.\n",
      "File '4229331784858039-ASK.mp4' copied.\n",
      "File '4230517548202062-TINY.mp4' copied.\n",
      "File '2816661891091392-REALLY.mp4' copied.\n",
      "File '28171734226378664-BLOND.mp4' copied.\n",
      "File '4900609523380457-HANDSOME 4.mp4' copied.\n",
      "File '07270539352192218-NINE.mp4' copied.\n",
      "File '8484732185649799-WINK.mp4' copied.\n",
      "File '9973277236979394-THIRD.mp4' copied.\n",
      "File '3863873468220538-TAKE.mp4' copied.\n",
      "File '2560906178937685-SEEM.mp4' copied.\n",
      "File '9084470998512257-SEEM.mp4' copied.\n",
      "File '14141815259340995-BETTER.mp4' copied.\n",
      "File '93340344109002-DEAF.mp4' copied.\n",
      "File '1072225635555093-TAKE.mp4' copied.\n",
      "File '16726028482044364-TINY.mp4' copied.\n",
      "File '09534140668975666-FOND.mp4' copied.\n",
      "File '5002484283202087-BEST.mp4' copied.\n",
      "File '7502499499997279-ELEVEN.mp4' copied.\n",
      "File '4097290850808508-HONEY 1.mp4' copied.\n",
      "File '8290422744503321-LOOK AT.mp4' copied.\n",
      "File '19502128713184197-NORTH.mp4' copied.\n",
      "File '19511217890707733-STRAIGHT.mp4' copied.\n",
      "File '17947981022974036-REALLY.mp4' copied.\n",
      "File '9872398820097483-BETTER.mp4' copied.\n",
      "File '11044006960520525-STRAIGHT.mp4' copied.\n",
      "File '639478265303518-LIGHTER.mp4' copied.\n",
      "File '639527032932734-HOW 2.mp4' copied.\n",
      "File '18332190418072036-STRAIGHT.mp4' copied.\n",
      "File '23621389224191303-STRAIGHT.mp4' copied.\n",
      "File '7588425489738773-CLICK.mp4' copied.\n",
      "File '28831386813183557-FOND.mp4' copied.\n",
      "File '2884856504523816-GAY.mp4' copied.\n",
      "File '34193514830123983-HOW 2.mp4' copied.\n",
      "File '913611175252012-SEEM.mp4' copied.\n",
      "File '05289594676196807-THIRD.mp4' copied.\n",
      "File '7113898894018067-STRANGE.mp4' copied.\n",
      "File '7209245410156855-OFF.mp4' copied.\n",
      "File '3177617138630928-CANDY 2.mp4' copied.\n",
      "File '2798092128206946-BOLT.mp4' copied.\n",
      "File '87014144499279-SEND.mp4' copied.\n",
      "File '052260060033033406-SHORT DISTANCE.mp4' copied.\n",
      "File '2294900578606751-COME.mp4' copied.\n",
      "File '2369063593492864-HONEY 1.mp4' copied.\n",
      "File '15158433513577485-BEST.mp4' copied.\n",
      "File '15473615846571032-HANDSOME 4.mp4' copied.\n",
      "File '15672281354752404-SEEM.mp4' copied.\n",
      "File '174515932829846-HOW 2.mp4' copied.\n",
      "File '5361878284892854-NINE.mp4' copied.\n",
      "File '7163426908687083-DENTIST 2.mp4' copied.\n",
      "File '008712488396102502-HANDSOME 4.mp4' copied.\n",
      "File '16278771062552466-OFF.mp4' copied.\n",
      "File '3388252366934028-LUCKY.mp4' copied.\n",
      "File '6077651039031762-EAST.mp4' copied.\n",
      "File '28527056597748013-FIND.mp4' copied.\n",
      "File '5577903292454827-RECENT.mp4' copied.\n",
      "File '989106010692617-SELECT.mp4' copied.\n",
      "File '9700186902669536-SHORT DISTANCE.mp4' copied.\n",
      "File '9300108445921016-NOT CARE.mp4' copied.\n",
      "File '1255266871868459-SPIT OUT.mp4' copied.\n",
      "File '5633579651003058-SELECT.mp4' copied.\n",
      "File '42062102594500606-ELEVEN.mp4' copied.\n",
      "File '9216989955416042-DOG.mp4' copied.\n",
      "File '2345167415094147-GOTCHA.mp4' copied.\n",
      "File '4605549971284748-HOW 2.mp4' copied.\n",
      "File '978089590876015-TAKE.mp4' copied.\n",
      "File '4326169993763198-FINE.mp4' copied.\n",
      "File '864714217171799-FIND.mp4' copied.\n",
      "File '5983459406831033-FIND.mp4' copied.\n",
      "File '5027124950379596-NOT CARE.mp4' copied.\n",
      "File '08287833815598877-CANDY 2.mp4' copied.\n",
      "File '45467021937296437-BEST.mp4' copied.\n",
      "File '6486132285116715-DENTIST 2.mp4' copied.\n",
      "File '030959011181703078-UNDERSTAND.mp4' copied.\n",
      "File '4124102705155146-BOLT.mp4' copied.\n",
      "File '050732774807632275-STRANGE.mp4' copied.\n",
      "File '5358275641298946-COME.mp4' copied.\n",
      "File '0630591575543733-WISH.mp4' copied.\n",
      "File '8582081133628761-TINY.mp4' copied.\n",
      "File '1900191486784637-THINK.mp4' copied.\n",
      "File '8962977271516672-FAKE.mp4' copied.\n",
      "File '8018890964087735-PATIENT 2.mp4' copied.\n",
      "File '8560455777036837-RECENT.mp4' copied.\n",
      "File '4179885145928237-TINY.mp4' copied.\n",
      "File '055633165115255956-TWINS.mp4' copied.\n",
      "File '3371284451449936-LOOK AT.mp4' copied.\n",
      "File '05047362294562241-WINK.mp4' copied.\n",
      "File '1520648884549911-ELEVEN.mp4' copied.\n",
      "File '22843928801980362-OFF.mp4' copied.\n",
      "File '19194765554180226-HANDSOME 4.mp4' copied.\n",
      "File '819028006626159-NINE.mp4' copied.\n",
      "File '6691110697569587-GREEN.mp4' copied.\n",
      "File '6691698807153292-SHORT DISTANCE.mp4' copied.\n",
      "File '04074209864432898-SEEM.mp4' copied.\n",
      "File '5366927772142136-PINK.mp4' copied.\n",
      "File '4320670014874919-FINE.mp4' copied.\n",
      "File '6977974861738809-BEST.mp4' copied.\n",
      "File '9304799283678831-WINK.mp4' copied.\n",
      "File '3674122534455828-STRAIGHT.mp4' copied.\n",
      "File '5882347360908131-EAT.mp4' copied.\n",
      "File '4733713256209504-TAKE.mp4' copied.\n",
      "File '01840327755913629-GOTCHA.mp4' copied.\n",
      "File '3113706936671736-AND.mp4' copied.\n",
      "File '1363018727818166-GAY.mp4' copied.\n",
      "File '5921657843863637-STRAIGHT.mp4' copied.\n",
      "File '5922098297054987-TINY.mp4' copied.\n",
      "File '2621288608804102-UNDERSTAND.mp4' copied.\n",
      "File '1453814940673277-TINY.mp4' copied.\n",
      "File '32863346544547345-LUCKY.mp4' copied.\n",
      "File '954911942661782-THINK.mp4' copied.\n",
      "File '954983118428528-LUCKY.mp4' copied.\n",
      "File '5298380938535534-FINE.mp4' copied.\n",
      "File '7820242288903554-GALLAUDET.mp4' copied.\n",
      "File '11966470519900585-NORTH.mp4' copied.\n",
      "File '11970003756754344-EAST.mp4' copied.\n",
      "File '938121928998171-TAKE.mp4' copied.\n",
      "File '0484770172692337-NINE.mp4' copied.\n",
      "File '4842321638867-SELECT.mp4' copied.\n",
      "File '7403167170909308-COME.mp4' copied.\n",
      "File '964587696332518-BLOND.mp4' copied.\n",
      "File '6990328291359291-SEND.mp4' copied.\n",
      "File '4657635412822545-HONEY 1.mp4' copied.\n",
      "File '8615822021106332-DOG.mp4' copied.\n",
      "File '42788073545628125-TAKE.mp4' copied.\n",
      "File '14450612350510017-OFF.mp4' copied.\n",
      "File '9702837684339749-NORTH.mp4' copied.\n",
      "File '585385587824101-RECENT.mp4' copied.\n",
      "File '699994024863398-PINK.mp4' copied.\n",
      "File '18111245519260621-SPIT OUT.mp4' copied.\n",
      "File '18119590042846156-HANDSOME 4.mp4' copied.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '8618961603650133-FIND.mp4' copied.\n",
      "File '06996746044765945-ELEVEN.mp4' copied.\n",
      "File '6745834273988278-UNDERSTAND.mp4' copied.\n",
      "File '25866202861571086-HOW 2.mp4' copied.\n",
      "File '13734587041918878-BOLT.mp4' copied.\n",
      "File '9864209236776549-DENTIST 2.mp4' copied.\n",
      "File '7025796673937177-OFF.mp4' copied.\n",
      "File '7072821167111014-ASK.mp4' copied.\n",
      "File '3200787903337785-HOT.mp4' copied.\n",
      "File '7769434916738955-EAT.mp4' copied.\n",
      "File '5547021297445855-NINE.mp4' copied.\n",
      "File '8598719617773274-TWINS.mp4' copied.\n",
      "File '5240410951548111-GALLAUDET.mp4' copied.\n",
      "File '5240887216596288-FIND.mp4' copied.\n",
      "File '6876614460019714-LUCKY.mp4' copied.\n",
      "File '7162964278884962-CLICK.mp4' copied.\n",
      "File '2825233660609592-TWINS.mp4' copied.\n",
      "File '5781025522650556-PATIENT 2.mp4' copied.\n",
      "File '38426637881924686-FOND.mp4' copied.\n",
      "File '8071758688201891-UNDERSTAND.mp4' copied.\n",
      "File '6370702900476413-ASK.mp4' copied.\n",
      "File '4163757443011573-SIX.mp4' copied.\n",
      "File '6516460654825258-ELEVEN.mp4' copied.\n",
      "File '83004477178377-BLOND.mp4' copied.\n",
      "File '5086571279720689-GREEN.mp4' copied.\n",
      "File '49736162388061267-HONEY 1.mp4' copied.\n",
      "File '4983578103314874-SHORT DISTANCE.mp4' copied.\n",
      "File '0980248040975249-LUCKY.mp4' copied.\n",
      "File '7815332110154865-THINK.mp4' copied.\n",
      "File '48057975889534643-REALLY.mp4' copied.\n",
      "File '24393293337340283-DEAF.mp4' copied.\n",
      "File '3934510873242827-WINK.mp4' copied.\n",
      "File '8936069295395894-BETTER.mp4' copied.\n",
      "File '3222160502487865-NINE.mp4' copied.\n",
      "File '3223491372772138-GREEN.mp4' copied.\n",
      "File '24437475145413878-TINY.mp4' copied.\n",
      "File '635034042192421-DOG.mp4' copied.\n",
      "File '656039289068084-ASK.mp4' copied.\n",
      "File '5697649035143537-NINE.mp4' copied.\n",
      "File '2450624847020626-FIND.mp4' copied.\n",
      "File '7664642326742872-HURDLE-TRIP.mp4' copied.\n",
      "File '6547611227075889-LIGHTER.mp4' copied.\n",
      "File '45962000750661813-BOLT.mp4' copied.\n",
      "File '8217461136679527-BOLT.mp4' copied.\n",
      "File '15495056482554492-SIX.mp4' copied.\n",
      "File '7416561706981699-HOT.mp4' copied.\n",
      "File '5245211280359048-COME.mp4' copied.\n",
      "File '09909674431836946-HURDLE-TRIP.mp4' copied.\n",
      "File '4538390780755446-STRANGE.mp4' copied.\n",
      "File '24605674688653978-TWINS.mp4' copied.\n",
      "File '7532911171254717-TAKE PILL.mp4' copied.\n",
      "File '3523194257215756-LIGHTER.mp4' copied.\n",
      "File '2270119782013318-SELECT.mp4' copied.\n",
      "File '32693107913849806-SELECT.mp4' copied.\n",
      "File '5947152517790328-LUCKY.mp4' copied.\n",
      "File '9317452998495337-GALLAUDET.mp4' copied.\n",
      "File '9319298873644923-DEAF.mp4' copied.\n",
      "File '7689090634484697-HURDLE-TRIP.mp4' copied.\n",
      "File '9899925230812674-WISH.mp4' copied.\n",
      "File '1823075331771542-GIVE.mp4' copied.\n",
      "File '4107370316562351-NINE.mp4' copied.\n",
      "File '9179668481329466-OK.mp4' copied.\n",
      "File '5838385837602562-BETTER.mp4' copied.\n",
      "File '009129075128726294-DENTIST 2.mp4' copied.\n",
      "File '009149560375806498-HANDSOME 4.mp4' copied.\n",
      "File '8927537165486459-LOOK AT.mp4' copied.\n",
      "File '7016774114845865-ASK.mp4' copied.\n",
      "File '5614362564622106-SIX.mp4' copied.\n",
      "File '8372972407104144-BOLT.mp4' copied.\n",
      "File '37827505435337416-GAY.mp4' copied.\n",
      "File '008284236370929232-LOOK AT.mp4' copied.\n",
      "File '540755360226808-HOW 2.mp4' copied.\n",
      "File '6358240776836663-SIX.mp4' copied.\n",
      "File '5237841416193414-FOUR.mp4' copied.\n",
      "File '2474722734260606-FINE.mp4' copied.\n",
      "File '7753126798089989-PATIENT 2.mp4' copied.\n",
      "File '8520227641284277-LOOK AT.mp4' copied.\n",
      "File '4600763876177605-NINE.mp4' copied.\n",
      "File '038179403041048054-STRAIGHT.mp4' copied.\n",
      "File '5315843442514836-HANDSOME 4.mp4' copied.\n",
      "File '8295584177813573-BEST.mp4' copied.\n",
      "File '44771872253749656-SELECT.mp4' copied.\n",
      "File '9337433072795491-CANDY 2.mp4' copied.\n",
      "File '6455677348837485-ASK.mp4' copied.\n",
      "File '0846124215567774-STRANGE.mp4' copied.\n",
      "File '6704855310182656-GOTCHA.mp4' copied.\n",
      "File '9795058527483735-EAST.mp4' copied.\n",
      "File '7144725200382545-TAKE PILL.mp4' copied.\n",
      "File '7677851426600801-PATIENT 2.mp4' copied.\n",
      "File '49610949301626883-BETTER.mp4' copied.\n",
      "File '6410555216794429-EAST.mp4' copied.\n",
      "File '5038398188714364-AND.mp4' copied.\n",
      "File '4118252136245186-FAKE.mp4' copied.\n",
      "File '4095802504728605-DEAF.mp4' copied.\n",
      "File '32733747696483695-HONEY 1.mp4' copied.\n",
      "File '32736984709881467-WISH.mp4' copied.\n",
      "File '8111138744770106-LUCKY.mp4' copied.\n",
      "File '769931171329109-PINK.mp4' copied.\n",
      "File '43967700340807303-SEEM.mp4' copied.\n",
      "File '2556710153069994-GREEN.mp4' copied.\n",
      "File '2930598474553847-BOLT.mp4' copied.\n",
      "File '09463353669349228-FAKE.mp4' copied.\n",
      "File '9695299725983888-GREEN.mp4' copied.\n",
      "File '5911775875982508-THIRD.mp4' copied.\n",
      "File '5912119864011021-REALLY.mp4' copied.\n",
      "File '3261478241631237-HONEY 1.mp4' copied.\n",
      "File '8144507474855118-GAY.mp4' copied.\n",
      "File '08001027937835992-GALLAUDET.mp4' copied.\n",
      "File '3226049524969481-HOT.mp4' copied.\n",
      "File '2776366881359864-SIX.mp4' copied.\n",
      "File '8178850636707293-THINK.mp4' copied.\n",
      "File '15517992208133347-SELECT.mp4' copied.\n",
      "File '21077352033279784-GOTCHA.mp4' copied.\n",
      "File '47840846334507114-SEND.mp4' copied.\n",
      "File '4898001120466351-PATIENT 2.mp4' copied.\n",
      "File '02279197464201932-TAKE PILL.mp4' copied.\n",
      "File '5940829370614598-OK.mp4' copied.\n",
      "File '5523823677466979-DOG.mp4' copied.\n",
      "File '291615547979323-STRAIGHT.mp4' copied.\n",
      "File '8689103843315484-NORTH.mp4' copied.\n",
      "File '8195877851123277-PINK.mp4' copied.\n",
      "File '23047642101573373-HOT.mp4' copied.\n",
      "File '11707369231650211-HOT.mp4' copied.\n",
      "File '9504749022893753-BETTER.mp4' copied.\n",
      "File '8229344087589305-PATIENT 2.mp4' copied.\n",
      "File '5965324938375867-SEND.mp4' copied.\n",
      "File '5965960580596394-THINK.mp4' copied.\n",
      "File '04247014488309908-NORTH.mp4' copied.\n",
      "File '3748926579472207-BOLT.mp4' copied.\n",
      "File '9096827697693708-DENTIST 2.mp4' copied.\n",
      "File '9984673314288812-ASK.mp4' copied.\n",
      "File '5080148570731864-WISH.mp4' copied.\n",
      "File '06471690408627717-LOOK AT.mp4' copied.\n",
      "File '9615504393064633-PATIENT 2.mp4' copied.\n",
      "File '8450749478025767-OK.mp4' copied.\n",
      "File '658484494196101-HURDLE-TRIP.mp4' copied.\n",
      "File '27832701315476815-UNDERSTAND.mp4' copied.\n",
      "File '12427744708858346-ASK.mp4' copied.\n",
      "Copying complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Source Folder\n",
    "source_folder = '/media/kristian/HDD/ASL_Citizen/ASL_Citizen/videos/'\n",
    "\n",
    "# Destination FOlder\n",
    "destination_folder = '/home/kristian/ASL_Citizen/videos/'\n",
    "\n",
    "# Loop through each file in the source folder\n",
    "for filename in os.listdir(source_folder):\n",
    "    if filename in traindf['Video file'][:].values:\n",
    "        source_path = os.path.join(source_folder, filename)\n",
    "        destination_path = os.path.join(destination_folder, filename)\n",
    "        shutil.copy(source_path, destination_path)\n",
    "        print(f\"File '{filename}' copied.\")\n",
    "\n",
    "print(\"Copying complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f5533751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:02:17.357316Z",
     "start_time": "2023-08-13T22:02:17.349250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Participant ID    920\n",
       "Video file        920\n",
       "Gloss             920\n",
       "ASL-LEX Code      920\n",
       "Path              920\n",
       "Frequency         920\n",
       "Frames            920\n",
       "FPS               920\n",
       "Length            920\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a9a5517",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:02:22.157570Z",
     "start_time": "2023-08-13T22:02:22.154799Z"
    }
   },
   "outputs": [],
   "source": [
    "def frames_from_file(filepath):\n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "    frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    length = round(frames / fps)\n",
    "    return frames, fps, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2576a32d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:02:25.599869Z",
     "start_time": "2023-08-13T22:02:25.595274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 30, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_from_file(traindf.Path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "87551a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:04:26.928719Z",
     "start_time": "2023-08-13T22:04:26.924915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf['Frames'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0bfc1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-13T22:09:17.279Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▏                                     | 92/920 [04:31<45:54,  3.33s/it]"
     ]
    }
   ],
   "source": [
    "keypoints_series = traindf['Path'].progress_apply(extract_keypoints_from_file)\n",
    "np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe-60_hands/train_keypoints.npy\", keypoints_series)\n",
    "keypoints_series = traindf['Path'].progress_apply(extract_keypoints_from_file_flip)\n",
    "np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe-60_hands/train_keypoints_flip.npy\", keypoints_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "944e6f85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T22:05:24.020824Z",
     "start_time": "2023-08-13T22:05:14.719264Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                          | 4/920 [00:08<32:19,  2.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas()\n\u001b[0;32m----> 2\u001b[0m keypoints_series \u001b[38;5;241m=\u001b[39m \u001b[43mtraindf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_keypoints_from_file_flip\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tqdm/std.py:805\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tqdm/std.py:800\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    799\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[54], line 26\u001b[0m, in \u001b[0;36mextract_keypoints_from_file_flip\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     24\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mflip(frame, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Use the Holistic model to detect landmarks for the face, pose, and hands\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mholistic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Extract the keypoints from the results object and append them to the keypoints list\u001b[39;00m\n\u001b[1;32m     29\u001b[0m keypoints\u001b[38;5;241m.\u001b[39mappend(extract_keypoints(results))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/mediapipe/python/solutions/holistic.py:160\u001b[0m, in \u001b[0;36mHolistic.process\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks, left and right hand landmarks, and face landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/mediapipe/python/solution_base.py:365\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[1;32m    361\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[1;32m    362\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[1;32m    363\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[0;32m--> 365\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m solution_outputs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mnamedtuple(\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolutionOutputs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "keypoints_series = traindf['Path'].progress_apply(extract_keypoints_from_file_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e614bc50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:33:55.252932Z",
     "start_time": "2023-08-09T09:33:55.249450Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920,)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e13534ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:33:20.826662Z",
     "start_time": "2023-08-09T09:33:15.553193Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe-60/train_keypoints.npy\", keypoints_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "9f2a7ac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:33:51.473797Z",
     "start_time": "2023-08-09T09:33:51.301691Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "keypoints_series=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe-60/train_keypoints.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e1248da2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:33:58.487946Z",
     "start_time": "2023-08-09T09:33:58.481474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(keypoints.shape[0] for keypoints in keypoints_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e0706526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:33:59.490663Z",
     "start_time": "2023-08-09T09:33:59.487181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(keypoints.shape[0] for keypoints in keypoints_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5777338f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:34:25.863091Z",
     "start_time": "2023-08-09T09:34:25.506075Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len = traindf['Frames'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c59e0367",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:34:26.493703Z",
     "start_time": "2023-08-09T09:34:26.490133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "bd079722",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:34:29.171076Z",
     "start_time": "2023-08-09T09:34:29.168759Z"
    }
   },
   "outputs": [],
   "source": [
    "#keypoints_np = np.zeros((len(keypoints_series), max_len, 1662))\n",
    "#for i, keypoints in enumerate(keypoints_series):\n",
    "#    keypoints_np[i, :keypoints.shape[0], :] = keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0fb0f5e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:34:30.508963Z",
     "start_time": "2023-08-09T09:34:30.349375Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a padded array to store keypoints\n",
    "keypoints_np = np.zeros((len(keypoints_series), max_len, 1662))\n",
    "\n",
    "# Iterate through keypoints_series and fill keypoints_np with pre-padding\n",
    "for i, keypoints in enumerate(keypoints_series):\n",
    "    keypoints_len = min(keypoints.shape[0], max_len)\n",
    "    padding_len = max_len - keypoints_len\n",
    "    keypoints_np[i, padding_len:, :] = keypoints[:keypoints_len, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "26eb2969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:34:31.449604Z",
     "start_time": "2023-08-09T09:34:31.446335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 60, 1662)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "150f59b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:34:35.174483Z",
     "start_time": "2023-08-09T09:34:35.170339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.49567455  0.30508247 -1.63521326 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.495891    0.30340993 -1.66837811 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.49603844  0.30246556 -1.66233063 ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(keypoints_np[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "237a962e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:34:38.403233Z",
     "start_time": "2023-08-09T09:34:38.400072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 60, 1662)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "34332d29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:35:54.459896Z",
     "start_time": "2023-08-09T09:35:54.453285Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.48855895,  0.40100691, -0.92158365, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.48833609,  0.40101019, -0.91984463, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.48820359,  0.40102521, -0.91442269, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.48129115,  0.5108977 , -1.09578931, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.48112375,  0.51100415, -1.13838327, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.4811047 ,  0.51157063, -1.13534355, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.50599396,  0.26311007, -1.17430234, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.5059309 ,  0.26278868, -1.17611527, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.50600898,  0.26249462, -1.17522061, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.47998396,  0.40535492, -0.8028698 , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.47984272,  0.40572888, -0.80936861, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.47975874,  0.40614256, -0.81235874, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.53337514,  0.2846252 , -1.22431445, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.53183389,  0.28479242, -1.22484636, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.52973664,  0.28527215, -1.21189046, ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.51629192,  0.4404591 , -1.26061749, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.51559091,  0.44330582, -1.29858398, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.51495647,  0.44526622, -1.38469648, ...,  0.        ,\n",
       "          0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "72bad504",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:36:21.103782Z",
     "start_time": "2023-08-09T09:36:21.100540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 60, 1662)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "ce62069f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:36:22.009441Z",
     "start_time": "2023-08-09T09:36:22.005938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 60, 1662)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa54d2",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef55d8b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:57:52.837581Z",
     "start_time": "2023-08-13T21:57:52.596939Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Keypoints Shape: (920,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_keypoints=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe-60/train_keypoints.npy\",allow_pickle=True)\n",
    "#val_keypoints =np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe/val_keypoints.npy\",allow_pickle=True)\n",
    "#test_keypoints=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe/test_keypoints.npy\",allow_pickle=True)\n",
    "\n",
    "print('Training Keypoints Shape:', train_keypoints.shape)\n",
    "#print('Validation Kepoints Shape:', val_keypoints.shape)\n",
    "#print('Test Keypoints Shape:',test_keypoints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f26ef7f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:57:53.536545Z",
     "start_time": "2023-08-13T21:57:52.839593Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "max_len=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e3b03a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:57:54.295900Z",
     "start_time": "2023-08-13T21:57:53.538003Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Keypoints Shape: (920, 60, 1662)\n"
     ]
    }
   ],
   "source": [
    "# Create a padded array to store keypoints\n",
    "keypoints_np = np.zeros((len(train_keypoints), max_len, 1662))\n",
    "\n",
    "# Iterate through keypoints_series and fill keypoints_np with pre-padding\n",
    "for i, keypoints in enumerate(train_keypoints):\n",
    "    keypoints_len = min(keypoints.shape[0], max_len)\n",
    "    padding_len = max_len - keypoints_len\n",
    "    keypoints_np[i, padding_len:, :] = keypoints[:keypoints_len, :]\n",
    "    \n",
    "train_keypoints = keypoints_np\n",
    "print('Training Keypoints Shape:', train_keypoints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223cc5ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:57:57.557593Z",
     "start_time": "2023-08-13T21:57:54.298182Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 22:57:56.212257: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-13 22:57:56.843911: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ddc114ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:45:43.441587Z",
     "start_time": "2023-08-09T09:45:43.428630Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'traindf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraindf\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'traindf' is not defined"
     ]
    }
   ],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "71e58811",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:37:29.915898Z",
     "start_time": "2023-08-09T09:37:29.912622Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0129a2ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:37:44.223326Z",
     "start_time": "2023-08-09T09:37:43.526496Z"
    }
   },
   "outputs": [],
   "source": [
    "traindf['Cat_label'] = encoder.fit_transform(traindf[['Gloss']]).astype(int)\n",
    "traindf = traindf.sort_values(by='Gloss',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "21e97f05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:37:46.287270Z",
     "start_time": "2023-08-09T09:37:46.212651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Cat_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P29</td>\n",
       "      <td>6211759212759429-AND.mp4</td>\n",
       "      <td>AND</td>\n",
       "      <td>B_03_072</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/62117...</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P21</td>\n",
       "      <td>5038398188714364-AND.mp4</td>\n",
       "      <td>AND</td>\n",
       "      <td>B_03_072</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/50383...</td>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P16</td>\n",
       "      <td>3741021155965083-AND.mp4</td>\n",
       "      <td>AND</td>\n",
       "      <td>B_03_072</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/37410...</td>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P50</td>\n",
       "      <td>6610091794646322-AND.mp4</td>\n",
       "      <td>AND</td>\n",
       "      <td>B_03_072</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/66100...</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P49</td>\n",
       "      <td>7841237666552301-AND.mp4</td>\n",
       "      <td>AND</td>\n",
       "      <td>B_03_072</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/78412...</td>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant ID                Video file Gloss ASL-LEX Code  \\\n",
       "0             P29  6211759212759429-AND.mp4   AND     B_03_072   \n",
       "14            P21  5038398188714364-AND.mp4   AND     B_03_072   \n",
       "13            P16  3741021155965083-AND.mp4   AND     B_03_072   \n",
       "12            P50  6610091794646322-AND.mp4   AND     B_03_072   \n",
       "11            P49  7841237666552301-AND.mp4   AND     B_03_072   \n",
       "\n",
       "                                                 Path  Frequency  Frames  FPS  \\\n",
       "0   file:///home/kristian/ASL_Citizen/videos/62117...         15      43   30   \n",
       "14  file:///home/kristian/ASL_Citizen/videos/50383...         15      44   29   \n",
       "13  file:///home/kristian/ASL_Citizen/videos/37410...         15      56   29   \n",
       "12  file:///home/kristian/ASL_Citizen/videos/66100...         15      60   30   \n",
       "11  file:///home/kristian/ASL_Citizen/videos/78412...         15      41   30   \n",
       "\n",
       "    Length  Cat_label  \n",
       "0        1          0  \n",
       "14       2          0  \n",
       "13       2          0  \n",
       "12       2          0  \n",
       "11       1          0  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "5c7a48a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:37:48.829032Z",
     "start_time": "2023-08-09T09:37:48.821200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Cat_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>P27</td>\n",
       "      <td>7262581620088506-WISH.mp4</td>\n",
       "      <td>WISH</td>\n",
       "      <td>C_01_053</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/72625...</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>P7</td>\n",
       "      <td>9899925230812674-WISH.mp4</td>\n",
       "      <td>WISH</td>\n",
       "      <td>C_01_053</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/98999...</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>P11</td>\n",
       "      <td>5986296474103647-WISH.mp4</td>\n",
       "      <td>WISH</td>\n",
       "      <td>C_01_053</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/59862...</td>\n",
       "      <td>15</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>P35</td>\n",
       "      <td>3446645273513582-WISH.mp4</td>\n",
       "      <td>WISH</td>\n",
       "      <td>C_01_053</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/34466...</td>\n",
       "      <td>15</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>P17</td>\n",
       "      <td>3815358216512903-WISH.mp4</td>\n",
       "      <td>WISH</td>\n",
       "      <td>C_01_053</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/38153...</td>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Participant ID                 Video file Gloss ASL-LEX Code  \\\n",
       "906            P27  7262581620088506-WISH.mp4  WISH     C_01_053   \n",
       "905             P7  9899925230812674-WISH.mp4  WISH     C_01_053   \n",
       "918            P11  5986296474103647-WISH.mp4  WISH     C_01_053   \n",
       "911            P35  3446645273513582-WISH.mp4  WISH     C_01_053   \n",
       "919            P17  3815358216512903-WISH.mp4  WISH     C_01_053   \n",
       "\n",
       "                                                  Path  Frequency  Frames  \\\n",
       "906  file:///home/kristian/ASL_Citizen/videos/72625...         15      50   \n",
       "905  file:///home/kristian/ASL_Citizen/videos/98999...         15      60   \n",
       "918  file:///home/kristian/ASL_Citizen/videos/59862...         15      53   \n",
       "911  file:///home/kristian/ASL_Citizen/videos/34466...         15      51   \n",
       "919  file:///home/kristian/ASL_Citizen/videos/38153...         15      56   \n",
       "\n",
       "     FPS  Length  Cat_label  \n",
       "906   30       2         58  \n",
       "905   30       2         58  \n",
       "918   29       2         58  \n",
       "911   29       2         58  \n",
       "919   29       2         58  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "d9d509a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:38:06.200048Z",
     "start_time": "2023-08-09T09:38:06.142140Z"
    }
   },
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(traindf['Gloss'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b2139a4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:38:18.422070Z",
     "start_time": "2023-08-09T09:38:18.416877Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AND': 0,\n",
       " 'ASK': 1,\n",
       " 'BEST': 2,\n",
       " 'BETTER': 3,\n",
       " 'BLOND': 4,\n",
       " 'BOLT': 5,\n",
       " 'CANDY': 6,\n",
       " 'CLICK': 7,\n",
       " 'COME': 8,\n",
       " 'DEAF': 9,\n",
       " 'DENTIST': 10,\n",
       " 'DOG': 11,\n",
       " 'EAST': 12,\n",
       " 'EAT': 13,\n",
       " 'ELEVEN': 14,\n",
       " 'FAKE': 15,\n",
       " 'FIND': 16,\n",
       " 'FINE': 17,\n",
       " 'FOND': 18,\n",
       " 'FOUR': 19,\n",
       " 'GALLAUDET': 20,\n",
       " 'GAY': 21,\n",
       " 'GIVE': 22,\n",
       " 'GOTCHA': 23,\n",
       " 'GREEN': 24,\n",
       " 'HANDSOME': 25,\n",
       " 'HONEY': 26,\n",
       " 'HOT': 27,\n",
       " 'HOW': 28,\n",
       " 'HURDLE/TRIP': 29,\n",
       " 'LIGHTER': 30,\n",
       " 'LOOKAT': 31,\n",
       " 'LUCKY': 32,\n",
       " 'NINE': 33,\n",
       " 'NORTH': 34,\n",
       " 'NOTCARE': 35,\n",
       " 'OFF': 36,\n",
       " 'OK': 37,\n",
       " 'PATIENT': 38,\n",
       " 'PINK': 39,\n",
       " 'REALLY': 40,\n",
       " 'RECENT': 41,\n",
       " 'SEEM': 42,\n",
       " 'SELECT': 43,\n",
       " 'SEND': 44,\n",
       " 'SHORTDISTANCE': 45,\n",
       " 'SIX': 46,\n",
       " 'SPITOUT': 47,\n",
       " 'STRAIGHT': 48,\n",
       " 'STRANGE': 49,\n",
       " 'TAKE': 50,\n",
       " 'TAKEPILL': 51,\n",
       " 'THINK': 52,\n",
       " 'THIRD': 53,\n",
       " 'TINY': 54,\n",
       " 'TWINS': 55,\n",
       " 'UNDERSTAND': 56,\n",
       " 'WINK': 57,\n",
       " 'WISH': 58}"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "962046fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:38:23.907392Z",
     "start_time": "2023-08-09T09:38:23.843358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Video file</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>ASL-LEX Code</th>\n",
       "      <th>Path</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frames</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Length</th>\n",
       "      <th>Cat_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>P36</td>\n",
       "      <td>48027094398019576-NORTH.mp4</td>\n",
       "      <td>NORTH</td>\n",
       "      <td>C_01_080</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/48027...</td>\n",
       "      <td>15</td>\n",
       "      <td>59</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>P22</td>\n",
       "      <td>5617280048659572-TAKE.mp4</td>\n",
       "      <td>TAKE</td>\n",
       "      <td>G_01_093</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/56172...</td>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>P6</td>\n",
       "      <td>9915177398162693-WISH.mp4</td>\n",
       "      <td>WISH</td>\n",
       "      <td>C_01_053</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/99151...</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>P21</td>\n",
       "      <td>010356460960846414-GALLAUDET.mp4</td>\n",
       "      <td>GALLAUDET</td>\n",
       "      <td>B_02_010</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/01035...</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>P42</td>\n",
       "      <td>37942641665406507-SEEM.mp4</td>\n",
       "      <td>SEEM</td>\n",
       "      <td>F_01_043</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/37942...</td>\n",
       "      <td>16</td>\n",
       "      <td>55</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P6</td>\n",
       "      <td>3981207314157731-AND.mp4</td>\n",
       "      <td>AND</td>\n",
       "      <td>B_03_072</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/39812...</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>P14</td>\n",
       "      <td>8676867126730325-OFF.mp4</td>\n",
       "      <td>OFF</td>\n",
       "      <td>E_01_027</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/86768...</td>\n",
       "      <td>17</td>\n",
       "      <td>52</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>P17</td>\n",
       "      <td>5281867130394469-NORTH.mp4</td>\n",
       "      <td>NORTH</td>\n",
       "      <td>C_01_080</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/52818...</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>P50</td>\n",
       "      <td>5002484283202087-BEST.mp4</td>\n",
       "      <td>BEST</td>\n",
       "      <td>F_02_062</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/50024...</td>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>P11</td>\n",
       "      <td>2987380177072183-CANDY 2.mp4</td>\n",
       "      <td>CANDY</td>\n",
       "      <td>D_02_079</td>\n",
       "      <td>file:///home/kristian/ASL_Citizen/videos/29873...</td>\n",
       "      <td>16</td>\n",
       "      <td>46</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Participant ID                        Video file      Gloss ASL-LEX Code  \\\n",
       "534            P36       48027094398019576-NORTH.mp4      NORTH     C_01_080   \n",
       "783            P22         5617280048659572-TAKE.mp4       TAKE     G_01_093   \n",
       "916             P6         9915177398162693-WISH.mp4       WISH     C_01_053   \n",
       "328            P21  010356460960846414-GALLAUDET.mp4  GALLAUDET     B_02_010   \n",
       "672            P42        37942641665406507-SEEM.mp4       SEEM     F_01_043   \n",
       "10              P6          3981207314157731-AND.mp4        AND     B_03_072   \n",
       "568            P14          8676867126730325-OFF.mp4        OFF     E_01_027   \n",
       "544            P17        5281867130394469-NORTH.mp4      NORTH     C_01_080   \n",
       "40             P50         5002484283202087-BEST.mp4       BEST     F_02_062   \n",
       "104            P11      2987380177072183-CANDY 2.mp4      CANDY     D_02_079   \n",
       "\n",
       "                                                  Path  Frequency  Frames  \\\n",
       "534  file:///home/kristian/ASL_Citizen/videos/48027...         15      59   \n",
       "783  file:///home/kristian/ASL_Citizen/videos/56172...         16      45   \n",
       "916  file:///home/kristian/ASL_Citizen/videos/99151...         15      32   \n",
       "328  file:///home/kristian/ASL_Citizen/videos/01035...         15      46   \n",
       "672  file:///home/kristian/ASL_Citizen/videos/37942...         16      55   \n",
       "10   file:///home/kristian/ASL_Citizen/videos/39812...         15      32   \n",
       "568  file:///home/kristian/ASL_Citizen/videos/86768...         17      52   \n",
       "544  file:///home/kristian/ASL_Citizen/videos/52818...         15      46   \n",
       "40   file:///home/kristian/ASL_Citizen/videos/50024...         16      60   \n",
       "104  file:///home/kristian/ASL_Citizen/videos/29873...         16      46   \n",
       "\n",
       "     FPS  Length  Cat_label  \n",
       "534   30       2         34  \n",
       "783   30       2         50  \n",
       "916   30       1         58  \n",
       "328   30       2         20  \n",
       "672   30       2         42  \n",
       "10    29       1          0  \n",
       "568   29       2         36  \n",
       "544   30       2         34  \n",
       "40    30       2          2  \n",
       "104   29       2          6  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "6bf774ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:38:31.622658Z",
     "start_time": "2023-08-09T09:38:31.616590Z"
    }
   },
   "outputs": [],
   "source": [
    "Ytrain = encoder.fit_transform(traindf[['Gloss']])\n",
    "#Ytest = encoder.fit_transform(testdf[['Gloss']])\n",
    "#Yval = encoder.fit_transform(valdf[['Gloss']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "7cd74294",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:38:46.785121Z",
     "start_time": "2023-08-09T09:38:46.782483Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe-60/train_labels_array_1D.npy\", Ytrain)\n",
    "#np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe/test_labels_array_1D.npy\", Ytest)\n",
    "#np.save(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe/val_labels_array_1D.npy\", Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26877e3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:57:57.562316Z",
     "start_time": "2023-08-13T21:57:57.559222Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "Ytrain=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe-60/train_labels_array_1D.npy\")\n",
    "#Ytest=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe/test_labels_array_1D.npy\")\n",
    "#Yval=np.load(\"/home/kristian/Capstone/keypoints/ASL_Citizen/Mediapipe/val_labels_array_1D.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e63d67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:57:59.197606Z",
     "start_time": "2023-08-13T21:57:57.564033Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "Xtrain = train_keypoints\n",
    "#Xtest = test_keypoints\n",
    "#Xval = val_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d52a77ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:01.193882Z",
     "start_time": "2023-08-13T21:57:59.199193Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (920, 1)\n",
      "Shape after one-hot encoding:  (920, 59)\n"
     ]
    }
   ],
   "source": [
    "n_classes = 59\n",
    "print(\"Shape before one-hot encoding: \", Ytrain.shape)\n",
    "Ytrain = to_categorical(Ytrain, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Ytrain.shape)\n",
    "#print(\"Shape before one-hot encoding: \", Ytest.shape)\n",
    "#Ytest = to_categorical(Ytest, n_classes)\n",
    "#print(\"Shape after one-hot encoding: \", Ytest.shape)\n",
    "#print(\"Shape before one-hot encoding: \", Yval.shape)\n",
    "#Yval = to_categorical(Yval, n_classes)\n",
    "#print(\"Shape after one-hot encoding: \", Yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb749626",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:02.700087Z",
     "start_time": "2023-08-13T21:58:01.195504Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3258ad3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:03.576099Z",
     "start_time": "2023-08-13T21:58:02.701878Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 59)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "0a2e3c0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:40:08.536558Z",
     "start_time": "2023-08-09T09:40:08.520935Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[270], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, X_test, Y_train, Y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mX\u001b[49m, \n\u001b[1;32m      2\u001b[0m                                                     Y,\n\u001b[1;32m      3\u001b[0m                                                     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                                     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(Xtrain, \n",
    "                                                    Ytrain,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4298ab7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:04.540399Z",
     "start_time": "2023-08-13T21:58:03.579033Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "#Xtrain = np.concatenate((Xtrain, Xtest), axis=0)\n",
    "#print(Xtrain.shape)\n",
    "#Ytrain = np.concatenate((Ytrain, Ytest), axis=0)\n",
    "#print(Ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a8fde5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:06.501740Z",
     "start_time": "2023-08-13T21:58:04.541848Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "num_samples, num_frames, num_keypoints = Xtrain.shape\n",
    "Xtrain = Xtrain.reshape(num_samples, -1)\n",
    "\n",
    "# Create a MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "Xtrain = scaler.fit_transform(Xtrain)\n",
    "\n",
    "# Reshape the scaled data back to the original shape\n",
    "Xtrain = Xtrain.reshape(num_samples, num_frames, num_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8042926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:06.947848Z",
     "start_time": "2023-08-13T21:58:06.503121Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 60, 1662)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49da28e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T15:51:46.223692Z",
     "start_time": "2023-08-03T15:51:46.190010Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_data_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, X_test, Y_train, Y_test, mask_train, mask_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43minput_data_scaled\u001b[49m,\n\u001b[1;32m      2\u001b[0m                                                     Y, mask,\n\u001b[1;32m      3\u001b[0m                                                     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                                     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_data_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(input_data_scaled,\n",
    "                                                    Y,\n",
    "                                                    test_size=0.,\n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c00d3fb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:08.036679Z",
     "start_time": "2023-08-13T21:58:06.949138Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920, 60, 1662)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "#Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89609a73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:09.125494Z",
     "start_time": "2023-08-13T21:58:08.039479Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920, 59)\n"
     ]
    }
   ],
   "source": [
    "print(Ytrain.shape)\n",
    "#Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afebe752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:11.189278Z",
     "start_time": "2023-08-13T21:58:09.127131Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.35687297, 0.60991865, 0.63696317, ..., 0.02411595,\n",
       "         0.        , 1.        ],\n",
       "        [0.35465615, 0.60565768, 0.66566193, ..., 0.04406686,\n",
       "         0.        , 1.        ],\n",
       "        [0.35232813, 0.60329661, 0.67239554, ..., 0.0836537 ,\n",
       "         0.        , 1.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.33687262, 0.90758641, 0.52202365, ..., 0.02411595,\n",
       "         0.        , 1.        ],\n",
       "        [0.33475433, 0.90553464, 0.52364425, ..., 0.04406686,\n",
       "         0.        , 1.        ],\n",
       "        [0.33267689, 0.90518237, 0.5385358 , ..., 0.0836537 ,\n",
       "         0.        , 1.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.4048526 , 0.23638922, 0.47022138, ..., 0.02411595,\n",
       "         0.        , 1.        ],\n",
       "        [0.40320748, 0.22882388, 0.49912405, ..., 0.04406686,\n",
       "         0.        , 1.        ],\n",
       "        [0.40161732, 0.22498687, 0.51437361, ..., 0.0836537 ,\n",
       "         0.        , 1.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.33327535, 0.62169636, 0.71528963, ..., 0.02411595,\n",
       "         0.        , 1.        ],\n",
       "        [0.33121946, 0.61852226, 0.73745494, ..., 0.04406686,\n",
       "         0.        , 1.        ],\n",
       "        [0.32895097, 0.61727147, 0.73423785, ..., 0.0836537 ,\n",
       "         0.        , 1.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.4802032 , 0.29466854, 0.43722379, ..., 0.02411595,\n",
       "         0.        , 1.        ],\n",
       "        [0.47468449, 0.28881276, 0.46745607, ..., 0.04406686,\n",
       "         0.        , 1.        ],\n",
       "        [0.46730059, 0.28718946, 0.49215472, ..., 0.0836537 ,\n",
       "         0.        , 1.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.43319166, 0.71678517, 0.41327133, ..., 0.02411595,\n",
       "         0.        , 1.        ],\n",
       "        [0.42986342, 0.72096843, 0.41953756, ..., 0.04406686,\n",
       "         0.        , 1.        ],\n",
       "        [0.42638591, 0.72411329, 0.38744858, ..., 0.0836537 ,\n",
       "         0.        , 1.        ]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a4a24",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80a6472e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:12.187507Z",
     "start_time": "2023-08-13T21:58:11.191254Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, GRU\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam ,Adagrad, Adadelta, SGD, Lion\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84471a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:13.494831Z",
     "start_time": "2023-08-13T21:58:12.189240Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "tf.random.set_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ae984cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:14.655985Z",
     "start_time": "2023-08-13T21:58:13.496384Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "882eff58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:58:15.585590Z",
     "start_time": "2023-08-13T21:58:14.657528Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "max_len = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83de7026",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T20:32:59.595934Z",
     "start_time": "2023-08-07T20:31:15.893793Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 21:31:15.975071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1037 MB memory:  -> device: 0, name: NVIDIA GeForce MX250, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 130, 180)          1326960   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 130, 90)           97560     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 130, 180)          195120    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 90)                97560     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 90)                8190      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 90)                8190      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 90)                8190      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 90)                8190      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 45)                4095      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 90)                4140      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 50)                4550      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1762745 (6.72 MB)\n",
      "Trainable params: 1762745 (6.72 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 21:31:23.890758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-08-07 21:31:24.039649: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xa6a3900 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-07 21:31:24.039679: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce MX250, Compute Capability 6.1\n",
      "2023-08-07 21:31:24.100011: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 10s 360ms/step - loss: 8.4307 - categorical_accuracy: 0.0171 - val_loss: 5.4406 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "11/11 [==============================] - 2s 218ms/step - loss: 7.6683 - categorical_accuracy: 0.0311 - val_loss: 5.3028 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "11/11 [==============================] - 2s 220ms/step - loss: 7.6718 - categorical_accuracy: 0.0249 - val_loss: 5.0410 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "11/11 [==============================] - 2s 221ms/step - loss: 8.3987 - categorical_accuracy: 0.0187 - val_loss: 5.0319 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "11/11 [==============================] - 2s 221ms/step - loss: 7.4197 - categorical_accuracy: 0.0280 - val_loss: 5.5538 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "11/11 [==============================] - 2s 219ms/step - loss: 8.0407 - categorical_accuracy: 0.0311 - val_loss: 7.9545 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "11/11 [==============================] - 2s 219ms/step - loss: 8.0923 - categorical_accuracy: 0.0280 - val_loss: 5.0318 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "11/11 [==============================] - 2s 220ms/step - loss: 7.8106 - categorical_accuracy: 0.0249 - val_loss: 8.0347 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "11/11 [==============================] - 2s 219ms/step - loss: 8.6343 - categorical_accuracy: 0.0264 - val_loss: 5.0350 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "11/11 [==============================] - 2s 219ms/step - loss: 7.6313 - categorical_accuracy: 0.0233 - val_loss: 5.0359 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "11/11 [==============================] - 2s 220ms/step - loss: 6.9260 - categorical_accuracy: 0.0218 - val_loss: 11.0226 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "11/11 [==============================] - 2s 220ms/step - loss: 8.2332 - categorical_accuracy: 0.0202 - val_loss: 4.9825 - val_categorical_accuracy: 0.0994\n",
      "Epoch 13/1000\n",
      "11/11 [==============================] - 2s 220ms/step - loss: 7.8706 - categorical_accuracy: 0.0233 - val_loss: 4.9841 - val_categorical_accuracy: 0.0994\n",
      "Epoch 14/1000\n",
      "11/11 [==============================] - 2s 221ms/step - loss: 7.3172 - categorical_accuracy: 0.0249 - val_loss: 4.9831 - val_categorical_accuracy: 0.0994\n",
      "Epoch 15/1000\n",
      "11/11 [==============================] - 2s 217ms/step - loss: 8.2094 - categorical_accuracy: 0.0171 - val_loss: 11.3550 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "11/11 [==============================] - 2s 222ms/step - loss: 7.8881 - categorical_accuracy: 0.0187 - val_loss: 7.9880 - val_categorical_accuracy: 0.0994\n",
      "Epoch 17/1000\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 8.3123 - categorical_accuracy: 0.0218 - val_loss: 7.9903 - val_categorical_accuracy: 0.0994\n",
      "Epoch 18/1000\n",
      "11/11 [==============================] - 2s 222ms/step - loss: 8.2341 - categorical_accuracy: 0.0171 - val_loss: 4.9904 - val_categorical_accuracy: 0.0994\n",
      "Epoch 19/1000\n",
      "11/11 [==============================] - 2s 224ms/step - loss: 6.9151 - categorical_accuracy: 0.0187 - val_loss: 5.9431 - val_categorical_accuracy: 0.0994\n",
      "Epoch 20/1000\n",
      "11/11 [==============================] - 2s 221ms/step - loss: 7.6260 - categorical_accuracy: 0.0218 - val_loss: 4.9903 - val_categorical_accuracy: 0.0994\n",
      "Epoch 21/1000\n",
      "11/11 [==============================] - 2s 220ms/step - loss: 7.8169 - categorical_accuracy: 0.0295 - val_loss: 4.9939 - val_categorical_accuracy: 0.0994\n",
      "Epoch 22/1000\n",
      "11/11 [==============================] - 2s 221ms/step - loss: 7.6955 - categorical_accuracy: 0.0171 - val_loss: 4.9973 - val_categorical_accuracy: 0.0994\n",
      "Epoch 23/1000\n",
      "11/11 [==============================] - 2s 221ms/step - loss: 7.3087 - categorical_accuracy: 0.0171 - val_loss: 4.9986 - val_categorical_accuracy: 0.0994\n",
      "Epoch 24/1000\n",
      "11/11 [==============================] - 2s 222ms/step - loss: 7.4312 - categorical_accuracy: 0.0249 - val_loss: 4.9984 - val_categorical_accuracy: 0.0994\n",
      "Epoch 25/1000\n",
      "11/11 [==============================] - 2s 220ms/step - loss: 7.3447 - categorical_accuracy: 0.0233 - val_loss: 5.8044 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "11/11 [==============================] - 2s 221ms/step - loss: 6.9409 - categorical_accuracy: 0.0218 - val_loss: 6.5245 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "11/11 [==============================] - 2s 221ms/step - loss: 8.0626 - categorical_accuracy: 0.0311 - val_loss: 7.9870 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "11/11 [==============================] - 2s 223ms/step - loss: 9.5177 - categorical_accuracy: 0.0156 - val_loss: 11.3321 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "11/11 [==============================] - 2s 222ms/step - loss: 9.0008 - categorical_accuracy: 0.0171 - val_loss: 5.9848 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 8.8190 - categorical_accuracy: 0.0202 - val_loss: 13.5651 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "11/11 [==============================] - 2s 223ms/step - loss: 8.9168 - categorical_accuracy: 0.0187 - val_loss: 7.9912 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 9.8154 - categorical_accuracy: 0.0233 - val_loss: 7.9926 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "11/11 [==============================] - 2s 221ms/step - loss: 9.9764 - categorical_accuracy: 0.0218 - val_loss: 7.9943 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "11/11 [==============================] - 2s 224ms/step - loss: 9.8159 - categorical_accuracy: 0.0202 - val_loss: 7.9935 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 8.6428 - categorical_accuracy: 0.0249 - val_loss: 7.9950 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 7.2037 - categorical_accuracy: 0.0218 - val_loss: 6.0162 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 9.6929 - categorical_accuracy: 0.0187 - val_loss: 12.7522 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 38/1000\n",
      " 2/11 [====>.........................] - ETA: 1s - loss: 6.5004 - categorical_accuracy: 0.0156    "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m SGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.00001\u001b[39m,nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1748\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1746\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1747\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1748\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/tf_utils.py:694\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/nest.py:624\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    540\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 624\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1054\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \n\u001b[1;32m    959\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1054\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/tf_utils.py:687\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 687\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1141\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m \n\u001b[1;32m   1120\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1107\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1106\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1108\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential(name='Sequential')\n",
    "act_function = 'tanh'\n",
    "model.add(LSTM(180, return_sequences=True, activation=act_function, input_shape=(60,1662)))\n",
    "model.add(LSTM(90, return_sequences=True, activation=act_function))\n",
    "model.add(LSTM(180, return_sequences=True, activation=act_function))\n",
    "model.add(LSTM(90, return_sequences=False,activation=act_function))\n",
    "model.add(Dense(90, activation=act_function))\n",
    "model.add(Dense(90, activation=act_function))\n",
    "model.add(Dense(90, activation=act_function))\n",
    "model.add(Dense(90, activation=act_function))\n",
    "model.add(Dense(45, activation=act_function))\n",
    "model.add(Dense(90, activation=act_function))\n",
    "model.add(Dense(59, activation=act_function))\n",
    "model.summary()\n",
    "\n",
    "optimizer = SGD(learning_rate=.00001,nesterov=True)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, epochs=1000, validation_split=.2, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4546c78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T20:49:37.295257Z",
     "start_time": "2023-08-07T20:49:05.389345Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 21:49:05.468776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1037 MB memory:  -> device: 0, name: NVIDIA GeForce MX250, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 21:49:09.595786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-08-07 21:49:09.643909: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8864929fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-07 21:49:09.643936: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce MX250, Compute Capability 6.1\n",
      "2023-08-07 21:49:09.647840: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-07 21:49:09.756578: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 178ms/step - loss: 7.8501 - categorical_accuracy: 0.0311 - val_loss: 8.1508 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 8.1865 - categorical_accuracy: 0.0218 - val_loss: 9.0874 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 7.9489 - categorical_accuracy: 0.0171 - val_loss: 9.2725 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 8.4394 - categorical_accuracy: 0.0264 - val_loss: 7.0158 - val_categorical_accuracy: 0.0435\n",
      "Epoch 5/1000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 7.9150 - categorical_accuracy: 0.0264 - val_loss: 6.5328 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 7.8367 - categorical_accuracy: 0.0249 - val_loss: 7.1868 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 7.4580 - categorical_accuracy: 0.0218 - val_loss: 7.9999 - val_categorical_accuracy: 0.0435\n",
      "Epoch 8/1000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 7.6811 - categorical_accuracy: 0.0202 - val_loss: 8.0838 - val_categorical_accuracy: 0.0435\n",
      "Epoch 9/1000\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 8.0921 - categorical_accuracy: 0.0156 - val_loss: 10.9521 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 7.6189 - categorical_accuracy: 0.0280 - val_loss: 8.0590 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 8.2331 - categorical_accuracy: 0.0249 - val_loss: 9.4764 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 8.2073 - categorical_accuracy: 0.0249 - val_loss: 7.8109 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 7.9964 - categorical_accuracy: 0.0218 - val_loss: 7.8109 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 8.0214 - categorical_accuracy: 0.0218 - val_loss: 7.8109 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 8.0214 - categorical_accuracy: 0.0233 - val_loss: 7.8109 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 7.9713 - categorical_accuracy: 0.0233 - val_loss: 7.8109 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 7.9964 - categorical_accuracy: 0.0249 - val_loss: 7.8109 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 7.9713 - categorical_accuracy: 0.0233 - val_loss: 7.8109 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 7.9713 - categorical_accuracy: 0.0249 - val_loss: 7.8109 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 7.9713 - categorical_accuracy: 0.0280 - val_loss: 7.8109 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 7.9964 - categorical_accuracy: 0.0202 - val_loss: 7.8109 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 8.0465 - categorical_accuracy: 0.0264 - val_loss: 7.8109 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 8.0465 - categorical_accuracy: 0.0187 - val_loss: 7.8109 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 8.0465 - categorical_accuracy: 0.0218 - val_loss: 7.8109 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 8.0716 - categorical_accuracy: 0.0249 - val_loss: 7.8109 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 7.9964 - categorical_accuracy: 0.0233 - val_loss: 7.8109 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 7.9964 - categorical_accuracy: 0.0202 - val_loss: 7.8109 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      " 6/11 [===============>..............] - ETA: 0s - loss: 8.4368 - categorical_accuracy: 0.0208"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adagrad(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.01\u001b[39m)\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential(name='Sequential')\n",
    "act_function = 'tanh'\n",
    "model.add(GRU(64, return_sequences=True, activation=act_function, input_shape=(130,1662)))\n",
    "model.add(GRU(64, return_sequences=False, activation=act_function))\n",
    "model.add(Dense(64, activation=act_function))\n",
    "model.add(Dense(50, activation=act_function))\n",
    "optimizer = Adagrad(learning_rate=.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, epochs=1000, validation_split=.2, batch_size = 64)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b335502b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T21:56:51.582243Z",
     "start_time": "2023-08-07T21:56:18.508905Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/1000\n",
      "21/21 [==============================] - 16s 566ms/step - loss: 3.9102 - categorical_accuracy: 0.0218 - val_loss: 3.9294 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 11s 541ms/step - loss: 3.9102 - categorical_accuracy: 0.0218 - val_loss: 3.9294 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      " 7/21 [=========>....................] - ETA: 7s - loss: 3.9032 - categorical_accuracy: 0.0223"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m SGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.0000005\u001b[39m)\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "act_function = 'LeakyReLU'\n",
    "model.add(LSTM(64, return_sequences=True, activation=act_function, input_shape=(130,1662)))\n",
    "model.add(GRU(128, return_sequences=True, activation=act_function))\n",
    "model.add(LSTM(64, return_sequences=False, activation=act_function))\n",
    "model.add(Dense(64, activation=act_function))\n",
    "model.add(Dense(32, activation=act_function))\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "optimizer = SGD(learning_rate=.0000005)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, epochs=1000, validation_split=.2, batch_size = 32, callbacks=[tb_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c679311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T10:35:27.486345Z",
     "start_time": "2023-08-08T10:35:27.486327Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential(name='Sequential') #good, overfitting\n",
    "\n",
    "act_function = 'LeakyReLU'\n",
    "model.add(GRU(128, return_sequences=True, activation=act_function, input_shape=(130,1662)))\n",
    "model.add(GRU(128, return_sequences=False, activation=act_function))\n",
    "#model.add(LSTM(64, return_sequences=False, activation=act_function))\n",
    "model.add(Dense(128, activation=act_function, input_shape=(130,1662)))\n",
    "model.add(Dense(128, activation=act_function))\n",
    "model.add(Dense(64, activation=act_function))\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "optimizer = Lion(learning_rate=.00025)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, epochs=1000, validation_split=.4, batch_size = 64, callbacks=[tb_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08d05ac6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T10:17:07.348123Z",
     "start_time": "2023-08-08T10:17:06.489076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 50ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6b4e57c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T10:18:19.616395Z",
     "start_time": "2023-08-08T10:18:19.613175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(res[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29089018",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T10:18:22.529590Z",
     "start_time": "2023-08-08T10:18:22.525712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Yval[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a2582eb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T09:58:37.081230Z",
     "start_time": "2023-08-09T09:58:07.486115Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "11/11 [==============================] - 3s 180ms/step - loss: 4.1087 - categorical_accuracy: 0.0171 - val_loss: 4.1858 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 4.0747 - categorical_accuracy: 0.0202 - val_loss: 4.3024 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 4.0751 - categorical_accuracy: 0.0140 - val_loss: 4.2856 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 4.0439 - categorical_accuracy: 0.0171 - val_loss: 4.3756 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 4.0622 - categorical_accuracy: 0.0155 - val_loss: 4.3673 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 4.0239 - categorical_accuracy: 0.0186 - val_loss: 4.4005 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "11/11 [==============================] - 0s 47ms/step - loss: 4.0228 - categorical_accuracy: 0.0171 - val_loss: 4.4193 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 3.9915 - categorical_accuracy: 0.0295 - val_loss: 4.5663 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 3.9889 - categorical_accuracy: 0.0280 - val_loss: 4.7817 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 3.9672 - categorical_accuracy: 0.0311 - val_loss: 4.8244 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 3.9809 - categorical_accuracy: 0.0186 - val_loss: 4.7760 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 3.9580 - categorical_accuracy: 0.0155 - val_loss: 4.9157 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 3.9464 - categorical_accuracy: 0.0155 - val_loss: 4.9414 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 3.9193 - categorical_accuracy: 0.0326 - val_loss: 5.0058 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 3.9183 - categorical_accuracy: 0.0311 - val_loss: 5.1755 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 3.9203 - categorical_accuracy: 0.0264 - val_loss: 5.1967 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 3.8883 - categorical_accuracy: 0.0311 - val_loss: 5.1476 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 3.8837 - categorical_accuracy: 0.0342 - val_loss: 5.2273 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 3.8757 - categorical_accuracy: 0.0311 - val_loss: 5.3465 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 3.8569 - categorical_accuracy: 0.0295 - val_loss: 5.5196 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 3.8375 - categorical_accuracy: 0.0388 - val_loss: 5.6230 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 3.8509 - categorical_accuracy: 0.0357 - val_loss: 5.5512 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 3.8164 - categorical_accuracy: 0.0326 - val_loss: 5.8052 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 3.8442 - categorical_accuracy: 0.0342 - val_loss: 5.7013 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 3.8432 - categorical_accuracy: 0.0342 - val_loss: 5.6743 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 3.8487 - categorical_accuracy: 0.0140 - val_loss: 5.6833 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 3.8376 - categorical_accuracy: 0.0171 - val_loss: 5.8494 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 3.7938 - categorical_accuracy: 0.0326 - val_loss: 6.2235 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 3.8155 - categorical_accuracy: 0.0233 - val_loss: 6.1601 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 3.7840 - categorical_accuracy: 0.0435 - val_loss: 6.1392 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 3.7855 - categorical_accuracy: 0.0326 - val_loss: 6.1635 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 3.7987 - categorical_accuracy: 0.0450 - val_loss: 6.2191 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 3.7791 - categorical_accuracy: 0.0295 - val_loss: 6.5121 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 3.7883 - categorical_accuracy: 0.0326 - val_loss: 6.4925 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 3.7604 - categorical_accuracy: 0.0481 - val_loss: 6.2822 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 3.7951 - categorical_accuracy: 0.0326 - val_loss: 6.2173 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 3.7632 - categorical_accuracy: 0.0311 - val_loss: 6.4224 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 3.7617 - categorical_accuracy: 0.0342 - val_loss: 6.6403 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 3.7603 - categorical_accuracy: 0.0295 - val_loss: 6.3519 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 3.7530 - categorical_accuracy: 0.0357 - val_loss: 6.4992 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 3.7634 - categorical_accuracy: 0.0357 - val_loss: 6.4741 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 3.7406 - categorical_accuracy: 0.0295 - val_loss: 6.8594 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 3.7300 - categorical_accuracy: 0.0388 - val_loss: 6.9399 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 3.7265 - categorical_accuracy: 0.0373 - val_loss: 6.8115 - val_categorical_accuracy: 0.0036\n",
      "Epoch 45/1000\n",
      "11/11 [==============================] - 1s 66ms/step - loss: 3.7415 - categorical_accuracy: 0.0373 - val_loss: 6.7508 - val_categorical_accuracy: 0.0036\n",
      "Epoch 46/1000\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 3.7183 - categorical_accuracy: 0.0217 - val_loss: 6.8852 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 47/1000\n",
      " 8/11 [====================>.........] - ETA: 0s - loss: 3.7380 - categorical_accuracy: 0.0312"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Lion(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.0005\u001b[39m)\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential(name='Sequential') ##best\n",
    "\n",
    "act_function = 'LeakyReLU'\n",
    "model.add(GRU(16, return_sequences=False, activation=act_function, dropout=0,input_shape=(60,1662)))\n",
    "#model.add(GRU(128, return_sequences=False, activation=act_function))\n",
    "#model.add(LSTM(64, return_sequences=False, activation=act_function))\n",
    "model.add(Dense(16, activation=act_function))\n",
    "#model.add(Dense(64, activation=act_function))\n",
    "#model.add(Dense(16, activation=act_function))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(59, activation='softmax'))\n",
    "optimizer = Lion(learning_rate=.0005)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, epochs=1000, validation_split=.3, batch_size = 64, callbacks=[tb_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9db2dd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T16:43:40.044523Z",
     "start_time": "2023-08-08T16:36:17.221137Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 17:36:17.297939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1739 MB memory:  -> device: 0, name: NVIDIA GeForce MX250, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2023-08-08 17:36:18.593263: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1040544960 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 17:36:21.722239: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7b18452100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-08 17:36:21.722274: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce MX250, Compute Capability 6.1\n",
      "2023-08-08 17:36:21.728081: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-08 17:36:21.741053: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-08-08 17:36:21.805903: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 7s 234ms/step - loss: 4.0885 - categorical_accuracy: 0.0291 - val_loss: 4.1440 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/5000\n",
      "19/19 [==============================] - 4s 217ms/step - loss: 4.0645 - categorical_accuracy: 0.0191 - val_loss: 4.0806 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/5000\n",
      "19/19 [==============================] - 4s 225ms/step - loss: 3.9947 - categorical_accuracy: 0.0183 - val_loss: 4.0219 - val_categorical_accuracy: 0.0299\n",
      "Epoch 4/5000\n",
      "19/19 [==============================] - 4s 221ms/step - loss: 3.9759 - categorical_accuracy: 0.0183 - val_loss: 3.9075 - val_categorical_accuracy: 0.0149\n",
      "Epoch 5/5000\n",
      "19/19 [==============================] - 4s 224ms/step - loss: 3.9454 - categorical_accuracy: 0.0191 - val_loss: 3.9256 - val_categorical_accuracy: 0.0075\n",
      "Epoch 6/5000\n",
      "19/19 [==============================] - 4s 226ms/step - loss: 3.9341 - categorical_accuracy: 0.0282 - val_loss: 3.9267 - val_categorical_accuracy: 0.0075\n",
      "Epoch 7/5000\n",
      "19/19 [==============================] - 4s 227ms/step - loss: 3.9261 - categorical_accuracy: 0.0249 - val_loss: 4.0117 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/5000\n",
      "19/19 [==============================] - 4s 228ms/step - loss: 3.9200 - categorical_accuracy: 0.0233 - val_loss: 3.9008 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/5000\n",
      "19/19 [==============================] - 4s 228ms/step - loss: 3.9136 - categorical_accuracy: 0.0249 - val_loss: 3.9326 - val_categorical_accuracy: 0.0075\n",
      "Epoch 10/5000\n",
      "19/19 [==============================] - 4s 232ms/step - loss: 3.9090 - categorical_accuracy: 0.0241 - val_loss: 3.9544 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/5000\n",
      "19/19 [==============================] - 4s 232ms/step - loss: 3.8984 - categorical_accuracy: 0.0316 - val_loss: 3.9615 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/5000\n",
      "19/19 [==============================] - 4s 234ms/step - loss: 3.8981 - categorical_accuracy: 0.0374 - val_loss: 3.9912 - val_categorical_accuracy: 0.0224\n",
      "Epoch 13/5000\n",
      "19/19 [==============================] - 4s 233ms/step - loss: 3.8905 - categorical_accuracy: 0.0341 - val_loss: 3.9687 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 14/5000\n",
      "19/19 [==============================] - 4s 234ms/step - loss: 3.8858 - categorical_accuracy: 0.0282 - val_loss: 3.9780 - val_categorical_accuracy: 0.0075\n",
      "Epoch 15/5000\n",
      "19/19 [==============================] - 4s 234ms/step - loss: 3.8833 - categorical_accuracy: 0.0399 - val_loss: 3.9740 - val_categorical_accuracy: 0.0075\n",
      "Epoch 16/5000\n",
      "19/19 [==============================] - 4s 235ms/step - loss: 3.8733 - categorical_accuracy: 0.0382 - val_loss: 3.9876 - val_categorical_accuracy: 0.0224\n",
      "Epoch 17/5000\n",
      "19/19 [==============================] - 5s 245ms/step - loss: 3.8727 - categorical_accuracy: 0.0374 - val_loss: 4.0069 - val_categorical_accuracy: 0.0299\n",
      "Epoch 18/5000\n",
      "19/19 [==============================] - 5s 240ms/step - loss: 3.8663 - categorical_accuracy: 0.0382 - val_loss: 4.0111 - val_categorical_accuracy: 0.0149\n",
      "Epoch 19/5000\n",
      "19/19 [==============================] - 5s 241ms/step - loss: 3.8508 - categorical_accuracy: 0.0407 - val_loss: 4.0281 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/5000\n",
      "19/19 [==============================] - 5s 238ms/step - loss: 3.8568 - categorical_accuracy: 0.0465 - val_loss: 3.9819 - val_categorical_accuracy: 0.0075\n",
      "Epoch 21/5000\n",
      "19/19 [==============================] - 5s 239ms/step - loss: 3.8353 - categorical_accuracy: 0.0540 - val_loss: 3.9703 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 22/5000\n",
      "19/19 [==============================] - 5s 239ms/step - loss: 3.8171 - categorical_accuracy: 0.0598 - val_loss: 4.0379 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 23/5000\n",
      "19/19 [==============================] - 5s 241ms/step - loss: 3.8018 - categorical_accuracy: 0.0540 - val_loss: 4.0642 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 24/5000\n",
      "19/19 [==============================] - 5s 239ms/step - loss: 3.8040 - categorical_accuracy: 0.0573 - val_loss: 4.0592 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 25/5000\n",
      "19/19 [==============================] - 5s 240ms/step - loss: 3.7878 - categorical_accuracy: 0.0548 - val_loss: 4.0643 - val_categorical_accuracy: 0.0075\n",
      "Epoch 26/5000\n",
      "19/19 [==============================] - 5s 242ms/step - loss: 3.7856 - categorical_accuracy: 0.0640 - val_loss: 4.0778 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 27/5000\n",
      "19/19 [==============================] - 5s 240ms/step - loss: 3.7725 - categorical_accuracy: 0.0540 - val_loss: 4.0107 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 28/5000\n",
      "19/19 [==============================] - 5s 243ms/step - loss: 3.7555 - categorical_accuracy: 0.0498 - val_loss: 4.0598 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 29/5000\n",
      "19/19 [==============================] - 5s 264ms/step - loss: 3.7462 - categorical_accuracy: 0.0706 - val_loss: 4.0550 - val_categorical_accuracy: 0.0149\n",
      "Epoch 30/5000\n",
      "19/19 [==============================] - 5s 250ms/step - loss: 3.7422 - categorical_accuracy: 0.0606 - val_loss: 4.0529 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 31/5000\n",
      "19/19 [==============================] - 5s 246ms/step - loss: 3.7316 - categorical_accuracy: 0.0573 - val_loss: 4.0415 - val_categorical_accuracy: 0.0075\n",
      "Epoch 32/5000\n",
      "19/19 [==============================] - 5s 245ms/step - loss: 3.7252 - categorical_accuracy: 0.0623 - val_loss: 4.0489 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 33/5000\n",
      "19/19 [==============================] - 5s 251ms/step - loss: 3.7174 - categorical_accuracy: 0.0590 - val_loss: 4.0351 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 34/5000\n",
      "19/19 [==============================] - 5s 244ms/step - loss: 3.7019 - categorical_accuracy: 0.0756 - val_loss: 4.0325 - val_categorical_accuracy: 0.0075\n",
      "Epoch 35/5000\n",
      "19/19 [==============================] - 5s 241ms/step - loss: 3.6891 - categorical_accuracy: 0.0714 - val_loss: 4.1088 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 36/5000\n",
      "19/19 [==============================] - 5s 244ms/step - loss: 3.6852 - categorical_accuracy: 0.0714 - val_loss: 4.0857 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 37/5000\n",
      "19/19 [==============================] - 5s 246ms/step - loss: 3.6798 - categorical_accuracy: 0.0523 - val_loss: 4.0594 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 38/5000\n",
      "19/19 [==============================] - 5s 245ms/step - loss: 3.6490 - categorical_accuracy: 0.0706 - val_loss: 4.0521 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 39/5000\n",
      "19/19 [==============================] - 5s 249ms/step - loss: 3.6480 - categorical_accuracy: 0.0789 - val_loss: 3.9775 - val_categorical_accuracy: 0.0224\n",
      "Epoch 40/5000\n",
      "19/19 [==============================] - 5s 246ms/step - loss: 3.6327 - categorical_accuracy: 0.0689 - val_loss: 3.9828 - val_categorical_accuracy: 0.0075\n",
      "Epoch 41/5000\n",
      "19/19 [==============================] - 5s 244ms/step - loss: 3.6328 - categorical_accuracy: 0.0847 - val_loss: 3.9629 - val_categorical_accuracy: 0.0299\n",
      "Epoch 42/5000\n",
      "19/19 [==============================] - 5s 250ms/step - loss: 3.6179 - categorical_accuracy: 0.0797 - val_loss: 3.9892 - val_categorical_accuracy: 0.0149\n",
      "Epoch 43/5000\n",
      "19/19 [==============================] - 5s 250ms/step - loss: 3.5870 - categorical_accuracy: 0.0864 - val_loss: 3.9844 - val_categorical_accuracy: 0.0075\n",
      "Epoch 44/5000\n",
      "19/19 [==============================] - 5s 245ms/step - loss: 3.6008 - categorical_accuracy: 0.0880 - val_loss: 4.0426 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 45/5000\n",
      "19/19 [==============================] - 5s 250ms/step - loss: 3.5921 - categorical_accuracy: 0.0706 - val_loss: 3.9665 - val_categorical_accuracy: 0.0149\n",
      "Epoch 46/5000\n",
      "19/19 [==============================] - 5s 247ms/step - loss: 3.5997 - categorical_accuracy: 0.0855 - val_loss: 3.9753 - val_categorical_accuracy: 0.0373\n",
      "Epoch 47/5000\n",
      "19/19 [==============================] - 5s 244ms/step - loss: 3.5630 - categorical_accuracy: 0.0789 - val_loss: 3.9760 - val_categorical_accuracy: 0.0075\n",
      "Epoch 48/5000\n",
      "19/19 [==============================] - 5s 244ms/step - loss: 3.5581 - categorical_accuracy: 0.0980 - val_loss: 4.0553 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 49/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 5s 244ms/step - loss: 3.5412 - categorical_accuracy: 0.0822 - val_loss: 4.0214 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 50/5000\n",
      "19/19 [==============================] - 5s 244ms/step - loss: 3.5468 - categorical_accuracy: 0.0831 - val_loss: 3.9519 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 51/5000\n",
      "19/19 [==============================] - 5s 244ms/step - loss: 3.5162 - categorical_accuracy: 0.0872 - val_loss: 3.9390 - val_categorical_accuracy: 0.0075\n",
      "Epoch 52/5000\n",
      "19/19 [==============================] - 5s 246ms/step - loss: 3.5342 - categorical_accuracy: 0.0955 - val_loss: 3.8922 - val_categorical_accuracy: 0.0149\n",
      "Epoch 53/5000\n",
      "19/19 [==============================] - 5s 250ms/step - loss: 3.4977 - categorical_accuracy: 0.1030 - val_loss: 3.9604 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 54/5000\n",
      "19/19 [==============================] - 5s 245ms/step - loss: 3.4793 - categorical_accuracy: 0.1071 - val_loss: 3.9357 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 55/5000\n",
      "19/19 [==============================] - 5s 246ms/step - loss: 3.4592 - categorical_accuracy: 0.0930 - val_loss: 3.9497 - val_categorical_accuracy: 0.0224\n",
      "Epoch 56/5000\n",
      "19/19 [==============================] - 5s 252ms/step - loss: 3.4692 - categorical_accuracy: 0.1005 - val_loss: 3.8997 - val_categorical_accuracy: 0.0149\n",
      "Epoch 57/5000\n",
      "19/19 [==============================] - 5s 249ms/step - loss: 3.4375 - categorical_accuracy: 0.1121 - val_loss: 3.9349 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 58/5000\n",
      "19/19 [==============================] - 5s 251ms/step - loss: 3.4495 - categorical_accuracy: 0.1071 - val_loss: 3.8984 - val_categorical_accuracy: 0.0299\n",
      "Epoch 59/5000\n",
      "19/19 [==============================] - 5s 249ms/step - loss: 3.4331 - categorical_accuracy: 0.1055 - val_loss: 3.9374 - val_categorical_accuracy: 0.0075\n",
      "Epoch 60/5000\n",
      "19/19 [==============================] - 5s 249ms/step - loss: 3.4423 - categorical_accuracy: 0.1071 - val_loss: 3.8863 - val_categorical_accuracy: 0.0299\n",
      "Epoch 61/5000\n",
      "19/19 [==============================] - 5s 247ms/step - loss: 3.3914 - categorical_accuracy: 0.1229 - val_loss: 3.9182 - val_categorical_accuracy: 0.0149\n",
      "Epoch 62/5000\n",
      "19/19 [==============================] - 5s 248ms/step - loss: 3.4384 - categorical_accuracy: 0.1105 - val_loss: 3.8560 - val_categorical_accuracy: 0.0299\n",
      "Epoch 63/5000\n",
      "19/19 [==============================] - 5s 249ms/step - loss: 3.3495 - categorical_accuracy: 0.1321 - val_loss: 3.8607 - val_categorical_accuracy: 0.0224\n",
      "Epoch 64/5000\n",
      "19/19 [==============================] - 5s 247ms/step - loss: 3.3719 - categorical_accuracy: 0.1154 - val_loss: 3.8604 - val_categorical_accuracy: 0.0299\n",
      "Epoch 65/5000\n",
      "19/19 [==============================] - 5s 252ms/step - loss: 3.3594 - categorical_accuracy: 0.1279 - val_loss: 3.9002 - val_categorical_accuracy: 0.0075\n",
      "Epoch 66/5000\n",
      "19/19 [==============================] - 5s 249ms/step - loss: 3.3509 - categorical_accuracy: 0.1229 - val_loss: 3.8858 - val_categorical_accuracy: 0.0149\n",
      "Epoch 67/5000\n",
      "19/19 [==============================] - 5s 249ms/step - loss: 3.3545 - categorical_accuracy: 0.1188 - val_loss: 3.8653 - val_categorical_accuracy: 0.0224\n",
      "Epoch 68/5000\n",
      "19/19 [==============================] - 5s 254ms/step - loss: 3.3249 - categorical_accuracy: 0.1387 - val_loss: 3.8259 - val_categorical_accuracy: 0.0373\n",
      "Epoch 69/5000\n",
      "19/19 [==============================] - 5s 247ms/step - loss: 3.2907 - categorical_accuracy: 0.1254 - val_loss: 3.7832 - val_categorical_accuracy: 0.0299\n",
      "Epoch 70/5000\n",
      "19/19 [==============================] - 5s 249ms/step - loss: 3.3408 - categorical_accuracy: 0.1229 - val_loss: 3.8391 - val_categorical_accuracy: 0.0373\n",
      "Epoch 71/5000\n",
      "19/19 [==============================] - 5s 251ms/step - loss: 3.2906 - categorical_accuracy: 0.1429 - val_loss: 3.7939 - val_categorical_accuracy: 0.0373\n",
      "Epoch 72/5000\n",
      "19/19 [==============================] - 5s 249ms/step - loss: 3.3037 - categorical_accuracy: 0.1329 - val_loss: 3.7651 - val_categorical_accuracy: 0.0373\n",
      "Epoch 73/5000\n",
      "19/19 [==============================] - 5s 252ms/step - loss: 3.2813 - categorical_accuracy: 0.1379 - val_loss: 3.8513 - val_categorical_accuracy: 0.0522\n",
      "Epoch 74/5000\n",
      "19/19 [==============================] - 5s 251ms/step - loss: 3.2980 - categorical_accuracy: 0.1354 - val_loss: 3.7634 - val_categorical_accuracy: 0.0597\n",
      "Epoch 75/5000\n",
      "19/19 [==============================] - 5s 247ms/step - loss: 3.2436 - categorical_accuracy: 0.1445 - val_loss: 3.7707 - val_categorical_accuracy: 0.0522\n",
      "Epoch 76/5000\n",
      "19/19 [==============================] - 5s 254ms/step - loss: 3.2368 - categorical_accuracy: 0.1495 - val_loss: 3.8018 - val_categorical_accuracy: 0.0373\n",
      "Epoch 77/5000\n",
      "19/19 [==============================] - 5s 251ms/step - loss: 3.2209 - categorical_accuracy: 0.1404 - val_loss: 3.8021 - val_categorical_accuracy: 0.0224\n",
      "Epoch 78/5000\n",
      "19/19 [==============================] - 5s 246ms/step - loss: 3.2056 - categorical_accuracy: 0.1528 - val_loss: 3.7326 - val_categorical_accuracy: 0.0672\n",
      "Epoch 79/5000\n",
      "19/19 [==============================] - 5s 252ms/step - loss: 3.2090 - categorical_accuracy: 0.1445 - val_loss: 3.8851 - val_categorical_accuracy: 0.0373\n",
      "Epoch 80/5000\n",
      "19/19 [==============================] - 5s 250ms/step - loss: 3.1917 - categorical_accuracy: 0.1553 - val_loss: 3.8319 - val_categorical_accuracy: 0.0373\n",
      "Epoch 81/5000\n",
      "19/19 [==============================] - 5s 258ms/step - loss: 3.1849 - categorical_accuracy: 0.1545 - val_loss: 3.7441 - val_categorical_accuracy: 0.0448\n",
      "Epoch 82/5000\n",
      "19/19 [==============================] - 5s 252ms/step - loss: 3.1894 - categorical_accuracy: 0.1620 - val_loss: 3.8227 - val_categorical_accuracy: 0.0448\n",
      "Epoch 83/5000\n",
      "19/19 [==============================] - 5s 248ms/step - loss: 3.1350 - categorical_accuracy: 0.1595 - val_loss: 3.7341 - val_categorical_accuracy: 0.0448\n",
      "Epoch 84/5000\n",
      "19/19 [==============================] - 5s 251ms/step - loss: 3.1378 - categorical_accuracy: 0.1561 - val_loss: 3.7643 - val_categorical_accuracy: 0.0299\n",
      "Epoch 85/5000\n",
      "19/19 [==============================] - 5s 249ms/step - loss: 3.1398 - categorical_accuracy: 0.1537 - val_loss: 3.7108 - val_categorical_accuracy: 0.0299\n",
      "Epoch 86/5000\n",
      "19/19 [==============================] - 5s 251ms/step - loss: 3.1032 - categorical_accuracy: 0.1844 - val_loss: 3.7140 - val_categorical_accuracy: 0.0672\n",
      "Epoch 87/5000\n",
      "19/19 [==============================] - 5s 249ms/step - loss: 3.1114 - categorical_accuracy: 0.1752 - val_loss: 3.7022 - val_categorical_accuracy: 0.0522\n",
      "Epoch 88/5000\n",
      "19/19 [==============================] - 5s 249ms/step - loss: 3.1362 - categorical_accuracy: 0.1578 - val_loss: 3.6934 - val_categorical_accuracy: 0.0373\n",
      "Epoch 89/5000\n",
      "19/19 [==============================] - 5s 252ms/step - loss: 3.0692 - categorical_accuracy: 0.1935 - val_loss: 3.6675 - val_categorical_accuracy: 0.0597\n",
      "Epoch 90/5000\n",
      "19/19 [==============================] - 5s 246ms/step - loss: 3.0924 - categorical_accuracy: 0.1703 - val_loss: 3.7075 - val_categorical_accuracy: 0.0373\n",
      "Epoch 91/5000\n",
      "19/19 [==============================] - 5s 251ms/step - loss: 3.0770 - categorical_accuracy: 0.1761 - val_loss: 3.6833 - val_categorical_accuracy: 0.0299\n",
      "Epoch 92/5000\n",
      "19/19 [==============================] - 5s 253ms/step - loss: 3.0705 - categorical_accuracy: 0.1777 - val_loss: 3.7107 - val_categorical_accuracy: 0.0373\n",
      "Epoch 93/5000\n",
      "19/19 [==============================] - 5s 249ms/step - loss: 3.0435 - categorical_accuracy: 0.1761 - val_loss: 3.7476 - val_categorical_accuracy: 0.0299\n",
      "Epoch 94/5000\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 3.0724 - categorical_accuracy: 0.1820"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Lion(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.00005\u001b[39m,global_clipnorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential(name='Sequential')\n",
    "\n",
    "act_function = 'selu'\n",
    "model.add(GRU(64, return_sequences=False, activation=act_function, dropout=.5,kernel_initializer='he_uniform',input_shape=(130,1662)))\n",
    "#model.add(GRU(128, return_sequences=True, activation=act_function))\n",
    "#model.add(LSTM(64, return_sequences=False, activation=act_function))\n",
    "model.add(Dense(32, activation=act_function))\n",
    "#model.add(Dense(64, activation=act_function))\n",
    "model.add(Dense(16, activation=act_function))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "optimizer = Lion(learning_rate=.005,global_clipnorm=10)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, epochs=5000, validation_split=.4, batch_size = 64, callbacks=[tb_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9f29569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T18:26:53.506688Z",
     "start_time": "2023-08-08T18:25:08.408775Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 19:25:08.494048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1739 MB memory:  -> device: 0, name: NVIDIA GeForce MX250, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 19:25:09.673381: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 808928640 exceeds 10% of free system memory.\n",
      "2023-08-08 19:25:10.394759: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 808928640 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 19:25:13.937670: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f402c03b3b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-08 19:25:13.937718: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce MX250, Compute Capability 6.1\n",
      "2023-08-08 19:25:13.943961: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-08 19:25:13.959021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-08-08 19:25:14.021873: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 10s 456ms/step - loss: 3.9890 - categorical_accuracy: 0.0224 - val_loss: 4.0937 - val_categorical_accuracy: 0.0025\n",
      "Epoch 2/1000\n",
      "15/15 [==============================] - 6s 382ms/step - loss: 3.9361 - categorical_accuracy: 0.0310 - val_loss: 4.1797 - val_categorical_accuracy: 0.0124\n",
      "Epoch 3/1000\n",
      "15/15 [==============================] - 6s 398ms/step - loss: 3.9642 - categorical_accuracy: 0.0331 - val_loss: 4.0007 - val_categorical_accuracy: 0.0075\n",
      "Epoch 4/1000\n",
      "15/15 [==============================] - 6s 414ms/step - loss: 3.9640 - categorical_accuracy: 0.0182 - val_loss: 4.0517 - val_categorical_accuracy: 0.0100\n",
      "Epoch 5/1000\n",
      "15/15 [==============================] - 6s 410ms/step - loss: 3.9601 - categorical_accuracy: 0.0267 - val_loss: 4.1521 - val_categorical_accuracy: 0.0274\n",
      "Epoch 6/1000\n",
      "15/15 [==============================] - 6s 418ms/step - loss: 3.9760 - categorical_accuracy: 0.0278 - val_loss: 4.3156 - val_categorical_accuracy: 0.0274\n",
      "Epoch 7/1000\n",
      "15/15 [==============================] - 6s 416ms/step - loss: 3.9817 - categorical_accuracy: 0.0321 - val_loss: 4.1318 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "15/15 [==============================] - 6s 419ms/step - loss: 3.9300 - categorical_accuracy: 0.0267 - val_loss: 4.3375 - val_categorical_accuracy: 0.0249\n",
      "Epoch 9/1000\n",
      "15/15 [==============================] - 6s 433ms/step - loss: 4.0013 - categorical_accuracy: 0.0214 - val_loss: 4.2034 - val_categorical_accuracy: 0.0348\n",
      "Epoch 10/1000\n",
      "15/15 [==============================] - 6s 433ms/step - loss: 3.9682 - categorical_accuracy: 0.0235 - val_loss: 4.2177 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "15/15 [==============================] - 6s 431ms/step - loss: 3.9657 - categorical_accuracy: 0.0267 - val_loss: 4.2617 - val_categorical_accuracy: 0.0025\n",
      "Epoch 12/1000\n",
      "15/15 [==============================] - 6s 430ms/step - loss: 4.1451 - categorical_accuracy: 0.0321 - val_loss: 4.3738 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "15/15 [==============================] - 7s 446ms/step - loss: 3.9314 - categorical_accuracy: 0.0385 - val_loss: nan - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "15/15 [==============================] - 7s 436ms/step - loss: nan - categorical_accuracy: 0.0310 - val_loss: nan - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "15/15 [==============================] - 7s 464ms/step - loss: nan - categorical_accuracy: 0.0310 - val_loss: nan - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      " 3/15 [=====>........................] - ETA: 5s - loss: nan - categorical_accuracy: 0.0365"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Lion(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.005\u001b[39m)\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential(name='Sequential') \n",
    "\n",
    "act_function = 'LeakyReLU'\n",
    "initializer = 'lecun_uniform'\n",
    "model.add(GRU(32, return_sequences=True, kernel_initializer=initializer, activation=act_function, dropout=0,input_shape=(130,1662)))\n",
    "model.add(GRU(8, return_sequences=False, activation=act_function))\n",
    "#model.add(LSTM(64, return_sequences=False, activation=act_function))\n",
    "model.add(Dense(32, activation=act_function, kernel_initializer=initializer))\n",
    "model.add(Dense(32, activation=act_function, kernel_initializer=initializer))\n",
    "model.add(Dense(16, activation=act_function, kernel_initializer=initializer))\n",
    "#model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "optimizer = Lion(learning_rate=.005)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, epochs=1000, validation_split=.3, batch_size = 64, callbacks=[tb_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8df18665",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T17:06:41.794473Z",
     "start_time": "2023-08-08T17:06:41.777177Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initializer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minitializer\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'initializer' is not defined"
     ]
    }
   ],
   "source": [
    "initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30e0c4e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T16:43:40.044523Z",
     "start_time": "2023-08-08T16:36:17.221137Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 10:10:09.127784: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 924736800 exceeds 10% of free system memory.\n",
      "2023-08-08 10:10:09.961623: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 924736800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "34/34 [==============================] - 9s 207ms/step - loss: 3.9179 - categorical_accuracy: 0.0224 - val_loss: 4.3422 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 3.8832 - categorical_accuracy: 0.0234 - val_loss: 5.0312 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "34/34 [==============================] - 7s 192ms/step - loss: 3.8310 - categorical_accuracy: 0.0215 - val_loss: 5.5114 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 3.8174 - categorical_accuracy: 0.0271 - val_loss: 5.8857 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "34/34 [==============================] - 7s 210ms/step - loss: 3.7950 - categorical_accuracy: 0.0336 - val_loss: 5.7742 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "34/34 [==============================] - 7s 212ms/step - loss: 3.7763 - categorical_accuracy: 0.0262 - val_loss: 6.2825 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "34/34 [==============================] - 7s 208ms/step - loss: 3.7677 - categorical_accuracy: 0.0393 - val_loss: 6.2689 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "34/34 [==============================] - 7s 214ms/step - loss: 3.7600 - categorical_accuracy: 0.0318 - val_loss: 6.8157 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "34/34 [==============================] - 7s 213ms/step - loss: 3.7398 - categorical_accuracy: 0.0336 - val_loss: 6.5783 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      " 2/34 [>.............................] - ETA: 6s - loss: 3.6622 - categorical_accuracy: 0.0156    "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Lion(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.00025\u001b[39m)\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential(name='Sequential')\n",
    "\n",
    "act_function = 'LeakyReLU'\n",
    "model.add(GRU(128, return_sequences=False, activation=act_function, input_shape=(130,1662)))\n",
    "#model.add(GRU(128, return_sequences=True, activation=act_function))\n",
    "#model.add(LSTM(64, return_sequences=False, activation=act_function))\n",
    "model.add(Dense(128, activation=act_function, input_shape=(130,1662)))\n",
    "model.add(Dense(128, activation=act_function))\n",
    "model.add(Dense(64, activation=act_function))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "optimizer = Lion(learning_rate=.00025)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, epochs=1000, validation_split=.2, batch_size = 32, callbacks=[tb_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cbab687d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T10:30:29.377211Z",
     "start_time": "2023-08-09T10:29:27.097297Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_17 (Conv1D)          (None, 59, 16)            53200     \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPooli  (None, 29, 16)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 29, 16)            0         \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 28, 100)           3300      \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPooli  (None, 14, 100)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 14, 100)           0         \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 12, 128)           38528     \n",
      "                                                                 \n",
      " max_pooling1d_19 (MaxPooli  (None, 6, 128)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 768)               0         \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 768)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 59)                45371     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140399 (548.43 KB)\n",
      "Trainable params: 140399 (548.43 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 5.9579 - categorical_accuracy: 0.0095 - val_loss: 4.1926 - val_categorical_accuracy: 0.0217\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 4.9529 - categorical_accuracy: 0.0190 - val_loss: 4.2427 - val_categorical_accuracy: 0.0380\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 4.4660 - categorical_accuracy: 0.0217 - val_loss: 4.2751 - val_categorical_accuracy: 0.0054\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 4.4371 - categorical_accuracy: 0.0149 - val_loss: 4.3254 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 4.4974 - categorical_accuracy: 0.0149 - val_loss: 4.3952 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 4.5563 - categorical_accuracy: 0.0204 - val_loss: 4.4295 - val_categorical_accuracy: 0.0109\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 4.5876 - categorical_accuracy: 0.0136 - val_loss: 4.4875 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 4.5561 - categorical_accuracy: 0.0204 - val_loss: 4.5582 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 4.5156 - categorical_accuracy: 0.0272 - val_loss: 4.5394 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 4.5858 - categorical_accuracy: 0.0177 - val_loss: 4.5417 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 4.4622 - categorical_accuracy: 0.0340 - val_loss: 4.5939 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 4.4444 - categorical_accuracy: 0.0326 - val_loss: 4.6336 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 4.4587 - categorical_accuracy: 0.0245 - val_loss: 4.6322 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 4.4195 - categorical_accuracy: 0.0204 - val_loss: 4.6719 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 4.4175 - categorical_accuracy: 0.0245 - val_loss: 4.6186 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 4.3634 - categorical_accuracy: 0.0258 - val_loss: 4.6275 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 4.3610 - categorical_accuracy: 0.0122 - val_loss: 4.6034 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 4.2916 - categorical_accuracy: 0.0231 - val_loss: 4.5963 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 4.2639 - categorical_accuracy: 0.0204 - val_loss: 4.5962 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 4.2927 - categorical_accuracy: 0.0204 - val_loss: 4.5257 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 4.2616 - categorical_accuracy: 0.0285 - val_loss: 4.4528 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 4.1957 - categorical_accuracy: 0.0272 - val_loss: 4.4733 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 4.2367 - categorical_accuracy: 0.0190 - val_loss: 4.6150 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 4.2071 - categorical_accuracy: 0.0217 - val_loss: 4.5153 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 4.2176 - categorical_accuracy: 0.0136 - val_loss: 4.4580 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 4.1198 - categorical_accuracy: 0.0353 - val_loss: 4.4936 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 4.1760 - categorical_accuracy: 0.0190 - val_loss: 4.4165 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 4.1669 - categorical_accuracy: 0.0231 - val_loss: 4.4818 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 4.1766 - categorical_accuracy: 0.0272 - val_loss: 4.4313 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 4.1181 - categorical_accuracy: 0.0245 - val_loss: 4.5012 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 4.1682 - categorical_accuracy: 0.0217 - val_loss: 4.4519 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 4.1020 - categorical_accuracy: 0.0217 - val_loss: 4.4524 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 4.1361 - categorical_accuracy: 0.0258 - val_loss: 4.4873 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 4.1223 - categorical_accuracy: 0.0326 - val_loss: 4.5395 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 4.1125 - categorical_accuracy: 0.0312 - val_loss: 4.4299 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 4.1082 - categorical_accuracy: 0.0149 - val_loss: 4.4015 - val_categorical_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 4.1005 - categorical_accuracy: 0.0258 - val_loss: 4.3966 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 4.0964 - categorical_accuracy: 0.0163 - val_loss: 4.5598 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 4.1334 - categorical_accuracy: 0.0299 - val_loss: 4.4114 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 4.1018 - categorical_accuracy: 0.0285 - val_loss: 4.5172 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 4.0980 - categorical_accuracy: 0.0272 - val_loss: 4.5305 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 4.0656 - categorical_accuracy: 0.0353 - val_loss: 4.4715 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 4.0793 - categorical_accuracy: 0.0326 - val_loss: 4.4884 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 4.0997 - categorical_accuracy: 0.0326 - val_loss: 4.5625 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 4.0869 - categorical_accuracy: 0.0190 - val_loss: 4.6086 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 4.0709 - categorical_accuracy: 0.0190 - val_loss: 4.5883 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 4.0712 - categorical_accuracy: 0.0258 - val_loss: 4.5156 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 4.0825 - categorical_accuracy: 0.0245 - val_loss: 4.5075 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 4.0894 - categorical_accuracy: 0.0217 - val_loss: 4.5634 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 4.0821 - categorical_accuracy: 0.0272 - val_loss: 4.5878 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 4.0656 - categorical_accuracy: 0.0272 - val_loss: 4.5704 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 4.0857 - categorical_accuracy: 0.0204 - val_loss: 4.5619 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 4.0537 - categorical_accuracy: 0.0299 - val_loss: 4.5818 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 4.0613 - categorical_accuracy: 0.0204 - val_loss: 4.6701 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 4.0901 - categorical_accuracy: 0.0190 - val_loss: 4.6202 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 4.0572 - categorical_accuracy: 0.0312 - val_loss: 4.6002 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 4.0471 - categorical_accuracy: 0.0272 - val_loss: 4.6620 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 4.0387 - categorical_accuracy: 0.0299 - val_loss: 4.6154 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 4.0588 - categorical_accuracy: 0.0272 - val_loss: 4.6411 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 4.0568 - categorical_accuracy: 0.0258 - val_loss: 4.6849 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 4.0273 - categorical_accuracy: 0.0340 - val_loss: 4.6728 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 4.0187 - categorical_accuracy: 0.0258 - val_loss: 4.6471 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 4.0641 - categorical_accuracy: 0.0245 - val_loss: 4.5799 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 4.0518 - categorical_accuracy: 0.0204 - val_loss: 4.8954 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 4.0178 - categorical_accuracy: 0.0353 - val_loss: 4.9808 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 4.0250 - categorical_accuracy: 0.0190 - val_loss: 4.8933 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 4.0290 - categorical_accuracy: 0.0326 - val_loss: 4.7689 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 4.0074 - categorical_accuracy: 0.0231 - val_loss: 4.8894 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 3.9949 - categorical_accuracy: 0.0231 - val_loss: 4.9566 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 4.0415 - categorical_accuracy: 0.0285 - val_loss: 4.6350 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 3.9931 - categorical_accuracy: 0.0367 - val_loss: 4.7442 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 3.9957 - categorical_accuracy: 0.0340 - val_loss: 4.8194 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 4.0187 - categorical_accuracy: 0.0326 - val_loss: 4.9560 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 4.0264 - categorical_accuracy: 0.0299 - val_loss: 4.9939 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 3.9765 - categorical_accuracy: 0.0312 - val_loss: 5.3476 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 3.9855 - categorical_accuracy: 0.0285 - val_loss: 5.3146 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 4.0355 - categorical_accuracy: 0.0258 - val_loss: 5.1200 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 3.9840 - categorical_accuracy: 0.0367 - val_loss: 5.3457 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 3.9791 - categorical_accuracy: 0.0340 - val_loss: 5.0934 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 3.9769 - categorical_accuracy: 0.0367 - val_loss: 5.2449 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 3.9754 - categorical_accuracy: 0.0448 - val_loss: 5.2177 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 3.9520 - categorical_accuracy: 0.0476 - val_loss: 5.5591 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 3.9623 - categorical_accuracy: 0.0448 - val_loss: 5.7134 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 3.9665 - categorical_accuracy: 0.0476 - val_loss: 5.6963 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 3.9391 - categorical_accuracy: 0.0435 - val_loss: 5.7611 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 3.9034 - categorical_accuracy: 0.0476 - val_loss: 5.7206 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 3.9245 - categorical_accuracy: 0.0435 - val_loss: 5.6415 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 3.9395 - categorical_accuracy: 0.0394 - val_loss: 5.6779 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 3.8890 - categorical_accuracy: 0.0516 - val_loss: 5.8657 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 3.9230 - categorical_accuracy: 0.0557 - val_loss: 5.5547 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 3.9013 - categorical_accuracy: 0.0462 - val_loss: 5.5604 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 3.9010 - categorical_accuracy: 0.0489 - val_loss: 6.1210 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 3.8845 - categorical_accuracy: 0.0489 - val_loss: 5.5002 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 3.8954 - categorical_accuracy: 0.0584 - val_loss: 5.6156 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 3.8938 - categorical_accuracy: 0.0503 - val_loss: 5.9453 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 3.8904 - categorical_accuracy: 0.0571 - val_loss: 5.8242 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 3.8640 - categorical_accuracy: 0.0598 - val_loss: 5.7942 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 3.8828 - categorical_accuracy: 0.0394 - val_loss: 6.1397 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 3.8443 - categorical_accuracy: 0.0543 - val_loss: 6.3462 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 3.8517 - categorical_accuracy: 0.0598 - val_loss: 6.2280 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 3.8539 - categorical_accuracy: 0.0625 - val_loss: 5.9663 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 3.8740 - categorical_accuracy: 0.0298"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1791\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1777\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1778\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1789\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1790\u001b[0m     )\n\u001b[0;32m-> 1791\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1800\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1802\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1804\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1806\u001b[0m }\n\u001b[1;32m   1807\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:2189\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_counter\u001b[38;5;241m.\u001b[39massign(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2188\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_test_begin()\n\u001b[0;32m-> 2189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[1;32m   2190\u001b[0m     _,\n\u001b[1;32m   2191\u001b[0m     dataset_or_iterator,\n\u001b[1;32m   2192\u001b[0m ) \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[1;32m   2193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[1;32m   2194\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1331\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[0;32m-> 1331\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[1;32m   1333\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:506\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:710\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    706\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 710\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    746\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    747\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[1;32m    748\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[0;32m--> 749\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3420\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3419\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3420\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3421\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3423\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, SpatialDropout1D\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential(name='Sequential')\n",
    "act_function = 'selu'\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv1D(filters=16, kernel_size=2, activation=act_function, input_shape=(60, 1662)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Conv1D(filters=100, kernel_size=2, activation=act_function))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu', kernel_regularizer=regularizers.l2(l=0.001)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# droput layer, remove if no work\n",
    "#model.add(SpatialDropout1D(0.5))\n",
    "\n",
    "# Flatten the output for the fully connected layers\n",
    "model.add(Flatten())\n",
    "# Add fully connected layers\n",
    "#model.add(Dense(16, activation=act_function))\n",
    "#model.add(Dense(16, activation=act_function))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(59, activation='softmax'))  # Output layer\n",
    "optimizer = Lion(learning_rate=.00005)\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(Xtrain, Ytrain, epochs=1000, validation_split=.2, batch_size = 96, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add094ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "401.844px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
